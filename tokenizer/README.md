# Tokenizer as implemented by [google-research/cubert](https://github.com/google-research/google-research/tree/master/cubert)