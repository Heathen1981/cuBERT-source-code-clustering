{"label_name":"train","label":0,"method_name":"no_op_train_fn","method":"\n\ndef no_op_train_fn(loss):\n    del loss\n    return control_flow_ops.no_op()\n"}
{"label_name":"forward","label":3,"method_name":"conv_forward","method":"\n\ndef conv_forward(x, weights, conv_params):\n    \"\\n        The input consists of N data points, each with C channels, height H and\\n    width W. We convolve each input with F different filters, where each filter\\n    spans all C channels and has height HH and width HH.\\n\\n    Input:\\n    - x: Input data of shape (N, C, H, W)\\n    - w: Filter weights of shape (F, C, HH, WW)\\n    - b: Biases, of shape (F,)\\n    - conv_param: A dictionary with the following keys:\\n      - 'stride': The number of pixels between adjacent receptive fields in the\\n        horizontal and vertical directions.\\n      - 'pad': The number of pixels that will be used to zero-pad the input.\\n\\n    Returns a tuple of:\\n    - out: Output data, of shape (N, F, H', W') where H' and W' are given by\\n      H' = 1 + (H + 2 * pad - HH) \/ stride\\n      W' = 1 + (W + 2 * pad - WW) \/ stride\\n    - cache: (x, w, b, conv_param)\\n    \"\n    out = None\n    (w, b) = weights\n    (N, C, H, W) = x.shape\n    (F, _, HH, WW) = w.shape\n    (stride, pad) = (conv_params['stride'], conv_params['pad'])\n    H_out = int((1 + (((H + (2 * pad)) - HH) \/ stride)))\n    W_out = int((1 + (((W + (2 * pad)) - WW) \/ stride)))\n    out = np.zeros((N, F, H_out, W_out))\n    x_pad = np.pad(x, ((0,), (0,), (pad,), (pad,)), mode='constant', constant_values=0)\n    for i in range(H_out):\n        for j in range(W_out):\n            x_pad_masked = x_pad[:, :, (i * stride):((i * stride) + HH), (j * stride):((j * stride) + WW)]\n            for k in range(F):\n                out[:, k, i, j] = np.sum((x_pad_masked * w[k, :, :, :]), axis=(1, 2, 3))\n    out = (out + b[None, :, None, None])\n    return out\n"}
{"label_name":"train","label":0,"method_name":"train_evaluate_cv","method":"\n\n@main.command()\n@click.option('-p', '--pipeline_name', help='pipeline to be trained', required=True)\n@click.option('-l', '--model_level', help='level of modeling first or second are available', default='first', required=True)\n@click.option('-d', '--dev_mode', help='if true only a small sample of data will be used', is_flag=True, required=False)\ndef train_evaluate_cv(pipeline_name, model_level, dev_mode):\n    pipeline_manager.train_evaluate_cv(pipeline_name, model_level, dev_mode)\n"}
{"label_name":"process","label":2,"method_name":"process_data","method":"\n\ndef process_data():\n    print('Preparing data to be model-ready ...')\n    build_vocab('train.enc')\n    build_vocab('train.dec')\n    token2id('train', 'enc')\n    token2id('train', 'dec')\n    token2id('test', 'enc')\n    token2id('test', 'dec')\n"}
{"label_name":"train","label":0,"method_name":"create_training_data","method":"\n\ndef create_training_data(grid_x, grid_y):\n    data_x = []\n    data_y = []\n    tr_count = 0\n    for i in index70:\n        for j in range(10):\n            x = []\n            for k in range(1, 25):\n                b = rain_models[i, j, k, (grid_y - 1):(grid_y + 2), (grid_x - 1):(grid_x + 2)]\n                rain100 = np.array(b)\n                x.append(list(it.chain.from_iterable(rain100)))\n            bt = rain_models[(i, j, 0, grid_y, grid_x)]\n            rainR = bt\n            data_y.append(rainR)\n            data_x.append(list(it.chain.from_iterable(x)))\n    return (data_x, data_y)\n"}
{"label_name":"train","label":0,"method_name":"_retrieve_rowid_constraints","method":"\n\ndef _retrieve_rowid_constraints(bdb, population_id, constraints):\n    rowid = core.bayesdb_population_fresh_row_id(bdb, population_id)\n    if constraints:\n        user_rowid = [v for (c, v) in constraints if (c in core.bayesdb_rowid_tokens(bdb))]\n        if (len(user_rowid) == 1):\n            rowid = user_rowid[0]\n        elif (len(user_rowid) > 1):\n            raise BQLError(bdb, ('Multiple rowids given: %s.' % (constraints,)))\n        constraints = [(c, v) for (c, v) in constraints if (c not in core.bayesdb_rowid_tokens(bdb))]\n    return (rowid, constraints)\n"}
{"label_name":"train","label":0,"method_name":"basic_train","method":"\n\ndef basic_train(loss_op, update_op, profile=0, save_dir='asset\/unamed', **kwargs):\n    profile_state = _ShouldProfile(profile)\n\n    @stf.sg_train_func\n    def train_func(sess, arg):\n        profile_state.increment()\n        if profile_state.should_profile():\n            options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n            run_metadata = tf.RunMetadata()\n        else:\n            options = None\n            run_metadata = None\n        loss = sess.run(([loss_op] + update_op), options=options, run_metadata=run_metadata)[0]\n        if profile_state.should_profile():\n            tl = tf_timeline.Timeline(run_metadata.step_stats)\n            ctf = tl.generate_chrome_trace_format()\n            with open(path.join(save_dir, 'timeline.json'), 'w') as fd:\n                print(ctf, file=fd)\n        return loss\n    train_func(save_dir=save_dir, **kwargs)\n"}
{"label_name":"save","label":1,"method_name":"save_smi","method":"\n\ndef save_smi(name, smiles):\n    if (not os.path.exists('epoch_data')):\n        os.makedirs('epoch_data')\n    smi_file = os.path.join('epoch_data', '{}.smi'.format(name))\n    with open(smi_file, 'w') as afile:\n        afile.write('\\n'.join(smiles))\n    return\n"}
{"label_name":"train","label":0,"method_name":"train_step","method":"\n\n@tf.function\ndef train_step(model, x, y):\n    with tf.GradientTape() as tape:\n        y_pred = model(x)\n        loss = cross_entropy_loss(y_pred, y)\n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train(model, generated_image, initial_image):\n    \" Train your model.\\n    Don't forget to create folders for checkpoints and outputs.\\n    \"\n    skip_step = 1\n    with tf.Session() as sess:\n        saver = tf.train.Saver()\n        saver = tf.train.Saver()\n        sess.run(tf.global_variables_initializer())\n        writer = tf.summary.FileWriter('graphs', sess.graph)\n        sess.run(generated_image.assign(initial_image))\n        ckpt = tf.train.get_checkpoint_state(os.path.dirname('checkpoints\/checkpoint'))\n        if (ckpt and ckpt.model_checkpoint_path):\n            saver.restore(sess, ckpt.model_checkpoint_path)\n        initial_step = model['global_step'].eval()\n        start_time = time.time()\n        for index in range(initial_step, ITERS):\n            if ((index >= 5) and (index < 20)):\n                skip_step = 10\n            elif (index >= 20):\n                skip_step = 20\n            sess.run(model['optimizer'])\n            if (((index + 1) % skip_step) == 0):\n                (gen_image, total_loss, summary) = sess.run([generated_image, model['total_loss'], model['summary_op']])\n                gen_image = (gen_image + MEAN_PIXELS)\n                writer.add_summary(summary, global_step=index)\n                print('Step {}\\n   Sum: {:5.1f}'.format((index + 1), np.sum(gen_image)))\n                print('   Loss: {:5.1f}'.format(total_loss))\n                print('   Time: {}'.format((time.time() - start_time)))\n                start_time = time.time()\n                filename = ('outputs\/%d.png' % index)\n                utils.save_image(filename, gen_image)\n                if (((index + 1) % 20) == 0):\n                    saver.save(sess, 'checkpoints\/style_transfer', index)\n"}
{"label_name":"predict","label":4,"method_name":"append_concat_predictions","method":"\n\ndef append_concat_predictions(y_batch, predictions):\n    '\\n\\n    Args:\\n        y_batch (torch.Tensor or list):\\n        predictions (list): accumulation list where all the batched predictions are added\\n\\n    Returns:\\n        list: predictions list with the new tensor appended\\n    '\n    if isinstance(y_batch, list):\n        predictions += y_batch\n    else:\n        predictions.append(y_batch)\n    return predictions\n"}
{"label_name":"process","label":2,"method_name":"init_processors","method":"\n\ndef init_processors(caption_config: Dict, butd_config: Dict):\n    'Build the caption and text processors.\\n\\n    '\n    captioning_config = butd_config.task_attributes.captioning.dataset_attributes.coco\n    text_processor_config = captioning_config.processors.text_processor\n    caption_processor_config = captioning_config.processors.caption_processor\n    vocab_file_path = caption_config['text_caption_processor_vocab_txt']\n    text_processor_config.params.vocab.vocab_file = vocab_file_path\n    caption_processor_config.params.vocab.vocab_file = vocab_file_path\n    text_processor = VocabProcessor(text_processor_config.params)\n    caption_processor = CaptionProcessor(caption_processor_config.params)\n    registry.register('coco_text_processor', text_processor)\n    registry.register('coco_caption_processor', caption_processor)\n    return (caption_processor, text_processor)\n"}
{"label_name":"process","label":2,"method_name":"process_output","method":"\n\ndef process_output(output, i, detect_thresh=0.25):\n    (clas_pred, bbox_pred, sizes) = (output[0][i], output[1][i], output[2])\n    anchors = create_anchors(sizes, ratios, scales).to(clas_pred.device)\n    bbox_pred = activ_to_bbox(bbox_pred, anchors)\n    clas_pred = torch.sigmoid(clas_pred)\n    detect_mask = (clas_pred.max(1)[0] > detect_thresh)\n    (bbox_pred, clas_pred) = (bbox_pred[detect_mask], clas_pred[detect_mask])\n    bbox_pred = tlbr2cthw(torch.clamp(cthw2tlbr(bbox_pred), min=(- 1), max=1))\n    (scores, preds) = clas_pred.max(1)\n    return (bbox_pred, scores, preds)\n"}
{"label_name":"process","label":2,"method_name":"preprocess","method":"\n\ndef preprocess(img):\n    img = scipy.misc.imresize(img, [im_size, im_size])\n    img = ((img.astype(np.float32) \/ 127.5) - 1.0)\n    return img\n"}
{"label_name":"predict","label":4,"method_name":"predict_classification","method":"\n\ndef predict_classification(x_test, trained_estimator):\n    '\\n    Given feature data and a trained estimator, return a classification prediction\\n\\n    Args:\\n        x_test: \\n        trained_estimator (sklearn.base.BaseEstimator): a trained scikit-learn estimator\\n\\n    Returns:\\n        a prediction\\n    '\n    validate_estimator(trained_estimator)\n    prediction = np.squeeze(trained_estimator.predict_proba(x_test)[:, 1])\n    return prediction\n"}
{"label_name":"predict","label":4,"method_name":"saving_predict","method":"\n\ndef saving_predict(model, X, index, cache_dir=''):\n    csv_file = get_cache_file(model.id, index, cache_dir)\n    try:\n        df = pd.read_csv(csv_file)\n        prediction = df.values[:, 1:]\n        prediction = prediction.reshape([prediction.size])\n        print('**** prediction is loaded from {0} ****'.format(csv_file))\n    except IOError:\n        prediction = model.predict(X)\n        df = pd.DataFrame({'index': index})\n        prediction.reshape([prediction.shape[(- 1)]])\n        df['prediction'] = prediction\n        df.to_csv(csv_file, index=False)\n    return prediction\n"}
{"label_name":"save","label":1,"method_name":"savefig","method":"\n\ndef savefig(writekey, dpi=None, ext=None):\n    \"Save current figure to file.\\n\\n    The `filename` is generated as follows:\\n\\n        filename = settings.figdir \/ (writekey + settings.plot_suffix + '.' + settings.file_format_figs)\\n    \"\n    if (dpi is None):\n        if ((not isinstance(rcParams['savefig.dpi'], str)) and (rcParams['savefig.dpi'] < 150)):\n            if settings._low_resolution_warning:\n                logg.warning(\"You are using a low resolution (dpi<150) for saving figures.\\nConsider running `set_figure_params(dpi_save=...)`, which will adjust `matplotlib.rcParams['savefig.dpi']`\")\n                settings._low_resolution_warning = False\n        else:\n            dpi = rcParams['savefig.dpi']\n    settings.figdir.mkdir(parents=True, exist_ok=True)\n    if (ext is None):\n        ext = settings.file_format_figs\n    filename = (settings.figdir \/ f'{writekey}{settings.plot_suffix}.{ext}')\n    logg.warning(f'saving figure to file {filename}')\n    pl.savefig(filename, dpi=dpi, bbox_inches='tight')\n"}
{"label_name":"predict","label":4,"method_name":"model_predict","method":"\n\ndef model_predict(X, pipeline):\n    if (model_type == 'mlp'):\n        json_file = open((projectfolder + '\/model.json'), 'r')\n        loaded_model_json = json_file.read()\n        json_file.close()\n        model = model_from_json(loaded_model_json)\n        model.load_weights((projectfolder + '\/weights.hdf5'))\n        model.compile(loss=pipeline['options']['loss'], optimizer=pipeline['options']['optimizer'], metrics=pipeline['options']['scoring'])\n        if (type(X) is pandas.DataFrame):\n            X = X.values\n        Y = model.predict(X)\n    else:\n        picklefile = (projectfolder + '\/model.out')\n        with open(picklefile, 'rb') as f:\n            model = pickle.load(f)\n        Y = model.predict(X)\n    return Y\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\n@deprecated(since='2.0.0', update_to='paddle.text.datasets.WMT16', reason='Please use new dataset API which supports paddle.io.DataLoader')\ndef train(src_dict_size, trg_dict_size, src_lang='en'):\n    '\\n    WMT16 train set reader.\\n\\n    This function returns the reader for train data. Each sample the reader\\n    returns is made up of three fields: the source language word index sequence,\\n    target language word index sequence and next word index sequence.\\n\\n\\n    NOTE:\\n    The original like for training data is:\\n    http:\/\/www.quest.dcs.shef.ac.uk\/wmt16_files_mmt\/training.tar.gz\\n\\n    paddle.dataset.wmt16 provides a tokenized version of the original dataset by\\n    using moses\\'s tokenization script:\\n    https:\/\/github.com\/moses-smt\/mosesdecoder\/blob\/master\/scripts\/tokenizer\/tokenizer.perl\\n\\n    Args:\\n        src_dict_size(int): Size of the source language dictionary. Three\\n                            special tokens will be added into the dictionary:\\n                            <s> for start mark, <e> for end mark, and <unk> for\\n                            unknown word.\\n        trg_dict_size(int): Size of the target language dictionary. Three\\n                            special tokens will be added into the dictionary:\\n                            <s> for start mark, <e> for end mark, and <unk> for\\n                            unknown word.\\n        src_lang(string): A string indicating which language is the source\\n                          language. Available options are: \"en\" for English\\n                          and \"de\" for Germany.\\n\\n    Returns:\\n        callable: The train reader.\\n    '\n    if (src_lang not in ['en', 'de']):\n        raise ValueError('An error language type.  Only support: en (for English); de(for Germany).')\n    (src_dict_size, trg_dict_size) = __get_dict_size(src_dict_size, trg_dict_size, src_lang)\n    return reader_creator(tar_file=paddle.dataset.common.download(DATA_URL, 'wmt16', DATA_MD5, 'wmt16.tar.gz'), file_name='wmt16\/train', src_dict_size=src_dict_size, trg_dict_size=trg_dict_size, src_lang=src_lang)\n"}
{"label_name":"train","label":0,"method_name":"training_loop","method":"\n\ndef training_loop(closure: Callable[([], tf.Tensor)], optimizer: Optional[tf.optimizers.Optimizer]=None, var_list: List[tf.Variable]=None, maxiter=1000.0, compile=False):\n    '\\n    Simple generic training loop. At each iteration uses a GradientTape to compute\\n    the gradients of a loss function with respect to a set of variables.\\n\\n    :param closure: Callable that constructs a loss function based on data and model being trained\\n    :param optimizer: tf.optimizers or tf.keras.optimizers that updates variables by applying the\\n        corresponding loss gradients. Adam is a default optimizer with default settings.\\n    :param var_list: List of model variables to be learnt during training\\n    :param maxiter: Maximum number of\\n    :return:\\n    '\n    optimizer = (tf.optimizers.Adam() if (optimizer is None) else optimizer)\n\n    def optimization_step():\n        with tf.GradientTape(watch_accessed_variables=False) as tape:\n            tape.watch(var_list)\n            loss = closure()\n        grads = tape.gradient(loss, var_list)\n        optimizer.apply_gradients(zip(grads, var_list))\n    if compile:\n        optimization_step = tf.function(optimization_step)\n    for _ in range(int(maxiter)):\n        optimization_step()\n"}
{"label_name":"process","label":2,"method_name":"process_log_line","method":"\n\ndef process_log_line(x):\n    'Process a single line of the log'\n    obj = x['object']\n    date = datetime.strptime(x['date'][:(- 6)], '%a %b %d %Y %H:%M:%S %Z%z')\n    relative_position = (obj['time_elapsed'] \/ obj['time_remaining'])\n    return ([date, obj['guess'], obj['qid'], obj['time_elapsed'], obj['time_remaining'], relative_position, obj['ruling'], obj['user']['id']], obj['qid'], obj['question_text'])\n"}
{"label_name":"train","label":0,"method_name":"simple_training_loop","method":"\n\ndef simple_training_loop(model: gpflow.models.SVGP, epochs: int=1, logging_epoch_freq: int=10):\n    tf_optimization_step = tf.function(optimization_step)\n    batches = iter(train_dataset)\n    for epoch in range(epochs):\n        for _ in range(ci_niter(num_batches_per_epoch)):\n            tf_optimization_step(model, next(batches))\n        epoch_id = (epoch + 1)\n        if ((epoch_id % logging_epoch_freq) == 0):\n            tf.print(f'Epoch {epoch_id}: ELBO (train) {model.elbo(data)}')\n"}
{"label_name":"train","label":0,"method_name":"execute_train_scripts","method":"\n\ndef execute_train_scripts(pop, gen):\n    str = ''\n    for thread in range(_NUM_THREADS):\n        str += (script_filename(gen, thread) + ' & ')\n    os.system(str)\n"}
{"label_name":"train","label":0,"method_name":"load_train","method":"\n\ndef load_train(train_path):\n    images = []\n    classes = []\n    path = train_path\n    file_names = os.listdir(os.path.join(os.getcwd(), train_path))\n    counter = 1\n    print('Creating Classes, reading images and breaking things ...\\n')\n    for file in file_names:\n        drawProgressBar((counter \/ len(file_names)))\n        classes.append(file.split('_')[0])\n        image = cv2.imread(os.path.join(os.getcwd(), train_path, file))\n        image = image.astype(np.float32)\n        image = np.multiply(image, (1.0 \/ 255.0))\n        images.append(image)\n        counter += 1\n    print('\\nDone!')\n    images = np.array(images)\n    for i in range(len(classes)):\n        if (classes[i] not in imp_labels):\n            classes[i] = 'unkown'\n    d = {ni: indi for (indi, ni) in enumerate(set(classes))}\n    classes = [d[ni] for ni in classes]\n    classes = np.array(classes)\n    n_values = (np.max(classes) + 1)\n    classes = np.eye(n_values)[classes]\n    print('\\nDone!')\n    print('\\n images shape: {}, labels shape: {}'.format(images.shape, classes.shape))\n    return (images, classes)\n"}
{"label_name":"train","label":0,"method_name":"train_breast_cancer","method":"\n\ndef train_breast_cancer(config: dict):\n    (data, labels) = sklearn.datasets.load_breast_cancer(return_X_y=True)\n    (train_x, test_x, train_y, test_y) = train_test_split(data, labels, test_size=0.25)\n    train_set = xgb.DMatrix(train_x, label=train_y)\n    test_set = xgb.DMatrix(test_x, label=test_y)\n    xgb.train(config, train_set, evals=[(test_set, 'eval')], verbose_eval=False, callbacks=[TuneReportCheckpointCallback(filename='model.xgb')])\n"}
{"label_name":"train","label":0,"method_name":"decorated_train_function","method":"\n\n@wandb_mixin\ndef decorated_train_function(config, checkpoint_dir=None):\n    for i in range(30):\n        loss = (config['mean'] + (config['sd'] * np.random.randn()))\n        tune.report(loss=loss)\n        wandb.log(dict(loss=loss))\n"}
{"label_name":"forward","label":3,"method_name":"forward","method":"\n\ndef forward(X):\n    Z = (X.dot(W) + b)\n    Z = (Z * (Z > 0))\n    Yhat = (Z.dot(V) + c)\n    return (Z, Yhat)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train(config, args):\n    gan = setup_gan(config, inputs, args)\n    trainable_gan = hg.TrainableGAN(gan, save_file=save_file, devices=args.devices, backend_name=args.backend)\n    test_batches = []\n    accuracy = 0\n    for i in range(args.steps):\n        trainable_gan.step()\n        if ((i == (args.steps - 1)) or (((i % args.sample_every) == 0) and (i > 0))):\n            correct_prediction = 0\n            total = 0\n            for (x, y) in gan.inputs.testdata():\n                prediction = gan.generator(x)\n                correct_prediction += (torch.argmax(prediction, 1) == torch.argmax(y, 1)).sum()\n                total += y.shape[0]\n            accuracy = ((float(correct_prediction) \/ total) * 100)\n            print(config_name)\n            print('accuracy: ', accuracy)\n    return accuracy\n"}
{"label_name":"predict","label":4,"method_name":"get_predictor_metrics","method":"\n\ndef get_predictor_metrics(positive_scores, negative_scores, threshold=0):\n    '\\n    This function calculates positive predictive value (PPV), negative predictive value, false discovery rate,\\n    and accuracy of a scoring metric\\n    :param positive_scores: A numpy array of scores for positive data\\n    :param negative_scores: A numpy array of scores for negative data\\n    :param threshold:\\n    :return: A pandas dataframe containing prediction metrics\\n    '\n    metrics = ['tp', 'fp', 'fn', 'tn', 'tpr', 'fpr', 'fnr', 'tnr', 'ppv', 'npv', 'fdr', 'acc']\n    series = pd.Series(index=metrics)\n    series.tp = np.sum((positive_scores >= threshold))\n    series.fp = np.sum((negative_scores >= threshold))\n    series.fn = np.sum((positive_scores < threshold))\n    series.tn = np.sum((negative_scores < threshold))\n    (series.tpr, series.fpr, series.fnr, series.tnr) = get_truth_table(positive_scores, negative_scores, threshold=threshold)\n    series.ppv = (float(series.tp) \/ (series.tp + series.fp))\n    series.npv = (float(series.tn) \/ (series.tn + series.fn))\n    series.fdr = (1 - series.ppv)\n    series.acc = (float((series.tp + series.tn)) \/ (((series.tp + series.fp) + series.fn) + series.tn))\n    return series\n"}
{"label_name":"predict","label":4,"method_name":"predict","method":"\n\ndef predict(args):\n    file_names = pd.read_csv(args.csv, dtype=object, keep_default_na=False, na_values=[]).as_matrix()\n    file_names = file_names[(- N_VALIDATION_SUBJECTS):]\n    export_dir = [os.path.join(args.model_path, o) for o in sorted(os.listdir(args.model_path)) if (os.path.isdir(os.path.join(args.model_path, o)) and o.isdigit())][(- 1)]\n    print('Loading from {}'.format(export_dir))\n    my_predictor = predictor.from_saved_model(export_dir)\n    accuracy = []\n    for output in read_fn(file_references=file_names, mode=tf.estimator.ModeKeys.EVAL, params=READER_PARAMS):\n        t0 = time.time()\n        img = output['features']['x']\n        lbl = output['labels']['y']\n        test_id = output['img_id']\n        num_crop_predictions = 4\n        crop_batch = extract_random_example_array(image_list=img, example_size=[64, 96, 96], n_examples=num_crop_predictions)\n        y_ = my_predictor.session.run(fetches=my_predictor._fetch_tensors['y_prob'], feed_dict={my_predictor._feed_tensors['x']: crop_batch})\n        y_ = np.mean(y_, axis=0)\n        predicted_class = np.argmax(y_)\n        accuracy.append((predicted_class == lbl))\n        print('id={}; pred={}; true={}; run time={:0.2f} s; '.format(test_id, predicted_class, lbl[0], (time.time() - t0)))\n    print('accuracy={}'.format(np.mean(accuracy)))\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train(images, labels, ckpt_path, dropout=False):\n    '\\n  This function contains the loop that actually trains the model.\\n  :param images: a numpy array with the input data\\n  :param labels: a numpy array with the output labels\\n  :param ckpt_path: a path (including name) where model checkpoints are saved\\n  :param dropout: Boolean, whether to use dropout or not\\n  :return: True if everything went well\\n  '\n    assert (len(images) == len(labels))\n    assert (images.dtype == np.float32)\n    assert (labels.dtype == np.int32)\n    with tf.Graph().as_default():\n        global_step = tf.Variable(0, trainable=False)\n        train_data_node = _input_placeholder()\n        train_labels_shape = (FLAGS.batch_size,)\n        train_labels_node = tf.placeholder(tf.int32, shape=train_labels_shape)\n        print('Done Initializing Training Placeholders')\n        if FLAGS.deeper:\n            logits = inference_deeper(train_data_node, dropout=dropout)\n        else:\n            logits = inference(train_data_node, dropout=dropout)\n        loss = loss_fun(logits, train_labels_node)\n        train_op = train_op_fun(loss, global_step)\n        saver = tf.train.Saver(tf.all_variables())\n        print('Graph constructed and saver created')\n        init = tf.global_variables_initializer()\n        sess = tf.Session(config=tf.ConfigProto(log_device_placement=FLAGS.log_device_placement))\n        sess.run(init)\n        print('Session ready, beginning training loop')\n        data_length = len(images)\n        nb_batches = math.ceil((data_length \/ FLAGS.batch_size))\n        for step in xrange(FLAGS.max_steps):\n            start_time = time.time()\n            batch_nb = (step % nb_batches)\n            (start, end) = utils.batch_indices(batch_nb, data_length, FLAGS.batch_size)\n            feed_dict = {train_data_node: images[start:end], train_labels_node: labels[start:end]}\n            (_, loss_value) = sess.run([train_op, loss], feed_dict=feed_dict)\n            duration = (time.time() - start_time)\n            assert (not np.isnan(loss_value)), 'Model diverged with loss = NaN'\n            if ((step % 100) == 0):\n                num_examples_per_step = FLAGS.batch_size\n                examples_per_sec = (num_examples_per_step \/ duration)\n                sec_per_batch = float(duration)\n                format_str = '%s: step %d, loss = %.2f (%.1f examples\/sec; %.3f sec\/batch)'\n                print((format_str % (datetime.now(), step, loss_value, examples_per_sec, sec_per_batch)))\n            if (((step % 1000) == 0) or ((step + 1) == FLAGS.max_steps)):\n                saver.save(sess, ckpt_path, global_step=step)\n    return True\n"}
{"label_name":"process","label":2,"method_name":"_process_data","method":"\n\ndef _process_data(data, vocab, pos_tags, chunk_tags, maxlen=None, onehot=False):\n    if (maxlen is None):\n        maxlen = max((len(s) for s in data))\n    word2idx = dict(((w, i) for (i, w) in enumerate(vocab)))\n    x = [[word2idx.get(w[0].lower(), 1) for w in s] for s in data]\n    y_pos = [[pos_tags.index(w[1]) for w in s] for s in data]\n    y_chunk = [[chunk_tags.index(w[2]) for w in s] for s in data]\n    x = pad_sequences(x, maxlen)\n    y_pos = pad_sequences(y_pos, maxlen, value=(- 1))\n    y_chunk = pad_sequences(y_chunk, maxlen, value=(- 1))\n    if onehot:\n        y_pos = numpy.eye(len(pos_tags), dtype='float32')[y]\n        y_chunk = numpy.eye(len(chunk_tags), dtype='float32')[y]\n    else:\n        y_pos = numpy.expand_dims(y_pos, 2)\n        y_chunk = numpy.expand_dims(y_chunk, 2)\n    return (x, y_pos, y_chunk)\n"}
{"label_name":"predict","label":4,"method_name":"run_link_prediction","method":"\n\ndef run_link_prediction(binary_operator):\n    clf = train_link_prediction_model(examples_train, labels_train, embedding_train, binary_operator)\n    score = evaluate_link_prediction_model(clf, examples_model_selection, labels_model_selection, embedding_train, binary_operator)\n    return {'classifier': clf, 'binary_operator': binary_operator, 'score': score}\n"}
{"label_name":"predict","label":4,"method_name":"get_prediction","method":"\n\n@app.route('\/predict-slow\/<uuid:id>')\ndef get_prediction(id):\n    'Retrieve a completed prediction.'\n    query_result = db.engine.execute('SELECT class FROM results WHERE id = :id', id=str(id)).first()\n    if (query_result is None):\n        abort(404)\n    return jsonify({'class': query_result[0]})\n"}
{"label_name":"train","label":0,"method_name":"convert_images_to_arrays_train","method":"\n\ndef convert_images_to_arrays_train(file_path, df):\n    '\\n    Converts each image to an array, and appends each array to a new NumPy\\n    array, based on the image column equaling the image file name.\\n\\n    INPUT\\n        file_path: Specified file path for resized test and train images.\\n        df: Pandas DataFrame being used to assist file imports.\\n\\n    OUTPUT\\n        NumPy array of image arrays.\\n    '\n    lst_imgs = [l for l in df['train_image_name']]\n    return np.array([np.array(Image.open((file_path + img))) for img in lst_imgs])\n"}
{"label_name":"train","label":0,"method_name":"trainNB0","method":"\n\ndef trainNB0(trainMatrix, trainCategory):\n    numTrainDocs = len(trainMatrix)\n    numWords = len(trainMatrix[0])\n    pAbusive = (sum(trainCategory) \/ float(numTrainDocs))\n    p0Num = np.zeros(numWords)\n    p1Num = np.zeros(numWords)\n    p0Denom = 0.0\n    p1Denom = 0.0\n    for i in range(numTrainDocs):\n        if (trainCategory[i] == 1):\n            p1Num += trainMatrix[i]\n            p1Denom += sum(trainMatrix[i])\n        else:\n            p0Num += trainMatrix[i]\n            p0Denom += sum(trainMatrix[i])\n    p1Vect = (p1Num \/ p1Denom)\n    p0Vect = (p0Num \/ p0Denom)\n    return (p0Vect, p1Vect, pAbusive)\n"}
{"label_name":"train","label":0,"method_name":"train_rllib_policy","method":"\n\ndef train_rllib_policy(config):\n    'Trains a DQNTrainer on MsPacman-v0 for n iterations.\\n\\n    Saves the trained Trainer to disk and returns the checkpoint path.\\n\\n    Returns:\\n        str: The saved checkpoint to restore the trainer DQNTrainer from.\\n    '\n    trainer = dqn.DQNTrainer(config=config)\n    for _ in range(args.train_iters):\n        print(trainer.train())\n    return trainer.save()\n"}
{"label_name":"predict","label":4,"method_name":"negative_predictive_score","method":"\n\ndef negative_predictive_score(y_true: str, y_score: str, input_relation: (str, vDataFrame), cursor=None, pos_label: (int, float, str)=1):\n    '\\n---------------------------------------------------------------------------\\nComputes the Negative Predictive Score.\\n\\nParameters\\n----------\\ny_true: str\\n\\tResponse column.\\ny_score: str\\n\\tPrediction.\\ninput_relation: str\/vDataFrame\\n\\tRelation to use to do the scoring. The relation can be a view or a table\\n\\tor even a customized relation. For example, you could write:\\n\\t\"(SELECT ... FROM ...) x\" as long as an alias is given at the end of the\\n\\trelation.\\ncursor: DBcursor, optional\\n\\tVertica database cursor.\\npos_label: int\/float\/str, optional\\n\\tTo compute the Negative Predictive Score, one of the response column class \\n\\tmust be the positive one. The parameter \\'pos_label\\' represents this class.\\n\\nReturns\\n-------\\nfloat\\n\\tscore\\n\\t'\n    check_types([('y_true', y_true, [str]), ('y_score', y_score, [str]), ('input_relation', input_relation, [str, vDataFrame])])\n    (cursor, conn, input_relation) = check_cursor(cursor, input_relation)\n    matrix = confusion_matrix(y_true, y_score, input_relation, cursor, pos_label)\n    if conn:\n        conn.close()\n    non_pos_label = (0 if (pos_label == 1) else 'Non-{}'.format(pos_label))\n    (tn, fn, fp, tp) = (matrix.values[non_pos_label][0], matrix.values[non_pos_label][1], matrix.values[pos_label][0], matrix.values[pos_label][1])\n    npv = ((tn \/ (tn + fn)) if ((tn + fn) != 0) else 0)\n    return npv\n"}
{"label_name":"predict","label":4,"method_name":"make_predicted_annotations","method":"\n\ndef make_predicted_annotations(annotations, labels=cfg.PROJECT_LABELS):\n    annos = []\n    for anno in annotations:\n        if (anno['label'] in labels):\n            annos.append(anno)\n    return annos\n"}
{"label_name":"train","label":0,"method_name":"run_train","method":"\n\ndef run_train():\n    dictionary = DP.read_dict(dict_file)\n    train_label = DP.read_train(train_label_file)\n    train = DataSet(train_path, train_label, len(dictionary), dictionary[EOS_tag])\n    N_input = train.datalen\n    N_iter = ((N_input * N_epoch) \/\/ batch_size)\n    print(('Total training steps: %d' % N_iter))\n    model = s2vtModel(image_dim=train.feat_dim, vocab_size=train.vocab_size, N_hidden=N_hidden, N_video_step=train.feat_timestep, N_caption_step=train.maxseqlen, batch_size=batch_size)\n    (tf_loss, tf_video, tf_caption, tf_caption_mask, _) = model.build_train_model(dictionary)\n    tf_optimizer = tf.train.AdamOptimizer(learning_rate).minimize(tf_loss)\n    init = tf.global_variables_initializer()\n    with tf.Session() as sess:\n        sess.run(init)\n        model.restore_model(sess, model_file)\n        step = 0\n        t = time.time()\n        while (step < N_iter):\n            (batch_x, batch_y) = train.next_batch(batch_size=batch_size)\n            y = np.full((batch_size, train.maxseqlen), dictionary[EOS_tag])\n            y_mask = np.zeros(y.shape)\n            for (i, caption) in enumerate(batch_y):\n                y[i, :len(caption)] = caption\n                y_mask[i, :len(caption)] = 1\n            sess.run(tf_optimizer, feed_dict={tf_video: batch_x, tf_caption: y, tf_caption_mask: y_mask})\n            if ((step % display_step) == 0):\n                used_time = (time.time() - t)\n                t = time.time()\n                loss = sess.run(tf_loss, feed_dict={tf_video: batch_x, tf_caption: y, tf_caption_mask: y_mask})\n                print((((((((str(step) + '\/') + str(N_iter)) + ' step: loss = ') + str(loss)) + ' time = ') + str(used_time)) + ' secs'))\n                model.save_model(sess, model_file)\n            step += 1\n        model.save_model(sess, model_file)\n    return\n"}
{"label_name":"train","label":0,"method_name":"initial_constraints_as_canonical","method":"\n\ndef initial_constraints_as_canonical(n, prepared_constraints, sparse_jacobian):\n    'Convert initial values of the constraints to the canonical format.\\n\\n    The purpose to avoid one additional call to the constraints at the initial\\n    point. It takes saved values in `PreparedConstraint`, modify and\\n    concatenate them to the the canonical constraint format.\\n    '\n    c_eq = []\n    c_ineq = []\n    J_eq = []\n    J_ineq = []\n    for c in prepared_constraints:\n        f = c.fun.f\n        J = c.fun.J\n        (lb, ub) = c.bounds\n        if np.all((lb == ub)):\n            c_eq.append((f - lb))\n            J_eq.append(J)\n        elif np.all((lb == (- np.inf))):\n            finite_ub = (ub < np.inf)\n            c_ineq.append((f[finite_ub] - ub[finite_ub]))\n            J_ineq.append(J[finite_ub])\n        elif np.all((ub == np.inf)):\n            finite_lb = (lb > (- np.inf))\n            c_ineq.append((lb[finite_lb] - f[finite_lb]))\n            J_ineq.append((- J[finite_lb]))\n        else:\n            lb_inf = (lb == (- np.inf))\n            ub_inf = (ub == np.inf)\n            equal = (lb == ub)\n            less = (lb_inf & (~ ub_inf))\n            greater = (ub_inf & (~ lb_inf))\n            interval = (((~ equal) & (~ lb_inf)) & (~ ub_inf))\n            c_eq.append((f[equal] - lb[equal]))\n            c_ineq.append((f[less] - ub[less]))\n            c_ineq.append((lb[greater] - f[greater]))\n            c_ineq.append((f[interval] - ub[interval]))\n            c_ineq.append((lb[interval] - f[interval]))\n            J_eq.append(J[equal])\n            J_ineq.append(J[less])\n            J_ineq.append((- J[greater]))\n            J_ineq.append(J[interval])\n            J_ineq.append((- J[interval]))\n    c_eq = (np.hstack(c_eq) if c_eq else np.empty(0))\n    c_ineq = (np.hstack(c_ineq) if c_ineq else np.empty(0))\n    if sparse_jacobian:\n        vstack = sps.vstack\n        empty = sps.csr_matrix((0, n))\n    else:\n        vstack = np.vstack\n        empty = np.empty((0, n))\n    J_eq = (vstack(J_eq) if J_eq else empty)\n    J_ineq = (vstack(J_ineq) if J_ineq else empty)\n    return (c_eq, c_ineq, J_eq, J_ineq)\n"}
{"label_name":"train","label":0,"method_name":"train_cli","method":"\n\n@app.command('train', context_settings={'allow_extra_args': True, 'ignore_unknown_options': True})\ndef train_cli(ctx: typer.Context, config_path: Path=Arg(..., help='Path to config file', exists=True, allow_dash=True), output_path: Optional[Path]=Opt(None, '--output', '--output-path', '-o', help='Output directory to store trained pipeline in'), code_path: Optional[Path]=Opt(None, '--code', '-c', help='Path to Python file with additional code (registered functions) to be imported'), verbose: bool=Opt(False, '--verbose', '-V', '-VV', help='Display more information for debugging purposes'), use_gpu: int=Opt((- 1), '--gpu-id', '-g', help='GPU ID or -1 for CPU')):\n    '\\n    Train or update a spaCy pipeline. Requires data in spaCy\\'s binary format. To\\n    convert data from other formats, use the `spacy convert` command. The\\n    config file includes all settings and hyperparameters used during traing.\\n    To override settings in the config, e.g. settings that point to local\\n    paths or that you want to experiment with, you can override them as\\n    command line options. For instance, --training.batch_size 128 overrides\\n    the value of \"batch_size\" in the block \"[training]\". The --code argument\\n    lets you pass in a Python file that\\'s imported before training. It can be\\n    used to register custom functions and architectures that can then be\\n    referenced in the config.\\n\\n    DOCS: https:\/\/spacy.io\/api\/cli#train\\n    '\n    util.logger.setLevel((logging.DEBUG if verbose else logging.INFO))\n    if ((not config_path) or ((str(config_path) != '-') and (not config_path.exists()))):\n        msg.fail('Config file not found', config_path, exits=1)\n    if ((output_path is not None) and (not output_path.exists())):\n        output_path.mkdir(parents=True)\n        msg.good(f'Created output directory: {output_path}')\n    overrides = parse_config_overrides(ctx.args)\n    import_code(code_path)\n    setup_gpu(use_gpu)\n    with show_validation_error(config_path):\n        config = util.load_config(config_path, overrides=overrides, interpolate=False)\n    msg.divider('Initializing pipeline')\n    with show_validation_error(config_path, hint_fill=False):\n        nlp = init_nlp(config, use_gpu=use_gpu)\n    msg.good('Initialized pipeline')\n    msg.divider('Training pipeline')\n    train(nlp, output_path, use_gpu=use_gpu, stdout=sys.stdout, stderr=sys.stderr)\n"}
{"label_name":"train","label":0,"method_name":"trainKeyWords","method":"\n\ndef trainKeyWords(stop):\n    fr = open('.\/data_origin\/OriginTrainData.txt', 'r')\n    arrayOfLines = fr.readlines()\n    for line in arrayOfLines:\n        line = line.strip()\n        line = line.split('\\t')\n        writeStr(line[0], '.\/data_process\/classLabel.txt')\n        ustring = preProcess(line[1])\n        leftWords = cutWords(ustring, stop)\n        writeListWords(leftWords, '.\/data_process\/trainLeft.txt')\n"}
{"label_name":"train","label":0,"method_name":"shift_crop_training_sample","method":"\n\ndef shift_crop_training_sample(sample, bb_params):\n    '\\n    Given an image with bounding box, this method randomly shifts the box and\\n    generates a training example. It returns current image crop with shifted\\n    box (with respect to current image).\\n    '\n    output_sample = {}\n    opts = {}\n    currimg = sample['image']\n    currbb = sample['bb']\n    bbox_curr_gt = BoundingBox(currbb[0], currbb[1], currbb[2], currbb[3])\n    bbox_curr_shift = BoundingBox(0, 0, 0, 0)\n    bbox_curr_shift = bbox_curr_gt.shift(currimg, bb_params['lambda_scale_frac'], bb_params['lambda_shift_frac'], bb_params['min_scale'], bb_params['max_scale'], True, bbox_curr_shift)\n    (rand_search_region, rand_search_location, edge_spacing_x, edge_spacing_y) = cropPadImage(bbox_curr_shift, currimg)\n    bbox_curr_gt = BoundingBox(currbb[0], currbb[1], currbb[2], currbb[3])\n    bbox_gt_recentered = BoundingBox(0, 0, 0, 0)\n    bbox_gt_recentered = bbox_curr_gt.recenter(rand_search_location, edge_spacing_x, edge_spacing_y, bbox_gt_recentered)\n    output_sample['image'] = rand_search_region\n    output_sample['bb'] = bbox_gt_recentered.get_bb_list()\n    opts['edge_spacing_x'] = edge_spacing_x\n    opts['edge_spacing_y'] = edge_spacing_y\n    opts['search_location'] = rand_search_location\n    opts['search_region'] = rand_search_region\n    return (output_sample, opts)\n"}
{"label_name":"train","label":0,"method_name":"train_split","method":"\n\n@pytest.fixture\ndef train_split():\n\n    def func(dataset, y):\n        ds_train = type(dataset)(dataset.X[:2], dataset.y[:2])\n        ds_valid = type(dataset)(dataset.X[2:], dataset.y[2:])\n        return (ds_train, ds_valid)\n    return func\n"}
{"label_name":"process","label":2,"method_name":"_process_array_argument","method":"\n\ndef _process_array_argument(x):\n    if (not is_tuple_or_list(x)):\n        x = [x]\n    return x\n"}
{"label_name":"save","label":1,"method_name":"save_workload_func_registry","method":"\n\ndef save_workload_func_registry(filename):\n    'Dump workload function registry to a pickle binary file.\\n\\n    Parameters\\n    ----------\\n    filename : str\\n        The filename to dump workload function registry to.\\n    '\n    global WORKLOAD_FUNC_REGISTRY\n    pickle.dump(WORKLOAD_FUNC_REGISTRY, open(filename, 'wb'))\n"}
{"label_name":"process","label":2,"method_name":"process_luna_candidates_patient","method":"\n\ndef process_luna_candidates_patient(src_path, patient_id):\n    dst_dir = (settings.LUNA16_EXTRACTED_IMAGE_DIR + '\/_labels\/')\n    img_dir = ((dst_dir + patient_id) + '\/')\n    df_pos_annos = pandas.read_csv(((dst_dir + patient_id) + '_annos_pos_lidc.csv'))\n    if (not os.path.exists(dst_dir)):\n        os.mkdir(dst_dir)\n    pos_annos_manual = None\n    manual_path = (((settings.EXTRA_DATA_DIR + 'luna16_manual_labels\/') + patient_id) + '.csv')\n    if os.path.exists(manual_path):\n        pos_annos_manual = pandas.read_csv(manual_path)\n    itk_img = SimpleITK.ReadImage(src_path)\n    img_array = SimpleITK.GetArrayFromImage(itk_img)\n    print('Img array: ', img_array.shape)\n    print('Pos annos: ', len(df_pos_annos))\n    (num_z, height, width) = img_array.shape\n    origin = numpy.array(itk_img.GetOrigin())\n    print('Origin (x,y,z): ', origin)\n    spacing = numpy.array(itk_img.GetSpacing())\n    print('Spacing (x,y,z): ', spacing)\n    rescale = (spacing \/ settings.TARGET_VOXEL_MM)\n    print('Rescale: ', rescale)\n    direction = numpy.array(itk_img.GetDirection())\n    print('Direction: ', direction)\n    flip_direction_x = False\n    flip_direction_y = False\n    if (round(direction[0]) == (- 1)):\n        origin[0] *= (- 1)\n        direction[0] = 1\n        flip_direction_x = True\n        print('Swappint x origin')\n    if (round(direction[4]) == (- 1)):\n        origin[1] *= (- 1)\n        direction[4] = 1\n        flip_direction_y = True\n        print('Swappint y origin')\n    print('Direction: ', direction)\n    assert (abs((sum(direction) - 3)) < 0.01)\n    src_df = pandas.read_csv(('resources\/luna16_annotations\/' + 'candidates_V2.csv'))\n    src_df = src_df[(src_df['seriesuid'] == patient_id)]\n    src_df = src_df[(src_df['class'] == 0)]\n    patient_imgs = helpers.load_patient_images(patient_id, settings.LUNA16_EXTRACTED_IMAGE_DIR, '*_i.png')\n    candidate_list = []\n    for (df_index, candiate_row) in src_df.iterrows():\n        node_x = candiate_row['coordX']\n        if flip_direction_x:\n            node_x *= (- 1)\n        node_y = candiate_row['coordY']\n        if flip_direction_y:\n            node_y *= (- 1)\n        node_z = candiate_row['coordZ']\n        candidate_diameter = 6\n        center_float = numpy.array([node_x, node_y, node_z])\n        center_int = numpy.rint(((center_float - origin) \/ spacing))\n        center_float_rescaled = ((center_float - origin) \/ settings.TARGET_VOXEL_MM)\n        center_float_percent = (center_float_rescaled \/ patient_imgs.swapaxes(0, 2).shape)\n        coord_x = center_float_rescaled[0]\n        coord_y = center_float_rescaled[1]\n        coord_z = center_float_rescaled[2]\n        ok = True\n        for (index, row) in df_pos_annos.iterrows():\n            pos_coord_x = (row['coord_x'] * patient_imgs.shape[2])\n            pos_coord_y = (row['coord_y'] * patient_imgs.shape[1])\n            pos_coord_z = (row['coord_z'] * patient_imgs.shape[0])\n            diameter = (row['diameter'] * patient_imgs.shape[2])\n            dist = math.sqrt(((math.pow((pos_coord_x - coord_x), 2) + math.pow((pos_coord_y - coord_y), 2)) + math.pow((pos_coord_z - coord_z), 2)))\n            if (dist < (diameter + 64)):\n                ok = False\n                print('################### Too close', (coord_x, coord_y, coord_z))\n                break\n        if ((pos_annos_manual is not None) and ok):\n            for (index, row) in pos_annos_manual.iterrows():\n                pos_coord_x = (row['x'] * patient_imgs.shape[2])\n                pos_coord_y = (row['y'] * patient_imgs.shape[1])\n                pos_coord_z = (row['z'] * patient_imgs.shape[0])\n                diameter = (row['d'] * patient_imgs.shape[2])\n                print((pos_coord_x, pos_coord_y, pos_coord_z))\n                print(center_float_rescaled)\n                dist = math.sqrt(((math.pow((pos_coord_x - center_float_rescaled[0]), 2) + math.pow((pos_coord_y - center_float_rescaled[1]), 2)) + math.pow((pos_coord_z - center_float_rescaled[2]), 2)))\n                if (dist < (diameter + 72)):\n                    ok = False\n                    print('################### Too close', center_float_rescaled)\n                    break\n        if (not ok):\n            continue\n        candidate_list.append([len(candidate_list), round(center_float_percent[0], 4), round(center_float_percent[1], 4), round(center_float_percent[2], 4), round((candidate_diameter \/ patient_imgs.shape[0]), 4), 0])\n    df_candidates = pandas.DataFrame(candidate_list, columns=['anno_index', 'coord_x', 'coord_y', 'coord_z', 'diameter', 'malscore'])\n    df_candidates.to_csv(((dst_dir + patient_id) + '_candidates_luna.csv'), index=False)\n"}
{"label_name":"train","label":0,"method_name":"parse_constraint","method":"\n\ndef parse_constraint(constraint):\n    try:\n        (feature, _type, threshold) = constraint.split(':')\n    except ValueError:\n        raise errors.Invalid(\"invalid format for 'constraint' parameter\")\n    if (_type not in ('low', 'high')):\n        raise errors.Invalid(\"invalid threshold type for 'constraint' parameter\")\n    try:\n        threshold = float(threshold)\n    except ValueError:\n        raise errors.Invalid(\"invalid threshold for 'constraint' parameter\")\n    return {'feature': feature, 'type': _type, 'threshold': threshold}\n"}
{"label_name":"train","label":0,"method_name":"trainSparseModel","method":"\n\ndef trainSparseModel(Xtrain, Ytrain, exact_model, isFITC, Xtest, Ytest):\n    sparse_model = getSparseModel(Xtrain, Ytrain, isFITC)\n    sparse_model.likelihood.variance = exact_model.likelihood.variance.numpy()\n    sparse_model.kern.lengthscales = exact_model.kern.lengthscales.numpy()\n    sparse_model.kern.variance = exact_model.kern.variance.numpy()\n    return (sparse_model, repeatMinimization(sparse_model, Xtest, Ytest))\n"}
{"label_name":"process","label":2,"method_name":"if_safe_multiprocessing_with_blas","method":"\n\ndef if_safe_multiprocessing_with_blas(func):\n    'Decorator for tests involving both BLAS calls and multiprocessing.\\n\\n    Under POSIX (e.g. Linux or OSX), using multiprocessing in conjunction with\\n    some implementation of BLAS (or other libraries that manage an internal\\n    posix thread pool) can cause a crash or a freeze of the Python process.\\n\\n    In practice all known packaged distributions (from Linux distros or\\n    Anaconda) of BLAS under Linux seems to be safe. So we this problem seems to\\n    only impact OSX users.\\n\\n    This wrapper makes it possible to skip tests that can possibly cause\\n    this crash under OS X with.\\n\\n    Under Python 3.4+ it is possible to use the `forkserver` start method\\n    for multiprocessing to avoid this issue. However it can cause pickling\\n    errors on interactively defined functions. It therefore not enabled by\\n    default.\\n    '\n\n    @wraps(func)\n    def run_test(*args, **kwargs):\n        if (sys.platform == 'darwin'):\n            raise SkipTest('Possible multi-process bug with some BLAS')\n        return func(*args, **kwargs)\n    return run_test\n"}
{"label_name":"predict","label":4,"method_name":"_predictions","method":"\n\ndef _predictions(predictions, unused_targets, **unused_kwargs):\n    return predictions\n"}
{"label_name":"predict","label":4,"method_name":"self_predict_impl","method":"\n\ndef self_predict_impl(clf, X, y, cv, method):\n    if (type(y) is not pd.Series):\n        y = pd.Series(y)\n    if ((y is not None) and (X.shape[0] != len(y))):\n        X = X[:len(y)]\n    start((((('self_' + method) + ' with ') + 'cv') + ' chunks starting'))\n    reseed(clf)\n\n    def op(X, y, X2):\n        if ((len(X.shape) == 2) and (X.shape[1] == 1)):\n            if hasattr(X, 'values'):\n                X = X.values\n            X = X.T[0]\n        if ((len(X2.shape) == 2) and (X2.shape[1] == 1)):\n            if hasattr(X2, 'values'):\n                X2 = X2.values\n            X2 = X2.T[0]\n        this_clf = sklearn.base.clone(clf)\n        this_clf.fit(X, y)\n        new_predictions = getattr(this_clf, method)(X2)\n        if (new_predictions.shape[0] == 1):\n            new_predictions = new_predictions.reshape((- 1), 1)\n        return new_predictions\n    predictions = self_chunked_op(X, y, op, cv)\n    stop('self_predict completed')\n    return predictions.values\n"}
{"label_name":"save","label":1,"method_name":"save_tensor_image","method":"\n\ndef save_tensor_image(image: tf.Tensor, fn: str):\n    tf.io.write_file(fn, tf.image.encode_png(tf.cast(image, tf.uint8)))\n"}
{"label_name":"predict","label":4,"method_name":"predict","method":"\n\ndef predict(summaries, vector):\n    probability = calculateClassProbablity(summaries, vector)\n    class_ = None\n    best_prob = 0\n    for (key, value) in probability.items():\n        if (value > best_prob):\n            class_ = key\n            best_prob = value\n    return class_\n"}
{"label_name":"train","label":0,"method_name":"run_training","method":"\n\ndef run_training(train_op, loss, global_step, variables_to_restore=None, pretrained_model_dir=None):\n    'Sets up and runs training loop.'\n    tf.gfile.MakeDirs(FLAGS.train_dir)\n    if pretrained_model_dir:\n        assert variables_to_restore\n        tf.logging.info('Will attempt restore from %s: %s', pretrained_model_dir, variables_to_restore)\n        saver_for_restore = tf.train.Saver(variables_to_restore)\n    if FLAGS.sync_replicas:\n        local_init_op = tf.get_collection('local_init_op')[0]\n        ready_for_local_init_op = tf.get_collection('ready_for_local_init_op')[0]\n    else:\n        local_init_op = tf.train.Supervisor.USE_DEFAULT\n        ready_for_local_init_op = tf.train.Supervisor.USE_DEFAULT\n    is_chief = (FLAGS.task == 0)\n    sv = tf.train.Supervisor(logdir=FLAGS.train_dir, is_chief=is_chief, save_summaries_secs=30, save_model_secs=30, local_init_op=local_init_op, ready_for_local_init_op=ready_for_local_init_op, global_step=global_step)\n    with sv.managed_session(master=FLAGS.master, config=tf.ConfigProto(log_device_placement=FLAGS.log_device_placement), start_standard_services=False) as sess:\n        if is_chief:\n            if pretrained_model_dir:\n                maybe_restore_pretrained_model(sess, saver_for_restore, pretrained_model_dir)\n            if FLAGS.sync_replicas:\n                sess.run(tf.get_collection('chief_init_op')[0])\n            sv.start_standard_services(sess)\n        sv.start_queue_runners(sess)\n        global_step_val = 0\n        while ((not sv.should_stop()) and (global_step_val < FLAGS.max_steps)):\n            global_step_val = train_step(sess, train_op, loss, global_step)\n        if (is_chief and (global_step_val >= FLAGS.max_steps)):\n            sv.saver.save(sess, sv.save_path, global_step=global_step)\n"}
{"label_name":"save","label":1,"method_name":"save_scores","method":"\n\ndef save_scores(exp, proj_name, loader):\n    print('Saving scores')\n    (probs, preds) = get_preds(exp, loader)\n    targs = loader.dataset.targets\n    loss = metric_utils.get_cross_entropy_loss(probs, targs)\n    scores_fpath = get_scores_fpath(proj_name)\n    scores = load_scores(scores_fpath)\n    scores['experiments'][exp.name] = exp.history.metrics_history\n    scores['counts'] = get_img_counts(proj_name)\n    scores['experiments'][exp.name]['created'] = time.strftime('%m\/%d\/%Y %H:%M:%S', time.localtime())\n    for m in exp.metrics:\n        scores['latest'][m.name] = m.evaluate(loss, preds, probs, targs)\n    utils.files.save_json(scores_fpath, scores)\n"}
{"label_name":"save","label":1,"method_name":"_save","method":"\n\ndef _save(im, fp, tile, bufsize=0):\n    'Helper to save image based on tile list\\n\\n    :param im: Image object.\\n    :param fp: File object.\\n    :param tile: Tile list.\\n    :param bufsize: Optional buffer size\\n    '\n    im.load()\n    if (not hasattr(im, 'encoderconfig')):\n        im.encoderconfig = ()\n    tile.sort(key=_tilesort)\n    bufsize = max(MAXBLOCK, bufsize, (im.size[0] * 4))\n    if (fp == sys.stdout):\n        fp.flush()\n        return\n    try:\n        fh = fp.fileno()\n        fp.flush()\n    except (AttributeError, io.UnsupportedOperation):\n        for (e, b, o, a) in tile:\n            e = Image._getencoder(im.mode, e, a, im.encoderconfig)\n            if (o > 0):\n                fp.seek(o, 0)\n            e.setimage(im.im, b)\n            if e.pushes_fd:\n                e.setfd(fp)\n                (l, s) = e.encode_to_pyfd()\n            else:\n                while True:\n                    (l, s, d) = e.encode(bufsize)\n                    fp.write(d)\n                    if s:\n                        break\n            if (s < 0):\n                raise IOError(('encoder error %d when writing image file' % s))\n            e.cleanup()\n    else:\n        for (e, b, o, a) in tile:\n            e = Image._getencoder(im.mode, e, a, im.encoderconfig)\n            if (o > 0):\n                fp.seek(o, 0)\n            e.setimage(im.im, b)\n            if e.pushes_fd:\n                e.setfd(fp)\n                (l, s) = e.encode_to_pyfd()\n            else:\n                s = e.encode_to_file(fh, bufsize)\n            if (s < 0):\n                raise IOError(('encoder error %d when writing image file' % s))\n            e.cleanup()\n    if hasattr(fp, 'flush'):\n        fp.flush()\n"}
{"label_name":"process","label":2,"method_name":"append_postprocessing_op","method":"\n\ndef append_postprocessing_op(frozen_graph_def, max_detections, max_classes_per_detection, nms_score_threshold, nms_iou_threshold, num_classes, scale_values, detections_per_class=100, use_regular_nms=False):\n    'Appends postprocessing custom op.\\n\\n  Args:\\n    frozen_graph_def: Frozen GraphDef for SSD model after freezing the\\n      checkpoint\\n    max_detections: Maximum number of detections (boxes) to show\\n    max_classes_per_detection: Number of classes to display per detection\\n    nms_score_threshold: Score threshold used in Non-maximal suppression in\\n      post-processing\\n    nms_iou_threshold: Intersection-over-union threshold used in Non-maximal\\n      suppression in post-processing\\n    num_classes: number of classes in SSD detector\\n    scale_values: scale values is a dict with following key-value pairs\\n      {y_scale: 10, x_scale: 10, h_scale: 5, w_scale: 5} that are used in decode\\n      centersize boxes\\n    detections_per_class: In regular NonMaxSuppression, number of anchors used\\n    for NonMaxSuppression per class\\n    use_regular_nms: Flag to set postprocessing op to use Regular NMS instead\\n      of Fast NMS.\\n\\n  Returns:\\n    transformed_graph_def: Frozen GraphDef with postprocessing custom op\\n    appended\\n    TFLite_Detection_PostProcess custom op node has four outputs:\\n    detection_boxes: a float32 tensor of shape [1, num_boxes, 4] with box\\n    locations\\n    detection_classes: a float32 tensor of shape [1, num_boxes]\\n    with class indices\\n    detection_scores: a float32 tensor of shape [1, num_boxes]\\n    with class scores\\n    num_boxes: a float32 tensor of size 1 containing the number of detected\\n    boxes\\n  '\n    new_output = frozen_graph_def.node.add()\n    new_output.op = 'TFLite_Detection_PostProcess'\n    new_output.name = 'TFLite_Detection_PostProcess'\n    new_output.attr['_output_quantized'].CopyFrom(attr_value_pb2.AttrValue(b=True))\n    new_output.attr['_output_types'].list.type.extend([types_pb2.DT_FLOAT, types_pb2.DT_FLOAT, types_pb2.DT_FLOAT, types_pb2.DT_FLOAT])\n    new_output.attr['_support_output_type_float_in_quantized_op'].CopyFrom(attr_value_pb2.AttrValue(b=True))\n    new_output.attr['max_detections'].CopyFrom(attr_value_pb2.AttrValue(i=max_detections))\n    new_output.attr['max_classes_per_detection'].CopyFrom(attr_value_pb2.AttrValue(i=max_classes_per_detection))\n    new_output.attr['nms_score_threshold'].CopyFrom(attr_value_pb2.AttrValue(f=nms_score_threshold.pop()))\n    new_output.attr['nms_iou_threshold'].CopyFrom(attr_value_pb2.AttrValue(f=nms_iou_threshold.pop()))\n    new_output.attr['num_classes'].CopyFrom(attr_value_pb2.AttrValue(i=num_classes))\n    new_output.attr['y_scale'].CopyFrom(attr_value_pb2.AttrValue(f=scale_values['y_scale'].pop()))\n    new_output.attr['x_scale'].CopyFrom(attr_value_pb2.AttrValue(f=scale_values['x_scale'].pop()))\n    new_output.attr['h_scale'].CopyFrom(attr_value_pb2.AttrValue(f=scale_values['h_scale'].pop()))\n    new_output.attr['w_scale'].CopyFrom(attr_value_pb2.AttrValue(f=scale_values['w_scale'].pop()))\n    new_output.attr['detections_per_class'].CopyFrom(attr_value_pb2.AttrValue(i=detections_per_class))\n    new_output.attr['use_regular_nms'].CopyFrom(attr_value_pb2.AttrValue(b=use_regular_nms))\n    new_output.input.extend(['raw_outputs\/box_encodings', 'raw_outputs\/class_predictions', 'anchors'])\n    input_names = []\n    output_names = ['TFLite_Detection_PostProcess']\n    transforms = ['strip_unused_nodes']\n    transformed_graph_def = TransformGraph(frozen_graph_def, input_names, output_names, transforms)\n    return transformed_graph_def\n"}
{"label_name":"process","label":2,"method_name":"process_text","method":"\n\ndef process_text(args):\n    (ids, shelve_file) = args\n    shelf = shelve.open(str((Path(data_dir) \/ 'questions.shelve')), 'r')\n    vocab = nltk.FreqDist()\n    tag_freq = nltk.FreqDist()\n    lens = []\n    prev_perc = (- 1)\n    print('Processing text...')\n    for (i, Id) in enumerate(ids):\n        row = shelf[Id]\n        perc = int((100 * (i \/ len(ids))))\n        if (perc != prev_perc):\n            if ((perc % 10) == 0):\n                print(perc, i)\n            prev_perc = perc\n        title = row['Title']\n        body = row['Body']\n        tags = row['Tags']\n        text = ((title + ' : ') + body)\n        tag_freq.update(tags)\n        note_len = 0\n        for sent in mimic_tokenize(text, fix_anon=False):\n            note_len += len(sent)\n            for word in sent:\n                vocab[word] += 1\n        lens.append(note_len)\n    shelf.close()\n    return (vocab, tag_freq, lens)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\n@click.command()\n@click.option(u'-i', u'--input-s3-dir', required=True, help='s3 location to input data', type=click.Path())\n@click.option(u'-o', u'--output-s3-dir', required=True, help='s3 location to save output (models, etc)', type=click.Path())\n@click.option(u'-h', u'--hyperparams-file', required=False, help='Path to hyperparams file', type=click.Path(resolve_path=True))\n@click.option(u'-e', u'--ec2-type', required=True, help='ec2 instance type')\n@click.option(u'-v', u'--volume-size', required=False, default=30, help='size in GB of the EBS volume (default: 30)')\n@click.option(u'-s', u'--time-out', required=False, default=((24 * 60) * 60), help='time-out in seconds (default: 24 * 60 * 60)')\n@click.option(u'-a', u'--aws-tags', callback=validate_tags, required=False, default=None, help='Tags for labeling a training job of the form \"tag1=value1;tag2=value2\". For more, see https:\/\/docs.aws.amazon.com\/sagemaker\/latest\/dg\/API_Tag.html.')\n@click.option(u'-r', u'--iam-role-arn', required=False, help='The AWS role to use for the push command')\n@click.option(u'-x', u'--external-id', required=False, help='Optional external id used when using an IAM role')\n@click.option(u'-n', u'--base-job-name', required=False, help='Optional prefix for the SageMaker training job.If not specified, the estimator generates a default job name, based on the training image name and current timestamp.')\n@click.option(u'--job-name', required=False, help='Optional name for the SageMaker training job.NOTE: if a `--base-job-name` is passed along with this option, it will be ignored.')\n@click.option(u'--use-spot-instances', default=False, is_flag=True, help='Optional flag that specifies whether to use SageMaker Managed Spot instances for training. It should be used only for training jobs that take less than 1 hour.')\n@click.option(u'--metric-names', required=False, default=None, help='Optional comma-separated metric names for tracking performance of training jobs. Example: Precision,Recall,AUC ')\n@click.pass_obj\ndef train(obj, input_s3_dir, output_s3_dir, hyperparams_file, ec2_type, volume_size, time_out, aws_tags, iam_role_arn, external_id, base_job_name, job_name, use_spot_instances, metric_names):\n    '\\n    Command to train ML model(s) on SageMaker\\n    '\n    logger.info(ASCII_LOGO)\n    logger.info('Started training on SageMaker...\\n')\n    if use_spot_instances:\n        time_out = 3600\n    try:\n        s3_model_location = api_cloud.train(dir=_config().sagify_module_dir, input_s3_dir=input_s3_dir, output_s3_dir=output_s3_dir, hyperparams_file=hyperparams_file, ec2_type=ec2_type, volume_size=volume_size, time_out=time_out, docker_tag=obj['docker_tag'], tags=aws_tags, aws_role=iam_role_arn, external_id=external_id, base_job_name=base_job_name, job_name=job_name, use_spot_instances=use_spot_instances, metric_names=([_val.strip() for _val in metric_names.split(',')] if metric_names else None))\n        logger.info('Training on SageMaker succeeded')\n        logger.info('Model S3 location: {}'.format(s3_model_location))\n    except ValueError as e:\n        logger.info('{}'.format(e))\n        sys.exit((- 1))\n"}
{"label_name":"train","label":0,"method_name":"generate_svm_rank_train","method":"\n\ndef generate_svm_rank_train():\n    X_train = make_X('xml\/train', 'xml\/train')\n    y = open('data\/project_train_scores.txt', 'r').read().splitlines()\n    outfile = open('train.dat', 'w')\n    print('running svm file generator train')\n    for i in range(0, len(X_train)):\n        outfile.write((y[i] + ' qid:1 '))\n        for j in range(1, (len(X_train[0]) + 1)):\n            if (X_train[i][(j - 1)] == 0):\n                continue\n            outfile.write((((str(j) + ':') + str(X_train[i][(j - 1)])) + ' '))\n        outfile.write('\\n')\n"}
{"label_name":"process","label":2,"method_name":"process","method":"\n\ndef process(jiayuan_data_base_root):\n    for gender_dir in os.listdir(jiayuan_data_base_root):\n        for province_dir in os.listdir(((jiayuan_data_base_root + os.path.sep) + gender_dir)):\n            user_lists = json_to_list(((((jiayuan_data_base_root + os.path.sep) + gender_dir) + os.path.sep) + province_dir))\n            excel_name = ((gender_dir + '-') + province_dir)\n            write_excel(user_lists, excel_name)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train(max_features, maxlen, num_nodes, dropout, optimizer, log_learning_rate, batch_size, epochs):\n    model = Sequential()\n    model.add(Embedding(max_features, 128, input_length=maxlen))\n    model.add(Bidirectional(LSTM(num_nodes)))\n    model.add(Dropout(dropout))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(OPTIMIZERS[optimizer](lr=(10 ** log_learning_rate)), loss='binary_crossentropy', metrics=['accuracy'])\n    model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=[x_test, y_test], callbacks=[EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=3, verbose=1, mode='auto'), PolyaxonCallback(), TensorBoard(log_dir=tracking.get_tensorboard_path(), histogram_freq=1), ModelCheckpoint(tracking.get_outputs_path('model'))])\n    return model.evaluate(x_test, y_test)[1]\n"}
{"label_name":"save","label":1,"method_name":"save_source_vocabs","method":"\n\ndef save_source_vocabs(source_vocabs: List[Vocab], folder: str):\n    '\\n    Saves source vocabularies (primary surface form vocabulary) and optional factor vocabularies to folder.\\n\\n    :param source_vocabs: List of source vocabularies.\\n    :param folder: Destination folder.\\n    '\n    for (i, vocab) in enumerate(source_vocabs):\n        vocab_to_json(vocab, os.path.join(folder, (C.VOCAB_SRC_NAME % i)))\n"}
{"label_name":"predict","label":4,"method_name":"accumulate_prediction","method":"\n\ndef accumulate_prediction(predict, X, out, lock):\n    prediction = predict(X, check_input=False)\n    with lock:\n        if (len(out) == 1):\n            out[0] += prediction\n        else:\n            for i in range(len(out)):\n                out[i] += prediction[i]\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train(config, inputs, args):\n    gan = setup_gan(config, inputs, args)\n    sampler = lookup_sampler((args.sampler or 'autoencode'))(gan)\n    accuracy_t = batch_accuracy(gan.inputs.x, gan.generator.sample)\n    diversity_t = batch_diversity(gan.uniform_sample)\n    metrics = [accuracy_t, diversity_t]\n    sum_metrics = [0 for metric in metrics]\n    samples = 0\n    for i in range(args.steps):\n        gan.step()\n        if (i == (args.steps - 1)):\n            for (k, metric) in enumerate(gan.session.run(metrics)):\n                print(((('Metric ' + str(k)) + ' ') + str(metric)))\n                sum_metrics[k] += metric\n        if ((i % args.sample_every) == 0):\n            print(('sampling ' + str(i)))\n            sample_file = ('samples\/%06d.png' % samples)\n            samples += 1\n            sampler.sample(sample_file, args.save_samples)\n        if ((args.action == 'train') and ((i % args.save_every) == 0) and (i > 0)):\n            print(('saving ' + save_file))\n            gan.save(save_file)\n        if ((i % 100) and (i > 500)):\n            losses = gan.session.run([loss[1] for loss in gan.trainer.losses])\n            (accuracy, diversity) = gan.session.run([accuracy_t, diversity_t])\n            has_failed = (any([math.isnan(loss) for loss in losses]) or (accuracy > 1000) or (diversity < 1000))\n            if has_failed:\n                sum_metrics = [(- 1), (- 1)]\n                print('breaking from failure detection')\n                break\n    return sum_metrics\n"}
{"label_name":"process","label":2,"method_name":"process_givenData","method":"\n\ndef process_givenData():\n    try:\n        for i in token:\n            words = nltk.word_tokenize(i)\n            tagged = nltk.pos_tag(words)\n            chunkGram = 'Chunking: {<NNS>}'\n            chunkParser = nltk.RegexpParser(chunkGram)\n            chunk = chunkParser.parse(tagged)\n            chunk.draw()\n    except Exception as e:\n        print('i am in exception')\n"}
{"label_name":"predict","label":4,"method_name":"assert_fit_predict_correct","method":"\n\ndef assert_fit_predict_correct(model, X):\n    model2 = copy.deepcopy(model)\n    predictions_1 = model.fit(X).predict(X)\n    predictions_2 = model2.fit_predict(X)\n    assert (adjusted_rand_score(predictions_1, predictions_2) == 1.0)\n"}
{"label_name":"process","label":2,"method_name":"process_decoder_input","method":"\n\ndef process_decoder_input(target_data, target_vocab_to_int, batch_size):\n    '\\n    Preprocess target data for encoding\\n    :param target_data: Target Placehoder\\n    :param target_vocab_to_int: Dictionary to go from the target words to an id\\n    :param batch_size: Batch Size\\n    :return: Preprocessed target data\\n    '\n    return None\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train():\n    'Train CIFAR-10 for a number of steps.'\n    with tf.Graph().as_default():\n        global_step = tf.train.get_or_create_global_step()\n        with tf.device('\/cpu:0'):\n            (images, labels) = cifar10.distorted_inputs()\n        logits = cifar10.inference(images)\n        loss = cifar10.loss(logits, labels)\n        train_op = cifar10.train(loss, global_step)\n\n        class _LoggerHook(tf.train.SessionRunHook):\n            'Logs loss and runtime.'\n\n            def begin(self):\n                self._step = (- 1)\n                self._start_time = time.time()\n\n            def before_run(self, run_context):\n                self._step += 1\n                return tf.train.SessionRunArgs(loss)\n\n            def after_run(self, run_context, run_values):\n                if ((self._step % FLAGS.log_frequency) == 0):\n                    current_time = time.time()\n                    duration = (current_time - self._start_time)\n                    self._start_time = current_time\n                    loss_value = run_values.results\n                    examples_per_sec = ((FLAGS.log_frequency * FLAGS.batch_size) \/ duration)\n                    sec_per_batch = float((duration \/ FLAGS.log_frequency))\n                    format_str = '%s: step %d, loss = %.2f (%.1f examples\/sec; %.3f sec\/batch)'\n                    print((format_str % (datetime.now(), self._step, loss_value, examples_per_sec, sec_per_batch)))\n        with tf.train.MonitoredTrainingSession(checkpoint_dir=FLAGS.train_dir, hooks=[tf.train.StopAtStepHook(last_step=FLAGS.max_steps), tf.train.NanTensorHook(loss), _LoggerHook()], config=tf.ConfigProto(log_device_placement=FLAGS.log_device_placement)) as mon_sess:\n            while (not mon_sess.should_stop()):\n                mon_sess.run(train_op)\n"}
{"label_name":"train","label":0,"method_name":"load_train_data","method":"\n\ndef load_train_data():\n    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n    return mnist.train.images\n"}
{"label_name":"process","label":2,"method_name":"preprocess_image","method":"\n\ndef preprocess_image(file_name, output_height=224, output_width=224, num_channels=3):\n    'Run standard ImageNet preprocessing on the passed image file.\\n\\n  Args:\\n    file_name: string, path to file containing a JPEG image\\n    output_height: int, final height of image\\n    output_width: int, final width of image\\n    num_channels: int, depth of input image\\n\\n  Returns:\\n    Float array representing processed image with shape\\n      [output_height, output_width, num_channels]\\n\\n  Raises:\\n    ValueError: if image is not a JPEG.\\n  '\n    if (imghdr.what(file_name) != 'jpeg'):\n        raise ValueError('At this time, only JPEG images are supported. Please try another image.')\n    image_buffer = tf.read_file(file_name)\n    normalized = imagenet_preprocessing.preprocess_image(image_buffer=image_buffer, bbox=None, output_height=output_height, output_width=output_width, num_channels=num_channels, is_training=False)\n    with tf.Session(config=get_gpu_config()) as sess:\n        result = sess.run([normalized])\n    return result[0]\n"}
{"label_name":"train","label":0,"method_name":"train_not_distributed","method":"\n\ndef train_not_distributed():\n    'Train a model in non-distributed TensorFlow mode.'\n    with tf.Graph().as_default() as graph:\n        (train_data, test_data, embeddings_file) = prepare_data()\n        model = create_model(False)\n        (test_loss, test_perplexity, bucket_loss_placeholders, bucket_perplexity_placeholders, summary, summary_writer) = create_summary_objects(graph)\n        with tf.Session() as sess:\n            init_model(sess, model)\n            after_init(sess, model, embeddings_file)\n            train(sess, model, train_data, test_data, summary, summary_writer, test_loss, test_perplexity, bucket_loss_placeholders, bucket_perplexity_placeholders)\n"}
{"label_name":"train","label":0,"method_name":"print_trainer_logs","method":"\n\n@trainer.on(Events.EPOCH_COMPLETED)\ndef print_trainer_logs(engine):\n    avg_loss = engine.state.metrics['loss']\n    avg_bce = engine.state.metrics['bce']\n    avg_kld = engine.state.metrics['kld']\n    print('Trainer Results - Epoch {} - Avg loss: {:.2f} Avg bce: {:.2f} Avg kld: {:.2f}'.format(engine.state.epoch, avg_loss, avg_bce, avg_kld))\n"}
{"label_name":"process","label":2,"method_name":"process_submission_callback","method":"\n\ndef process_submission_callback(body):\n    try:\n        logger.info('{} [x] Received submission message {}'.format(SUBMISSION_LOGS_PREFIX, body))\n        body = yaml.safe_load(body)\n        body = dict(((k, int(v)) for (k, v) in body.items()))\n        process_submission_message(body)\n    except Exception as e:\n        logger.exception('{} Exception while receiving message from submission queue with error {}'.format(SUBMISSION_LOGS_PREFIX, e))\n"}
{"label_name":"process","label":2,"method_name":"preprocess_for_eval","method":"\n\ndef preprocess_for_eval(image, output_height, output_width, resize_side):\n    'Preprocesses the given image for evaluation.\\n\\n  Args:\\n    image: A `Tensor` representing an image of arbitrary size.\\n    output_height: The height of the image after preprocessing.\\n    output_width: The width of the image after preprocessing.\\n    resize_side: The smallest side of the image for aspect-preserving resizing.\\n\\n  Returns:\\n    A preprocessed image.\\n  '\n    image = _aspect_preserving_resize(image, resize_side)\n    image = _central_crop([image], output_height, output_width)[0]\n    image.set_shape([output_height, output_width, 3])\n    image = tf.to_float(image)\n    return _mean_image_subtraction(image, [_R_MEAN, _G_MEAN, _B_MEAN])\n"}
{"label_name":"process","label":2,"method_name":"_preprocess_subtract_imagenet_mean","method":"\n\ndef _preprocess_subtract_imagenet_mean(inputs):\n    'Subtract Imagenet mean RGB value.'\n    mean_rgb = tf.reshape(_MEAN_RGB, [1, 1, 1, 3])\n    return (inputs - mean_rgb)\n"}
{"label_name":"process","label":2,"method_name":"_PreprocessBenchmarkInnerLoop","method":"\n\ndef _PreprocessBenchmarkInnerLoop(preprocessors_: typing.List[str], code_in: str, code_out: str):\n    'Benchmark inner loop for code with expected output.'\n    assert (preprocessors.Preprocess(code_in, preprocessors_) == code_out)\n"}
{"label_name":"save","label":1,"method_name":"save_virtual_workbook","method":"\n\ndef save_virtual_workbook(workbook):\n    'Return an in-memory workbook, suitable for a Django response.'\n    temp_buffer = BytesIO()\n    archive = ZipFile(temp_buffer, 'w', ZIP_DEFLATED, allowZip64=True)\n    writer = ExcelWriter(workbook, archive)\n    try:\n        writer.write_data()\n    finally:\n        archive.close()\n    virtual_workbook = temp_buffer.getvalue()\n    temp_buffer.close()\n    return virtual_workbook\n"}
{"label_name":"save","label":1,"method_name":"data_prep_from_saved_model","method":"\n\ndef data_prep_from_saved_model(graph_def, data_filenames, batch_size, data_prep_start_node='serialized_example:0', data_prep_end_node='DatasetToSingleElement:0'):\n    'Main function to extract data processing pipelines.'\n    data_prep_end_node_name = data_prep_end_node.split(':')[0]\n    gdef_trimmed = extract_sub_graph(graph_def, dest_nodes=[data_prep_end_node_name])\n    dataset = tf.data.TFRecordDataset(data_filenames)\n    dataset = dataset.batch(batch_size)\n    iterator = dataset.make_one_shot_iterator()\n    dataset_b = iterator.get_next()\n    (data_out,) = tf.import_graph_def(gdef_trimmed, input_map={data_prep_start_node: dataset_b}, return_elements=[data_prep_end_node])\n    fixed_shape = ([batch_size] + data_out.get_shape().as_list()[1:])\n    data_out = tf.reshape(data_out, fixed_shape)\n    return data_out\n"}
{"label_name":"train","label":0,"method_name":"mock_train_regressor","method":"\n\ndef mock_train_regressor(monkeypatch, assert_model=None, assert_model_kwargs=None):\n    'Mock the train_regressor to return the mocked regressor instead'\n\n    def train_regressor(model, data, **kwargs):\n        'Return the mocked model, and then model argument if requested'\n        if assert_model:\n            assert (model == assert_model)\n        if assert_model_kwargs:\n            assert (kwargs == assert_model_kwargs)\n        return mock_model()\n    monkeypatch.setattr('orion.analysis.partial_dependency_utils.train_regressor', train_regressor)\n"}
{"label_name":"save","label":1,"method_name":"save_smi","method":"\n\ndef save_smi(name, smiles):\n    if (not os.path.exists('epoch_data')):\n        os.makedirs('epoch_data')\n    smi_file = os.path.join('epoch_data', '{}.smi'.format(name))\n    with open(smi_file, 'w') as afile:\n        afile.write('\\n'.join(smiles))\n    return\n"}
{"label_name":"save","label":1,"method_name":"save_obj","method":"\n\ndef save_obj(obj, name):\n    with open(name, 'wb') as f:\n        pickle.dump(obj=obj, file=f)\n"}
{"label_name":"train","label":0,"method_name":"prepare_training_data","method":"\n\ndef prepare_training_data():\n    '\\n    \u51c6\u5907\u8bad\u7ec3\u6570\u636e\\n    '\n    trainset = load_dataset('data\/train_data.txt')\n    testset_recom = load_dataset('data\/test_predict_recom_data.txt')\n    test_result = load_dataset('data\/test_predict_data.txt')\n    print('Finished Loading Dataset')\n    user_file = open('data\/user_dict.pkl', 'rb')\n    user_dict = pickle.load(user_file)\n    user_file.close()\n    print('Finished Loading User Dict')\n    product_file = open('data\/product_dict.pkl', 'rb')\n    product_dict = pickle.load(product_file)\n    product_file.close()\n    print('Finished Loading Product Dict')\n    return (trainset, testset_recom, test_result, product_dict, user_dict)\n"}
{"label_name":"process","label":2,"method_name":"vqa_v2_preprocess_image","method":"\n\ndef vqa_v2_preprocess_image(image, height, width, mode, resize_side=512, distort=True, image_model_fn='resnet_v1_152'):\n    'vqa v2 preprocess image.'\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    assert (resize_side > 0)\n    if resize_side:\n        image = _aspect_preserving_resize(image, resize_side)\n    if (mode == tf.estimator.ModeKeys.TRAIN):\n        image = tf.random_crop(image, [height, width, 3])\n    else:\n        image = tf.image.resize_image_with_crop_or_pad(image, height, width)\n    image = tf.clip_by_value(image, 0.0, 1.0)\n    if ((mode == tf.estimator.ModeKeys.TRAIN) and distort):\n        image = _flip(image)\n        num_distort_cases = 4\n        image = _apply_with_random_selector(image, (lambda x, ordering: _distort_color(x, ordering)), num_cases=num_distort_cases)\n    if image_model_fn.startswith('resnet_v1'):\n        image = (image * 255.0)\n        image = _mean_image_subtraction(image, [_R_MEAN, _G_MEAN, _B_MEAN])\n    elif image_model_fn.startswith('resnet_v2'):\n        image = tf.subtract(image, 0.5)\n        image = tf.multiply(image, 2.0)\n    return image\n"}
{"label_name":"train","label":0,"method_name":"train_svm_history","method":"\n\ndef train_svm_history(project, params, output_file_path):\n    params_model = params['model']\n    if (params_model.get('classifier') != 'svm'):\n        raise GaiaWrapperException('Can only use this script on SVM config parameters.')\n    ds = DataSet()\n    fname = os.path.join(project['datasetsDirectory'], ('%s-%s.db' % (project['className'], params_model['preprocessing'])))\n    ds.load(str(fname))\n    gt = GroundTruth.fromFile(project['groundtruth'])\n    gt.className = str(('highlevel.' + project['className']))\n    history = train_svm(ds, gt, type=params_model['type'], kernel=params_model['kernel'], C=params_model['C'], gamma=params_model['gamma'])\n    if isinstance(output_file_path, unicode):\n        output_file_path = output_file_path.encode('utf-8')\n    history.save(output_file_path)\n"}
{"label_name":"process","label":2,"method_name":"corpus_preprocess","method":"\n\ndef corpus_preprocess(corpus):\n    import re\n    ret = []\n    for line in corpus:\n        x = re.sub('\\\\d', '#', line)\n        ret.append(x)\n    return ret\n"}
{"label_name":"predict","label":4,"method_name":"get_predictions","method":"\n\ndef get_predictions(output, idx, detect_thresh=0.05):\n    (bbox_pred, scores, preds) = process_output(output, idx, detect_thresh)\n    to_keep = nms(bbox_pred, scores)\n    return (bbox_pred[to_keep], preds[to_keep], scores[to_keep])\n"}
{"label_name":"predict","label":4,"method_name":"predict_throughput_pack_sum","method":"\n\ndef predict_throughput_pack_sum(raw_preds, pack_ids):\n    'Predict the throughputs for predictions in pack-sum format\\n    Parameters\\n    ----------\\n    raw_preds: np.ndarray\\n        The raw predictions\\n    pack_ids: List[int]\\n        The pack id for predictions\\n    Returns\\n    -------\\n    throughputs: np.ndarray\\n        The throughput\\n    '\n    sum_pred = np.bincount(pack_ids, weights=raw_preds)\n    return sum_pred\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train(num, base_path=base_path):\n    '\\n\\tthis function is used to process train.bid.txt format\\n\\tnum:sequence number of the iPinYou,str\\n\\t'\n    train_data_file = os.path.join(base_path, num, train_file)\n    b_data = defaultdict(list)\n    fi = open(train_data_file, 'r')\n    size = 0\n    maxb = 0\n    for line in fi:\n        s = line.strip().split()\n        b = int(s[0])\n        maxb = max(b, maxb)\n        o = int(s[1])\n        b_data[b].append(o)\n        size += 1\n    fi.close()\n    b_data = sorted(b_data.items(), key=(lambda e: e[0]), reverse=False)\n    b_data = dict(b_data)\n    bdns = []\n    wins = 0\n    for z in b_data:\n        wins = sum(b_data[z])\n        b = z\n        d = wins\n        n = size\n        bdn = [b, d, n]\n        bdns.append(bdn)\n        size -= len(b_data[z])\n    zw_dict = {}\n    min_p_w = 0\n    bdns_length = len(bdns)\n    count = 0\n    p_l_tmp = 1.0\n    for bdn in bdns:\n        count += 1\n        b = float(bdn[0])\n        d = float(bdn[1])\n        n = float(bdn[2])\n        if (count < bdns_length):\n            p_l_tmp *= ((n - d) \/ n)\n        p_l = p_l_tmp\n        p_w = max((1.0 - p_l), min_p_w)\n        zw_dict[int(b)] = p_w\n    return (zw_dict, maxb)\n"}
{"label_name":"predict","label":4,"method_name":"sklearn_multiclass_prediction","method":"\n\ndef sklearn_multiclass_prediction(mode, X_train, y_train, X_test):\n    \"\\n    Use Scikit Learn built-in functions multiclass.OneVsRestClassifier\\n    and multiclass.OneVsOneClassifier to perform multiclass classification.\\n\\n    Arguments:\\n        mode: one of 'ovr', 'ovo' or 'crammer'.\\n        X_train, X_test: numpy ndarray of training and test features.\\n        y_train: labels of training data, from 0 to 9.\\n\\n    Returns:\\n        y_pred_train, y_pred_test: a tuple of 2 numpy ndarrays,\\n                                   being your prediction of labels on\\n                                   training and test data, from 0 to 9.\\n    \"\n    if (mode == 'ovo'):\n        clf = multiclass.OneVsOneClassifier(svm.LinearSVC(random_state=12345), n_jobs=(- 3))\n    elif (mode == 'ovr'):\n        clf = multiclass.OneVsRestClassifier(svm.LinearSVC(random_state=12345), n_jobs=(- 3))\n    elif (mode == 'crammer'):\n        clf = svm.LinearSVC(random_state=12345, multi_class='crammer_singer')\n    else:\n        print('Unknown mode', mode)\n    clf.fit(X_train, y_train)\n    y_pred_train = clf.predict(X_train)\n    y_pred_test = clf.predict(X_test)\n    return (y_pred_train, y_pred_test)\n"}
{"label_name":"predict","label":4,"method_name":"get_predictions","method":"\n\ndef get_predictions(logits):\n    '\\n    Define predictions to use with evaluation metrics or TF Serving.\\n    '\n    prediction = tf.round(tf.nn.sigmoid(logits))\n    predictions = {'prediction': prediction}\n    return predictions\n"}
{"label_name":"predict","label":4,"method_name":"predict","method":"\n\ndef predict(theta):\n    print(theta)\n    dir = 'Task1\/'\n    files = os.listdir(dir)\n    files = sorted(files, key=(lambda x: (int(re.sub('\\\\D', '', x)), x)))\n    testDir = 'testFiles\/'\n    testfiles = os.listdir(testDir)\n    random.shuffle(testfiles)\n    xAll = []\n    yAll = []\n    for iterFile in range(0, len(files)):\n        currFile = files[iterFile]\n        fid = open((dir + currFile), 'r')\n        lines = fid.readlines()\n        lines = [l.strip('\\n\\r') for l in lines]\n        lines = lines[1:len(lines)]\n        xVal = []\n        yVal = []\n        for x in lines:\n            xVal.append(float(x.split()[0]))\n            yVal.append(float(x.split()[1]))\n        fid.close()\n        xAll.append(xVal)\n        yAll.append(yVal)\n    result = []\n    for testIdx in range(0, len(testfiles)):\n        name = testfiles[testIdx]\n        print(name)\n        TESTFILEPATH = (testDir + name)\n        (X, Y, userID) = getXY(xAll, yAll, TESTFILEPATH)\n        print('\\nUSER ID: ', userID, '\\n')\n        if (int(name[4:6]) < 20):\n            gen = 1\n        else:\n            gen = 0\n        data = np.array((1, X, Y))\n        inner_prod = np.dot(data, theta)\n        h_theta = sigmoid(inner_prod)\n        if (h_theta >= 0.5):\n            gentes = 1\n        else:\n            gentes = 0\n        if (gen == gentes):\n            result.append(1)\n        else:\n            result.append(0)\n    countOnes = 0\n    print(result)\n    for i in range(0, len(result)):\n        if (result[i] == 1):\n            countOnes += 1\n    accuracy = ((float(countOnes) \/ len(result)) * 100)\n    print(accuracy)\n"}
{"label_name":"process","label":2,"method_name":"_process_image","method":"\n\ndef _process_image(filename, coder):\n    \"Process a single image file.\\n\\n  Args:\\n    filename: string, path to an image file e.g., '\/path\/to\/example.JPG'.\\n    coder: instance of ImageCoder to provide TensorFlow image coding utils.\\n  Returns:\\n    image_buffer: string, JPEG encoding of RGB image.\\n    height: integer, image height in pixels.\\n    width: integer, image width in pixels.\\n  \"\n    with tf.gfile.FastGFile(filename, 'rb') as f:\n        image_data = f.read()\n    if _is_png(filename):\n        print(('Converting PNG to JPEG for %s' % filename))\n        image_data = coder.png_to_jpeg(image_data)\n    elif _is_cmyk(filename):\n        print(('Converting CMYK to RGB for %s' % filename))\n        image_data = coder.cmyk_to_rgb(image_data)\n    image = coder.decode_jpeg(image_data)\n    assert (len(image.shape) == 3)\n    height = image.shape[0]\n    width = image.shape[1]\n    assert (image.shape[2] == 3)\n    return (image_data, height, width)\n"}
{"label_name":"train","label":0,"method_name":"load_train_data","method":"\n\ndef load_train_data(filename):\n    ext = filename.split('.')[(- 1)]\n    if (ext == 'csv'):\n        return read_smiles_csv(filename)\n    if (ext == 'smi'):\n        return read_smi(filename)\n    else:\n        raise ValueError('data is not smi or csv!')\n    return\n"}
{"label_name":"predict","label":4,"method_name":"to_dataset_for_prediction","method":"\n\ndef to_dataset_for_prediction(df, k, with_bias):\n    df = df[1:].reset_index(drop=True)\n    df = df.drop(['date'], axis=1)\n    (n, cols) = df.shape\n    windows_num = ((n - k) + 1)\n    x = np.empty([windows_num, ((k * cols) + int(with_bias))])\n    for i in range(windows_num):\n        window = df[i:(i + k)]\n        row = window.as_matrix().reshape(((- 1),))\n        if with_bias:\n            row = np.insert(row, 0, 1)\n        x[i] = row\n    vlog('Data set for prediction:', x.shape)\n    return x\n"}
{"label_name":"process","label":2,"method_name":"ngramPreprocess","method":"\n\ndef ngramPreprocess(comment, lemm=True):\n    starting = str(comment.encode('utf-8', 'replace')).lower()\n    starting = starting.replace('](', '] (')\n    tokens = starting.split()\n    acceptablePunct = string.punctuation.replace('<=>', '=')\n    for (idx, token) in enumerate(tokens):\n        tokens[idx] = ''.join((char for char in token if (char not in acceptablePunct)))\n    acceptable = (string.ascii_lowercase + string.digits)\n    if lemm:\n        tokens = [Word(token).lemmatize() for token in tokens if ((False not in [(letter in acceptable) for letter in token]) and (len(token) > 0))]\n    else:\n        tokens = [token for token in tokens if ((False not in [(letter in acceptable) for letter in token]) and (len(token) > 0))]\n    return ' '.join(tokens)\n"}
{"label_name":"predict","label":4,"method_name":"get_prediction","method":"\n\n@app.route('\/titanic', methods=['POST'])\ndef get_prediction():\n    data = request.json\n    titanic_test = pd.DataFrame(data)\n    print(titanic_test.shape)\n    print(titanic_test.info())\n    titanic_test.loc[((titanic_test['Fare'].isnull() == True), 'Fare')] = titanic_test['Fare'].mean()\n    titanic_test1 = pd.get_dummies(titanic_test, columns=cat_columns)\n    titanic_test1.drop(['PassengerId', 'Name', 'Age', 'Ticket', 'Cabin'], axis=1, inplace=True)\n    predictions = classifier.predict(titanic_test1)\n    print(predictions)\n    return jsonify(prediction=predictions)\n"}
{"label_name":"train","label":0,"method_name":"pretrain","method":"\n\ndef pretrain(sess, generator, target_lstm, train_discriminator):\n    gen_data_loader = Gen_Data_loader(BATCH_SIZE)\n    gen_data_loader.create_batches(positive_samples)\n    results = OrderedDict({'exp_name': PREFIX})\n    print('Start pre-training...')\n    for epoch in range(PRE_EPOCH_NUM):\n        print('pre-train epoch:', epoch)\n        loss = pre_train_epoch(sess, generator, gen_data_loader)\n        if ((epoch == 10) or ((epoch % 40) == 0)):\n            samples = generate_samples(sess, generator, BATCH_SIZE, SAMPLE_NUM)\n            likelihood_data_loader.create_batches(samples)\n            test_loss = target_loss(sess, target_lstm, likelihood_data_loader)\n            print('\\t test_loss {}, train_loss {}'.format(test_loss, loss))\n            mm.compute_results(samples, train_samples, ord_dict, results)\n    samples = generate_samples(sess, generator, BATCH_SIZE, SAMPLE_NUM)\n    likelihood_data_loader.create_batches(samples)\n    test_loss = target_loss(sess, target_lstm, likelihood_data_loader)\n    samples = generate_samples(sess, generator, BATCH_SIZE, SAMPLE_NUM)\n    likelihood_data_loader.create_batches(samples)\n    print('Start training discriminator...')\n    for i in range(dis_alter_epoch):\n        print('epoch {}'.format(i))\n        (d_loss, acc) = train_discriminator()\n    return\n"}
{"label_name":"predict","label":4,"method_name":"plot_predictions_3d","method":"\n\ndef plot_predictions_3d(ax_data, ax_pred, low, high, func, model):\n    \"Plots a 3D contour of the function c=sqrt(a^2 + b^2) and the model's predictions.\\n\\n    Arguments:\\n        ax_data(Axes3D): A matplotlib Axes3D object.\\n        ax_pred(Axes3D): A matplotlib Axes3D object\\n        low(int): The smallest value for x and y.\\n        high(int): The largest value for x and y.\\n        func(function): The 3D function underlying the data.\\n        model(Sequential): A trained keras Sequential model.\\n    \"\n    x = np.linspace(low, high, 100)\n    y = np.linspace(low, high, 100)\n    (X, Y) = np.meshgrid(x, y)\n    Z = func(X, Y)\n    ax_data.contour3D(X, Y, Z, 500, cmap=plt.cm.viridis)\n    Z_pred = model.predict(np.c_[(X.ravel(), Y.ravel())])\n    Z_pred = Z_pred.reshape(X.shape)\n    ax_pred.contour3D(X, Y, Z_pred, 500, cmap=plt.cm.plasma)\n"}
{"label_name":"save","label":1,"method_name":"save_csv","method":"\n\ndef save_csv(out_file, data):\n    with open(out_file, 'wb') as f:\n        writer = csv.writer(f)\n        writer.writerows(data)\n    print(('Data saved to file: %s' % out_file))\n"}
{"label_name":"predict","label":4,"method_name":"make_prediction","method":"\n\ndef make_prediction(X_test):\n    '\\n    send PUT request to an IP:PORT. a server should be listening \\n    on the other end, ready to respond with predictions.\\n    '\n    r = requests.put('http:\/\/localhost:5000\/api', json={'input': X_test})\n    return r.json()['pred_val']\n"}
{"label_name":"save","label":1,"method_name":"save_pickle","method":"\n\ndef save_pickle(data, filepath):\n    save_documents = open(filepath, 'wb')\n    pickle.dump(data, save_documents)\n    save_documents.close()\n"}
{"label_name":"train","label":0,"method_name":"get_train_eval_loaders","method":"\n\ndef get_train_eval_loaders(path, batch_size=256):\n    'Setup the dataflow:\\n        - load CIFAR100 train and test datasets\\n        - setup train\/test image transforms\\n            - horizontally flipped randomly and augmented using cutout.\\n            - each mini-batch contained 256 examples\\n        - setup train\/test data loaders\\n\\n    Returns:\\n        train_loader, test_loader, eval_train_loader\\n    '\n    train_transform = Compose([Pad(4), RandomCrop(32), RandomHorizontalFlip(), ToTensor(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), RandomErasing()])\n    test_transform = Compose([ToTensor(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n    train_dataset = CIFAR100(root=path, train=True, transform=train_transform, download=True)\n    test_dataset = CIFAR100(root=path, train=False, transform=test_transform, download=False)\n    train_eval_indices = [random.randint(0, (len(train_dataset) - 1)) for i in range(len(test_dataset))]\n    train_eval_dataset = Subset(train_dataset, train_eval_indices)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=12, shuffle=True, drop_last=True, pin_memory=True)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=12, shuffle=False, drop_last=False, pin_memory=True)\n    eval_train_loader = DataLoader(train_eval_dataset, batch_size=batch_size, num_workers=12, shuffle=False, drop_last=False, pin_memory=True)\n    return (train_loader, test_loader, eval_train_loader)\n"}
{"label_name":"predict","label":4,"method_name":"predict","method":"\n\ndef predict(json_input):\n    '\\n    Prediction given the request input\\n    :param json_input: [dict], request input\\n    :return: [dict], prediction\\n    '\n    model_input = None\n    prediction = ModelService.predict(model_input)\n    print(prediction)\n    result = {}\n    return result\n"}
{"label_name":"train","label":0,"method_name":"generate_training_command","method":"\n\ndef generate_training_command(model_folder):\n    'Generate a string that contains a command with all necessary\\n    parameters to train the model.'\n    update_if_outdated(model_folder)\n    model_description_file = os.path.join(model_folder, 'info.yml')\n    with open(model_description_file) as ymlfile:\n        model_description = yaml.safe_load(ymlfile)\n    project_root = utils.get_project_root()\n    data = {}\n    data['training'] = os.path.join(project_root, model_description['data-source'], 'traindata.hdf5')\n    data['testing'] = os.path.join(project_root, model_description['data-source'], 'testdata.hdf5')\n    data['validating'] = os.path.join(project_root, model_description['data-source'], 'validdata.hdf5')\n    basename = 'model'\n    latest_model = utils.get_latest_working_model(model_folder)\n    if (latest_model == ''):\n        logger.error(f\"There is no model with basename '{basename}' in {model_folder}\")\n        return None\n    logger.info(f\"Model '{latest_model}' found.\")\n    i = int(latest_model.split('-')[(- 1)].split('.')[0])\n    model_src = os.path.join(model_folder, f'{basename}-{i}.json')\n    model_target = os.path.join(model_folder, f'{basename}-{(i + 1)}.json')\n    training = model_description['training']\n    training = training.replace('{{testing}}', data['testing'])\n    training = training.replace('{{training}}', data['training'])\n    training = training.replace('{{validation}}', data['validating'])\n    training = training.replace('{{src_model}}', model_src)\n    training = training.replace('{{target_model}}', model_target)\n    training = training.replace('{{nntoolkit}}', utils.get_nntoolkit())\n    return training\n"}
{"label_name":"process","label":2,"method_name":"layer_prepostprocess_dropout","method":"\n\ndef layer_prepostprocess_dropout(x, hparams):\n    batch_dim = x.shape.dims[0]\n    model_dim = x.shape.dims[(- 1)]\n    mode = getattr(hparams, 'mode', tf.estimator.ModeKeys.TRAIN)\n    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n    return mtf.dropout(x, is_training, keep_prob=(1.0 - hparams.layer_prepostprocess_dropout), noise_shape=mtf.Shape([batch_dim, model_dim]))\n"}
{"label_name":"process","label":2,"method_name":"preprocess_for_eval","method":"\n\ndef preprocess_for_eval(image, height, width, central_fraction=0.875, scope=None):\n    'Prepare one image for evaluation.\\n\\n  If height and width are specified it would output an image with that size by\\n  applying resize_bilinear.\\n  If central_fraction is specified it would crop the central fraction of the\\n  input image.\\n\\n  Args:\\n    image: 3-D Tensor of image. If dtype is tf.float32 then the range should be\\n      [0, 1], otherwise it would converted to tf.float32 assuming that the range\\n      is [0, MAX], where MAX is largest positive representable number for\\n      int(8\/16\/32) data type (see `tf.image.convert_image_dtype` for details)\\n    height: integer\\n    width: integer\\n    central_fraction: Optional Float, fraction of the image to crop.\\n    scope: Optional scope for name_scope.\\n  Returns:\\n    3-D float Tensor of prepared image.\\n  '\n    with tf.name_scope(scope, 'eval_image', [image, height, width]):\n        if (image.dtype != tf.float32):\n            image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n        if central_fraction:\n            image = tf.image.central_crop(image, central_fraction=central_fraction)\n        if (height and width):\n            image = tf.expand_dims(image, 0)\n            image = tf.image.resize_bilinear(image, [height, width], align_corners=False)\n            image = tf.squeeze(image, [0])\n        image = tf.subtract(image, 0.5)\n        image = tf.multiply(image, 2.0)\n        return image\n"}
{"label_name":"save","label":1,"method_name":"save_field","method":"\n\ndef save_field(field, mongo_url, skip_save_to_mongodb):\n    with open('ncaa-field.json', 'w') as f:\n        json.dump(field, f)\n    if skip_save_to_mongodb:\n        return\n    client = MongoClient(mongo_url)\n    db = client.clarktechsports\n    db.ncaa_field.update_many({}, {'$set': {'latest': False}})\n    db.ncaa_field.insert({'latest': True, 'field': field})\n"}
{"label_name":"predict","label":4,"method_name":"get_image_to_emotion_predictor","method":"\n\ndef get_image_to_emotion_predictor(model_path='assets\/model_best.pth'):\n    'Returns predictor, from image to emotion index.'\n    net = Net().float()\n    pretrained_model = torch.load(model_path)\n    net.load_state_dict(pretrained_model['state_dict'])\n\n    def predictor(image: np.array):\n        'Translates images into emotion indices.'\n        if (image.shape[2] > 1):\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        frame = cv2.resize(image, (48, 48)).reshape((1, 1, 48, 48))\n        X = Variable(torch.from_numpy(frame)).float()\n        return np.argmax(net(X).data.numpy(), axis=1)[0]\n    return predictor\n"}
{"label_name":"save","label":1,"method_name":"save_templates","method":"\n\ndef save_templates():\n    scriptDirectory = os.path.dirname(os.path.abspath(__file__))\n    snidTemplateDirectory = os.path.join(scriptDirectory, '..\/templates\/snid_templates_Modjaz_BSNIP\/')\n    snidTempFileList = (snidTemplateDirectory + 'templist.txt')\n    galTemplateDirectory = os.path.join(scriptDirectory, '..\/templates\/superfit_templates\/gal\/')\n    galTempFileList = (galTemplateDirectory + 'gal.list')\n    saveTemplateSpectra = SaveTemplateSpectra('data_files\/training_params.pickle')\n    saveFilename = 'data_files\/sn_and_gal_templates.pklz'\n    saveTemplateSpectra.save_templates(snidTempFileList, snidTemplateDirectory, galTempFileList, galTemplateDirectory, saveFilename)\n    return saveFilename\n"}
{"label_name":"predict","label":4,"method_name":"_fit_and_predict","method":"\n\ndef _fit_and_predict(estimator, X, y, train, test, verbose, fit_params, method):\n    \"Fit estimator and predict values for a given dataset split.\\n\\n    Read more in the :ref:`User Guide <cross_validation>`.\\n\\n    Parameters\\n    ----------\\n    estimator : estimator object implementing 'fit' and 'predict'\\n        The object to use to fit the data.\\n\\n    X : array-like of shape at least 2D\\n        The data to fit.\\n\\n    y : array-like, optional, default: None\\n        The target variable to try to predict in the case of\\n        supervised learning.\\n\\n    train : array-like, shape (n_train_samples,)\\n        Indices of training samples.\\n\\n    test : array-like, shape (n_test_samples,)\\n        Indices of test samples.\\n\\n    verbose : integer\\n        The verbosity level.\\n\\n    fit_params : dict or None\\n        Parameters that will be passed to ``estimator.fit``.\\n\\n    method : string\\n        Invokes the passed method name of the passed estimator.\\n\\n    Returns\\n    -------\\n    predictions : sequence\\n        Result of calling 'estimator.method'\\n\\n    test : array-like\\n        This is the value of the test parameter\\n    \"\n    fit_params = (fit_params if (fit_params is not None) else {})\n    fit_params = dict([(k, _index_param_value(X, v, train)) for (k, v) in fit_params.items()])\n    (X_train, y_train) = _safe_split(estimator, X, y, train)\n    (X_test, _) = _safe_split(estimator, X, y, test, train)\n    if (y_train is None):\n        estimator.fit(X_train, **fit_params)\n    else:\n        estimator.fit(X_train, y_train, **fit_params)\n    func = getattr(estimator, method)\n    predictions = func(X_test)\n    if (method in ['decision_function', 'predict_proba', 'predict_log_proba']):\n        n_classes = len(set(y))\n        if (n_classes != len(estimator.classes_)):\n            recommendation = 'To fix this, use a cross-validation technique resulting in properly stratified folds'\n            warnings.warn('Number of classes in training fold ({}) does not match total number of classes ({}). Results may not be appropriate for your use case. {}'.format(len(estimator.classes_), n_classes, recommendation), RuntimeWarning)\n            if (method == 'decision_function'):\n                if ((predictions.ndim == 2) and (predictions.shape[1] != len(estimator.classes_))):\n                    raise ValueError('Output shape {} of {} does not match number of classes ({}) in fold. Irregular decision_function outputs are not currently supported by cross_val_predict'.format(predictions.shape, method, len(estimator.classes_), recommendation))\n                if (len(estimator.classes_) <= 2):\n                    raise ValueError('Only {} class\/es in training fold, this is not supported for decision_function with imbalanced folds. {}'.format(len(estimator.classes_), recommendation))\n            float_min = np.finfo(predictions.dtype).min\n            default_values = {'decision_function': float_min, 'predict_log_proba': float_min, 'predict_proba': 0}\n            predictions_for_all_classes = np.full((_num_samples(predictions), n_classes), default_values[method])\n            predictions_for_all_classes[:, estimator.classes_] = predictions\n            predictions = predictions_for_all_classes\n    return (predictions, test)\n"}
{"label_name":"process","label":2,"method_name":"process_data","method":"\n\ndef process_data(word_sentences, max_len, word_to_ix):\n    sequences = np.zeros((len(word_sentences), max_len, len(word_to_ix)))\n    for (i, sentence) in enumerate(word_sentences):\n        for (j, word) in enumerate(sentence):\n            sequences[(i, j, word)] = 1.0\n    return sequences\n"}
{"label_name":"train","label":0,"method_name":"in_training_mode","method":"\n\ndef in_training_mode(options):\n    return (options.mode == deeptrio_pb2.DeepTrioOptions.TRAINING)\n"}
{"label_name":"predict","label":4,"method_name":"predict_analysis_inference","method":"\n\ndef predict_analysis_inference(data):\n    output = PredictorTools(MODEL_SAVE_DIR, MODEL_FILENAME, PARAMS_FILENAME, [data])\n    out = output()\n    return out\n"}
{"label_name":"train","label":0,"method_name":"train_seq2seq","method":"\n\ndef train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):\n    'Train a model for sequence to sequence.'\n    net.initialize(init.Xavier(), force_reinit=True, ctx=device)\n    trainer = gluon.Trainer(net.collect_params(), 'adam', {'learning_rate': lr})\n    loss = MaskedSoftmaxCELoss()\n    animator = d2l.Animator(xlabel='epoch', ylabel='loss', xlim=[10, num_epochs])\n    for epoch in range(num_epochs):\n        timer = d2l.Timer()\n        metric = d2l.Accumulator(2)\n        for batch in data_iter:\n            (X, X_valid_len, Y, Y_valid_len) = [x.as_in_ctx(device) for x in batch]\n            bos = np.array(([tgt_vocab['<bos>']] * Y.shape[0]), ctx=device).reshape((- 1), 1)\n            dec_input = d2l.concat([bos, Y[:, :(- 1)]], 1)\n            with autograd.record():\n                (Y_hat, _) = net(X, dec_input, X_valid_len)\n                l = loss(Y_hat, Y, Y_valid_len)\n            l.backward()\n            d2l.grad_clipping(net, 1)\n            num_tokens = Y_valid_len.sum()\n            trainer.step(num_tokens)\n            metric.add(l.sum(), num_tokens)\n        if (((epoch + 1) % 10) == 0):\n            animator.add((epoch + 1), ((metric[0] \/ metric[1]),))\n    print(f'loss {(metric[0] \/ metric[1]):.3f}, {(metric[1] \/ timer.stop()):.1f} tokens\/sec on {str(device)}')\n"}
{"label_name":"train","label":0,"method_name":"train_agent_real_env","method":"\n\ndef train_agent_real_env(env, learner, hparams, epoch):\n    'Train the PPO agent in the real environment.'\n    base_algo_str = hparams.base_algo\n    train_hparams = trainer_lib.create_hparams(hparams.base_algo_params)\n    rl_utils.update_hparams_from_hparams(train_hparams, hparams, (('real_' + base_algo_str) + '_'))\n    if hparams.wm_policy_param_sharing:\n        train_hparams.optimizer_zero_grads = True\n    env_fn = rl.make_real_env_fn(env)\n    num_env_steps = real_env_step_increment(hparams)\n    learner.train(env_fn, train_hparams, simulated=False, save_continuously=False, epoch=epoch, sampling_temp=hparams.real_sampling_temp, num_env_steps=num_env_steps)\n    env.reset()\n"}
{"label_name":"train","label":0,"method_name":"subsubtrain_split_method","method":"\n\ndef subsubtrain_split_method() -> str:\n    return _get_name_from_file('subsubtrain_split_method')\n"}
{"label_name":"process","label":2,"method_name":"post_process_samples","method":"\n\ndef post_process_samples(samples, config: TrainerConfigDict):\n    split_lst = []\n    for sample in samples:\n        indexes = np.asarray(sample['dones']).nonzero()[0]\n        indexes = (indexes + 1)\n        reward_list = np.split(sample['rewards'], indexes)[:(- 1)]\n        observation_list = np.split(sample['obs'], indexes)[:(- 1)]\n        paths = []\n        for i in range(0, len(reward_list)):\n            paths.append({'rewards': reward_list[i], 'observations': observation_list[i]})\n        paths = calculate_gae_advantages(paths, config['gamma'], config['lambda'])\n        advantages = np.concatenate([path['advantages'] for path in paths])\n        sample['advantages'] = standardized(advantages)\n        split_lst.append(sample.count)\n    return (samples, split_lst)\n"}
{"label_name":"process","label":2,"method_name":"preprocess_tags","method":"\n\ndef preprocess_tags(filename, threshold):\n    sounds = json.load(open(filename))\n    tags = {sound['id']: [sound['tags']] for sound in sounds}\n    df = pd.DataFrame(tags).transpose().rename(columns={0: 'tags'})\n    vocabulary = make_vocabulary(df, threshold)\n    df.tags = df.tags.map((lambda x: preprocess(_filter(x, vocabulary.index))))\n    df = df[df.tags.map((lambda x: (len(x) > 0)))]\n    df.tags = df.tags.str.join(' ')\n    return df\n"}
{"label_name":"train","label":0,"method_name":"train_model","method":"\n\ndef train_model(train):\n    train = list(read_corpus(train))\n    model = Doc2Vec(size=30, window=10, min_count=1, workers=11, alpha=0.025, min_alpha=0.025)\n    model.build_vocab(train)\n    model.train(train, total_examples=model.corpus_count, epochs=model.iter)\n    return model\n"}
{"label_name":"predict","label":4,"method_name":"predict_image_with_CNN","method":"\n\ndef predict_image_with_CNN(path, model):\n    '\\n        predicts an image\\n        Returns:\\n            path of the image and its class\\n    '\n    img = image_utils.load_img(path, target_size=(100, 100))\n    img = PIL.ImageOps.invert(img)\n    img = image_utils.img_to_array(img)\n    img = (img \/ 255.0)\n    img = img.reshape(1, img.shape[0], img.shape[1], img.shape[2])\n    y = model.predict_classes(img, verbose=0, batch_size=1)\n    return (path, T.classes[y[0]])\n"}
{"label_name":"train","label":0,"method_name":"train_model","method":"\n\ndef train_model(model, nb_epoch, generators, callbacks=[]):\n    (train_generator, validation_generator) = generators\n    model.fit_generator(train_generator, steps_per_epoch=100, validation_data=validation_generator, validation_steps=10, epochs=nb_epoch, callbacks=callbacks)\n    return model\n"}
{"label_name":"process","label":2,"method_name":"preprocess","method":"\n\ndef preprocess(args):\n    '\\n    Extract a tensor of (arrivals,departures) to Embarcadero station.\\n    '\n    print('Loading data')\n    dataset = load_bart_od()\n    i = dataset['stations'].index('EMBR')\n    arrivals = dataset['counts'][:, :, i].sum((- 1))\n    departures = dataset['counts'][:, i, :].sum((- 1))\n    data = torch.stack([arrivals, departures], dim=(- 1))\n    covariates = torch.zeros(len(data), 0)\n    return (data, covariates)\n"}
{"label_name":"train","label":0,"method_name":"add_train_parser","method":"\n\ndef add_train_parser(subparsers, formatter_class):\n    subparser = subparsers.add_parser('train', formatter_class=formatter_class, help='Train an NLU engine on a provided dataset')\n    subparser.add_argument('dataset_path', type=str, help='Path to the training dataset file')\n    subparser.add_argument('output_path', type=str, help='Path of the output model')\n    subparser.add_argument('-c', '--config_path', type=str, help='Path to the NLU engine configuration')\n    subparser.add_argument('-r', '--random_seed', type=int, help='Random seed to use for training')\n    subparser.add_argument('-v', '--verbosity', action='count', default=0, help='Increase output verbosity')\n    subparser.set_defaults(func=_train)\n    return subparser\n"}
{"label_name":"process","label":2,"method_name":"process_box","method":"\n\ndef process_box(self, b, h, w, threshold):\n    max_indx = np.argmax(b.probs)\n    max_prob = b.probs[max_indx]\n    label = self.meta['labels'][max_indx]\n    if (max_prob > threshold):\n        left = int(((b.x - (b.w \/ 2.0)) * w))\n        right = int(((b.x + (b.w \/ 2.0)) * w))\n        top = int(((b.y - (b.h \/ 2.0)) * h))\n        bot = int(((b.y + (b.h \/ 2.0)) * h))\n        if (left < 0):\n            left = 0\n        if (right > (w - 1)):\n            right = (w - 1)\n        if (top < 0):\n            top = 0\n        if (bot > (h - 1)):\n            bot = (h - 1)\n        mess = '{}'.format(label)\n        return (left, right, top, bot, mess, max_indx, max_prob)\n    return None\n"}
{"label_name":"process","label":2,"method_name":"process_rollouts","method":"\n\ndef process_rollouts(rollouts, gamma, lambda_=1.0):\n    'Convert a batch of rollouts into tensors ready to be fed into a model.\\n\\n  Lists from each episode are stacked into 2D tensors and padded with 0s up to\\n  the maximum timestep in the batch.\\n\\n  Args:\\n    rollouts: A list of Rollout instances.\\n    gamma: The discount factor. A number between 0 and 1 (inclusive). See gamma\\n        argument in discounted_advantage_and_rewards.\\n    lambda_: See lambda_ argument in discounted_advantage_and_rewards.\\n\\n  Returns:\\n    Batch instance. states, actions, discounted_adv, and discounted_r are\\n    numpy arrays with shape (batch_size, max_episode_length). episode_lengths\\n    is a list of ints. total_rewards is a list of floats (total reward in each\\n    episode). batch_size and max_time are ints.\\n\\n  Raises:\\n    ValueError: If any of the rollouts are not terminal.\\n  '\n    for ro in rollouts:\n        if (not ro.terminated):\n            raise ValueError('Can only process terminal rollouts.')\n    episode_lengths = [len(ro.states) for ro in rollouts]\n    batch_size = len(rollouts)\n    max_time = max(episode_lengths)\n    states = utils.stack_pad([ro.states for ro in rollouts], 0, max_time)\n    actions = utils.stack_pad([ro.actions for ro in rollouts], 0, max_time)\n    discounted_rewards = ([None] * batch_size)\n    discounted_adv = ([None] * batch_size)\n    for (i, ro) in enumerate(rollouts):\n        (disc_r, disc_adv) = discounted_advantage_and_rewards(ro.rewards, ro.values, gamma, lambda_)\n        discounted_rewards[i] = disc_r\n        discounted_adv[i] = disc_adv\n    discounted_rewards = utils.stack_pad(discounted_rewards, 0, max_time)\n    discounted_adv = utils.stack_pad(discounted_adv, 0, max_time)\n    total_rewards = [sum(ro.rewards) for ro in rollouts]\n    return Batch(states=states, actions=actions, discounted_adv=discounted_adv, discounted_r=discounted_rewards, total_rewards=total_rewards, episode_lengths=episode_lengths, batch_size=batch_size, max_time=max_time)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train():\n    model = Schluter_CNN(DROPOUT_RATE)\n    model_save_path = (('.\/weights\/cnn_' + args.model_name) + '.h5')\n    opt = SGD(lr=LEARNING_RATE, momentum=0.9, nesterov=True)\n    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n    print(model.summary())\n    checkpoint = ModelCheckpoint(filepath=model_save_path, monitor='val_acc', verbose=1, save_weights_only=False, save_best_only=True, mode='auto')\n    earlyStopping = EarlyStopping(monitor='val_acc', patience=EARLY_STOPPING, verbose=1, mode='auto')\n    reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=REDUCE_LR, verbose=1, min_lr=1e-08)\n    (x_train, y_train) = load_xy_data(None, MEL_JAMENDO_DIR, JAMENDO_LABEL_DIR, args.model_name, 'train')\n    (x_val, y_val) = load_xy_data(None, MEL_JAMENDO_DIR, JAMENDO_LABEL_DIR, args.model_name, 'valid')\n    print('train, valid data loaded', x_val.shape, y_val.shape)\n    histories = Score_History()\n    model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, callbacks=[checkpoint, earlyStopping, reduce_lr, histories], shuffle=True, validation_data=(x_val, y_val))\n    print('Finished!')\n"}
{"label_name":"save","label":1,"method_name":"_parse_save_config","method":"\n\ndef _parse_save_config(configs):\n    supported_configs = ['use_binary_format', 'pickle_protocol']\n    for key in configs:\n        if (key not in supported_configs):\n            raise ValueError(('The additional config (%s) of `paddle.save` is not supported.' % key))\n    inner_config = _SaveLoadConfig()\n    inner_config.use_binary_format = configs.get('use_binary_format', False)\n    inner_config.pickle_protocol = configs.get('pickle_protocol', None)\n    return inner_config\n"}
{"label_name":"save","label":1,"method_name":"save3x3","method":"\n\ndef save3x3(x, filename):\n    numpy_device = chainer.get_device('@numpy')\n    (fig, ax) = plt.subplots(3, 3, figsize=(9, 9), dpi=100)\n    for (ai, xi) in zip(ax.flatten(), x):\n        im = xi.reshape(28, 28)\n        im = numpy_device.send(im)\n        ai.imshow(im)\n    fig.savefig(filename)\n"}
{"label_name":"save","label":1,"method_name":"save","method":"\n\ndef save(*args, **kwargs):\n    a = 1\n"}
{"label_name":"save","label":1,"method_name":"_save_salammbo_vector","method":"\n\ndef _save_salammbo_vector(vector_path: str, vector_content: Dict, tnorm: str, possible_classes: List[str], dialect: Dialect) -> None:\n    ' Dump the salammbo vector inside the subsubtrain directory for one t-norm. '\n    content = list()\n    content.append([KEY_ID, KEY_TRUECLASS, *(str(possible_class) for possible_class in possible_classes)])\n    for identifier in vector_content.keys():\n        row = [identifier, vector_content[identifier][KEY_TRUECLASS]]\n        for possible_class in possible_classes:\n            try:\n                row.append(vector_content[identifier][tnorm][possible_class])\n            except KeyError:\n                row.append(0.0)\n        content.append(row)\n    dump_csv_content(path=vector_path, content=content, dialect=dialect)\n"}
{"label_name":"save","label":1,"method_name":"saveResultByField","method":"\n\ndef saveResultByField(results, field_name):\n    d = {res['label']: getattr(res['history'], field_name) for res in results}\n    df = pd.DataFrame(d)\n    fn = (field_name + '.csv')\n    file_name = os.path.join(exp_name, fn)\n    df.to_csv(file_name)\n"}
{"label_name":"process","label":2,"method_name":"postprocess","method":"\n\ndef postprocess(self, net_out, im, save=True):\n    '\\n\\tTakes net output, draw net_out, save to disk\\n\\t'\n    boxes = self.findboxes(net_out)\n    meta = self.meta\n    threshold = meta['thresh']\n    colors = meta['colors']\n    labels = meta['labels']\n    if (type(im) is not np.ndarray):\n        imgcv = cv2.imread(im)\n    else:\n        imgcv = im\n    (h, w, _) = imgcv.shape\n    resultsForJSON = []\n    for b in boxes:\n        boxResults = self.process_box(b, h, w, threshold)\n        if (boxResults is None):\n            continue\n        (left, right, top, bot, mess, max_indx, confidence) = boxResults\n        thick = int(((h + w) \/\/ 300))\n        if self.FLAGS.json:\n            resultsForJSON.append({'label': mess, 'confidence': float(('%.2f' % confidence)), 'topleft': {'x': left, 'y': top}, 'bottomright': {'x': right, 'y': bot}})\n            continue\n        cv2.rectangle(imgcv, (left, top), (right, bot), colors[max_indx], thick)\n        cv2.putText(imgcv, mess, (left, (top - 12)), 0, (0.001 * h), colors[max_indx], (thick \/\/ 3))\n    if (not save):\n        return imgcv\n    outfolder = os.path.join(self.FLAGS.imgdir, 'out')\n    img_name = os.path.join(outfolder, os.path.basename(im))\n    if self.FLAGS.json:\n        textJSON = json.dumps(resultsForJSON)\n        textFile = (os.path.splitext(img_name)[0] + '.json')\n        with open(textFile, 'w') as f:\n            f.write(textJSON)\n        return\n    cv2.imwrite(img_name, imgcv)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train():\n    mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True, fake_data=FLAGS.fake_data)\n    sess = tf.InteractiveSession()\n    with tf.name_scope('input'):\n        x = tf.placeholder(tf.float32, [None, 784], name='x-input')\n        y_ = tf.placeholder(tf.float32, [None, 10], name='y-input')\n    with tf.name_scope('input_reshape'):\n        image_shaped_input = tf.reshape(x, [(- 1), 28, 28, 1])\n        tf.summary.image('input', image_shaped_input, 10)\n\n    def weight_variable(shape):\n        'Create a weight variable with appropriate initialization.'\n        initial = tf.truncated_normal(shape, stddev=0.1)\n        return tf.Variable(initial)\n\n    def bias_variable(shape):\n        'Create a bias variable with appropriate initialization.'\n        initial = tf.constant(0.1, shape=shape)\n        return tf.Variable(initial)\n\n    def variable_summaries(var):\n        'Attach a lot of summaries to a Tensor (for TensorBoard visualization).'\n        with tf.name_scope('summaries'):\n            mean = tf.reduce_mean(var)\n            tf.summary.scalar('mean', mean)\n            with tf.name_scope('stddev'):\n                stddev = tf.sqrt(tf.reduce_mean(tf.square((var - mean))))\n            tf.summary.scalar('stddev', stddev)\n            tf.summary.scalar('max', tf.reduce_max(var))\n            tf.summary.scalar('min', tf.reduce_min(var))\n            tf.summary.histogram('histogram', var)\n\n    def nn_layer(input_tensor, input_dim, output_dim, layer_name, act=tf.nn.relu):\n        'Reusable code for making a simple neural net layer.\\n\\n    It does a matrix multiply, bias add, and then uses relu to nonlinearize.\\n    It also sets up name scoping so that the resultant graph is easy to read,\\n    and adds a number of summary ops.\\n    '\n        with tf.name_scope(layer_name):\n            with tf.name_scope('weights'):\n                weights = weight_variable([input_dim, output_dim])\n                variable_summaries(weights)\n            with tf.name_scope('biases'):\n                biases = bias_variable([output_dim])\n                variable_summaries(biases)\n            with tf.name_scope('Wx_plus_b'):\n                preactivate = (tf.matmul(input_tensor, weights) + biases)\n                tf.summary.histogram('pre_activations', preactivate)\n            activations = act(preactivate, name='activation')\n            tf.summary.histogram('activations', activations)\n            return activations\n    hidden1 = nn_layer(x, 784, 500, 'layer1')\n    with tf.name_scope('dropout'):\n        keep_prob = tf.placeholder(tf.float32)\n        tf.summary.scalar('dropout_keep_probability', keep_prob)\n        dropped = tf.nn.dropout(hidden1, keep_prob)\n    y = nn_layer(dropped, 500, 10, 'layer2', act=tf.identity)\n    with tf.name_scope('cross_entropy'):\n        diff = tf.nn.softmax_cross_entropy_with_logits(y, y_)\n        with tf.name_scope('total'):\n            cross_entropy = tf.reduce_mean(diff)\n    tf.summary.scalar('cross_entropy', cross_entropy)\n    with tf.name_scope('train'):\n        train_step = tf.train.AdamOptimizer(FLAGS.learning_rate).minimize(cross_entropy)\n    with tf.name_scope('accuracy'):\n        with tf.name_scope('correct_prediction'):\n            correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n        with tf.name_scope('accuracy'):\n            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n    tf.summary.scalar('accuracy', accuracy)\n    merged = tf.summary.merge_all()\n    train_writer = tf.train.SummaryWriter((FLAGS.log_dir + '\/train'), sess.graph)\n    test_writer = tf.train.SummaryWriter((FLAGS.log_dir + '\/test'))\n    tf.global_variables_initializer().run()\n\n    def feed_dict(train):\n        'Make a TensorFlow feed_dict: maps data onto Tensor placeholders.'\n        if (train or FLAGS.fake_data):\n            (xs, ys) = mnist.train.next_batch(100, fake_data=FLAGS.fake_data)\n            k = FLAGS.dropout\n        else:\n            (xs, ys) = (mnist.test.images, mnist.test.labels)\n            k = 1.0\n        return {x: xs, y_: ys, keep_prob: k}\n    for i in range(FLAGS.max_steps):\n        if ((i % 10) == 0):\n            (summary, acc) = sess.run([merged, accuracy], feed_dict=feed_dict(False))\n            test_writer.add_summary(summary, i)\n            print(('Accuracy at step %s: %s' % (i, acc)))\n        elif ((i % 100) == 99):\n            run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n            run_metadata = tf.RunMetadata()\n            (summary, _) = sess.run([merged, train_step], feed_dict=feed_dict(True), options=run_options, run_metadata=run_metadata)\n            train_writer.add_run_metadata(run_metadata, ('step%03d' % i))\n            train_writer.add_summary(summary, i)\n            print('Adding run metadata for', i)\n        else:\n            (summary, _) = sess.run([merged, train_step], feed_dict=feed_dict(True))\n            train_writer.add_summary(summary, i)\n    train_writer.close()\n    test_writer.close()\n"}
{"label_name":"train","label":0,"method_name":"pretrain","method":"\n\ndef pretrain(sess, generator, target_lstm, train_discriminator):\n    gen_data_loader = Gen_Data_loader(BATCH_SIZE)\n    gen_data_loader.create_batches(positive_samples)\n    results = OrderedDict({'exp_name': PREFIX})\n    print('Start pre-training...')\n    for epoch in range(PRE_EPOCH_NUM):\n        print('pre-train epoch:', epoch)\n        loss = pre_train_epoch(sess, generator, gen_data_loader)\n        if ((epoch == 10) or ((epoch % 40) == 0)):\n            samples = generate_samples(sess, generator, BATCH_SIZE, SAMPLE_NUM)\n            likelihood_data_loader.create_batches(samples)\n            test_loss = target_loss(sess, target_lstm, likelihood_data_loader)\n            print('\\t test_loss {}, train_loss {}'.format(test_loss, loss))\n            mm.compute_results(samples, train_samples, ord_dict, results)\n    samples = generate_samples(sess, generator, BATCH_SIZE, SAMPLE_NUM)\n    likelihood_data_loader.create_batches(samples)\n    test_loss = target_loss(sess, target_lstm, likelihood_data_loader)\n    samples = generate_samples(sess, generator, BATCH_SIZE, SAMPLE_NUM)\n    likelihood_data_loader.create_batches(samples)\n    print('Start training discriminator...')\n    for i in range(dis_alter_epoch):\n        print('epoch {}'.format(i))\n        (d_loss, acc) = train_discriminator()\n    return\n"}
{"label_name":"predict","label":4,"method_name":"align_entity_predictions","method":"\n\ndef align_entity_predictions(result: EntityEvaluationResult, extractors: Set[Text]) -> Dict:\n    'Aligns entity predictions to the message tokens.\\n\\n    Determines for every token the true label based on the\\n    prediction targets and the label assigned by each\\n    single extractor.\\n\\n    Args:\\n        result: entity evaluation result\\n        extractors: the entity extractors that should be considered\\n\\n    Returns: dictionary containing the true token labels and token labels\\n             from the extractors\\n    '\n    true_token_labels = []\n    entities_by_extractors: Dict[(Text, List)] = {extractor: [] for extractor in extractors}\n    for p in result.entity_predictions:\n        entities_by_extractors[p[EXTRACTOR]].append(p)\n    extractor_labels: Dict[(Text, List)] = {extractor: [] for extractor in extractors}\n    extractor_confidences: Dict[(Text, List)] = {extractor: [] for extractor in extractors}\n    for t in result.tokens:\n        true_token_labels.append(_concat_entity_labels(t, result.entity_targets))\n        for (extractor, entities) in entities_by_extractors.items():\n            extracted_labels = _concat_entity_labels(t, entities, {extractor})\n            extracted_confidences = _get_entity_confidences(t, entities, {extractor})\n            extractor_labels[extractor].append(extracted_labels)\n            extractor_confidences[extractor].append(extracted_confidences)\n    return {'target_labels': true_token_labels, 'extractor_labels': extractor_labels, 'confidences': extractor_confidences}\n"}
{"label_name":"predict","label":4,"method_name":"predict_from_img","method":"\n\ndef predict_from_img(img, model, block_shape, batch_size=1, normalizer=None, n_samples=1, return_variance=False, return_entropy=False):\n    'Return a prediction given a Nibabel image instance and a predictor.\\n\\n    Parameters\\n    ----------\\n    img: nibabel image, image on which to predict.\\n    model: `tf.keras.Model`, trained model.\\n    block_shape: tuple of length 3, shape of sub-volumes on which to\\n        predict.\\n    batch_size: int, number of sub-volumes per batch for predictions.\\n    normalizer: callable, function that accepts an ndarray and returns an\\n        ndarray. Called before separating volume into blocks.\\n    n_samples: The number of sampling. If set as 1, it will just return the\\n        single prediction value. The default value is 1\\n    return_variance: Boolean. If set True, it returns the running population\\n        variance along with mean. Note, if the n_samples is smaller or equal to 1,\\n        the variance will not be returned; instead it will return None\\n    return_entropy: Boolean. If set True, it returns the running entropy.\\n        along with mean.\\n\\n    Returns\\n    -------\\n    `nibabel.spatialimages.SpatialImage` or arrays of prediction of mean,\\n    variance(optional) or entropy (optional).\\n    '\n    if (not isinstance(img, nib.spatialimages.SpatialImage)):\n        raise ValueError('image is not a nibabel image type')\n    inputs = np.asarray(img.dataobj)\n    img.uncache()\n    inputs = inputs.astype(np.float32)\n    y = predict_from_array(inputs=inputs, model=model, block_shape=block_shape, batch_size=batch_size, normalizer=normalizer, n_samples=n_samples, return_variance=return_variance, return_entropy=return_entropy)\n    if isinstance(y, np.ndarray):\n        return nib.spatialimages.SpatialImage(dataobj=y, affine=img.affine, header=img.header, extra=img.extra)\n    elif (len(y) == 2):\n        return (nib.spatialimages.SpatialImage(dataobj=y[0], affine=img.affine, header=img.header, extra=img.extra), nib.spatialimages.SpatialImage(dataobj=y[1], affine=img.affine, header=img.header, extra=img.extra))\n    elif (len(y) == 3):\n        return (nib.spatialimages.SpatialImage(dataobj=y[0], affine=img.affine, header=img.header, extra=img.extra), nib.spatialimages.SpatialImage(dataobj=y[1], affine=img.affine, header=img.header, extra=img.extra), nib.spatialimages.SpatialImage(dataobj=y[2], affine=img.affine, header=img.header, extra=img.extra))\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train(model, data, epochs=100, batch_size=128, callbacks=None, checkpoint=None, checkpoint_monitor='val_loss', verbose=1, **fit_kwargs):\n    'Train the model on the data.\\n\\n    Arguments:\\n    ----------\\n        model : Model\\n            Assumes the model has been already compiled.\\n        data : dict\\n        epochs : uint (default: 100)\\n        batch_size : uint (default: 128)\\n        callbacks : list (default: None)\\n        checkpoint : str (default: None)\\n        verbose : uint (default: 1)\\n\\n    Returns:\\n    --------\\n        history : training history\\n    '\n    (X_train, y_train) = data['train']\n    (X_test, y_test) = data['test']\n    validation_data = (data['valid'] if ('valid' in data) else None)\n    callbacks = (callbacks or [])\n    if (checkpoint is not None):\n        if (not os.path.isdir('checkpoints\/')):\n            os.makedirs('checkpoints\/')\n    if (checkpoint is not None):\n        callbacks += [ModelCheckpoint(('checkpoints\/%s.h5' % checkpoint), monitor=checkpoint_monitor, save_weights_only=True, save_best_only=True)]\n    if verbose:\n        sys.stdout.write('Training...\\n')\n        sys.stdout.flush()\n    history = model.fit(X_train, y_train, validation_data=validation_data, batch_size=batch_size, epochs=epochs, callbacks=callbacks, verbose=verbose, **fit_kwargs)\n    if verbose:\n        sys.stdout.write('Done.\\n')\n    if (checkpoint is not None):\n        if os.path.isfile(('checkpoints\/%s.h5' % checkpoint)):\n            model.load_weights(('checkpoints\/%s.h5' % checkpoint))\n        else:\n            warnings.warn('Checkpoint file was specified, but no models were saved by the monitor. Make sure the validation dataset is specified and the monitoring channel is set correctly.')\n    return history\n"}
{"label_name":"train","label":0,"method_name":"scoring_model_train","method":"\n\ndef scoring_model_train(config):\n    save_output = False\n    config['execution']['stream_mode'] = True\n    unet_pipeline = unet(config, train_mode=False)\n    mask_dilation = unet_pipeline.get_step('mask_dilation')\n    mask_resize = unet_pipeline.get_step('mask_resize')\n    feature_extractor = Step(name='feature_extractor', transformer=post.FeatureExtractor(), input_steps=[mask_dilation, mask_resize], input_data=['input'], adapter={'images': [(mask_dilation.name, 'dilated_images')], 'probabilities': [(mask_resize.name, 'resized_images')], 'annotations': [('input', 'annotations')]}, cache_dirpath=config.env.cache_dirpath, save_output=True)\n    scoring_model = Step(name='scoring_model', transformer=(ScoringLightGBM(**config.postprocessor.lightGBM) if (config.postprocessor.scoring_model == 'lgbm') else ScoringRandomForest(**config.postprocessor.random_forest)), input_steps=[feature_extractor], cache_dirpath=config.env.cache_dirpath, save_output=save_output, is_trainable=True, force_fitting=False)\n    return scoring_model\n"}
{"label_name":"train","label":0,"method_name":"pytorch_train_one_epoch","method":"\n\ndef pytorch_train_one_epoch(pytorch_network, optimizer, loss_function):\n    '\\n    Trains the neural network for one epoch on the train DataLoader.\\n    \\n    Args:\\n        pytorch_network (torch.nn.Module): The neural network to train.\\n        optimizer (torch.optim.Optimizer): The optimizer of the neural network\\n        loss_function: The loss function.\\n    \\n    Returns:\\n        A tuple (loss, accuracy) corresponding to an average of the losses and\\n        an average of the accuracy, respectively, on the train DataLoader.\\n    '\n    pytorch_network.train(True)\n    with torch.enable_grad():\n        loss_sum = 0.0\n        acc_sum = 0.0\n        example_count = 0\n        for (x, y) in train_loader:\n            x = x.to(device)\n            y = y.to(device)\n            optimizer.zero_grad()\n            y_pred = pytorch_network(x)\n            loss = loss_function(y_pred, y)\n            loss.backward()\n            optimizer.step()\n            loss_sum += (float(loss) * len(x))\n            acc_sum += (float(pytorch_accuracy(y_pred, y)) * len(x))\n            example_count += len(x)\n    avg_loss = (loss_sum \/ example_count)\n    avg_acc = (acc_sum \/ example_count)\n    return (avg_loss, avg_acc)\n"}
{"label_name":"process","label":2,"method_name":"multiprocess_pages","method":"\n\ndef multiprocess_pages(base_URL, job_title, job_location, page_num):\n    'Grab the URLs and other relevant info. from job postings on the page. \\n\\n    The ZipRecruiter URL used for job searching takes an additional parameter,   \\n    `page`, that allows you to start the job search at page 0-20 (20 is the max). \\n    Use this to grab job results from multiple pages at once, and then pass jobs\\n    on to threads to grab relevant info. \\n\\n    Args: \\n    ----\\n        base_URL: str \\n        job_title: str \\n        job_location: str \\n        page_start: int \\n    '\n    url = ((query_URL + '&page=') + str(page_num))\n    html = get_html(url)\n    rows = html.select('.job_result')\n    threads = []\n    mongo_update_lst = []\n    for row in rows:\n        thread = RequestInfoThread(row, job_title, job_location)\n        thread.start()\n        threads.append(thread)\n    for thread in threads:\n        thread.join()\n        mongo_update_lst.append(thread.json_dct)\n    store_in_mongo(mongo_update_lst, 'job_postings', 'ziprecruiter')\n"}
{"label_name":"train","label":0,"method_name":"trainIters","method":"\n\ndef trainIters(cnn, epoch, learning_rate=0.0001):\n    n_epochs = epoch\n    current_loss = 0\n    all_losses = []\n    err_rate = []\n    confusion = torch.zeros(6, 6)\n    err = 0\n    accTemp = 0\n    cnn_optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n    criterion = nn.CrossEntropyLoss()\n    for epoch in range(1, (n_epochs + 1)):\n        for (step1, (batch_x, batch_y)) in enumerate(train_loader):\n            batch_x = Variable(batch_x.type('torch.cuda.FloatTensor'))\n            batch_y = Variable(batch_y.type('torch.cuda.LongTensor'))\n            loss = train(batch_x.view(N, L, (- 1)), batch_y, cnn, cnn_optimizer, criterion)\n            current_loss += loss\n        for (step2, (test_x, test_y)) in enumerate(test_loader):\n            test_x = Variable(test_x.type('torch.cuda.FloatTensor'))\n            test_y = test_y.type('torch.cuda.LongTensor')\n            guess = test(test_x.view(1, L, (- 1)), cnn)\n            confusion[guess][test_y[0]] += 1\n        sen = (confusion[0][0] \/ ((confusion[0][0] + confusion[0][1]) + 1))\n        acc = ((confusion[0][0] + confusion[1][1]) \/ step2)\n        all_losses.append((current_loss \/ step1))\n        err_rate.append((acc * 100))\n        if (acc >= accTemp):\n            accTemp = acc\n            print(acc, accTemp)\n        print(('%d epoch: acc = %.2f, sen = %.2f%%' % (epoch, (acc * 100), (sen * 100))))\n        current_loss = 0\n        err = 0\n        confusion = torch.zeros(2, 2)\n    plt.figure()\n    plt.plot(all_losses)\n    plt.title('loss')\n    plt.figure()\n    plt.plot(err_rate)\n    plt.title('err')\n    print(confusion)\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    cax = ax.matshow(confusion.numpy())\n    fig.colorbar(cax)\n    plt.show()\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train(batch_size, num_steps, report_every_episodes, reward_function, logfile, save_every_trains, save_file, num_frames):\n    '\\n    Train A2C on Toribash tasks.\\n    '\n    controller = ToribashControl()\n    num_players = 1\n    controller.settings.set('matchframes', 1000)\n    controller.settings.set('turnframes', 5)\n    if (reward_function != reward_destroy_uke):\n        controller.settings.set('engagement_distance', 1500)\n    num_joints = controller.get_num_joints()\n    num_joint_states = controller.get_num_joint_states()\n    num_inputs = (controller.get_state_dim() * num_players)\n    a2c = ToribashA2C((num_inputs * num_frames), num_joints, num_joint_states)\n    train_op_ctr = 0\n    step_ctr = 0\n    episode_ctr = 0\n    batch_states = []\n    batch_stateprimes = []\n    batch_actions = []\n    batch_rewards = []\n    last_s = None\n    last_a = None\n    last_r = None\n    injury = None\n    last_orig_s = None\n    pi_losses = []\n    v_losses = []\n    h_losses = []\n    vs = []\n    last_episode_rewards = []\n    episode_reward = 0\n    stacker = deque([np.zeros(num_inputs) for i in range(num_frames)], maxlen=num_frames)\n    controller.init()\n    print_and_log('--- Training starts ---', logfile)\n    start_time = time()\n    while (step_ctr < num_steps):\n        (orig_s, terminal) = controller.get_state()\n        s = get_refined_state(orig_s, num_players)\n        stacker.append(s)\n        s = np.concatenate(stacker)\n        if ((last_s is not None) and (last_a is not None) and (last_r is not None)):\n            batch_states.append(last_s)\n            batch_stateprimes.append(s)\n            batch_actions.append(last_a)\n            batch_rewards.append(last_r)\n            if (len(batch_states) == batch_size):\n                states = np.array(batch_states)\n                stateprimes = np.array(batch_stateprimes)\n                actions = np.array(batch_actions)\n                actions -= 1\n                returns = np.array(batch_rewards)\n                losses = a2c.train_on_batch(states, stateprimes, actions, returns)\n                pi_losses.append(losses[0])\n                v_losses.append(losses[1])\n                h_losses.append(losses[2])\n                train_op_ctr += 1\n                batch_states.clear()\n                batch_stateprimes.clear()\n                batch_actions.clear()\n                batch_rewards.clear()\n        step_ctr += 1\n        if terminal:\n            last_s = None\n            last_a = None\n            last_r = None\n            last_orig_s = None\n            stacker = deque([np.zeros(num_inputs) for i in range(num_frames)], maxlen=num_frames)\n            orig_s = controller.reset()\n            episode_ctr += 1\n            last_episode_rewards.append(episode_reward)\n            episode_reward = 0\n            s = get_refined_state(orig_s, num_players)\n            stacker.append(s)\n            s = np.concatenate(stacker)\n            if ((episode_ctr % report_every_episodes) == 0):\n                print_and_log(((('Steps: %d\\tTime: %d\\tPloss: %.4f\\tVloss: %.4f\\t' + 'Hloss: %.4f') + '\\tAvrgR: %.4f\\t;MaxR: %.4f\\tMinR: %.4f\\tAvrgV: %.4f') % (step_ctr, int((time() - start_time)), (sum(pi_losses) \/ len(pi_losses)), (sum(v_losses) \/ len(v_losses)), (sum(h_losses) \/ len(h_losses)), (sum(last_episode_rewards) \/ len(last_episode_rewards)), max(last_episode_rewards), min(last_episode_rewards), (sum(vs) \/ len(vs)))), logfile)\n                pi_losses.clear()\n                v_losses.clear()\n                h_losses.clear()\n                last_episode_rewards.clear()\n                vs.clear()\n        (pi, v) = a2c.predict_pi_and_v(np.expand_dims(s, 0))\n        pi = pi[0]\n        v = v[0]\n        vs.append(v)\n        a = []\n        for probs in pi:\n            a.append((np.random.choice(num_joint_states, p=probs) + 1))\n        action = [a, [3 for i in range(num_joints)]]\n        controller.make_actions(action)\n        last_s = s\n        last_a = action[0]\n        if (last_orig_s is not None):\n            last_r = reward_function(last_orig_s, orig_s)\n        else:\n            last_r = 0\n        episode_reward += last_r\n        last_orig_s = orig_s\n        if (((train_op_ctr + 1) % save_every_trains) == 0):\n            a2c.save(save_file)\n"}
{"label_name":"train","label":0,"method_name":"load_train_data","method":"\n\ndef load_train_data(filename):\n    ext = filename.split('.')[(- 1)]\n    if (ext == 'csv'):\n        return read_smiles_csv(filename)\n    if (ext == 'smi'):\n        return read_smi(filename)\n    else:\n        raise ValueError('data is not smi or csv!')\n    return\n"}
{"label_name":"process","label":2,"method_name":"process_monitor","method":"\n\ndef process_monitor(process_dict_list):\n    while True:\n        print('monitor running')\n        for process_dict in process_dict_list:\n            process = process_dict['process']\n            if (process.is_alive() is False):\n                name = process_dict['name']\n                if (name == 'test_gen_quote'):\n                    p1 = Process(target=test_gen_quote, args=())\n                    p1.start()\n                    process_dict['process'] = p1\n                    print('name: {}, new_pid: {}'.format(name, p1.pid))\n                elif (name == 'test_event_strategy'):\n                    p2 = Process(target=test_event_strategy, args=())\n                    p2.start()\n                    process_dict['process'] = p2\n                    print('name: {}, new_pid: {}'.format(name, p2.pid))\n                elif (name == 'test_event_strategy_2'):\n                    p4 = Process(target=test_event_strategy_2, args=())\n                    p4.start()\n                    process_dict['process'] = p4\n                    print('name: {}, new_pid: {}'.format(name, p4.pid))\n                elif (name == 'test_trade_executor'):\n                    p3 = Process(target=test_trade_executor, args=())\n                    p3.start()\n                    process_dict['process'] = p3\n                    print('name: {}, new_pid: {}'.format(name, p3.pid))\n            else:\n                pass\n        time.sleep(10)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train(model, loss, optimizer, x_val, y_val):\n    model.train()\n    x = Variable(x_val, requires_grad=False)\n    y = Variable(y_val, requires_grad=False)\n    optimizer.zero_grad()\n    fx = model.forward(x)\n    output = loss.forward(fx, y)\n    output.backward()\n    optimizer.step()\n    return output.item()\n"}
{"label_name":"save","label":1,"method_name":"bayesdb_savepoint","method":"\n\n@contextlib.contextmanager\ndef bayesdb_savepoint(bdb):\n    bayesdb_txn_push(bdb)\n    try:\n        with sqlite3_savepoint(bdb._sqlite3):\n            (yield)\n    finally:\n        bayesdb_txn_pop(bdb)\n"}
{"label_name":"forward","label":3,"method_name":"cforwardsolve","method":"\n\ndef cforwardsolve(A, b, d):\n    '\\n    Solve the system A*x = b for a lower triangular d-banded matrix A, \\n    using algorithm 2.9 (column-oriented forward substitution)\\n    The input vector b will be updated with the solution x (i.e. in-place).\\n    \\n    A: A lower triangular matrix\\n    b: The right hand side\\n    d: The band-width\\n    '\n    A = matrix(A)\n    n = len(b)\n    for k in range((n - 1)):\n        b[k] \/= A[(k, k)]\n        uk = array([n, ((k + d) + 1)]).min()\n        b[(k + 1):uk] -= (A[(k + 1):uk, k] * b[k])\n    b[(n - 1)] \/= A[((n - 1), (n - 1))]\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train(total_loss, global_step, optimizer, learning_rate, moving_average_decay, update_gradient_vars, log_histograms=True):\n    loss_averages_op = _add_loss_summaries(total_loss)\n    with tf.control_dependencies([loss_averages_op]):\n        if (optimizer == 'ADAGRAD'):\n            opt = tf.train.AdagradOptimizer(learning_rate)\n        elif (optimizer == 'ADADELTA'):\n            opt = tf.train.AdadeltaOptimizer(learning_rate, rho=0.9, epsilon=1e-06)\n        elif (optimizer == 'ADAM'):\n            opt = tf.train.AdamOptimizer(learning_rate, beta1=0.9, beta2=0.999, epsilon=0.1)\n        elif (optimizer == 'RMSPROP'):\n            opt = tf.train.RMSPropOptimizer(learning_rate, decay=0.9, momentum=0.9, epsilon=1.0)\n        elif (optimizer == 'MOM'):\n            opt = tf.train.MomentumOptimizer(learning_rate, 0.9, use_nesterov=True)\n        else:\n            raise ValueError('Invalid optimization algorithm')\n        grads = opt.compute_gradients(total_loss, update_gradient_vars)\n    apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\n    if log_histograms:\n        for var in tf.trainable_variables():\n            tf.summary.histogram(var.op.name, var)\n    if log_histograms:\n        for (grad, var) in grads:\n            if (grad is not None):\n                tf.summary.histogram((var.op.name + '\/gradients'), grad)\n    variable_averages = tf.train.ExponentialMovingAverage(moving_average_decay, global_step)\n    variables_averages_op = variable_averages.apply(tf.trainable_variables())\n    with tf.control_dependencies([apply_gradient_op, variables_averages_op]):\n        train_op = tf.no_op(name='train')\n    return train_op\n"}
{"label_name":"save","label":1,"method_name":"save_image","method":"\n\n@csrf_exempt\ndef save_image(request):\n    if request.body:\n        f = open((settings.MEDIA_ROOT + '\/webcamimages\/someimage.jpeg'), 'wb')\n        f.write(request.body)\n        f.close()\n        print('something found')\n        return HttpResponse('http:\/\/127.0.0.1:8000\/media\/webcamimages\/someimage.jpeg')\n    else:\n        print('not get any data.')\n        return HttpResponse('no data')\n"}
{"label_name":"save","label":1,"method_name":"_save_distributed_persistables","method":"\n\ndef _save_distributed_persistables(executor, dirname, main_program):\n    '\\n    save_persistables for distributed training.\\n    the method will do things listed below:\\n    1.save part of persistable variables on trainer.\\n    2.receive \"remote prefetch variables\" from parameter servers and merge them.\\n    3.save \"distributed lookup table\" on parameter servers.\\n    4.receive \"optimizer variables\" from parameter servers and merge them.\\n\\n    Args:\\n        executor(Executor): The executor to run for saving parameters.\\n        dirname(str): The saving directory path.\\n        main_program(Program): The program whose parameters will be\\n                            saved. the main_program must be the trainer_program\\n                            get after transpiler.\\n\\n    Returns:\\n        None\\n\\n    Examples:\\n        .. code-block:: python\\n\\n            import paddle\\n            import paddle.fluid as fluid\\n\\n            paddle.enable_static()\\n            exe = fluid.Executor(fluid.CPUPlace())\\n            param_path = \".\/my_paddle_model\"\\n            t = distribute_transpiler.DistributeTranspiler()\\n            t.transpile(...)\\n            train_program = t.get_trainer_program()\\n            _save_distributed_persistables(executor=exe, dirname=param_path, main_program=train_program)\\n    '\n\n    def __save_remote_params(executor, dirname, remote_params_map):\n        '\\n        receive params on pserver through rpc.\\n        if the params are be sliced, will concat them to one, then save it.\\n        '\n        if (not remote_params_map):\n            return\n        prog = Program()\n        block = prog.global_block()\n        for (name, remote_params) in remote_params_map.items():\n            origin = remote_params[0].origin\n            is_slice = remote_params[0].is_slice\n            slices = ([None] * len(remote_params))\n            slice_varnames = ([None] * len(remote_params))\n            remote_varnames = ([None] * len(remote_params))\n            endpoints = ([None] * len(remote_params))\n            for (idx, optimizer) in enumerate(remote_params):\n                block_id = optimizer.block_id\n                slice = optimizer.slice\n                endpoint = optimizer.endpoint\n                index = (block_id if is_slice else idx)\n                slices[index] = slice\n                slice_varnames[index] = '{}.slice.{}'.format(slice.name, idx)\n                remote_varnames[index] = slice.name\n                endpoints[index] = endpoint\n            slice_shapes = []\n            for slice in slices:\n                tmp = [str(dim) for dim in slice.shape]\n                slice_shapes.append(','.join(tmp))\n            block.append_op(type='recv_save', attrs={'trainer_id': 0, 'shape': origin.shape, 'slice_shapes': slice_shapes, 'slice_varnames': slice_varnames, 'remote_varnames': remote_varnames, 'endpoints': endpoints, 'file_path': os.path.join(dirname, origin.name)})\n        executor.run(prog)\n\n    def __save_distributed_lookup_tables(executor, dirname, distributed_lookup_table, endpoints):\n        '\\n        because the distributed lookup table may too huge to merge and save at one place,\\n        it will be saved at parameter server independent respectively.\\n\\n        the save directory is dirname\/\"__lookup_table__\".\\n\\n        '\n        prog = Program()\n        block = prog.global_block()\n        lookup_table_filename = os.path.join(dirname, '__lookup_table__')\n        attrs = {}\n        attrs['epmap'] = endpoints\n        attrs['dir'] = lookup_table_filename\n        attrs['lookup_table'] = distributed_lookup_table\n        block.append_op(type='checkpoint_notify', inputs={}, outputs={}, attrs=attrs)\n        executor.run(prog)\n\n    def __exclude_vars(exclude_var_names=[]):\n\n        def is_valid(var):\n            if (var.name in exclude_var_names):\n                return False\n            if ((var.desc.type() == core.VarDesc.VarType.FEED_MINIBATCH) or (var.desc.type() == core.VarDesc.VarType.FETCH_LIST) or (var.desc.type() == core.VarDesc.VarType.READER)):\n                return False\n            return var.persistable\n        return is_valid\n    if (not isinstance(main_program, Program)):\n        raise TypeError(\"'main_program' should be an instance of Program.\")\n    if (not main_program._is_distributed):\n        raise ValueError(\"'_save_distributed_persistables' just be designed for distributed training.\")\n    remote_params_map = main_program._parameters_on_pservers.get_distributed_vars_by_vtypes(['Optimizer', 'RemotePrefetch'], groupby=True)\n    exclude_var_names = []\n    if remote_params_map:\n        exclude_var_names.extend(remote_params_map.keys())\n    if main_program._distributed_lookup_table:\n        if isinstance(main_program._distributed_lookup_table, list):\n            exclude_var_names.extend(main_program._distributed_lookup_table)\n        else:\n            exclude_var_names.append(main_program._distributed_lookup_table)\n    local_vars = list(filter(__exclude_vars(exclude_var_names), main_program.list_vars()))\n    save_vars(executor, main_program=main_program, dirname=dirname, vars=local_vars)\n    if main_program._is_chief:\n        if remote_params_map:\n            __save_remote_params(executor, dirname, remote_params_map)\n        if main_program._distributed_lookup_table:\n            __save_distributed_lookup_tables(executor, dirname, main_program._distributed_lookup_table, main_program._endpoints)\n"}
{"label_name":"process","label":2,"method_name":"process_cdr_sequences","method":"\n\ndef process_cdr_sequences(cdr_file):\n    with open(cdr_file, 'r') as f:\n        seqs = [s.rstrip() for s in f.readlines()]\n        process_sequences(seqs)\n"}
{"label_name":"process","label":2,"method_name":"add_process_env_sig","method":"\n\ndef add_process_env_sig(func):\n    '\\n    \u521d\u59cb\u5316\u88c5\u9970\u5668\u65f6\u7ed9\u88ab\u88c5\u9970\u51fd\u6570\u6dfb\u52a0env\u5173\u952e\u5b57\u53c2\u6570\uff0c\u5728wrapper\u4e2d\u5c06env\u5bf9\u8c61\u8fdb\u884c\u5b50\u8fdb\u7a0bcopy\\n    \u7531\u4e8e\u8981\u6539\u65b9\u6cd5\u7b7e\u540d\uff0c\u591a\u4e2a\u88c5\u9970\u5668\u7684\u60c5\u51b5\u8981\u653e\u5728\u6700\u4e0b\u9762\\n    :param func:\\n    :return:\\n    '\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        if ('env' in kwargs):\n            \"\\n                \u5b9e\u9645\u4e0alinux, mac os\u4e0a\u5e76\u4e0d\u9700\u8981\u8fdb\u884c\u8fdb\u7a0b\u95f4\u6a21\u5757\u5185\u5b58\u62f7\u8d1d\uff0c\\n                \u5b50\u8fdb\u7a0bfork\u540e\u643a\u5e26\u4e86\u7236\u8fdb\u7a0b\u7684\u5185\u5b58\u4fe1\u606f\uff0cwin\u4e0a\u662f\u9700\u8981\u7684\uff0c\\n                \u6682\u65f6\u4e0d\u505a\u533a\u5206\uff0c\u90fd\u8fdb\u884c\u8fdb\u7a0b\u95f4\u7684\u5185\u5b58\u62f7\u8d1d\uff0c\u5982\u7279\u522b\u5728\u4e4e\u6548\u7387\u7684\\n                \u60c5\u51b5\u4e0b\u57fa\u4e8elinux\u7cfb\u7edf\uff0cmac os\u53ef\u4ee5\u4e0d\u9700\u8981\u62f7\u8d1d\uff0c\u5982\u4e0b\uff1a\\n                if kwargs['env'] is not None and not ABuEnv.g_is_mac_os:\\n                    # \u53ea\u6709windows\u8fdb\u884c\u5185\u5b58\u8bbe\u7f6e\u62f7\u8d1d\\n                    env.copy_process_env()\\n            \"\n            env = kwargs.pop('env', None)\n            if (env is not None):\n                env.copy_process_env()\n        return func(*args, **kwargs)\n    sig = signature(func)\n    if ('env' not in list(sig.parameters.keys())):\n        parameters = list(sig.parameters.values())\n        parameters.append(Parameter('env', Parameter.KEYWORD_ONLY, default=None))\n        wrapper.__signature__ = sig.replace(parameters=parameters)\n    return wrapper\n"}
{"label_name":"save","label":1,"method_name":"create_save_model","method":"\n\ndef create_save_model(model):\n\n    def save_model(path):\n        torch.save(model.state_dict(), path)\n    return save_model\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train(word_idx):\n    '\\n    IMDB training set creator.\\n\\n    It returns a reader creator, each sample in the reader is an zero-based ID\\n    sequence and label in [0, 1].\\n\\n    :param word_idx: word dictionary\\n    :type word_idx: dict\\n    :return: Training reader creator\\n    :rtype: callable\\n    '\n    return reader_creator(re.compile('train\/pos\/.*\\\\.txt$'), re.compile('train\/neg\/.*\\\\.txt$'), word_idx)\n"}
{"label_name":"train","label":0,"method_name":"train_epoch","method":"\n\ndef train_epoch(model: Model, dl: DataLoader, opt: optim.Optimizer, loss_func: LossFunction) -> None:\n    'Simple training of `model` for 1 epoch of `dl` using optim `opt` and loss function `loss_func`'\n    model.train()\n    for (xb, yb) in dl:\n        loss = loss_func(model(xb), yb)\n        loss.backward()\n        opt.step()\n        opt.zero_grad()\n"}
{"label_name":"train","label":0,"method_name":"prepare_pretrain_npz_dataset","method":"\n\ndef prepare_pretrain_npz_dataset(filename, allow_pickle=False):\n    'Create dataset based on the numpy npz file'\n    if isinstance(filename, (list, tuple)):\n        assert (len(filename) == 1), 'When .npy\/.npz data file is loaded, len(filename) must be 1. Received len(filename)={}.'.format(len(filename))\n        filename = filename[0]\n    logging.debug('start to load file %s ...', filename)\n    return NumpyDataset(filename, allow_pickle=allow_pickle)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train(working_dir, tf_records, generation, params):\n    'Train the model for a specific generation.\\n\\n  Args:\\n    working_dir: The model working directory to save model parameters,\\n      drop logs, checkpoints, and so on.\\n    tf_records: A list of tf_record filenames for training input.\\n    generation: The generation to be trained.\\n    params: hyperparams of the model.\\n\\n  Raises:\\n    ValueError: if generation is not greater than 0.\\n  '\n    if (generation <= 0):\n        raise ValueError('Model 0 is random weights')\n    estimator = tf.estimator.Estimator(dualnet_model.model_fn, model_dir=working_dir, params=params)\n    max_steps = ((generation * params.examples_per_generation) \/\/ params.batch_size)\n    profiler_hook = tf.train.ProfilerHook(output_dir=working_dir, save_secs=600)\n\n    def input_fn():\n        return preprocessing.get_input_tensors(params, params.batch_size, tf_records)\n    estimator.train(input_fn, hooks=[profiler_hook], max_steps=max_steps)\n"}
{"label_name":"save","label":1,"method_name":"saveVocabulary","method":"\n\ndef saveVocabulary(model):\n    for (i, x) in enumerate(model['vocabulary']):\n        print(i, x)\n"}
{"label_name":"save","label":1,"method_name":"crop_and_resave","method":"\n\ndef crop_and_resave(inputfile, outputdir):\n    im = imread(inputfile)\n    (height, width, color) = im.shape\n    edge_h = int(round(((height - 108) \/ 2.0)))\n    edge_w = int(round(((width - 108) \/ 2.0)))\n    cropped = im[edge_h:(edge_h + 108), edge_w:(edge_w + 108)]\n    small = imresize(cropped, (64, 64))\n    filename = inputfile.split('\/')[(- 1)]\n    imsave(('%s\/%s' % (outputdir, filename)), small)\n"}
{"label_name":"predict","label":4,"method_name":"predictproba","method":"\n\n@route('\/predictproba', method='POST')\ndef predictproba():\n    response.content_type = 'application\/json'\n    try:\n        body = request.json\n        body = (body if isinstance(body, list) else [body])\n        X = pandas.DataFrame.from_dict(body)\n        if hasattr(model, 'get_booster'):\n            X = X[model.get_booster().feature_names]\n        result = pandas.DataFrame(model.predict_proba(X), columns=model.classes_)\n        return result.to_json(orient='records')\n    except Exception as error:\n        response.status = 500\n        return json.dumps({'error': str(error)})\n"}
{"label_name":"train","label":0,"method_name":"train_trimester_2","method":"\n\ndef train_trimester_2(train_whole, feature_columns, batch_size, label):\n    logging.info('2nd Trimester regresssion training')\n    layers_list = [layers.Dense(256, activation='tanh'), layers.Dense(128, activation='tanh'), layers.Dense(64, activation='tanh')]\n    (model_2trim, val_loss) = create_fit_model(train_whole, feature_columns, layers_list, batch_size, label, val_size=0.1, rate=0.001, loss_fn=tf.keras.losses.MeanSquaredError(), metrics_list=['MeanAbsoluteError', 'MeanSquaredError'], num_epochs=100)\n    if (model_2trim is None):\n        logging.error('Error training the trimester model {}'.format(e))\n        return None\n    logging.info('Validation set  metrics {}'.format(val_loss))\n    return model_2trim\n"}
{"label_name":"train","label":0,"method_name":"train_model","method":"\n\ndef train_model(model, dataloaders, dataset_sizes, criterion, optimizer, scheduler, use_gpu, num_epochs=25, mixup=False, alpha=0.1):\n    print('MIXUP'.format(mixup))\n    since = time.time()\n    best_model_wts = model.state_dict()\n    best_acc = 0.0\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, (num_epochs - 1)))\n        print(('-' * 10))\n        for phase in ['train', 'val']:\n            if (phase == 'train'):\n                scheduler.step()\n                model.train(True)\n            else:\n                model.train(False)\n            running_loss = 0.0\n            running_corrects = 0\n            for data in tqdm(dataloaders[phase]):\n                (inputs, labels) = data\n                if ((phase == 'train') and mixup):\n                    inputs = mixup_batch(inputs, alpha)\n                if use_gpu:\n                    inputs = Variable(inputs.cuda())\n                    labels = Variable(labels.cuda())\n                else:\n                    (inputs, labels) = (Variable(inputs), Variable(labels))\n                optimizer.zero_grad()\n                outputs = model(inputs)\n                if (type(outputs) == tuple):\n                    (outputs, _) = outputs\n                (_, preds) = torch.max(outputs.data, 1)\n                loss = criterion(outputs, labels)\n                if (phase == 'train'):\n                    loss.backward()\n                    optimizer.step()\n                running_loss += loss.data[0]\n                running_corrects += torch.sum((preds == labels.data))\n            epoch_loss = (running_loss \/ dataset_sizes[phase])\n            epoch_acc = (running_corrects \/ dataset_sizes[phase])\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n            if ((phase == 'val') and (epoch_acc > best_acc)):\n                best_acc = epoch_acc\n                best_model_wts = model.state_dict()\n        print()\n    time_elapsed = (time.time() - since)\n    print('Training complete in {:.0f}m {:.0f}s'.format((time_elapsed \/\/ 60), (time_elapsed % 60)))\n    print('Best val Acc: {:4f}'.format(best_acc))\n    model.load_state_dict(best_model_wts)\n    return model\n"}
{"label_name":"save","label":1,"method_name":"save_checkpoint","method":"\n\ndef save_checkpoint(state, is_best, folder='.\/', filename='checkpoint.pth.tar'):\n    if (not os.path.isdir(folder)):\n        os.mkdir(folder)\n    torch.save(state, os.path.join(folder, filename))\n    if is_best:\n        shutil.copyfile(os.path.join(folder, filename), os.path.join(folder, 'model_best.pth.tar'))\n"}
{"label_name":"predict","label":4,"method_name":"_get_majority_prediction","method":"\n\ndef _get_majority_prediction(predictions):\n    frequency = {}\n    for i in range(0, len(predictions)):\n        prediction = predictions[i]\n        if (prediction in frequency):\n            frequency[prediction] += 1\n        else:\n            frequency[prediction] = 1\n    max_frequency = 0\n    max_frequency_prediction = None\n    for prediction in frequency:\n        if (frequency[prediction] > max_frequency):\n            max_frequency = frequency[prediction]\n            max_frequency_prediction = prediction\n    return max_frequency_prediction\n"}
{"label_name":"predict","label":4,"method_name":"predict_x","method":"\n\ndef predict_x(x, node):\n    s = node.s\n    i = node.i\n    theta = node.theta\n    if node.is_leaf:\n        return node.sign\n    elif (stump_x(s, i, theta, x) == (- 1)):\n        return predict_x(x, node.l)\n    else:\n        return predict_x(x, node.r)\n"}
{"label_name":"predict","label":4,"method_name":"_fit_and_predict","method":"\n\ndef _fit_and_predict(estimator, X, y, train, test, verbose, fit_params):\n    \"Fit estimator and predict values for a given dataset split.\\n\\n    Read more in the :ref:`User Guide <cross_validation>`.\\n\\n    Parameters\\n    ----------\\n    estimator : estimator object implementing 'fit' and 'predict'\\n        The object to use to fit the data.\\n\\n    X : array-like of shape at least 2D\\n        The data to fit.\\n\\n    y : array-like, optional, default: None\\n        The target variable to try to predict in the case of\\n        supervised learning.\\n\\n    train : array-like, shape (n_train_samples,)\\n        Indices of training samples.\\n\\n    test : array-like, shape (n_test_samples,)\\n        Indices of test samples.\\n\\n    verbose : integer\\n        The verbosity level.\\n\\n    fit_params : dict or None\\n        Parameters that will be passed to ``estimator.fit``.\\n\\n    Returns\\n    -------\\n    preds : sequence\\n        Result of calling 'estimator.predict'\\n\\n    test : array-like\\n        This is the value of the test parameter\\n    \"\n    fit_params = (fit_params if (fit_params is not None) else {})\n    fit_params = dict([(k, _index_param_value(X, v, train)) for (k, v) in fit_params.items()])\n    (X_train, y_train) = _safe_split(estimator, X, y, train)\n    (X_test, _) = _safe_split(estimator, X, y, test, train)\n    if (y_train is None):\n        estimator.fit(X_train, **fit_params)\n    else:\n        estimator.fit(X_train, y_train, **fit_params)\n    preds = estimator.predict(X_test)\n    return (preds, test)\n"}
{"label_name":"process","label":2,"method_name":"_postprocess_conv3d_output","method":"\n\ndef _postprocess_conv3d_output(x, data_format):\n    'Transpose and cast the output from conv3d if needed.\\n\\n  Arguments:\\n      x: A tensor.\\n      data_format: string, one of \"channels_last\", \"channels_first\".\\n\\n  Returns:\\n      A tensor.\\n  '\n    if (data_format == 'channels_first'):\n        x = array_ops.transpose(x, (0, 4, 1, 2, 3))\n    if (floatx() == 'float64'):\n        x = math_ops.cast(x, 'float64')\n    return x\n"}
{"label_name":"save","label":1,"method_name":"create_dirs_to_save_models","method":"\n\ndef create_dirs_to_save_models(dirs_for_saved_models):\n    for new_save_dir in dirs_for_saved_models:\n        new_save_dir.mkdir(exist_ok=True, parents=True)\n"}
{"label_name":"save","label":1,"method_name":"saveBatchResultByField","method":"\n\ndef saveBatchResultByField(results, field_name):\n    d = {res['label']: getattr(res['history'], field_name) for res in results}\n    df = pd.DataFrame(d)\n    fn = (('b_' + field_name) + '.csv')\n    file_name = os.path.join(exp_name, fn)\n    df.to_csv(file_name)\n"}
{"label_name":"process","label":2,"method_name":"pre_process_dialouge","method":"\n\ndef pre_process_dialouge(raw_dialogue_file_path, pre_processed_dir, movie_dir_name, dialogue_file1, dialogue_file2, train_file1, train_file2, test_file1, test_file2, dev_file1, dev_file2, vocab_file1, vocab_file2, max_dialouge_count, max_dialouge_count_train_test, train_percentile, compare_count, symbol_seq, type_d, max_len, type_rand, max_test_dev_count):\n    print('Extracting file')\n    start = time.time()\n    delete_all_file_dir(pre_processed_dir, type_d)\n    if (movie_dir_name == cornell_movie_dir):\n        (dialogue_file1, dialogue_file2) = dialouge_seperator_cornell_movie(raw_dialogue_file_path, dialogue_file1, dialogue_file2, symbol_seq, max_dialouge_count, max_len)\n    elif (movie_dir_name == open_subtitles_dir):\n        (dialogue_file1, dialogue_file2) = dialouge_seperator_open_subtitle(raw_dialogue_file_path, dialogue_file1, dialogue_file2, max_dialouge_count)\n    elif (movie_dir_name == movie_subtitles_dir):\n        (dialogue_file1, dialogue_file2) = dialouge_seperator_movie_subtitle(raw_dialogue_file_path, dialogue_file1, dialogue_file2, max_dialouge_count)\n    else:\n        print('directory match not found')\n        return\n    (train_file1, train_file2, test_file1, test_file2, dev_file1, dev_file2) = train_test_split(dialogue_file1, dialogue_file2, max_dialouge_count_train_test, train_percentile, train_file1, train_file2, test_file1, test_file2, dev_file1, dev_file2, max_test_dev_count)\n    '\\n\\tvocab_dict1 = get_vocab(train_file1)\\n\\tvocab_dict2 = get_vocab(train_file2)\\n\\n\\twrite_dict(vocab_file1, vocab_dict1, \"key\")\\n\\twrite_dict(vocab_file2, vocab_dict2, \"key\")\\n    '\n    compare_chat_reply(dialogue_file1, dialogue_file2, compare_count, type_rand)\n    end = time.time()\n    time_lib.elapsed_time(start, end)\n"}
{"label_name":"save","label":1,"method_name":"save_abc","method":"\n\ndef save_abc(name, smiles):\n    folder = 'epoch_data'\n    if (not os.path.exists(folder)):\n        os.makedirs(folder)\n    smi_file = os.path.join(folder, (name + '.abc'))\n    with open(smi_file, 'w') as afile:\n        afile.write('\\n'.join(smiles))\n    return\n"}
{"label_name":"process","label":2,"method_name":"final_process_cleanup","method":"\n\ndef final_process_cleanup():\n    engines.testing_reaper._stop_test_ctx_aggressive()\n    assertions.global_cleanup_assertions()\n    _restore_engine()\n"}
{"label_name":"process","label":2,"method_name":"process_bundle","method":"\n\ndef process_bundle(rels):\n    '\\n    Given a list of relation metadata bundles, make a corresponding\\n    dictionary of concepts, indexed by the relation name.\\n\\n    :param rels: bundle of metadata needed for constructing a concept\\n    :type rels: list(dict)\\n    :return: a dictionary of concepts, indexed by the relation name.\\n    :rtype: dict(str): Concept\\n    '\n    concepts = {}\n    for rel in rels:\n        rel_name = rel['rel_name']\n        closures = rel['closures']\n        schema = rel['schema']\n        filename = rel['filename']\n        concept_list = clause2concepts(filename, rel_name, schema, closures)\n        for c in concept_list:\n            label = c.prefLabel\n            if (label in concepts):\n                for data in c.extension:\n                    concepts[label].augment(data)\n                concepts[label].close()\n            else:\n                concepts[label] = c\n    return concepts\n"}
{"label_name":"forward","label":3,"method_name":"point_wise_feed_forward_network","method":"\n\ndef point_wise_feed_forward_network(d_model, dff):\n    return tf.keras.Sequential([tf.keras.layers.Dense(dff, activation='relu'), tf.keras.layers.Dense(d_model)])\n"}
{"label_name":"process","label":2,"method_name":"abc_preprocessed","method":"\n\n@test.Fixture(scope='function')\ndef abc_preprocessed() -> preprocessed.PreprocessedContentFile:\n    'A test fixture which returns a preprocessed content file.'\n    return preprocessed.PreprocessedContentFile(id=123, text='aabbccddee')\n"}
{"label_name":"forward","label":3,"method_name":"lstm_forward","method":"\n\n@nb.jit(nopython=True)\ndef lstm_forward(X, W, b, activation):\n    outdim = (W.shape[(- 1)] \/\/ 4)\n    (time, batch, indim) = X.shape\n    Z = np.zeros((time, batch, (indim + outdim)))\n    O = np.zeros((time, batch, outdim))\n    T = np.zeros((time, 6, batch, outdim))\n    for t in range(time):\n        Z[t] = np.concatenate((X[t], O[(t - 1)]), axis=(- 1))\n        p = (np.dot(Z[t], W) + b)\n        p[:, :outdim] = activation(p[:, :outdim])\n        p[:, outdim:] = sigmoid(p[:, outdim:])\n        T[(t, 2)] = p[:, :outdim]\n        T[(t, 3)] = p[:, outdim:(2 * outdim)]\n        T[(t, 4)] = p[:, (2 * outdim):(3 * outdim)]\n        T[(t, 5)] = p[:, (3 * outdim):]\n        T[(t, 0)] = ((T[((t - 1), 0)] * T[(t, 3)]) + (T[(t, 2)] * T[(t, 4)]))\n        T[(t, 1)] = activation(T[(t, 0)])\n        O[t] = (T[(t, 1)] * T[(t, 5)])\n    return np.concatenate((O.ravel(), Z.ravel(), T.ravel()))\n"}
{"label_name":"process","label":2,"method_name":"process_dump","method":"\n\ndef process_dump(input_file, template_file, out_file, file_size, file_compress, process_count):\n    \"\\n    :param input_file: name of the wikipedia dump file; '-' to read from stdin\\n    :param template_file: optional file with template definitions.\\n    :param out_file: directory where to store extracted data, or '-' for stdout\\n    :param file_size: max size of each extracted file, or None for no max (one file)\\n    :param file_compress: whether to compress files with bzip.\\n    :param process_count: number of extraction processes to spawn.\\n    \"\n    global urlbase\n    global knownNamespaces\n    global templateNamespace, templatePrefix\n    global moduleNamespace, modulePrefix\n    if (input_file == '-'):\n        input = sys.stdin\n    else:\n        input = fileinput.FileInput(input_file, openhook=fileinput.hook_compressed)\n    for line in input:\n        if (not isinstance(line, text_type)):\n            line = line.decode('utf-8')\n        m = tagRE.search(line)\n        if (not m):\n            continue\n        tag = m.group(2)\n        if (tag == 'base'):\n            base = m.group(3)\n            urlbase = base[:base.rfind('\/')]\n        elif (tag == 'namespace'):\n            knownNamespaces.add(m.group(3))\n            if re.search('key=\"10\"', line):\n                templateNamespace = m.group(3)\n                templatePrefix = (templateNamespace + ':')\n            elif re.search('key=\"828\"', line):\n                moduleNamespace = m.group(3)\n                modulePrefix = (moduleNamespace + ':')\n        elif (tag == '\/siteinfo'):\n            break\n    if Extractor.expand_templates:\n        template_load_start = default_timer()\n        if template_file:\n            if os.path.exists(template_file):\n                logging.info(\"Preprocessing '%s' to collect template definitions: this may take some time.\", template_file)\n                file = fileinput.FileInput(template_file, openhook=fileinput.hook_compressed)\n                load_templates(file)\n                file.close()\n            else:\n                if (input_file == '-'):\n                    raise ValueError('to use templates with stdin dump, must supply explicit template-file')\n                logging.info(\"Preprocessing '%s' to collect template definitions: this may take some time.\", input_file)\n                load_templates(input, template_file)\n                input.close()\n                input = fileinput.FileInput(input_file, openhook=fileinput.hook_compressed)\n        template_load_elapsed = (default_timer() - template_load_start)\n        logging.info('Loaded %d templates in %.1fs', len(templates), template_load_elapsed)\n    logging.info('Starting page extraction from %s.', input_file)\n    extract_start = default_timer()\n    process_count = max(1, process_count)\n    maxsize = (10 * process_count)\n    output_queue = Queue(maxsize=maxsize)\n    if (out_file == '-'):\n        out_file = None\n    worker_count = process_count\n    max_spool_length = 10000\n    spool_length = Value('i', 0, lock=False)\n    reduce = Process(target=reduce_process, args=(output_queue, spool_length, out_file, file_size, file_compress))\n    reduce.start()\n    jobs_queue = Queue(maxsize=maxsize)\n    logging.info('Using %d extract processes.', worker_count)\n    workers = []\n    for i in range(worker_count):\n        extractor = Process(target=extract_process, args=(i, jobs_queue, output_queue))\n        extractor.daemon = True\n        extractor.start()\n        workers.append(extractor)\n    page_num = 0\n    for page_data in pages_from(input):\n        (id, revid, title, ns, page) = page_data\n        if keepPage(ns, page):\n            delay = 0\n            if (spool_length.value > max_spool_length):\n                while (spool_length.value > (max_spool_length \/ 10)):\n                    time.sleep(10)\n                    delay += 10\n            if delay:\n                logging.info('Delay %ds', delay)\n            job = (id, revid, title, page, page_num)\n            jobs_queue.put(job)\n            page_num += 1\n        page = None\n    input.close()\n    for _ in workers:\n        jobs_queue.put(None)\n    for w in workers:\n        w.join()\n    output_queue.put(None)\n    reduce.join()\n    extract_duration = (default_timer() - extract_start)\n    extract_rate = (page_num \/ extract_duration)\n    logging.info('Finished %d-process extraction of %d articles in %.1fs (%.1f art\/s)', process_count, page_num, extract_duration, extract_rate)\n"}
{"label_name":"train","label":0,"method_name":"build_constraints","method":"\n\ndef build_constraints(primitive_objectives, num_features):\n    constraints = []\n    i = 0\n    for objective in primitive_objectives:\n        (c, i) = parse_domain_constraints(objective['domain'], num_features, i)\n        constraints.extend(c)\n    return constraints\n"}
{"label_name":"predict","label":4,"method_name":"predict_from_filepaths","method":"\n\ndef predict_from_filepaths(filepaths, model, block_shape, batch_size=1, normalizer=None, n_samples=1, return_variance=False, return_entropy=False):\n    \"Yield a model's predictions on a list of filepaths.\\n\\n    Parameters\\n    ----------\\n    filepaths: list, volume filepaths on which to predict.\\n    model: `tf.keras.Model`, trained model.\\n    block_shape: tuple of length 3, shape of sub-volumes on which to\\n        predict.\\n    batch_size: int, number of sub-volumes per batch for predictions.\\n    normalizer: callable, function that accepts an ndarray and returns an\\n        ndarray. Called before separating volume into blocks.\\n    n_samples: The number of sampling. If set as 1, it will just return the\\n        single prediction value. The default value is 1\\n    return_variance: Boolean. If set True, it returns the running population\\n        variance along with mean. Note, if the n_samples is smaller or equal to 1,\\n        the variance will not be returned; instead it will return None\\n    return_entropy: Boolean. If set True, it returns the running entropy.\\n        along with mean.\\n\\n    Returns\\n    -------\\n    Generator object that yields a `nibabel.spatialimages.SpatialImage` or\\n    arrays of predictions per filepath in list of input filepaths.\\n    \"\n    for filepath in filepaths:\n        (yield predict_from_filepath(filepath=filepath, model=model, block_shape=block_shape, batch_size=batch_size, normalizer=normalizer, n_samples=n_samples, return_variance=return_variance, return_entropy=return_entropy))\n"}
{"label_name":"predict","label":4,"method_name":"read_predictions","method":"\n\ndef read_predictions(prediction_dir, concat_mode='concat'):\n    labels = pd.read_csv(os.path.join(prediction_dir, 'labels.csv'))\n    (filepaths_train, filepaths_test) = ([], [])\n    for filepath in sorted(glob.glob('{}\/*'.format(prediction_dir))):\n        if filepath.endswith('predictions_train_oof.csv'):\n            filepaths_train.append(filepath)\n        elif filepath.endswith('predictions_test_oof.csv'):\n            filepaths_test.append(filepath)\n    train_dfs = []\n    for filepath in filepaths_train:\n        train_dfs.append(pd.read_csv(filepath))\n    train_dfs = reduce((lambda df1, df2: pd.merge(df1, df2, on=['id', 'fold_id'])), train_dfs)\n    train_dfs.columns = _clean_columns(train_dfs, keep_colnames=['id', 'fold_id'])\n    train_dfs = pd.merge(train_dfs, labels, on=['id'])\n    test_dfs = []\n    for filepath in filepaths_test:\n        test_dfs.append(pd.read_csv(filepath))\n    test_dfs = reduce((lambda df1, df2: pd.merge(df1, df2, on=['id', 'fold_id'])), test_dfs)\n    test_dfs.columns = _clean_columns(test_dfs, keep_colnames=['id', 'fold_id'])\n    return (train_dfs, test_dfs)\n"}
{"label_name":"save","label":1,"method_name":"save_structure","method":"\n\ndef save_structure(structure, file_name):\n    io = PDBIO()\n    io.set_structure(structure)\n    io.save(file_name)\n"}
{"label_name":"process","label":2,"method_name":"process_ui_get_market_indicators_rr","method":"\n\ndef process_ui_get_market_indicators_rr(msg, ui_conn_pipe):\n    log.debug('enter')\n    exch = msg.get('exchange')\n    product = msg.get('product')\n    num_periods = msg.get('periods', 0)\n    start_time = msg.get('start_time', 0)\n    market = get_market_by_product(exch, product)\n    ind_list = {}\n    if market:\n        ind_list = market.get_indicator_list(num_periods, start_time)\n    msg['type'] = 'GET_MARKET_INDICATORS_RESP'\n    msg['data'] = ind_list\n    ui_conn_pipe.send(msg)\n"}
{"label_name":"train","label":0,"method_name":"train_neural_network","method":"\n\ndef train_neural_network(x):\n    prediction = neural_network_model(x)\n    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))\n    optimizer = tf.train.AdamOptimizer().minimize(cost)\n    hm_epochs = 10\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        for epoch in range(hm_epochs):\n            epoch_loss = 0\n            for _ in range(int((mnist.train.num_examples \/ batch_size))):\n                (epoch_x, epoch_y) = mnist.train.next_batch(batch_size)\n                (_, c) = sess.run([optimizer, cost], feed_dict={x: epoch_x, y: epoch_y})\n                epoch_loss += c\n            print('Epoch', epoch, 'completed out of', hm_epochs, 'loss:', epoch_loss)\n        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n        print('Accuracy:', accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))\n"}
{"label_name":"train","label":0,"method_name":"lms_train","method":"\n\ndef lms_train(p0, Zi, Data):\n\n    def error(p, y, args):\n        l = len(p)\n        f = p[(l - 1)]\n        for i in range(len(args)):\n            f += (p[i] * args[i])\n        return (f - y)\n    Para = leastsq(error, p0, args=(Zi, Data))\n    return Para[0]\n"}
{"label_name":"save","label":1,"method_name":"_check_save_and_load","method":"\n\ndef _check_save_and_load(dense_matrix):\n    for matrix_class in [csc_matrix, csr_matrix, bsr_matrix, dia_matrix, coo_matrix]:\n        matrix = matrix_class(dense_matrix)\n        loaded_matrix = _save_and_load(matrix)\n        assert_((type(loaded_matrix) is matrix_class))\n        assert_((loaded_matrix.shape == dense_matrix.shape))\n        assert_((loaded_matrix.dtype == dense_matrix.dtype))\n        assert_equal(loaded_matrix.toarray(), dense_matrix)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train(input_data_path, model_save_path, hyperparams_path=None):\n    '\\n    The function to execute the training.\\n\\n    :param input_data_path: [str], input directory path where all the training file(s) reside in\\n    :param model_save_path: [str], directory path to save your model(s)\\n    :param hyperparams_path: [optional[str], default=None], input path to hyperparams json file.\\n    Example:\\n        {\\n            \"max_leaf_nodes\": 10,\\n            \"n_estimators\": 200\\n        }\\n    '\n"}
{"label_name":"save","label":1,"method_name":"_save_batch_norm_model","method":"\n\ndef _save_batch_norm_model(export_dir, save_from_keras=False):\n    'Writes a Hub-style SavedModel with a batch norm layer.'\n    inp = tf.keras.layers.Input(shape=(1,), dtype=tf.float32)\n    bn = tf.keras.layers.BatchNormalization(momentum=0.8)\n    outp = bn(inp)\n    model = tf.keras.Model(inp, outp)\n    if save_from_keras:\n        tf.saved_model.save(model, export_dir)\n        return\n\n    @tf.function\n    def call_fn(inputs, training=False):\n        return model(inputs, training=training)\n    for training in (True, False):\n        call_fn.get_concrete_function(tf.TensorSpec((None, 1), tf.float32), training=training)\n    obj = tf.train.Checkpoint()\n    obj.__call__ = call_fn\n    obj.trainable_variables = [bn.beta, bn.gamma]\n    assert (_tensors_names_set(obj.trainable_variables) == _tensors_names_set(model.trainable_variables))\n    obj.variables = [bn.beta, bn.gamma, bn.moving_mean, bn.moving_variance]\n    assert (_tensors_names_set(obj.variables) == _tensors_names_set((model.trainable_variables + model.non_trainable_variables)))\n    obj.regularization_losses = []\n    assert (not model.losses)\n    tf.saved_model.save(obj, export_dir)\n"}
{"label_name":"predict","label":4,"method_name":"predicted_label","method":"\n\ndef predicted_label(prediction_tensor, label_dict):\n    \"\\n    Generates the predicted label by comparing the tensor prediction to `label_dict`.\\n\\n    Parameters:\\n        - prediction (np.ndarray)\\n            - The prediction as represented by the model's tensor output.\\n        - label_dict (dict, str --> np.ndarray)\\n            - See the parent function for details.\\n    Returns:\\n        - A string; the predicted label.\\n    \"\n    classes = list(label_dict.keys())\n    labels = list(label_dict.values())\n    differences = []\n    for label in labels:\n        l2_difference = np.sqrt(np.sum(((label - prediction_tensor) ** 2)))\n        differences.append(l2_difference)\n    index_of_smallest_difference = differences.index(min(differences))\n    return classes[index_of_smallest_difference]\n"}
{"label_name":"predict","label":4,"method_name":"plot_predictions","method":"\n\ndef plot_predictions(predictions, target_names=None, figsize=(18, 4), width=0.8):\n    predictions = to_numpy(predictions)\n    fig = plt.figure(figsize=figsize)\n    if target_names:\n        plt.bar(range(0, len(target_names)), predictions, width)\n        plt.xticks(range(0, len(target_names)), target_names)\n    else:\n        plt.bar(range(0, predictions.shape[0]), predictions, width)\n    plt.show()\n"}
{"label_name":"process","label":2,"method_name":"postprocess_fn_add_next_actions_for_sarsa","method":"\n\ndef postprocess_fn_add_next_actions_for_sarsa(policy: Policy, batch: SampleBatch, other_agent=None, episode=None) -> SampleBatch:\n    'Add next_actions to SampleBatch for SARSA training'\n    if (policy.config['slateq_strategy'] == 'SARSA'):\n        if (not batch['dones'][(- 1)]):\n            raise RuntimeError(f'Expected a complete episode in each sample batch. But this batch is not: {batch}.')\n        batch['next_actions'] = np.roll(batch['actions'], (- 1), axis=0)\n    return batch\n"}
{"label_name":"train","label":0,"method_name":"train_one_epoch","method":"\n\ndef train_one_epoch(model, criterion, optimizer, data_loader, device, epoch, print_freq, apex=False):\n    model.train()\n    metric_logger = utils.MetricLogger(delimiter='  ')\n    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value}'))\n    metric_logger.add_meter('img\/s', utils.SmoothedValue(window_size=10, fmt='{value}'))\n    header = 'Epoch: [{}]'.format(epoch)\n    for (image, target) in metric_logger.log_every(data_loader, print_freq, header):\n        start_time = time.time()\n        (image, target) = (image.to(device), target.to(device))\n        output = model(image)\n        loss = criterion(output, target)\n        optimizer.zero_grad()\n        if apex:\n            with amp.scale_loss(loss, optimizer) as scaled_loss:\n                scaled_loss.backward()\n        else:\n            loss.backward()\n        optimizer.step()\n        (acc1, acc5) = utils.accuracy(output, target, topk=(1, 5))\n        batch_size = image.shape[0]\n        metric_logger.update(loss=loss.item(), lr=optimizer.param_groups[0]['lr'])\n        metric_logger.meters['acc1'].update(acc1.item(), n=batch_size)\n        metric_logger.meters['acc5'].update(acc5.item(), n=batch_size)\n        metric_logger.meters['img\/s'].update((batch_size \/ (time.time() - start_time)))\n"}
{"label_name":"process","label":2,"method_name":"old_img_preprocess","method":"\n\ndef old_img_preprocess(img_path, size=224):\n    mean = [103.939, 116.779, 123.68]\n    img = imread(img_path)\n    img = (resize(img, (size, size)) * 255.0)\n    if (len(img.shape) == 2):\n        img = np.dstack([img, img, img])\n    img[:, :, 0] -= mean[2]\n    img[:, :, 1] -= mean[1]\n    img[:, :, 2] -= mean[0]\n    img[:, :, [0, 1, 2]] = img[:, :, [2, 1, 0]]\n    img = np.reshape(img, [1, size, size, 3])\n    return img\n"}
{"label_name":"process","label":2,"method_name":"process_str","method":"\n\ndef process_str(astr):\n    code = [header]\n    code.extend(parse_string(astr, global_names, 0, 1))\n    return ''.join(code)\n"}
{"label_name":"train","label":0,"method_name":"create_gen_pretrain_op","method":"\n\ndef create_gen_pretrain_op(hparams, cross_entropy_loss, global_step):\n    'Create a train op for pretraining.'\n    with tf.name_scope('pretrain_generator'):\n        optimizer = tf.train.AdamOptimizer(hparams.gen_pretrain_learning_rate)\n        gen_vars = [v for v in tf.trainable_variables() if v.op.name.startswith('gen')]\n        gen_grads = tf.gradients(cross_entropy_loss, gen_vars)\n        (gen_grads_clipped, _) = tf.clip_by_global_norm(gen_grads, FLAGS.grad_clipping)\n        gen_pretrain_op = optimizer.apply_gradients(zip(gen_grads_clipped, gen_vars), global_step=global_step)\n        return gen_pretrain_op\n"}
{"label_name":"train","label":0,"method_name":"create_train_parser","method":"\n\ndef create_train_parser(subparsers):\n    parser = subparsers.add_parser('train', help='train skipgram model to learn embeddings')\n    parser.add_argument('inputs', nargs='+')\n    parser.add_argument('-o', '--output-dir', required=True)\n    parser.add_argument('--vocab-size', type=int, required=True)\n    parser.add_argument('--emb-size', type=int, default=100)\n    parser.add_argument('--batch-size', type=int, default=1024)\n    parser.add_argument('--l2-value', type=float, default=0.0)\n    parser.add_argument('--num-sampled', type=int, default=10)\n    parser.add_argument('--optimizer', default='adam')\n    parser.add_argument('--epochs', type=int, default=5)\n    parser.add_argument('--learning-rate', type=float, default=0.001)\n    parser.add_argument('--threads-count', type=int, default=multiprocessing.cpu_count())\n    parser.add_argument('--no-clipping', action='store_true', default=False)\n    parser.add_argument('--checkpoint', default=None)\n    return parser\n"}
{"label_name":"train","label":0,"method_name":"generate_training_data","method":"\n\ndef generate_training_data(vocab_ids, writer_lm_all, writer_seq_ae_all):\n    'Generates training data.'\n    writer_lm = build_shuffling_tf_record_writer(data.TRAIN_LM)\n    writer_seq_ae = build_shuffling_tf_record_writer(data.TRAIN_SA)\n    writer_class = build_shuffling_tf_record_writer(data.TRAIN_CLASS)\n    writer_valid_class = build_tf_record_writer(data.VALID_CLASS)\n    writer_rev_lm = build_shuffling_tf_record_writer(data.TRAIN_REV_LM)\n    writer_bd_class = build_shuffling_tf_record_writer(data.TRAIN_BD_CLASS)\n    writer_bd_valid_class = build_shuffling_tf_record_writer(data.VALID_BD_CLASS)\n    for doc in document_generators.documents(dataset='train', include_unlabeled=True, include_validation=True):\n        input_seq = build_input_sequence(doc, vocab_ids)\n        if (len(input_seq) < 2):\n            continue\n        rev_seq = data.build_reverse_sequence(input_seq)\n        lm_seq = data.build_lm_sequence(input_seq)\n        rev_lm_seq = data.build_lm_sequence(rev_seq)\n        seq_ae_seq = data.build_seq_ae_sequence(input_seq)\n        if (doc.label is not None):\n            label_seq = data.build_labeled_sequence(input_seq, doc.label, label_gain=(FLAGS.label_gain and (not doc.is_validation)))\n            bd_label_seq = data.build_labeled_sequence(data.build_bidirectional_seq(input_seq, rev_seq), doc.label, label_gain=(FLAGS.label_gain and (not doc.is_validation)))\n            class_writer = (writer_valid_class if doc.is_validation else writer_class)\n            bd_class_writer = (writer_bd_valid_class if doc.is_validation else writer_bd_class)\n            class_writer.write(label_seq.seq.SerializeToString())\n            bd_class_writer.write(bd_label_seq.seq.SerializeToString())\n        lm_seq_ser = lm_seq.seq.SerializeToString()\n        seq_ae_seq_ser = seq_ae_seq.seq.SerializeToString()\n        writer_lm_all.write(lm_seq_ser)\n        writer_seq_ae_all.write(seq_ae_seq_ser)\n        if (not doc.is_validation):\n            writer_lm.write(lm_seq_ser)\n            writer_rev_lm.write(rev_lm_seq.seq.SerializeToString())\n            writer_seq_ae.write(seq_ae_seq_ser)\n    writer_lm.close()\n    writer_seq_ae.close()\n    writer_class.close()\n    writer_valid_class.close()\n    writer_rev_lm.close()\n    writer_bd_class.close()\n    writer_bd_valid_class.close()\n"}
{"label_name":"predict","label":4,"method_name":"assert_predictions_equal","method":"\n\ndef assert_predictions_equal(coxnet, x, expected_pred):\n    pred = numpy.array([coxnet.predict(x.iloc[122:123, :], alpha=a)[0] for a in coxnet.alphas_])\n    assert_array_almost_equal(pred, expected_pred)\n    pred_last = coxnet.predict(x.iloc[122:123, :])\n    assert_array_almost_equal(pred_last, expected_pred[(- 1)])\n"}
{"label_name":"predict","label":4,"method_name":"predict","method":"\n\ndef predict(t1, t2, x):\n    m = np.size(x, 0)\n    x = np.concatenate((np.ones((m, 1)), x), axis=1)\n    temp1 = sigmoid(x.dot(theta1.T))\n    temp = np.concatenate((np.ones((m, 1)), temp1), axis=1)\n    temp2 = sigmoid(temp.dot(theta2.T))\n    p = (np.argmax(temp2, axis=1) + 1)\n    return p\n"}
{"label_name":"save","label":1,"method_name":"_save_and_load","method":"\n\ndef _save_and_load(matrix):\n    (fd, tmpfile) = tempfile.mkstemp(suffix='.npz')\n    os.close(fd)\n    try:\n        save_npz(tmpfile, matrix)\n        loaded_matrix = load_npz(tmpfile)\n    finally:\n        os.remove(tmpfile)\n    return loaded_matrix\n"}
{"label_name":"forward","label":3,"method_name":"feedforward_neural_network","method":"\n\ndef feedforward_neural_network(inputs):\n    x = tf.placeholder('float', name='input')\n    (oil_train, stock_train, oil_test, stock_test, oil_price, stock_price) = inputs\n    prediction = neural_network_model(x)\n    cost = tf.reduce_mean(tf.square((tf.transpose(prediction) - y)))\n    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n    (oil_train, stock_train, oil_test, stock_test) = refine_input_with_lag(oil_train, stock_train, oil_test, stock_test)\n    saver = tf.train.Saver()\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        for epoch in range(hm_epoch):\n            epoch_loss = 0\n            for (X, Y) in zip(oil_train.values, stock_train.values):\n                (_, c) = sess.run([optimizer, cost], feed_dict={x: [[X]], y: [[Y]]})\n                epoch_loss += c\n            print('Epoch', epoch, 'completed out of', hm_epoch, 'loss:', epoch_loss)\n        correct = tf.subtract(prediction, y)\n        total = 0\n        cor = 0\n        for (X, Y) in zip(oil_test.values, stock_test.values):\n            total += 1\n            if (abs(correct.eval({x: [[X]], y: [[Y]]})) < 5):\n                cor += 1\n        print('Accuracy:', (cor \/ total))\n        save_path = saver.save(sess, 'data\/model\/feedforward\/feedforward.ckpt')\n        print(('Model saved in file: %s' % save_path))\n        date_labels = oil_price.index\n        date_labels = matplotlib.dates.date2num(date_labels.to_pydatetime())\n        predictions = []\n        for i in oil_price:\n            predictions.append(sess.run(prediction, feed_dict={x: [[i]]})[0][0])\n        plt.plot_date(date_labels, predictions, 'b-', label='Feedforward Predictions')\n        plt.plot_date(date_labels, stock_price.values, 'r-', label='Stock Prices')\n        plt.legend()\n        plt.ylabel('Price')\n        plt.xlabel('Year')\n        plt.show()\n"}
{"label_name":"process","label":2,"method_name":"process_file","method":"\n\ndef process_file(filename):\n    try:\n        tokens = tokenizer.tokenize_file(filename, process_file.options)\n        if tokens:\n            process_file.queue.put(QueueItem(filename, tokens))\n        else:\n            logging.debug('skipped file %s', filename)\n    except Exception as e:\n        logging.error('failed to process %s: %s', filename, str(e))\n"}
{"label_name":"process","label":2,"method_name":"postprocess","method":"\n\ndef postprocess(x, n_bits_x=8):\n    'Converts x from [-0.5, 0.5], to [0, 255].\\n\\n  Args:\\n    x: 3-D or 4-D Tensor normalized between [-0.5, 0.5]\\n    n_bits_x: Number of bits representing each pixel of the output.\\n              Defaults to 8, to default to 256 possible values.\\n  Returns:\\n    x: 3-D or 4-D Tensor representing images or videos.\\n  '\n    x = tf.where(tf.is_finite(x), x, tf.ones_like(x))\n    x = tf.clip_by_value(x, (- 0.5), 0.5)\n    x += 0.5\n    x = (x * (2 ** n_bits_x))\n    return tf.cast(tf.clip_by_value(x, 0, 255), dtype=tf.uint8)\n"}
{"label_name":"train","label":0,"method_name":"_retrieve_mnist_training","method":"\n\ndef _retrieve_mnist_training():\n    urls = ['http:\/\/yann.lecun.com\/exdb\/mnist\/train-images-idx3-ubyte.gz', 'http:\/\/yann.lecun.com\/exdb\/mnist\/train-labels-idx1-ubyte.gz']\n    return _retrieve_mnist('train.npz', urls)\n"}
{"label_name":"process","label":2,"method_name":"preprocess","method":"\n\ndef preprocess():\n    'splits _sources\/reference.rst into separate files'\n    text = open('.\/_sources\/reference.rst', 'r').read()\n    os.remove('.\/_sources\/reference.rst')\n    if (not os.path.exists('.\/_sources\/reference')):\n        os.makedirs('.\/_sources\/reference')\n\n    def pairwise(iterable):\n        's -> (s0, s1), (s2, s3), (s4, s5), ...'\n        iteration = iter(iterable)\n        return izip(iteration, iteration)\n    sections = map(str.strip, re.split('<!--\\\\s*(.+)\\\\s*-->', text))\n    for (section, content) in pairwise(sections[1:]):\n        if section.endswith('.proto'):\n            section_name = section[:(- len('.proto'))]\n            file_name = '.\/_sources\/reference\/{0}.rst'.format(section_name)\n            with open(file_name, 'w') as f:\n                f.truncate()\n                f.write(content)\n                f.close()\n"}
{"label_name":"train","label":0,"method_name":"fill_nan_with_mean_training","method":"\n\ndef fill_nan_with_mean_training(training, test):\n    trainingFill = training.copy()\n    testFill = test.copy()\n    trainingFill = trainingFill.fillna(trainingFill.mean())\n    trainingFill = trainingFill.fillna(0)\n    testFill = testFill.fillna(trainingFill.mean())\n    testFill = testFill.fillna(0)\n    return (trainingFill, testFill)\n"}
{"label_name":"save","label":1,"method_name":"save_mov","method":"\n\ndef save_mov(img, rows, cols, H, W, C, fn):\n    img = img.reshape(rows, cols, H, W, C)\n    img = img.transpose(1, 0, 2, 3, 4)\n    img = img.reshape(cols, int(np.sqrt(rows)), int(np.sqrt(rows)), H, W, C)\n    img = img.transpose(0, 1, 3, 2, 4, 5)\n    img = img.reshape(cols, (H * int(np.sqrt(rows))), (W * int(np.sqrt(rows))), C)\n    out_dir = os.path.splitext(fn)[0]\n    if (not os.path.exists(out_dir)):\n        os.makedirs(out_dir)\n    for (frame_i, frame) in enumerate(img):\n        if ((frame.ndim == 2) or (frame.shape[2] == 1)):\n            frame = np.broadcast_to(frame, (frame.shape[0], frame.shape[1], 3))\n        frame = frame.astype(np.uint8)\n        Image.fromarray(frame).save('{}\/{}.png'.format(out_dir, frame_i))\n    subprocess.call(['ffmpeg', '-r', '10', '-i', '{}\/%d.png'.format(out_dir), '-qscale', '0', '-s', '640x640', fn])\n    subprocess.call(['ffmpeg', '-i', '{}.avi'.format(os.path.splitext(fn)[0]), fn.replace('.avi', '.mov')])\n"}
{"label_name":"save","label":1,"method_name":"save_file","method":"\n\ndef save_file(ct, file_name):\n    '\\n    \u5c06\u5185\u5bb9ct\u4fdd\u5b58\u6587\u4ef6\\n    :param ct: \u5185\u5bb9str\u5bf9\u8c61\\n    :param file_name: \u4fdd\u5b58\u7684\u6587\u4ef6\u540d\u79f0\\n    :return:\\n    '\n    ensure_dir(file_name)\n    with open(file_name, 'wb') as f:\n        f.write(ct)\n"}
{"label_name":"train","label":0,"method_name":"train_model","method":"\n\ndef train_model():\n    features = np.genfromtxt(conf['Data_feature_dir'], dtype=float, delimiter=',')\n    labels = np.genfromtxt(conf['Class_labels_dir'], dtype=float, delimiter=',')\n    sigma = 4\n    max_iter = 5000\n    alpha = 0.003\n    c = 10\n    '\\n    MODEL 1: find the Kernel cnvrt features, cost_function and Parameters (thetas) and store them as models\\n\\tNote:\\n\\t\\tThe more the sigma is the less the gamma will be\\n\\t'\n    Models(type='rbf').fit(features, labels)\n"}
{"label_name":"process","label":2,"method_name":"if_safe_multiprocessing_with_blas","method":"\n\ndef if_safe_multiprocessing_with_blas(func):\n    'Decorator for tests involving both BLAS calls and multiprocessing.\\n\\n    Under POSIX (e.g. Linux or OSX), using multiprocessing in conjunction with\\n    some implementation of BLAS (or other libraries that manage an internal\\n    posix thread pool) can cause a crash or a freeze of the Python process.\\n\\n    In practice all known packaged distributions (from Linux distros or\\n    Anaconda) of BLAS under Linux seems to be safe. So we this problem seems to\\n    only impact OSX users.\\n\\n    This wrapper makes it possible to skip tests that can possibly cause\\n    this crash under OS X with.\\n\\n    Under Python 3.4+ it is possible to use the `forkserver` start method\\n    for multiprocessing to avoid this issue. However it can cause pickling\\n    errors on interactively defined functions. It therefore not enabled by\\n    default.\\n    '\n\n    @wraps(func)\n    def run_test(*args, **kwargs):\n        if (sys.platform == 'darwin'):\n            raise SkipTest('Possible multi-process bug with some BLAS')\n        return func(*args, **kwargs)\n    return run_test\n"}
{"label_name":"train","label":0,"method_name":"subtrain_name","method":"\n\ndef subtrain_name() -> str:\n    return _get_value_from_file('subtrain_name')\n"}
{"label_name":"train","label":0,"method_name":"trainRegressionWrapper","method":"\n\ndef trainRegressionWrapper(method, beat_feats, dirName, model_name):\n    aT.feature_extraction_train_regression(dirName, 1, 1, aT.shortTermWindow, aT.shortTermStep, method.lower(), model_name, compute_beat=beat_feats)\n"}
{"label_name":"train","label":0,"method_name":"pre_train_epoch","method":"\n\ndef pre_train_epoch(sess, trainable_model, data_loader):\n    supervised_g_losses = []\n    data_loader.reset_pointer()\n    for it in range(data_loader.num_batch):\n        batch = data_loader.next_batch()\n        (_, g_loss, g_pred) = trainable_model.pretrain_step(sess, batch)\n        supervised_g_losses.append(g_loss)\n    return np.mean(supervised_g_losses)\n"}
{"label_name":"train","label":0,"method_name":"get_normalized_train_dir","method":"\n\ndef get_normalized_train_dir(train_dir):\n    '\\n    Adds symlink to {train_dir} from \/tmp\/cs224n-squad-train to canonicalize the\\n    file paths saved in the checkpoint. This allows the model to be reloaded even\\n    if the location of the checkpoint files has moved, allowing usage with CodaLab.\\n    This must be done on both train.py and qa_answer.py in order to work.\\n    '\n    global_train_dir = '\/tmp\/cs224n-squad-train'\n    if os.path.exists(global_train_dir):\n        os.unlink(global_train_dir)\n    if (not os.path.exists(train_dir)):\n        os.makedirs(train_dir)\n    os.symlink(os.path.abspath(train_dir), global_train_dir)\n    return global_train_dir\n"}
{"label_name":"train","label":0,"method_name":"_create_training_set","method":"\n\ndef _create_training_set(data_paths, training_set_path):\n    ' Create a text file storing the path to the images and there class label in one row.\\n\\n        Args:\\n            data_paths: list of the paths where the input is stored\\n            training_set_path: path where the file is being stored\\n            number_of_items_per_class: Number of items per class you want to have in your training dataset. This\\n                number must be smaller than the maximum number of images per class. By default each class will\\n                have 500 entries for training.\\n    '\n    if os.path.exists(training_set_path):\n        print('Training set file already exists.')\n        return\n    training_set_file = open(training_set_path, 'w')\n    for path in data_paths:\n        for photo in os.listdir(path)[0:number_of_images_for_training]:\n            photo_path = os.path.join(path, photo)\n            training_entry = ('%s %s \\n' % (photo_path, data_paths.index(path)))\n            training_set_file.write(training_entry)\n    training_set_file.close()\n"}
{"label_name":"process","label":2,"method_name":"_process_input_file","method":"\n\ndef _process_input_file(filename, vocab, stats):\n    'Processes the sentences in an input file.\\n\\n  Args:\\n    filename: Path to a pre-tokenized input .txt file.\\n    vocab: A dictionary of word to id.\\n    stats: A Counter object for statistics.\\n\\n  Returns:\\n    processed: A list of serialized Example protos\\n  '\n    tf.logging.info('Processing input file: %s', filename)\n    processed = []\n    predecessor = None\n    current = None\n    successor = None\n    for successor_str in tf.gfile.FastGFile(filename):\n        stats.update(['sentences_seen'])\n        successor = successor_str.split()\n        if (predecessor and current and successor):\n            stats.update(['sentences_considered'])\n            if (FLAGS.max_sentence_length and ((len(predecessor) >= FLAGS.max_sentence_length) or (len(current) >= FLAGS.max_sentence_length) or (len(successor) >= FLAGS.max_sentence_length))):\n                stats.update(['sentences_too_long'])\n            else:\n                serialized = _create_serialized_example(predecessor, current, successor, vocab)\n                processed.append(serialized)\n                stats.update(['sentences_output'])\n        predecessor = current\n        current = successor\n        sentences_seen = stats['sentences_seen']\n        sentences_output = stats['sentences_output']\n        if (sentences_seen and ((sentences_seen % 100000) == 0)):\n            tf.logging.info('Processed %d sentences (%d output)', sentences_seen, sentences_output)\n        if (FLAGS.max_sentences and (sentences_output >= FLAGS.max_sentences)):\n            break\n    tf.logging.info('Completed processing file %s', filename)\n    return processed\n"}
{"label_name":"save","label":1,"method_name":"save_imgs","method":"\n\ndef save_imgs(imgs, filename='images.png', image_size=800):\n    (mode, bgcol) = ('RGB', (255, 255, 255))\n    channel_axis = (1 if (K.image_dim_ordering() == 'th') else 3)\n    if (imgs.shape[channel_axis] == 1):\n        (mode, bgcol) = ('L', 255)\n    if (channel_axis == 1):\n        imgs = np.swapaxes(imgs, 1, 3)\n    if (imgs.max() <= 1):\n        imgs = (imgs * 255)\n    imgs = imgs.astype('uint8')\n    if ('.' not in filename):\n        filename += '.png'\n    new_im = Image.new(mode, (image_size, image_size))\n    rows = cols = math.ceil(math.sqrt(len(imgs)))\n    if (((rows - 1) * cols) >= len(imgs)):\n        rows -= 1\n    size_s = int(math.ceil((image_size \/ float(cols))))\n    idx = 0\n    for y in range(0, image_size, size_s):\n        for x in range(0, image_size, size_s):\n            if (idx == len(imgs)):\n                continue\n            im = Image.fromarray(imgs[idx], mode)\n            w_border = Image.new(mode, (size_s, size_s), bgcol)\n            new_size = (size_s - 2)\n            if ((im.size[0] != new_size) or (im.size[1] != new_size)):\n                im = im.resize((new_size, new_size))\n            w_border.paste(im, (1, 1))\n            idx += 1\n            new_im.paste(w_border, (x, y))\n            new_im.paste(im, (x, y))\n    new_im.save(filename)\n"}
{"label_name":"train","label":0,"method_name":"add_training_io_args","method":"\n\ndef add_training_io_args(params):\n    params = params.add_argument_group('Data & I\/O')\n    add_training_data_args(params, required=False)\n    add_prepared_data_args(params)\n    add_validation_data_params(params)\n    add_bucketing_args(params)\n    add_vocab_args(params)\n    add_training_output_args(params)\n    add_monitoring_args(params)\n"}
{"label_name":"save","label":1,"method_name":"save_checkpoint","method":"\n\ndef save_checkpoint(state, is_best, folder='.\/', filename='checkpoint.pth.tar'):\n    if (not os.path.isdir(folder)):\n        os.mkdir(folder)\n    torch.save(state, os.path.join(folder, filename))\n    if is_best:\n        shutil.copyfile(os.path.join(folder, filename), os.path.join(folder, 'model_best.pth.tar'))\n"}
{"label_name":"process","label":2,"method_name":"process_results","method":"\n\ndef process_results(metrics):\n    'Extract useful information from given metrics.\\n\\n  Args:\\n    metrics: List of results dicts. These should have been written to disk by\\n        training jobs.\\n\\n  Returns:\\n    Dict mapping stats names to values.\\n\\n  Raises:\\n    ValueError: If max_npe or max_global_repetitions values are inconsistant\\n        across dicts in the `metrics` list.\\n  '\n    count = len(metrics)\n    success_count = 0\n    total_npe = 0\n    success_npe = 0\n    max_npe = 0\n    max_repetitions = 0\n    for metric_dict in metrics:\n        if (not max_npe):\n            max_npe = metric_dict['max_npe']\n        elif (max_npe != metric_dict['max_npe']):\n            raise ValueError('Invalid experiment. Different reps have different max-NPE settings.')\n        if (not max_repetitions):\n            max_repetitions = metric_dict['max_global_repetitions']\n        elif (max_repetitions != metric_dict['max_global_repetitions']):\n            raise ValueError('Invalid experiment. Different reps have different num-repetition settings.')\n        if metric_dict['found_solution']:\n            success_count += 1\n            success_npe += metric_dict['npe']\n        total_npe += metric_dict['npe']\n    stats = {}\n    stats['max_npe'] = max_npe\n    stats['max_repetitions'] = max_repetitions\n    stats['repetitions'] = count\n    stats['successes'] = success_count\n    stats['failures'] = (count - success_count)\n    stats['success_npe'] = success_npe\n    stats['total_npe'] = total_npe\n    if success_count:\n        stats['avg_success_npe'] = (stats['success_npe'] \/ float(success_count))\n    else:\n        stats['avg_success_npe'] = 0.0\n    if count:\n        stats['success_rate'] = (success_count \/ float(count))\n        stats['avg_total_npe'] = (stats['total_npe'] \/ float(count))\n    else:\n        stats['success_rate'] = 0.0\n        stats['avg_total_npe'] = 0.0\n    return stats\n"}
{"label_name":"process","label":2,"method_name":"process_sample","method":"\n\ndef process_sample(submission_id):\n    '\\n    Processes a sample after it has been submitted.  This runs as a thread.\\n\\n    :param submission_id:  The ID of the submission in the database.\\n    :return: Nothing.\\n    '\n    sys.modules['library'] = library\n    try:\n        submission = Submission.query.filter_by(id=submission_id).first()\n    except Exception as exc:\n        app.logger.exception('Exception while looking up submission: {0}'.format(exc))\n        return\n    try:\n        ml = ML.load_classifier(os.path.join('..', '..', 'classifier'))\n        s = Sample(fromfile=os.path.join('\/samples', submission.sha256))\n        y = ml.predict_sample(s)\n        submission.status = 'Done'\n        submission.classification = y\n        app.logger.info('Finished processing sample: {0} as: {1}'.format(s.sha256, y))\n    except Exception as exc:\n        submission.status = 'Error'\n        app.logger.exception('Error processing sample: {0} - Exception: {1}'.format(s.sha256, exc))\n    db.session.add(submission)\n    db.session.commit()\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train(epoch):\n    model.train()\n    train_sampler.set_epoch(epoch)\n    for (batch_idx, (data, target)) in enumerate(train_loader):\n        if args.cuda:\n            (data, target) = (data.cuda(), target.cuda())\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.nll_loss(output, target)\n        loss.backward()\n        optimizer.step()\n        if ((batch_idx % args.log_interval) == 0):\n            print('Train Epoch: {} [{}\/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, (batch_idx * len(data)), len(train_sampler), ((100.0 * batch_idx) \/ len(train_loader)), loss.item()))\n            if (hvd.rank() == 0):\n                experiment.log_metrics(step=epoch, loss=loss.item())\n"}
{"label_name":"train","label":0,"method_name":"load_train2","method":"\n\ndef load_train2(train_path):\n    images = []\n    classes = []\n    path = train_path\n    file_names = os.listdir(os.path.join(os.getcwd(), train_path))\n    counter = 1\n    print('Creating Classes, reading images and breaking things ...\\n')\n    for file in file_names:\n        drawProgressBar((counter \/ len(file_names)))\n        classes.append(file.split('_')[0])\n        image = cv2.imread(os.path.join(os.getcwd(), train_path, file))\n        image = image.astype(np.float32)\n        image = np.multiply(image, (1.0 \/ 255.0))\n        images.append(image)\n        counter += 1\n    print('\\nDone!')\n    images = np.array(images)\n    for i in range(len(classes)):\n        if (classes[i] not in imp_labels):\n            classes[i] = 'unkown'\n    d = {ni: indi for (indi, ni) in enumerate(set(classes))}\n    classes = [d[ni] for ni in classes]\n    classes = np.array(classes)\n    n_values = (np.max(classes) + 1)\n    classes = np.eye(n_values)[classes]\n    print(d)\n    print('\\n images shape: {}, labels shape: {}'.format(images.shape, classes.shape))\n    return (images, classes)\n"}
{"label_name":"predict","label":4,"method_name":"predict","method":"\n\ndef predict(X, W1, b1, W2, b2):\n    (Y, _) = forward(X, W1, b1, W2, b2)\n    return np.round(Y)\n"}
{"label_name":"process","label":2,"method_name":"preprocess_image","method":"\n\ndef preprocess_image(image, augment):\n    image = tf.image.decode_jpeg(image, channels=3)\n    if augment:\n        image = tf.image.resize(image, [256, 256])\n        image = tf.image.random_crop(image, INPUT_IMAGE_SIZE)\n        if (random.random() < 0.5):\n            image = tf.image.flip_left_right(image)\n    else:\n        image = tf.image.resize(image, INPUT_IMAGE_SIZE[:2])\n    image \/= 255.0\n    return image\n"}
{"label_name":"train","label":0,"method_name":"get_variables_to_train","method":"\n\ndef get_variables_to_train():\n    train_variables = []\n    for var in tf.trainable_variables():\n        if ('Inception' not in var.name):\n            train_variables.append(var)\n    return train_variables\n"}
{"label_name":"train","label":0,"method_name":"_get_train_epoch_range","method":"\n\ndef _get_train_epoch_range():\n    return g_train_epoch_range\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train(is_finetune=False):\n    startstep = (0 if (not is_finetune) else int(FLAGS.finetune_dir.split('-')[(- 1)]))\n    (image_filenames, label_filenames) = AirNet.get_filename_list(FLAGS.train_dir)\n    (val_image_filenames, val_label_filenames) = AirNet.get_filename_list(FLAGS.val_dir)\n    with tf.Graph().as_default():\n        (images, labels, is_training, keep_prob) = AirNet.placeholder_inputs(batch_size=FLAGS.batch_size)\n        (images, labels) = AirNet.dataset_inputs(image_filenames, label_filenames, FLAGS.batch_size)\n        (val_images, val_labels) = AirNet.dataset_inputs(val_image_filenames, val_label_filenames, FLAGS.eval_batch_size, False)\n        if (FLAGS.model == 'basic'):\n            logits = AirNet.inference_basic(images, is_training)\n        elif (FLAGS.model == 'extended'):\n            logits = AirNet.inference_extended(images, is_training)\n        elif (FLAGS.model == 'basic_dropout'):\n            logits = AirNet.inference_basic_dropout(images, is_training, keep_prob)\n        elif (FLAGS.model == 'extended_dropout'):\n            logits = AirNet.inference_extended_dropout(images, is_training, keep_prob)\n        else:\n            raise ValueError('The selected model does not exist')\n        loss = AirNet.loss_calc(logits=logits, labels=labels)\n        (train_op, global_step) = AirNet.training(loss=loss)\n        accuracy = tf.argmax(logits, axis=3)\n        summary = tf.summary.merge_all()\n        saver = tf.train.Saver(max_to_keep=100000)\n        with tf.Session() as sess:\n            if is_finetune:\n                print('\\n =====================================================')\n                print('  Finetuning with model: ', FLAGS.model)\n                print('\\n    Batch size is: ', FLAGS.batch_size)\n                print('    ckpt files are saved to: ', FLAGS.log_dir)\n                print('    Max iterations to train is: ', FLAGS.max_steps)\n                print(' =====================================================')\n                saver.restore(sess, FLAGS.finetune_dir)\n            else:\n                print('\\n =====================================================')\n                print('  Training from scratch with model: ', FLAGS.model)\n                print('\\n    Batch size is: ', FLAGS.batch_size)\n                print('    ckpt files are saved to: ', FLAGS.log_dir)\n                print('    Max iterations to train is: ', FLAGS.max_steps)\n                print(' =====================================================')\n                sess.run(tf.variables_initializer(tf.global_variables()))\n                sess.run(tf.local_variables_initializer())\n            coord = tf.train.Coordinator()\n            threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n            train_writer = tf.summary.FileWriter(FLAGS.log_dir, sess.graph)\n            ' Starting iterations to train the network '\n            for step in range((startstep + 1), ((startstep + FLAGS.max_steps) + 1)):\n                (images_batch, labels_batch) = sess.run(fetches=[images, labels])\n                train_feed_dict = {images: images_batch, labels: labels_batch, is_training: True, keep_prob: 0.5}\n                start_time = time.time()\n                (_, train_loss_value, train_accuracy_value, train_summary_str) = sess.run([train_op, loss, accuracy, summary], feed_dict=train_feed_dict)\n                duration = (time.time() - start_time)\n                if ((step % 10) == 0):\n                    examples_per_sec = (FLAGS.batch_size \/ duration)\n                    sec_per_batch = float(duration)\n                    print('\\n--- Normal training ---')\n                    format_str = '%s: step %d, loss = %.2f (%.1f examples\/sec; %.3f sec\/batch)'\n                    print((format_str % (datetime.now(), step, train_loss_value, examples_per_sec, sec_per_batch)))\n                    pred = sess.run(logits, feed_dict=train_feed_dict)\n                    AirNet.per_class_acc(pred, labels_batch)\n                    train_writer.add_summary(train_summary_str, step)\n                    train_writer.flush()\n                if (((step % 100) == 0) or ((step + 1) == FLAGS.max_steps)):\n                    test_iter = (FLAGS.num_examples_epoch_test \/\/ FLAGS.batch_size)\n                    ' Validate training by running validation dataset '\n                    print('\\n===========================================================')\n                    print('--- Running test on VALIDATION dataset ---')\n                    total_val_loss = 0.0\n                    hist = np.zeros((FLAGS.num_class, FLAGS.num_class))\n                    for val_step in range(test_iter):\n                        (val_images_batch, val_labels_batch) = sess.run(fetches=[val_images, val_labels])\n                        val_feed_dict = {images: val_images_batch, labels: val_labels_batch, is_training: True, keep_prob: 1.0}\n                        (_val_loss, _val_pred) = sess.run(fetches=[loss, logits], feed_dict=val_feed_dict)\n                        total_val_loss += _val_loss\n                        hist += AirNet.get_hist(_val_pred, val_labels_batch)\n                    print('Validation Loss: ', (total_val_loss \/ test_iter), '. If this value increases the model is likely overfitting.')\n                    AirNet.print_hist_summery(hist)\n                    print('===========================================================')\n                if (((step % 1000) == 0) or ((step % 500) == 0) or ((step + 1) == FLAGS.max_steps)):\n                    print('\\n--- SAVING SESSION ---')\n                    checkpoint_path = os.path.join(FLAGS.log_dir, 'model.ckpt')\n                    saver.save(sess, checkpoint_path, global_step=step)\n                    print('=========================')\n            coord.request_stop()\n            coord.join(threads)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train(x_train, x_test, y_train, y_test, train_lengths, test_lengths, sensor_data):\n    default_model = hmm.MultinomialHMM()\n    default_model.fit(np.array(x_train), y_train, train_lengths)\n    max_accuracy = default_model.score(np.array(x_test), y_test, test_lengths)\n    best_params = 'Default'\n    method_params_found = 'Default'\n    y_score = default_model.predict(np.array(x_test), lengths=test_lengths)\n    best_model = default_model\n    date_time = datetime.datetime.now()\n    msg = '{0}: The best MNHMM classifier was trained with the parameters {1} which produced an accuracy score of: {2}for {3} data. These parameters were found using the {4} method.'.format(str(date_time), str(best_params), str(max_accuracy), str(sensor_data), str(method_params_found))\n    logging.info(msg)\n    print(msg)\n    return {'model': best_model, 'model_type': 'MNHMM', 'max_accuracy': max_accuracy, 'best_params': best_params, 'method': method_params_found, 'y_score': y_score, 'y_test': y_test}\n"}
{"label_name":"save","label":1,"method_name":"save_sparse","method":"\n\ndef save_sparse(filename, X):\n    with h5py.File(filename, 'w') as file:\n        file['shape'] = np.array(X.shape)\n        file['data'] = X.data\n        file['indices'] = X.indices\n        file['indptr'] = X.indptr\n    logger.info('saved : {}\\t{}\\t{}'.format(filename, X.dtype, X.shape))\n"}
{"label_name":"process","label":2,"method_name":"preprocess_image","method":"\n\ndef preprocess_image(image):\n    return ((image - dataset.MEAN) \/ dataset.STD)\n"}
{"label_name":"save","label":1,"method_name":"save_pkg_resources_state","method":"\n\n@contextlib.contextmanager\ndef save_pkg_resources_state():\n    saved = pkg_resources.__getstate__()\n    try:\n        (yield saved)\n    finally:\n        pkg_resources.__setstate__(saved)\n"}
{"label_name":"process","label":2,"method_name":"_process_images_dir","method":"\n\ndef _process_images_dir(data, model):\n    if data.input_image_set_labels_path:\n        logger.info(\"Reading existing labels from '%s'\", data.input_image_set_labels_path)\n        image_set_labels = etai.ImageSetLabels.from_json(data.input_image_set_labels_path)\n    else:\n        image_set_labels = etai.ImageSetLabels()\n    for filename in etau.list_files(data.images_dir):\n        inpath = os.path.join(data.images_dir, filename)\n        logger.info(\"Processing image '%s'\", inpath)\n        img = etai.read(inpath)\n        image_labels = model.process(img)\n        image_set_labels[filename].merge_labels(image_labels)\n    logger.info(\"Writing labels to '%s'\", data.output_image_set_labels_path)\n    image_set_labels.write_json(data.output_image_set_labels_path)\n"}
{"label_name":"save","label":1,"method_name":"save_video","method":"\n\ndef save_video(y, seed, out_dir='infer', prefix=''):\n    y = y.transpose(0, 2, 3, 4, 1)\n    (n, f, h, w, c) = y.shape\n    y = y.transpose(1, 0, 2, 3, 4)\n    hn = int(np.sqrt(n))\n    y = y.reshape(f, hn, hn, h, w, c)\n    y = y.transpose(0, 1, 3, 2, 4, 5)\n    y = y.reshape(f, (hn * h), (hn * w), c)\n    for (i, p) in enumerate(y):\n        fn = '{}\/{}_seed-{}_{}.png'.format(out_dir, prefix, seed, i)\n        cv.imwrite(fn, p[:, :, ::(- 1)])\n    fn = '{}\/{}_seed-{}.avi'.format(out_dir, prefix, seed)\n    subprocess.call(['ffmpeg', '-i', '{}\/{}_seed-{}_%d.png'.format(out_dir, prefix, seed), '-vcodec', 'rawvideo', '-pix_fmt', 'yuv420p', fn])\n    for _fn in glob.glob('{}\/{}_*.png'.format(out_dir, prefix)):\n        os.remove(_fn)\n"}
{"label_name":"train","label":0,"method_name":"_get_train_op","method":"\n\ndef _get_train_op(loss_op, learning_rate, global_step):\n    return tf.train.AdamOptimizer(learning_rate).minimize(loss_op, global_step=global_step)\n"}
{"label_name":"process","label":2,"method_name":"process_qb_question","method":"\n\ndef process_qb_question(raw_question):\n    if (len(raw_question) < 2):\n        return None\n    question = raw_question.replace('.', '').replace('\/', '')\n    if question.startswith('\" '):\n        question = question[2:]\n    question = re.sub('\"[^\"]+\"', 'QUOTETOKEN', question)\n    if question.endswith(' \"'):\n        question = question[:(- 1)]\n    question = question.replace('\"', '')\n    question = re.sub('\\\\s+', ' ', question).strip()\n    return question\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train(maxloop, lr, X, y, w, b):\n    m = X.shape[0]\n    y = y.reshape((m, 1))\n    for i in range(maxloop):\n        a = forward(X, w, b)\n        d_z = (a - y)\n        d_w = (np.dot(X.T, d_z) \/ m)\n        d_b = (np.sum(d_z) \/ m)\n        w = (w - (lr * d_w))\n        b = (b - (lr * d_b))\n        y_ = a\n        print(calc_accuarcy(y_, y))\n    return (w, b)\n"}
{"label_name":"save","label":1,"method_name":"numpy_save","method":"\n\ndef numpy_save(list_to_save, write_location):\n    '\\n    Saves a list using the numpy \"Save\" function which is slightly faster than pickling.\\n    :param list_to_save: the list to persist.\\n    :param write_location: the location to write the list to.\\n    '\n    np.save(write_location, list_to_save)\n"}
{"label_name":"save","label":1,"method_name":"_save","method":"\n\ndef _save(im, fp, filename):\n    lossless = im.encoderinfo.get('lossless', False)\n    quality = im.encoderinfo.get('quality', 80)\n    icc_profile = im.encoderinfo.get('icc_profile', '')\n    exif = im.encoderinfo.get('exif', '')\n    xmp = im.encoderinfo.get('xmp', '')\n    if (im.mode not in _VALID_WEBP_LEGACY_MODES):\n        alpha = ((im.mode == 'P') and ('A' in im.im.getpalettemode()))\n        im = im.convert(('RGBA' if alpha else 'RGB'))\n    data = _webp.WebPEncode(im.tobytes(), im.size[0], im.size[1], lossless, float(quality), im.mode, icc_profile, exif, xmp)\n    if (data is None):\n        raise IOError('cannot write file as WebP (encoder returned None)')\n    fp.write(data)\n"}
{"label_name":"train","label":0,"method_name":"trainBoost","method":"\n\ndef trainBoost(base_classifier, X, labels, T=10):\n    (Npts, Ndims) = np.shape(X)\n    classifiers = []\n    alphas = []\n    wCur = (np.ones((Npts, 1)) \/ float(Npts))\n    for i_iter in range(0, T):\n        classifiers.append(base_classifier.trainClassifier(X, labels, wCur))\n        vote = classifiers[(- 1)].classify(X)\n        classes = np.unique(labels)\n        eps = 0\n        for jdx in classes:\n            idx = np.where((vote == jdx))[0]\n            eps += np.sum((np.transpose(wCur[idx]) * (1 - (jdx == labels[idx]))))\n        alpha = ((np.log((1 - eps)) - np.log(eps)) \/ 2)\n        alphas.append(alpha)\n        wOld = wCur\n        for i in range(Npts):\n            wCur[i] = (wOld[i] * np.exp((alpha * ((- 1) ** (vote[i] == labels[i])))))\n        wCur = (wCur \/ np.sum(wCur))\n    return (classifiers, alphas)\n"}
{"label_name":"train","label":0,"method_name":"train_epoch_ch3","method":"\n\ndef train_epoch_ch3(net, train_iter, loss, updater):\n    '\u8bad\u7ec3\u6a21\u578b\u4e00\u4e2a\u8fed\u4ee3\u5468\u671f\uff08\u5b9a\u4e49\u89c1\u7b2c3\u7ae0\uff09\u3002'\n    metric = Accumulator(3)\n    for (X, y) in train_iter:\n        with tf.GradientTape() as tape:\n            y_hat = net(X)\n            if isinstance(loss, tf.keras.losses.Loss):\n                l = loss(y, y_hat)\n            else:\n                l = loss(y_hat, y)\n        if isinstance(updater, tf.keras.optimizers.Optimizer):\n            params = net.trainable_variables\n            grads = tape.gradient(l, params)\n            updater.apply_gradients(zip(grads, params))\n        else:\n            updater(X.shape[0], tape.gradient(l, updater.params))\n        l_sum = ((l * float(tf.size(y))) if isinstance(loss, tf.keras.losses.Loss) else tf.reduce_sum(l))\n        metric.add(l_sum, accuracy(y_hat, y), tf.size(y))\n    return ((metric[0] \/ metric[2]), (metric[1] \/ metric[2]))\n"}
{"label_name":"process","label":2,"method_name":"process_planted","method":"\n\n@pytest.fixture()\ndef process_planted(min_size, max_size, max_count, n_samples, node_select):\n    'Fixture for loading samples from the Planted dataset'\n    samples = p_planted[:n_samples]\n    d = subgraph.search(samples, g_planted, min_size, max_size, max_count, node_select)\n    return d\n"}
{"label_name":"process","label":2,"method_name":"process_xml","method":"\n\ndef process_xml(file, download_path=get_download_path()):\n    root = et.parse(file).getroot()\n    activity_list = root.findall('*')\n    logger.info(('Found %d activities ' % len(activity_list)))\n    for activity in activity_list:\n        reader = ActivityReader(root=activity)\n        download_activity_data(reader, download_path=download_path, dump_activity=True)\n    docs_to_process = []\n    generate_docs_list(os.path.abspath(download_path), docs_to_process)\n    shuffle(docs_to_process)\n    logger.info(('There are %s documents, we will take a random subset of 200 ' % len(docs_to_process)))\n    for (path, file) in docs_to_process:\n        process_file(path, file)\n"}
{"label_name":"save","label":1,"method_name":"save","method":"\n\ndef save(estimator: Estimator, saved_model_dir: str) -> None:\n    'Save a Tensorflow estimator'\n    with TemporaryDirectory() as temporary_model_base_dir:\n        export_dir = estimator.export_saved_model(temporary_model_base_dir, _serving_input_receiver_fn)\n        Path(saved_model_dir).mkdir(exist_ok=True)\n        export_path = Path(export_dir.decode()).absolute()\n        for path in export_path.glob('*'):\n            shutil.move(str(path), saved_model_dir)\n"}
{"label_name":"save","label":1,"method_name":"_download_higgs_data_and_save_npz","method":"\n\ndef _download_higgs_data_and_save_npz(data_dir):\n    'Download higgs data and store as a numpy compressed file.'\n    input_url = os.path.join(URL_ROOT, INPUT_FILE)\n    np_filename = os.path.join(data_dir, NPZ_FILE)\n    if tf.gfile.Exists(np_filename):\n        raise ValueError('data_dir already has the processed data file: {}'.format(np_filename))\n    if (not tf.gfile.Exists(data_dir)):\n        tf.gfile.MkDir(data_dir)\n    try:\n        tf.logging.info('Data downloading...')\n        (temp_filename, _) = urllib.request.urlretrieve(input_url)\n        tf.logging.info('Data processing... taking multiple minutes...')\n        with gzip.open(temp_filename, 'rb') as csv_file:\n            data = pd.read_csv(csv_file, dtype=np.float32, names=[('c%02d' % i) for i in range(29)]).as_matrix()\n    finally:\n        tf.gfile.Remove(temp_filename)\n    f = tempfile.NamedTemporaryFile()\n    np.savez_compressed(f, data=data)\n    tf.gfile.Copy(f.name, np_filename)\n    tf.logging.info('Data saved to: {}'.format(np_filename))\n"}
{"label_name":"predict","label":4,"method_name":"predict","method":"\n\ndef predict(l1_model_results, profile):\n    '\\n    :param l1_model_results: results of l1 model predictions as a dictionary\\n                             { model_name : ndarray(NB_CLIPS, NB_FRAMES, NB_CLASSES) }\\n    :return: class probabilities as ndarray with shape (NB_CLIPS, NB_CLASSES)\\n    '\n    l1_model_names = config.PROFILES[profile]\n    xgboost_model = SecondLevelModelXGBoost(l1_model_names=l1_model_names, combined_model_name=('preset_' + profile))\n    mlp_model = SecondLevelModelMLP(l1_model_names=l1_model_names, combined_model_name=('preset_' + profile))\n    xgboost_predictions = xgboost_model.predict(l1_model_results)\n    mlp_predictions = mlp_model.predict(l1_model_results)\n    return ((xgboost_predictions * 0.5) + (mlp_predictions * 0.5))\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train(mnist):\n    x = tf.placeholder(tf.float32, [BATCH_SIZE, infrence.IMAGE_SIZE, infrence.IMAGE_SIZE, infrence.NUM_CHANNELS], name='x-input')\n    y_ = tf.placeholder(tf.float32, [None, infrence.OUTPUT_NODE], name='y-input')\n    regularizer = tf.contrib.layers.l2_regularizer(REGULARAZTION_RATE)\n    y = infrence.inference(x, True, regularizer)\n    global_step = tf.Variable(0, trainable=False)\n    variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)\n    variable_averages_op = variable_averages.apply(tf.trainable_variables())\n    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, 1))\n    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n    loss = (cross_entropy_mean + tf.add_n(tf.get_collection('losses')))\n    learning_rate = tf.train.exponential_decay(LEARNING_RATE_BASE, global_step, (mnist.train.num_examples \/ BATCH_SIZE), LEARNING_RATE_DECAY)\n    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n    with tf.control_dependencies([train_step, variable_averages_op]):\n        train_op = tf.no_op(name='train')\n    saver = tf.train.Saver()\n    with tf.Session() as sess:\n        tf.global_variables_initializer().run()\n        for i in range(TRAINING_STEPS):\n            (xs, ys) = mnist.train.next_batch(BATCH_SIZE)\n            reshaped_xs = np.reshape(xs, (BATCH_SIZE, infrence.IMAGE_SIZE, infrence.IMAGE_SIZE, infrence.NUM_CHANNELS))\n            (_, loss_value, step) = sess.run([train_op, loss, global_step], feed_dict={x: reshaped_xs, y_: ys})\n            if ((i % 1000) == 0):\n                print(('After %d training step(s), loss on training batch is %g' % (step, loss_value)))\n                if ((i \/ 1000) == 29):\n                    saver.save(sess, os.path.join(MODEL_SAVE_PATH, MODEL_NAME), global_step=global_step)\n"}
{"label_name":"train","label":0,"method_name":"check_all_trainers_ready","method":"\n\ndef check_all_trainers_ready(ready_path, epoch):\n    trainer_num = fleet.worker_num()\n    trainer_id = fleet.worker_index()\n    hadoop_home = os.getenv('HADOOP_HOME')\n    configs = {'fs.default.name': os.getenv('FS_NAME'), 'hadoop.job.ugi': os.getenv('FS_UGI')}\n    node_ready = 'ready.{}.{}.done'.format(epoch, trainer_id)\n    with open(node_ready, 'w') as node:\n        node.write('')\n    client = HDFSClient(hadoop_home, configs)\n    if (not client.is_dir(ready_path)):\n        client.makedirs(ready_path)\n    client.upload(hdfs_path=ready_path, local_path=node_ready, overwrite=True, retry_times=0)\n    print('PUT {} ON HDFS {} OK'.format(node_ready, ready_path))\n    while True:\n        ready_num = len(client.ls(ready_path))\n        print('have {} trainers need to be ready'.format((trainer_num - (ready_num % trainer_num))))\n        if ((ready_num % trainer_num) == 0):\n            break\n        time.sleep(10)\n        ready_num = len(client.ls(ready_path))\n    print('All trainers are ready, continue training')\n"}
{"label_name":"save","label":1,"method_name":"save_blob","method":"\n\ndef save_blob(content, path):\n    f = open(path, 'wb')\n    pickle.dump(content, f)\n    f.close()\n"}
{"label_name":"predict","label":4,"method_name":"predict","method":"\n\ndef predict(home_team, away_team, city, toss_winner, toss_decision):\n    matches_cleaned_data = pd.read_csv('.\/Dataset\/matches_cleaned.csv')\n    matches_df = matches_cleaned_data[['team1', 'team2', 'city', 'toss_winner', 'toss_decision', 'winner']]\n    array = matches_df.values\n    x = array[:, 0:5]\n    y = array[:, 5]\n    validation_size = 0.1\n    seed = 7\n    (x_train, x_validation, y_train, y_validation) = model_selection.train_test_split(x, y, test_size=validation_size, random_state=seed)\n    knn = DecisionTreeClassifier()\n    knn.fit(x_train, y_train)\n    results = convert_to_numerical_field(home_team, away_team, city, toss_winner, toss_decision)\n    predictions = knn.predict([results])\n    team = ''\n    if (predictions[0] == '6'):\n        team = 'KKR'\n    if (predictions[0] == '5'):\n        team = 'RCB'\n    if (predictions[0] == '9'):\n        team = 'CSK'\n    if (predictions[0] == '10'):\n        team = 'RR'\n    if (predictions[0] == '7'):\n        team = 'DD'\n    if (predictions[0] == '8'):\n        team = 'KXIP'\n    if (predictions[0] == '1'):\n        team = 'SRH'\n    if (predictions[0] == '2'):\n        team = 'MI'\n    print(('model->' + team))\n    if ((int(predictions) != convert_again(home_team).__int__()) and (int(predictions) != convert_again(away_team).__int__())):\n        print('Exception Case')\n        winner = convert_to_shortform(calculate_ef_score(home_team, away_team))\n        print(('EF score data ->' + winner))\n        return winner\n    else:\n        return team.__str__()\n"}
{"label_name":"predict","label":4,"method_name":"get_predicted_sentence","method":"\n\ndef get_predicted_sentence(args, input_sentence, vocab, rev_vocab, model, sess, debug=False, return_raw=False):\n\n    def model_step(enc_inp, dec_inp, dptr, target_weights, bucket_id):\n        (_, _, logits) = model.step(sess, enc_inp, dec_inp, target_weights, bucket_id, forward_only=True)\n        prob = softmax(logits[dptr][0])\n        return prob\n\n    def greedy_dec(output_logits, rev_vocab):\n        selected_token_ids = [int(np.argmax(logit, axis=1)) for logit in output_logits]\n        if (data_utils.EOS_ID in selected_token_ids):\n            eos = selected_token_ids.index(data_utils.EOS_ID)\n            selected_token_ids = selected_token_ids[:eos]\n        output_sentence = ' '.join([dict_lookup(rev_vocab, t) for t in selected_token_ids])\n        return output_sentence\n    input_token_ids = data_utils.sentence_to_token_ids(input_sentence, vocab)\n    bucket_id = min([b for b in range(len(args.buckets)) if (args.buckets[b][0] > len(input_token_ids))])\n    outputs = []\n    feed_data = {bucket_id: [(input_token_ids, outputs)]}\n    (encoder_inputs, decoder_inputs, target_weights) = model.get_batch(feed_data, bucket_id)\n    if debug:\n        print('\\n[get_batch]\\n', encoder_inputs, decoder_inputs, target_weights)\n    if (args.beam_size == 1):\n        (_, _, output_logits) = model.step(sess, encoder_inputs, decoder_inputs, target_weights, bucket_id, forward_only=True)\n        return [{'dec_inp': greedy_dec(output_logits, rev_vocab), 'prob': 1}]\n    (beams, new_beams, results) = ([(1, 0, {'eos': 0, 'dec_inp': decoder_inputs, 'prob': 1, 'prob_ts': 1, 'prob_t': 1})], [], [])\n    dummy_encoder_inputs = [np.array([data_utils.PAD_ID]) for _ in range(len(encoder_inputs))]\n    for dptr in range((len(decoder_inputs) - 1)):\n        if (dptr > 0):\n            target_weights[dptr] = [1.0]\n            (beams, new_beams) = (new_beams[:args.beam_size], [])\n        if debug:\n            print('=====[beams]=====', beams)\n        heapq.heapify(beams)\n        for (prob, _, cand) in beams:\n            if cand['eos']:\n                results += [(prob, 0, cand)]\n                continue\n            if debug:\n                print(cand['prob'], ' '.join([dict_lookup(rev_vocab, w) for w in cand['dec_inp']]))\n            all_prob_ts = model_step(encoder_inputs, cand['dec_inp'], dptr, target_weights, bucket_id)\n            if args.antilm:\n                all_prob_t = model_step(dummy_encoder_inputs, cand['dec_inp'], dptr, target_weights, bucket_id)\n                all_prob = ((all_prob_ts - (args.antilm * all_prob_t)) + (args.n_bonus * dptr))\n            else:\n                all_prob_t = ([0] * len(all_prob_ts))\n                all_prob = all_prob_ts\n            if (dptr < len(input_token_ids)):\n                all_prob[input_token_ids[dptr]] = (all_prob[input_token_ids[dptr]] * 0.01)\n            if return_raw:\n                return (all_prob, all_prob_ts, all_prob_t)\n            for c in np.argsort(all_prob)[::(- 1)][:args.beam_size]:\n                new_cand = {'eos': (c == data_utils.EOS_ID), 'dec_inp': [(np.array([c]) if (i == (dptr + 1)) else k) for (i, k) in enumerate(cand['dec_inp'])], 'prob_ts': (cand['prob_ts'] * all_prob_ts[c]), 'prob_t': (cand['prob_t'] * all_prob_t[c]), 'prob': (cand['prob'] * all_prob[c])}\n                new_cand = (new_cand['prob'], random(), new_cand)\n                try:\n                    if (len(new_beams) < args.beam_size):\n                        heapq.heappush(new_beams, new_cand)\n                    elif (new_cand[0] > new_beams[0][0]):\n                        heapq.heapreplace(new_beams, new_cand)\n                except Exception as e:\n                    print('[Error]', e)\n                    print('-----[new_beams]-----\\n', new_beams)\n                    print('-----[new_cand]-----\\n', new_cand)\n    results += new_beams\n    res_cands = []\n    for (prob, _, cand) in sorted(results, reverse=True):\n        cand['dec_inp'] = ' '.join([dict_lookup(rev_vocab, w) for w in cand['dec_inp']])\n        res_cands.append(cand)\n    return res_cands[:args.beam_size]\n"}
{"label_name":"train","label":0,"method_name":"train_valid_split","method":"\n\n@register_action\ndef train_valid_split(args):\n    meta_data_filepath = os.path.join(args.meta_data_dir, 'meta_train.csv')\n    meta_train_filepath = os.path.join(args.meta_data_processed_dir, 'meta_train_v1.csv')\n    meta_valid_filepath = os.path.join(args.meta_data_processed_dir, 'meta_valid_v1.csv')\n    meta_data = pd.read_csv(meta_data_filepath)\n    (meta_train, meta_valid) = train_test_split(meta_data, train_size=args.train_ratio, random_state=args.seed)\n    meta_train.to_csv(meta_train_filepath, index=None)\n    meta_valid.to_csv(meta_valid_filepath, index=None)\n"}
{"label_name":"save","label":1,"method_name":"_save_and_load","method":"\n\ndef _save_and_load(matrix):\n    (fd, tmpfile) = tempfile.mkstemp(suffix='.npz')\n    os.close(fd)\n    try:\n        save_npz(tmpfile, matrix)\n        loaded_matrix = load_npz(tmpfile)\n    finally:\n        os.remove(tmpfile)\n    return loaded_matrix\n"}
{"label_name":"train","label":0,"method_name":"check_regressors_train","method":"\n\n@ignore_warnings(category=(DeprecationWarning, FutureWarning))\ndef check_regressors_train(name, regressor_orig):\n    (X, y) = _boston_subset()\n    y = StandardScaler().fit_transform(y.reshape((- 1), 1))\n    y = y.ravel()\n    regressor = clone(regressor_orig)\n    y = multioutput_estimator_convert_y_2d(regressor, y)\n    rnd = np.random.RandomState(0)\n    if ((not hasattr(regressor, 'alphas')) and hasattr(regressor, 'alpha')):\n        regressor.alpha = 0.01\n    if (name == 'PassiveAggressiveRegressor'):\n        regressor.C = 0.01\n    assert_raises(ValueError, regressor.fit, X, y[:(- 1)])\n    if (name in CROSS_DECOMPOSITION):\n        y_ = np.vstack([y, ((2 * y) + rnd.randint(2, size=len(y)))])\n        y_ = y_.T\n    else:\n        y_ = y\n    set_random_state(regressor)\n    regressor.fit(X, y_)\n    regressor.fit(X.tolist(), y_.tolist())\n    y_pred = regressor.predict(X)\n    assert_equal(y_pred.shape, y_.shape)\n    if (name not in ('PLSCanonical', 'CCA', 'RANSACRegressor')):\n        assert_greater(regressor.score(X, y_), 0.5)\n"}
{"label_name":"save","label":1,"method_name":"save_output_plot","method":"\n\ndef save_output_plot(pytorch_variable, index, path='.\/l1_output\/'):\n    num_images = pytorch_variable.shape[0]\n    data = pytorch_variable.data.view([(- 1), 1, 28, 28])\n    data = (data \/ 2.0)\n    data = (data + 0.5)\n    output = torchvision.utils.make_grid(data, nrow=25)\n    output = deprocess_pil(output)\n    file_name = (path + 'output_{}.jpg'.format(index))\n    output.save(file_name)\n"}
{"label_name":"save","label":1,"method_name":"save_path","method":"\n\n@contextlib.contextmanager\ndef save_path():\n    saved = sys.path[:]\n    try:\n        (yield saved)\n    finally:\n        sys.path[:] = saved\n"}
{"label_name":"process","label":2,"method_name":"pre_process","method":"\n\ndef pre_process(batch):\n    (input, expected) = batch\n    input = utils.to_variable(input, dtype=torch.FloatTensor)\n    expected = utils.to_variable(expected, dtype=torch.LongTensor)\n    return (input, expected)\n"}
{"label_name":"train","label":0,"method_name":"trained_async","method":"\n\n@pytest.fixture(scope='session')\ndef trained_async(tmpdir_factory: TempdirFactory) -> Callable:\n\n    async def _train(*args: Any, output_path: Optional[Text]=None, **kwargs: Any) -> Optional[Text]:\n        if (output_path is None):\n            output_path = str(tmpdir_factory.mktemp('models'))\n        result = (await train_async(*args, output=output_path, **kwargs))\n        return result.model\n    return _train\n"}
{"label_name":"process","label":2,"method_name":"preprocess_image","method":"\n\ndef preprocess_image(image, height=INCEPTION_V3_DEFAULT_IMG_SIZE, width=INCEPTION_V3_DEFAULT_IMG_SIZE, central_fraction=0.875, scope=None):\n    'Prepare one image for evaluation.\\n\\n  If height and width are specified it would output an image with that size by\\n  applying resize_bilinear.\\n\\n  If central_fraction is specified it would crop the central fraction of the\\n  input image.\\n\\n  Args:\\n    image: 3-D Tensor of image. If dtype is tf.float32 then the range should be\\n      [0, 1], otherwise it would converted to tf.float32 assuming that the range\\n      is [0, MAX], where MAX is largest positive representable number for\\n      int(8\/16\/32) data type (see `tf.image.convert_image_dtype` for details).\\n    height: integer\\n    width: integer\\n    central_fraction: Optional Float, fraction of the image to crop.\\n    scope: Optional scope for name_scope.\\n  Returns:\\n    3-D float Tensor of prepared image.\\n  '\n    with ops.name_scope(scope, 'eval_image', [image, height, width]):\n        if (image.dtype != dtypes.float32):\n            image = image_ops.convert_image_dtype(image, dtype=dtypes.float32)\n        image = image_ops.central_crop(image, central_fraction=central_fraction)\n        image = array_ops.expand_dims(image, 0)\n        image = image_ops.resize_bilinear(image, [height, width], align_corners=False)\n        image = array_ops.squeeze(image, [0])\n        image = ((image - 0.5) * 2.0)\n        return image\n"}
{"label_name":"save","label":1,"method_name":"save_image","method":"\n\ndef save_image(path, image):\n    image = image[0]\n    image = denormalize(image)\n    scipy.misc.imsave(path, image)\n"}
{"label_name":"forward","label":3,"method_name":"unpool2dmax_forward_naive","method":"\n\ndef unpool2dmax_forward_naive(input, indices, ksize, strides, paddings):\n    (s0, s1, s2, s3) = input.shape\n    out_hsize = ((((s2 - 1) * strides[0]) - (2 * paddings[0])) + ksize[0])\n    out_wsize = ((((s2 - 1) * strides[1]) - (2 * paddings[1])) + ksize[1])\n    out = np.zeros((s0, s1, out_hsize, out_wsize))\n    for nidx in range(s0):\n        for cidx in range(s1):\n            for h in range(s2):\n                for w in range(s3):\n                    index = indices[(nidx, cidx, h, w)]\n                    hidx = ((index - (index % out_wsize)) \/\/ out_wsize)\n                    widx = (index % out_wsize)\n                    out[(nidx, cidx, int(hidx), int(widx))] = input[(nidx, cidx, h, w)]\n    return out\n"}
{"label_name":"process","label":2,"method_name":"process_1d_ising","method":"\n\ndef process_1d_ising(term):\n    components = term.split('_')\n    components.remove('1Dising')\n    include_transverse_component = include_chain_component = False\n    for l in components:\n        if (l[0] == 'd'):\n            dim = int(l.replace('d', ''))\n        elif (l[0] == 'i'):\n            chain_axis = str(l.replace('i', ''))\n            include_chain_component = True\n        elif (l[0] == 't'):\n            include_transverse_component = True\n            transverse_axis = str(l.replace('t', ''))\n    if (include_chain_component == True):\n        return ising_interaction_component(num_qubits=dim, interaction_axis=chain_axis)\n    elif (include_transverse_component == True):\n        return ising_transverse_component(num_qubits=dim, transverse_axis=transverse_axis)\n"}
{"label_name":"process","label":2,"method_name":"_processing_job_status","method":"\n\ndef _processing_job_status(sagemaker_client, job_name):\n    'Prints the job status for the given processing job name.\\n\\n    Returns the job description.\\n\\n    Args:\\n        sagemaker_client: The boto3 SageMaker client.\\n        job_name (str): The name of the job for which the status\\n            is requested.\\n\\n    Returns:\\n        dict: The processing job description.\\n    '\n    compile_status_codes = {'Completed': '!', 'InProgress': '.', 'Failed': '*', 'Stopped': 's', 'Stopping': '_'}\n    in_progress_statuses = ['InProgress', 'Stopping', 'Starting']\n    desc = sagemaker_client.describe_processing_job(ProcessingJobName=job_name)\n    status = desc['ProcessingJobStatus']\n    status = _STATUS_CODE_TABLE.get(status, status)\n    print(compile_status_codes.get(status, '?'), end='')\n    sys.stdout.flush()\n    if (status in in_progress_statuses):\n        return None\n    return desc\n"}
{"label_name":"train","label":0,"method_name":"run_core_training","method":"\n\ndef run_core_training(args: argparse.Namespace, train_path: Optional[Text]=None) -> Optional[Text]:\n    'Trains a Rasa Core model only.\\n\\n    Args:\\n        args: Command-line arguments to configure training.\\n        train_path: Path where trained model but not unzipped model should be stored.\\n\\n    Returns:\\n        Path to a trained model or `None` if training was not successful.\\n    '\n    from rasa.model_training import train_core\n    output = (train_path or args.out)\n    args.domain = rasa.cli.utils.get_validated_path(args.domain, 'domain', DEFAULT_DOMAIN_PATH, none_is_valid=True)\n    story_file = rasa.cli.utils.get_validated_path(args.stories, 'stories', DEFAULT_DATA_PATH, none_is_valid=True)\n    additional_arguments = extract_core_additional_arguments(args)\n    if ((not isinstance(args.config, list)) or (len(args.config) == 1)):\n        if isinstance(args.config, list):\n            args.config = args.config[0]\n        config = _get_valid_config(args.config, CONFIG_MANDATORY_KEYS_CORE)\n        return train_core(domain=args.domain, config=config, stories=story_file, output=output, train_path=train_path, fixed_model_name=args.fixed_model_name, additional_arguments=additional_arguments, model_to_finetune=_model_for_finetuning(args), finetuning_epoch_fraction=args.epoch_fraction)\n    else:\n        rasa.utils.common.run_in_loop(do_compare_training(args, story_file, additional_arguments))\n"}
{"label_name":"train","label":0,"method_name":"trainFileFromLines","method":"\n\ndef trainFileFromLines(addr_file, is_train=True):\n    lines = open(addr_file, 'r')\n    if (is_train is True):\n        outputFileName = (('training\/training_data\/' + re.sub('\\\\W+', '_', re.sub('.*\/', '', addr_file))) + '.xml')\n    else:\n        outputFileName = (('training\/test_data\/' + re.sub('\\\\W+', '_', re.sub('.*\/', '', addr_file))) + '.xml')\n    tag_list = [None, 'AddressNumber', 'USPSBox', 'StreetName', 'StreetNamePostType', 'PlaceName', 'StateName', 'ZipCode', 'suffix']\n    addr_list = etree.Element('AddressCollection')\n    addr = etree.Element('AddressString')\n    for line in lines:\n        if (line == '\\n'):\n            addr[(- 1)].tail = None\n            addr_list.append(addr)\n            addr = etree.Element('AddressString')\n        else:\n            split = line.split(' |')\n            addr_line = split[0]\n            addr_tokens = addr_line.split()\n            token_num = int(split[1].rstrip())\n            token_tag = tag_list[token_num]\n            for token in addr_tokens:\n                token_xml = etree.Element(token_tag)\n                token_xml.text = token\n                token_xml.tail = ' '\n                addr.append(token_xml)\n    output = etree.tostring(addr_list, pretty_print=True)\n    with open(outputFileName, 'w') as f:\n        f.write(output)\n"}
{"label_name":"train","label":0,"method_name":"load_train3","method":"\n\ndef load_train3(train_path):\n    images = []\n    classes = []\n    path = train_path\n    file_names = os.listdir(os.path.join(os.getcwd(), train_path))\n    counter = 1\n    print('Creating Classes, reading images and breaking things ...\\n')\n    for file in file_names:\n        drawProgressBar((counter \/ len(file_names)))\n        classes.append(file.split('_')[0])\n        image = cv2.imread(os.path.join(os.getcwd(), train_path, file))\n        image = image.astype(np.float32)\n        image = np.multiply(image, (1.0 \/ 255.0))\n        images.append(image)\n        counter += 1\n    print('\\nDone!')\n    images = np.array(images)\n    for i in range(len(classes)):\n        if (classes[i] not in imp_labels):\n            classes[i] = 'unkown'\n    d = {ni: indi for (indi, ni) in enumerate(set(classes))}\n    classes = [d[ni] for ni in classes]\n    classes = np.array(classes)\n    n_values = (np.max(classes) + 1)\n    classes = np.eye(n_values)[classes]\n    print(d)\n    print('\\n images shape: {}, labels shape: {}'.format(images.shape, classes.shape))\n    return (images, classes)\n"}
{"label_name":"train","label":0,"method_name":"train_basic_multilabel_classifier","method":"\n\ndef train_basic_multilabel_classifier(df_twitter_train):\n    column_descriptions = {'airline_sentiment': 'output', 'airline': 'categorical', 'text': 'ignore', 'tweet_location': 'categorical', 'user_timezone': 'categorical', 'tweet_created': 'date'}\n    ml_predictor = Predictor(type_of_estimator='classifier', column_descriptions=column_descriptions)\n    ml_predictor.train(df_twitter_train)\n    return ml_predictor\n"}
{"label_name":"predict","label":4,"method_name":"_calculate_batch_prediction_dot","method":"\n\ndef _calculate_batch_prediction_dot(lines, features_lookup):\n    (y_pred, submission_indices) = ([], [])\n    for line in lines:\n        submission_indices.append(line[0])\n        image_feature_a = features_lookup[line[1]]\n        image_feature_b = features_lookup[line[2]]\n        y_pred.append(np.dot(image_feature_a, image_feature_b))\n    return (y_pred, submission_indices)\n"}
{"label_name":"predict","label":4,"method_name":"predict","method":"\n\ndef predict(answers, thresholds, value):\n    if (value < thresholds[0]):\n        return answers[0]\n    elif (thresholds[0] <= value < thresholds[1]):\n        return answers[1]\n    else:\n        return answers[2]\n"}
{"label_name":"train","label":0,"method_name":"train_and_eval","method":"\n\ndef train_and_eval(X_param, y_param, max_depth=16, n_estimators=100):\n    (X_train, X_valid, y_train, y_valid) = train_test_split(X_param, y_param, random_state=77)\n    classifier = RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators)\n    classifier.fit(X_train, y_train)\n    y_pred = classifier.predict(X_valid)\n    score = accuracy_score(y_valid, y_pred)\n    return score\n"}
{"label_name":"process","label":2,"method_name":"query_preprocessor","method":"\n\ndef query_preprocessor(query_str):\n    ps = PorterStemmer()\n    query_dict = {}\n    query_str_modified = query_str.strip()\n    query_str_modified = remove_special_char(query_str_modified)\n    query_str_modified = query_str_modified.lower()\n    query_str_modified = re.sub(' +', ' ', query_str_modified)\n    words = query_str_modified.split(' ')\n    max_freq = 0\n    N = 0\n    for word in words:\n        word = word.strip()\n        if ((word not in stopwords) and (word != '')):\n            word = ps.stem(word)\n            if (word not in query_dict):\n                query_dict[word] = 1\n            else:\n                query_dict[word] = (query_dict[word] + 1)\n            if (query_dict[word] > max_freq):\n                max_freq = query_dict[word]\n            N += 1\n    return (query_dict, max_freq, N)\n"}
{"label_name":"train","label":0,"method_name":"train_step","method":"\n\ndef train_step(model, x, y):\n    with tf.GradientTape() as tape:\n        y_pred = model(x)\n        loss = mse_loss(y_pred, y)\n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n"}
{"label_name":"save","label":1,"method_name":"save_samples","method":"\n\ndef save_samples(samples, iteration: int):\n    d = 'results\/samples\/'\n    ensure_dir(d)\n    plot_samples(samples.view((- 1), 1, 28, 28), path=os.path.join(d, f'mnist-{iteration:03}.png'))\n"}
{"label_name":"save","label":1,"method_name":"_make_saver","method":"\n\ndef _make_saver(graph, keep_checkpoint_max=5):\n    vars_to_save = (graph.get_collection(ops.GraphKeys.GLOBAL_VARIABLES) + graph.get_collection(ops.GraphKeys.SAVEABLE_OBJECTS))\n    if vars_to_save:\n        return tf_saver.Saver(vars_to_save, sharded=True, max_to_keep=keep_checkpoint_max)\n    else:\n        return None\n"}
{"label_name":"train","label":0,"method_name":"trainHMMsegmenter_fromdir","method":"\n\ndef trainHMMsegmenter_fromdir(directory, hmmModelName, mt_win, mt_step):\n    if (not os.path.isdir(directory)):\n        raise Exception('Input folder not found!')\n    aS.train_hmm_from_directory(directory, hmmModelName, mt_win, mt_step)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train(config, inputs, args):\n    gan = setup_gan(config, inputs, args)\n    sampler = TrainingVideoFrameSampler(gan)\n    gan.selected_sampler = ''\n    samples = 0\n    for i in range(args.steps):\n        gan.step()\n        if ((args.action == 'train') and ((i % args.save_every) == 0) and (i > 0)):\n            print(('saving ' + save_file))\n            gan.save(save_file)\n        if ((i % args.sample_every) == 0):\n            sample_file = (('samples\/' + args.config) + ('\/%06d.png' % samples))\n            os.makedirs(os.path.expanduser(os.path.dirname(sample_file)), exist_ok=True)\n            samples += 1\n            sampler.sample(sample_file, args.save_samples)\n    return []\n"}
{"label_name":"process","label":2,"method_name":"process_all_stocks_data","method":"\n\ndef process_all_stocks_data(root_path, symbols, day_range, stock_memory, symbol_memory, index, range_len):\n    startTime_1 = time.time()\n    filename = 'cashflow_count.csv'\n    db_count = pd.DataFrame(columns=['symbol', '0-price', '1day', '1-pect', '1-price', '2day', '2-pect', '2-price', '3day', '3-pect', '3-price'])\n    db_count.index.name = 'index'\n    for symbol in symbols:\n        startTime = cal_stock_data(root_path, db_count, symbol, stock_memory, symbol_memory, day_range, index, range_len)\n    return db_count\n"}
{"label_name":"process","label":2,"method_name":"preprocess","method":"\n\ndef preprocess(image):\n    with tf.name_scope('preprocess'):\n        return ((image * 2) - 1)\n"}
{"label_name":"predict","label":4,"method_name":"get_predictions","method":"\n\ndef get_predictions(question_doc: Doc, rp: str, ml_algo: str):\n    '\\n    Gets data in the form of sparse matrix from `qc.dataprep.feature_stack` module\\n    which is ready for use in a machine learning model. Using the test data in `question-classification\/dataset`\\n    tests [[ml_algo]] model which is pre-trained and saved as serialized pickle files.\\n\\n    :argument\\n        :param question_doc The question to be classified given as tagged Doc from NLP process.\\n        :param rp: Absolute path of the root directory of the project.\\n        :param ml_algo: The type of machine learning models to be used. (svm | lr | linear_svm)\\n    :return:\\n        pred: Question class prediction.\\n    '\n    c_ft = get_ft_obj('api', rp, ml_algo, 'coarse', [question_doc]).tocsr()\n    a_ft = get_ft_obj('api', rp, ml_algo, 'abbr', [question_doc]).tocsr()\n    d_ft = get_ft_obj('api', rp, ml_algo, 'desc', [question_doc]).tocsr()\n    e_ft = get_ft_obj('api', rp, ml_algo, 'enty', [question_doc]).tocsr()\n    h_ft = get_ft_obj('api', rp, ml_algo, 'hum', [question_doc]).tocsr()\n    l_ft = get_ft_obj('api', rp, ml_algo, 'loc', [question_doc]).tocsr()\n    n_ft = get_ft_obj('api', rp, ml_algo, 'num', [question_doc]).tocsr()\n    print('- DataPrep done.')\n    c = coarse_model.predict(c_ft[0])[0]\n    if (c == 'ABBR'):\n        f = abbr_model.predict(a_ft[0])[0]\n    elif (c == 'DESC'):\n        f = desc_model.predict(d_ft[0])[0]\n    elif (c == 'ENTY'):\n        f = enty_model.predict(e_ft[0])[0]\n    elif (c == 'HUM'):\n        f = hum_model.predict(h_ft[0])[0]\n    elif (c == 'LOC'):\n        f = loc_model.predict(l_ft[0])[0]\n    else:\n        f = num_model.predict(n_ft[0])[0]\n    print('- Predict done.')\n    return [c, f]\n"}
{"label_name":"save","label":1,"method_name":"_save","method":"\n\ndef _save(im, fp, filename):\n    fp.write(_MAGIC)\n    sizes = im.encoderinfo.get('sizes', [(16, 16), (24, 24), (32, 32), (48, 48), (64, 64), (128, 128), (256, 256)])\n    (width, height) = im.size\n    sizes = filter((lambda x: (False if ((x[0] > width) or (x[1] > height) or (x[0] > 256) or (x[1] > 256)) else True)), sizes)\n    sizes = list(sizes)\n    fp.write(struct.pack('<H', len(sizes)))\n    offset = (fp.tell() + (len(sizes) * 16))\n    for size in sizes:\n        (width, height) = size\n        fp.write(struct.pack('B', (width if (width < 256) else 0)))\n        fp.write(struct.pack('B', (height if (height < 256) else 0)))\n        fp.write(b'\\x00')\n        fp.write(b'\\x00')\n        fp.write(b'\\x00\\x00')\n        fp.write(struct.pack('<H', 32))\n        image_io = BytesIO()\n        tmp = im.copy()\n        tmp.thumbnail(size, Image.LANCZOS)\n        tmp.save(image_io, 'png')\n        image_io.seek(0)\n        image_bytes = image_io.read()\n        bytes_len = len(image_bytes)\n        fp.write(struct.pack('<I', bytes_len))\n        fp.write(struct.pack('<I', offset))\n        current = fp.tell()\n        fp.seek(offset)\n        fp.write(image_bytes)\n        offset = (offset + bytes_len)\n        fp.seek(current)\n"}
{"label_name":"save","label":1,"method_name":"save_graph_to_file","method":"\n\ndef save_graph_to_file(graph_file_name, module_spec, class_count):\n    'Saves an graph to file, creating a valid quantized one if necessary.'\n    (sess, _, _, _, _, _) = build_eval_session(module_spec, class_count)\n    graph = sess.graph\n    output_graph_def = tf.graph_util.convert_variables_to_constants(sess, graph.as_graph_def(), [FLAGS.final_tensor_name])\n    with tf.gfile.GFile(graph_file_name, 'wb') as f:\n        f.write(output_graph_def.SerializeToString())\n"}
{"label_name":"predict","label":4,"method_name":"predict_dygraph","method":"\n\ndef predict_dygraph(data):\n    program_translator.enable(False)\n    paddle.disable_static(place)\n    resnet = ResNet()\n    (model_dict, _) = paddle.fluid.dygraph.load_dygraph(DY_STATE_DICT_SAVE_PATH)\n    resnet.set_dict(model_dict)\n    resnet.eval()\n    pred_res = resnet(paddle.to_tensor(data=data, dtype=None, place=None, stop_gradient=True))\n    ret = pred_res.numpy()\n    paddle.enable_static()\n    return ret\n"}
{"label_name":"train","label":0,"method_name":"do_train","method":"\n\ndef do_train():\n    train_data = si.read_data_sets()\n    global_step = tf.contrib.framework.get_or_create_global_step()\n    (images, labels) = input_placsholders(BATCH_SIZE)\n    logits = inference(images)\n    total_loss = loss(logits, labels)\n    (train_op, learning_rate) = train(total_loss, global_step)\n    eval_op = evaluation(logits, labels)\n    init_op = tf.global_variables_initializer()\n    saver = tf.train.Saver()\n    start_time = time.time()\n    with tf.Session() as sess:\n        sess.run(init_op)\n        for var in tf.trainable_variables():\n            tf.summary.histogram(var.op.name, var)\n        merged = tf.summary.merge_all()\n        run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n        run_metadata = tf.RunMetadata()\n        for step in xrange(NUME_STEPS):\n            _feed_dict = feed_data(train_data.train, BATCH_SIZE, images, labels)\n            (_, l, lrr) = sess.run([train_op, total_loss, learning_rate], feed_dict=_feed_dict)\n            duration = (time.time() - start_time)\n            if ((step % 10) == 0):\n                elapsed_time = (time.time() - start_time)\n                start_time = time.time()\n                examples_per_sec = (BATCH_SIZE \/ duration)\n                format_str = 'step %d, loss = %.2f  learning rate = %.6f  (%.1f examples\/sec; %.2f sec\/batch)'\n                print((format_str % (step, l, lrr, examples_per_sec, duration)))\n                sys.stdout.flush()\n            if (((step % 1000) == 0) or ((step + 1) == NUME_STEPS)):\n                print('Traning Data Eval:')\n                print('Validation Data Eval:')\n                print('Test Data Eval:')\n                do_eval(sess, eval_op, images, labels, train_data.test, BATCH_SIZE)\n        save_path = saver.save(sess, SAVE_FILE)\n        print(('model saved in file %s' % save_path))\n"}
{"label_name":"predict","label":4,"method_name":"predict","method":"\n\ndef predict(req, tfidf, df):\n    'Prediction'\n    kmeans = joblib.load('kmeans.pkl')\n    control = tfidf.transform(req)\n    preds = kmeans.predict(control)\n    print(preds)\n"}
{"label_name":"process","label":2,"method_name":"preprocess_for_eval","method":"\n\ndef preprocess_for_eval(image, output_height, output_width, add_image_summaries=True):\n    'Preprocesses the given image for evaluation.\\n\\n  Args:\\n    image: A `Tensor` representing an image of arbitrary size.\\n    output_height: The height of the image after preprocessing.\\n    output_width: The width of the image after preprocessing.\\n    add_image_summaries: Enable image summaries.\\n\\n  Returns:\\n    A preprocessed image.\\n  '\n    if add_image_summaries:\n        tf.summary.image('image', tf.expand_dims(image, 0))\n    image = tf.to_float(image)\n    resized_image = tf.image.resize_image_with_crop_or_pad(image, output_width, output_height)\n    if add_image_summaries:\n        tf.summary.image('resized_image', tf.expand_dims(resized_image, 0))\n    return tf.image.per_image_standardization(resized_image)\n"}
{"label_name":"train","label":0,"method_name":"prepare_pretrain_npz_dataset","method":"\n\ndef prepare_pretrain_npz_dataset(filename, allow_pickle=False):\n    'Create dataset based on the numpy npz file'\n    if isinstance(filename, (list, tuple)):\n        assert (len(filename) == 1), 'When .npy\/.npz data file is loaded, len(filename) must be 1. Received len(filename)={}.'.format(len(filename))\n        filename = filename[0]\n    logging.debug('start to load file %s ...', filename)\n    return NumpyDataset(filename, allow_pickle=allow_pickle)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train():\n    (src_train, dest_train, src_dev, dest_dev, _, _) = data_util.prepare_headline_data(FLAGS.data_dir, FLAGS.vocab_size)\n    dev_config = tf.ConfigProto(device_count={'CPU': 4}, inter_op_parallelism_threads=1, intra_op_parallelism_threads=2)\n    with tf.Session(config=dev_config) as sess:\n        model = create_model(sess, False)\n        dev_set = read_data(src_dev, dest_dev)\n        train_set = read_data(src_train, dest_train, FLAGS.max_train_data_size)\n        train_bucket_sizes = [len(train_set[b]) for b in xrange(len(buckets))]\n        train_total_size = float(sum(train_bucket_sizes))\n        trainbuckets_scale = [(sum(train_bucket_sizes[:(i + 1)]) \/ train_total_size) for i in xrange(len(train_bucket_sizes))]\n        (step_time, loss) = (0.0, 0.0)\n        current_step = 0\n        previous_losses = []\n        while True:\n            random_number_01 = np.random.random_sample()\n            bucket_id = min([i for i in xrange(len(trainbuckets_scale)) if (trainbuckets_scale[i] > random_number_01)])\n            start_time = time.time()\n            (encoder_inputs, decoder_inputs, target_weights) = model.get_batch(train_set, bucket_id)\n            (_, step_loss, _) = model.step(sess, encoder_inputs, decoder_inputs, target_weights, bucket_id, False)\n            step_time += ((time.time() - start_time) \/ FLAGS.steps_per_checkpoint)\n            loss += (step_loss \/ FLAGS.steps_per_checkpoint)\n            current_step += 1\n            if ((current_step % FLAGS.steps_per_checkpoint) == 0):\n                perplexity = (math.exp(float(loss)) if (loss < 300) else float('inf'))\n                print(('global step %d learning rate %.4f step-time %.2f perplexity %.2f' % (model.global_step.eval(), model.learning_rate.eval(), step_time, perplexity)))\n                if ((len(previous_losses) > 2) and (loss > max(previous_losses[(- 3):]))):\n                    sess.run(model.learning_rate_decay_op)\n                previous_losses.append(loss)\n                checkpoint_path = os.path.join(FLAGS.train_dir, 'headline_large.ckpt')\n                model.saver.save(sess, checkpoint_path, global_step=model.global_step)\n                (step_time, loss) = (0.0, 0.0)\n                for bucket_id in xrange(len(buckets)):\n                    if (len(dev_set[bucket_id]) == 0):\n                        print(('  eval: empty bucket %d' % bucket_id))\n                        continue\n                    (encoder_inputs, decoder_inputs, target_weights) = model.get_batch(dev_set, bucket_id)\n                    (_, eval_loss, _) = model.step(sess, encoder_inputs, decoder_inputs, target_weights, bucket_id, True)\n                    eval_ppx = (math.exp(float(eval_loss)) if (eval_loss < 300) else float('inf'))\n                    print(('  eval: bucket %d perplexity %.2f' % (bucket_id, eval_ppx)))\n                sys.stdout.flush()\n    pass\n"}
{"label_name":"forward","label":3,"method_name":"forward","method":"\n\ndef forward(x, W1, W2):\n    hidden = np.tanh(x.dot(W1))\n    output = hidden.dot(W2)\n    mean = output[:2]\n    stddev = softplus(output[2:])\n    return (mean, stddev)\n"}
{"label_name":"train","label":0,"method_name":"train_agent","method":"\n\ndef train_agent(real_env, learner, world_model_dir, hparams, epoch):\n    'Train the PPO agent in the simulated environment.'\n    initial_frame_chooser = rl_utils.make_initial_frame_chooser(real_env, hparams.frame_stack_size, hparams.simulation_random_starts, hparams.simulation_flip_first_random_for_beginning)\n    env_fn = rl.make_simulated_env_fn_from_hparams(real_env, hparams, batch_size=hparams.simulated_batch_size, initial_frame_chooser=initial_frame_chooser, model_dir=world_model_dir, sim_video_dir=os.path.join(learner.agent_model_dir, 'sim_videos_{}'.format(epoch)))\n    base_algo_str = hparams.base_algo\n    train_hparams = trainer_lib.create_hparams(hparams.base_algo_params)\n    if hparams.wm_policy_param_sharing:\n        train_hparams.optimizer_zero_grads = True\n    rl_utils.update_hparams_from_hparams(train_hparams, hparams, (base_algo_str + '_'))\n    final_epoch = (hparams.epochs - 1)\n    is_special_epoch = (((epoch + 3) == final_epoch) or ((epoch + 7) == final_epoch))\n    is_special_epoch = (is_special_epoch or (epoch == 1))\n    is_final_epoch = (epoch == final_epoch)\n    env_step_multiplier = (3 if is_final_epoch else (2 if is_special_epoch else 1))\n    learner.train(env_fn, train_hparams, simulated=True, save_continuously=True, epoch=epoch, env_step_multiplier=env_step_multiplier)\n"}
{"label_name":"save","label":1,"method_name":"_savez","method":"\n\ndef _savez(file, args, kwds, compress, allow_pickle=True, pickle_kwargs=None):\n    import zipfile\n    import tempfile\n    if isinstance(file, basestring):\n        if (not file.endswith('.npz')):\n            file = (file + '.npz')\n    elif is_pathlib_path(file):\n        if (not file.name.endswith('.npz')):\n            file = (file.parent \/ (file.name + '.npz'))\n    namedict = kwds\n    for (i, val) in enumerate(args):\n        key = ('arr_%d' % i)\n        if (key in namedict.keys()):\n            raise ValueError(('Cannot use un-named variables and keyword %s' % key))\n        namedict[key] = val\n    if compress:\n        compression = zipfile.ZIP_DEFLATED\n    else:\n        compression = zipfile.ZIP_STORED\n    zipf = zipfile_factory(file, mode='w', compression=compression)\n    (file_dir, file_prefix) = (os.path.split(file) if _is_string_like(file) else (None, 'tmp'))\n    (fd, tmpfile) = tempfile.mkstemp(prefix=file_prefix, dir=file_dir, suffix='-numpy.npy')\n    os.close(fd)\n    try:\n        for (key, val) in namedict.items():\n            fname = (key + '.npy')\n            fid = open(tmpfile, 'wb')\n            try:\n                format.write_array(fid, np.asanyarray(val), allow_pickle=allow_pickle, pickle_kwargs=pickle_kwargs)\n                fid.close()\n                fid = None\n                zipf.write(tmpfile, arcname=fname)\n            except IOError as exc:\n                raise IOError(('Failed to write to %s: %s' % (tmpfile, exc)))\n            finally:\n                if fid:\n                    fid.close()\n    finally:\n        os.remove(tmpfile)\n    zipf.close()\n"}
{"label_name":"save","label":1,"method_name":"_load_state_dict_from_save_inference_model","method":"\n\ndef _load_state_dict_from_save_inference_model(model_path, config):\n    programs = _construct_program_holders(model_path, config.model_filename)\n    with fluid.dygraph.guard():\n        persistable_var_dict = _construct_params_and_buffers(model_path, programs, config.params_filename, append_suffix=False)\n        load_param_dict = dict()\n        for var_name in persistable_var_dict:\n            load_param_dict[var_name] = persistable_var_dict[var_name].numpy()\n        var_info_filename = (str(config.params_filename) + '.info')\n        var_info_path = os.path.join(model_path, var_info_filename)\n        if os.path.exists(var_info_path):\n            with open(var_info_path, 'rb') as f:\n                extra_var_info = pickle.load(f)\n            structured_para_dict = dict()\n            for var_name in load_param_dict:\n                structured_name = extra_var_info[var_name].get('structured_name', None)\n                assert (structured_name is not None), (\"Cannot find saved variable (%s)'s structured name in saved model.\" % var_name)\n                structured_para_dict[structured_name] = load_param_dict[var_name]\n            load_param_dict = structured_para_dict\n    return load_param_dict\n"}
{"label_name":"forward","label":3,"method_name":"_tanh_forward_log_det_jacobian","method":"\n\ndef _tanh_forward_log_det_jacobian(x):\n    'Compute log|det(dy\/dx)| except summation where y=tanh(x).'\n    return (2.0 * ((np.log(2.0) - x) - F.softplus(((- 2.0) * x))))\n"}
{"label_name":"train","label":0,"method_name":"download_wmt14_train","method":"\n\ndef download_wmt14_train(lang_pair: str='en-de', path: str=_BASE_DATASET_PATH) -> Tuple[(List[str], List[str])]:\n    'Download the train dataset used for WMT2014\\n\\n    Parameters\\n    ----------\\n    lang_pair\\n    path\\n\\n    Returns\\n    -------\\n    train_src_paths\\n    train_tgt_paths\\n    '\n    if ((lang_pair == 'en-de') or (lang_pair == 'de-en')):\n        (train_src_paths, train_tgt_paths) = fetch_wmt_parallel_dataset([['europarl', 'v7'], ['commoncrawl', 'wmt13'], ['newscommentary', 'v9']], lang_pair, path=path)\n    else:\n        raise NotImplementedError\n    return (train_src_paths, train_tgt_paths)\n"}
{"label_name":"save","label":1,"method_name":"save_best_model_by_val_score","method":"\n\ndef save_best_model_by_val_score(output_path: str, evaluator: Engine, model: torch.nn.Module, metric_name: str, n_saved: int=3, trainer: Optional[Engine]=None, tag: str='val', **kwargs: Any) -> Checkpoint:\n    'Method adds a handler to ``evaluator`` to save on a disk ``n_saved`` of best models based on the metric\\n    (named by ``metric_name``) provided by ``evaluator`` (i.e. ``evaluator.state.metrics[metric_name]``).\\n    Models with highest metric value will be retained.\\n\\n    Args:\\n        output_path: output path to indicate where to save best models\\n        evaluator: evaluation engine used to provide the score\\n        model: model to store\\n        metric_name: metric name to use for score evaluation. This metric should be present in\\n            `evaluator.state.metrics`.\\n        n_saved: number of best models to store\\n        trainer: trainer engine to fetch the epoch when saving the best model.\\n        tag: score name prefix: `{tag}_{metric_name}`. By default, tag is \"val\".\\n        kwargs: optional keyword args to be passed to construct :class:`~ignite.handlers.checkpoint.Checkpoint`.\\n\\n    Returns:\\n        A :class:`~ignite.handlers.checkpoint.Checkpoint` handler.\\n    '\n    return gen_save_best_models_by_val_score(save_handler=DiskSaver(dirname=output_path, require_empty=False), evaluator=evaluator, models=model, metric_name=metric_name, n_saved=n_saved, trainer=trainer, tag=tag, **kwargs)\n"}
{"label_name":"predict","label":4,"method_name":"predict_sr","method":"\n\ndef predict_sr(model, player, scaler_for_X, hero):\n    stats_vector = np.array([get_vector_herostats(player, 'us', stat_keys=specific_stats[hero])])\n    X = scaler_for_X.transform(stats_vector)\n    y_matrix = model.predict(X)\n    sr = (np.squeeze(y_matrix) * 5000)\n    return int(sr)\n"}
{"label_name":"train","label":0,"method_name":"rasa_default_train_data","method":"\n\n@pytest.fixture\ndef rasa_default_train_data():\n    with io.open('data\/examples\/rasa\/demo-rasa.json', encoding='utf-8-sig') as train_file:\n        return json.loads(train_file.read())\n"}
{"label_name":"train","label":0,"method_name":"train_model","method":"\n\ndef train_model(model, x_train, y_train, batch_size, dropout, epochs):\n    (x, y, y_conv, keep_prob, train_step, _) = model\n    train_length = len(x_train)\n    for i in range(epochs):\n        indices = np.arange(train_length)\n        np.random.shuffle(indices)\n        for start in range(0, train_length, batch_size):\n            end = min((start + batch_size), train_length)\n            batch_indices = indices[start:end]\n            (x_batch, y_batch) = (x_train[batch_indices], y_train[batch_indices])\n            train_step.run(feed_dict={x: x_batch, y: y_batch, keep_prob: dropout})\n"}
{"label_name":"predict","label":4,"method_name":"predict","method":"\n\ndef predict(x, weights):\n    return np.dot(x, weights)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train(net, train_data, val_data, eval_metric, batch_size, ctx, logger, args):\n    'Training pipeline'\n    args.kv_store = ('device' if (args.amp and ('nccl' in args.kv_store)) else args.kv_store)\n    kv = mx.kvstore.create(args.kv_store)\n    net.collect_params().setattr('grad_req', 'null')\n    net.collect_train_params().setattr('grad_req', 'write')\n    for (k, v) in net.collect_params('.*bias').items():\n        v.wd_mult = 0.0\n    optimizer_params = {'learning_rate': args.lr, 'wd': args.wd, 'momentum': args.momentum}\n    if (args.clip_gradient > 0.0):\n        optimizer_params['clip_gradient'] = args.clip_gradient\n    if args.amp:\n        optimizer_params['multi_precision'] = True\n    if args.horovod:\n        hvd.broadcast_parameters(net.collect_params(), root_rank=0)\n        trainer = hvd.DistributedTrainer(net.collect_train_params(), 'sgd', optimizer_params)\n    else:\n        trainer = gluon.Trainer(net.collect_train_params(), 'sgd', optimizer_params, update_on_kvstore=(False if args.amp else None), kvstore=kv)\n    if args.amp:\n        amp.init_trainer(trainer)\n    lr_decay = float(args.lr_decay)\n    lr_steps = sorted([float(ls) for ls in args.lr_decay_epoch.split(',') if ls.strip()])\n    lr_warmup = float(args.lr_warmup)\n    rpn_cls_loss = mx.gluon.loss.SigmoidBinaryCrossEntropyLoss(from_sigmoid=False)\n    rpn_box_loss = mx.gluon.loss.HuberLoss(rho=args.rpn_smoothl1_rho)\n    rcnn_cls_loss = mx.gluon.loss.SoftmaxCrossEntropyLoss()\n    rcnn_box_loss = mx.gluon.loss.HuberLoss(rho=args.rcnn_smoothl1_rho)\n    rcnn_mask_loss = mx.gluon.loss.SigmoidBinaryCrossEntropyLoss(from_sigmoid=False)\n    metrics = [mx.metric.Loss('RPN_Conf'), mx.metric.Loss('RPN_SmoothL1'), mx.metric.Loss('RCNN_CrossEntropy'), mx.metric.Loss('RCNN_SmoothL1'), mx.metric.Loss('RCNN_Mask')]\n    rpn_acc_metric = RPNAccMetric()\n    rpn_bbox_metric = RPNL1LossMetric()\n    rcnn_acc_metric = RCNNAccMetric()\n    rcnn_bbox_metric = RCNNL1LossMetric()\n    rcnn_mask_metric = MaskAccMetric()\n    rcnn_fgmask_metric = MaskFGAccMetric()\n    metrics2 = [rpn_acc_metric, rpn_bbox_metric, rcnn_acc_metric, rcnn_bbox_metric, rcnn_mask_metric, rcnn_fgmask_metric]\n    async_eval_processes = []\n    logger.info(args)\n    if args.verbose:\n        logger.info('Trainable parameters:')\n        logger.info(net.collect_train_params().keys())\n    logger.info('Start training from [Epoch {}]'.format(args.start_epoch))\n    best_map = [0]\n    base_lr = trainer.learning_rate\n    for epoch in range(args.start_epoch, args.epochs):\n        rcnn_task = ForwardBackwardTask(net, trainer, rpn_cls_loss, rpn_box_loss, rcnn_cls_loss, rcnn_box_loss, rcnn_mask_loss, args.amp)\n        executor = (Parallel(args.executor_threads, rcnn_task) if (not args.horovod) else None)\n        if (not args.disable_hybridization):\n            net.hybridize(static_alloc=args.static_alloc)\n        while (lr_steps and (epoch >= lr_steps[0])):\n            new_lr = (trainer.learning_rate * lr_decay)\n            lr_steps.pop(0)\n            trainer.set_learning_rate(new_lr)\n            logger.info('[Epoch {}] Set learning rate to {}'.format(epoch, new_lr))\n        for metric in metrics:\n            metric.reset()\n        tic = time.time()\n        btic = time.time()\n        speed = []\n        train_data_iter = iter(train_data)\n        next_data_batch = next(train_data_iter)\n        next_data_batch = split_and_load(next_data_batch, ctx_list=ctx)\n        for i in range(len(train_data)):\n            batch = next_data_batch\n            if ((i + (epoch * len(train_data))) <= lr_warmup):\n                new_lr = (base_lr * get_lr_at_iter(((i + (epoch * len(train_data))) \/ lr_warmup), args.lr_warmup_factor))\n                if (new_lr != trainer.learning_rate):\n                    if ((i % args.log_interval) == 0):\n                        logger.info('[Epoch {} Iteration {}] Set learning rate to {}'.format(epoch, i, new_lr))\n                    trainer.set_learning_rate(new_lr)\n            metric_losses = [[] for _ in metrics]\n            add_losses = [[] for _ in metrics2]\n            if (executor is not None):\n                for data in zip(*batch):\n                    executor.put(data)\n            for j in range(len(ctx)):\n                if (executor is not None):\n                    result = executor.get()\n                else:\n                    result = rcnn_task.forward_backward(list(zip(*batch))[0])\n                if ((not args.horovod) or (hvd.rank() == 0)):\n                    for k in range(len(metric_losses)):\n                        metric_losses[k].append(result[k])\n                    for k in range(len(add_losses)):\n                        add_losses[k].append(result[(len(metric_losses) + k)])\n            try:\n                next_data_batch = next(train_data_iter)\n                next_data_batch = split_and_load(next_data_batch, ctx_list=ctx)\n            except StopIteration:\n                pass\n            trainer.step(batch_size)\n            for (metric, record) in zip(metrics, metric_losses):\n                metric.update(0, record)\n            for (metric, records) in zip(metrics2, add_losses):\n                for pred in records:\n                    metric.update(pred[0], pred[1])\n            if (((not args.horovod) or (hvd.rank() == 0)) and args.log_interval and (not ((i + 1) % args.log_interval))):\n                msg = ','.join(['{}={:.3f}'.format(*metric.get()) for metric in (metrics + metrics2)])\n                batch_speed = ((args.log_interval * args.batch_size) \/ (time.time() - btic))\n                speed.append(batch_speed)\n                logger.info('[Epoch {}][Batch {}], Speed: {:.3f} samples\/sec, {}'.format(epoch, i, batch_speed, msg))\n                btic = time.time()\n        if speed:\n            avg_batch_speed = (sum(speed) \/ len(speed))\n        if ((not args.horovod) or (hvd.rank() == 0)):\n            msg = ','.join(['{}={:.3f}'.format(*metric.get()) for metric in metrics])\n            logger.info('[Epoch {}] Training cost: {:.3f}, Speed: {:.3f} samples\/sec, {}'.format(epoch, (time.time() - tic), avg_batch_speed, msg))\n        if (not ((epoch + 1) % args.val_interval)):\n            validate(net, val_data, async_eval_processes, ctx, eval_metric, logger, epoch, best_map, args)\n        elif ((not args.horovod) or (hvd.rank() == 0)):\n            current_map = 0.0\n            save_params(net, logger, best_map, current_map, epoch, args.save_interval, args.save_prefix)\n    for thread in async_eval_processes:\n        thread.join()\n"}
{"label_name":"process","label":2,"method_name":"load_and_preprocess_data","method":"\n\ndef load_and_preprocess_data(args):\n    logger.info('Loading training data...')\n    train = read_conll(args.data_train)\n    logger.info('Done. Read %d sentences', len(train))\n    logger.info('Loading dev data...')\n    dev = read_conll(args.data_dev)\n    logger.info('Done. Read %d sentences', len(dev))\n    helper = ModelHelper.build(train)\n    train_data = helper.vectorize(train)\n    dev_data = helper.vectorize(dev)\n    return (helper, train_data, dev_data, train, dev)\n"}
{"label_name":"save","label":1,"method_name":"save_model","method":"\n\ndef save_model(model, path):\n    model.eval()\n    if torch.cuda.is_available():\n        model.cpu()\n        torch.save(model.state_dict(), path)\n        model.cuda()\n    else:\n        torch.save(model.state_dict(), path)\n    model.train()\n"}
{"label_name":"predict","label":4,"method_name":"gs_link_prediction","method":"\n\ndef gs_link_prediction(g, edge_ids, edge_labels, num_samples, optimizer, batch_size=4, epochs=4, bias=True, dropout=0.0, normalize='l2', seed=0, shuffle=True):\n    set_seed(seed)\n    tf.random.set_seed(seed)\n    if shuffle:\n        random.seed(seed)\n    generator = GraphSAGELinkGenerator(g, batch_size, num_samples)\n    train_gen = generator.flow(edge_ids, edge_labels, shuffle=True)\n    model = gs_link_pred_model(num_samples, generator, optimizer, bias, dropout, normalize)\n    model.fit(train_gen, epochs=epochs, verbose=1, use_multiprocessing=False, workers=4, shuffle=shuffle)\n    return model\n"}
{"label_name":"save","label":1,"method_name":"_save","method":"\n\ndef _save(im, fp, filename):\n    if ((_handler is None) or (not hasattr('_handler', 'save'))):\n        raise IOError('BUFR save handler not installed')\n    _handler.save(im, fp, filename)\n"}
{"label_name":"process","label":2,"method_name":"_preprocess","method":"\n\ndef _preprocess(weights, initial_layer_weights, wires):\n    'Validate and pre-process inputs as follows:\\n\\n    * Check the shapes of the two weights tensors.\\n\\n    Args:\\n        weights (tensor_like): trainable parameters of the template\\n        initial_layer_weights (tensor_like): weight tensor for the initial rotation block, shape ``(M,)``\\n        wires (Wires): wires that template acts on\\n\\n    Returns:\\n        int: number of times that the ansatz is repeated\\n    '\n    shape = qml.math.shape(weights)\n    repeat = shape[0]\n    if (len(shape) > 1):\n        if (shape[1] != (len(wires) - 1)):\n            raise ValueError(f'Weights tensor must have second dimension of length {(len(wires) - 1)}; got {shape[1]}')\n        if (shape[2] != 2):\n            raise ValueError(f'Weights tensor must have third dimension of length 2; got {shape[2]}')\n    shape2 = qml.math.shape(initial_layer_weights)\n    if (shape2 != (len(wires),)):\n        raise ValueError(f'Initial layer weights must be of shape {(len(wires),)}; got {shape2}')\n    return repeat\n"}
{"label_name":"predict","label":4,"method_name":"perceptron_predict","method":"\n\ndef perceptron_predict(model, row):\n    activation = model[0]\n    for i in range((len(row) - 1)):\n        activation += (model[(i + 1)] * row[i])\n    return (1.0 if (activation >= 0.0) else 0.0)\n"}
{"label_name":"train","label":0,"method_name":"training_pipeline","method":"\n\ndef training_pipeline():\n    training_set = make_tf_iterator().make_one_shot_iterator()\n    model = keras_model()\n    model.compile('adam', 'categorical_crossentropy', metrics=['acc'])\n    model.fit(training_set, epochs=10, verbose=1)\n"}
{"label_name":"save","label":1,"method_name":"save_checkpoint","method":"\n\ndef save_checkpoint(name):\n    torch.save(gcn.state_dict(), osp.join(save_path, (name + '.pth')))\n    torch.save(pred_obj, osp.join(save_path, (name + '.pred')))\n"}
{"label_name":"predict","label":4,"method_name":"predict_example1","method":"\n\ndef predict_example1(data_X, Y):\n    X = add_one(data_X)\n    C = ((X.T * X).I * (X.T * Y))\n    predict = (X * C)\n    mse = mean_squared_error(Y, predict)\n    (b, w) = (C[0], C[1:])\n    show_result(b, w, mse)\n    return predict\n"}
{"label_name":"train","label":0,"method_name":"training_epoch","method":"\n\ndef training_epoch(i, cim, model, optimizer, batchsize=100):\n    x_batch = Variable(cim.get_x_training_batch(i, batchsize))\n    t_batch = Variable(cim.get_t_training_batch(i, batchsize))\n    model.zerograds()\n    (loss, acc) = model(x_batch, t_batch)\n    loss.backward()\n    optimizer.update()\n    return (loss.data, acc.data)\n"}
{"label_name":"predict","label":4,"method_name":"predict_fn","method":"\n\ndef predict_fn(classifier, data, batchsize):\n    ' Return features from classifier '\n    out = np.zeros((len(data), RESNET_FEATURES), np.float32)\n    with chainer.using_config('train', False), chainer.using_config('enable_backprop', False):\n        for (idx, dta) in yield_mb_X(data, batchsize):\n            pred = classifier(cuda.to_gpu(dta), layers=['pool5'])\n            out[(idx * batchsize):((idx + 1) * batchsize)] = cuda.to_cpu(pred['pool5'].data).squeeze()\n    return out\n"}
{"label_name":"save","label":1,"method_name":"_save","method":"\n\ndef _save(im, fp, filename):\n    if ((_handler is None) or (not hasattr('_handler', 'save'))):\n        raise IOError('GRIB save handler not installed')\n    _handler.save(im, fp, filename)\n"}
{"label_name":"train","label":0,"method_name":"trainer_output","method":"\n\ndef trainer_output(func):\n    '\\n    Trainer output decorator for functions that train models.\\n\\n    This is a decorator that can be applied to any function, and it will print\\n    helpful information to the console such as the model type, and training\\n    results.\\n\\n    Args:\\n        func (function): Function to be applied with decorator.\\n\\n    Returns:\\n        trained_model: returns trained_model\\n    '\n\n    @wraps(func)\n    def wrap(self, *args, **kwargs):\n        algorithm_name = ' '.join(func.__name__.split('_')).title()\n        print('Training: {} , Type: {}'.format(algorithm_name, self._advanced_trainer.model_type))\n        trained_model = func(self, *args, **kwargs)\n        trained_model.print_training_results()\n        return trained_model\n    return wrap\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train(epoch, log_interval=200):\n    model.train()\n    for (batch_idx, (data, target)) in enumerate(train_loader):\n        data = data.to(device)\n        target = target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n        if ((batch_idx % log_interval) == 0):\n            print('Train Epoch: {} [{}\/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, (batch_idx * len(data)), len(train_loader.dataset), ((100.0 * batch_idx) \/ len(train_loader)), loss.data.item()))\n"}
{"label_name":"predict","label":4,"method_name":"predict_proba_cli","method":"\n\n@entry_point.command(name='predict_proba')\n@click.option('--text')\ndef predict_proba_cli(text: str) -> None:\n    '\\n    CLI function for predicting the probability of a language of a text.\\n\\n    Parameters\\n    ----------\\n    text : str\\n    '\n    print(classifier.predict_proba(text))\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train(rank, args, model, device, dataloader_kwargs):\n    torch.manual_seed((args.seed + rank))\n    train_loader = torch.utils.data.DataLoader(datasets.MNIST('..\/data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])), batch_size=args.batch_size, shuffle=True, num_workers=1, **dataloader_kwargs)\n    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n    for epoch in range(1, (args.epochs + 1)):\n        train_epoch(epoch, args, model, device, train_loader, optimizer)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train(num_batches, batch_size, learning_rate):\n    inputs = tf.placeholder(tf.float32, [None, 28, 28, 1])\n    labels = tf.placeholder(tf.float32, [None, 10])\n    is_training = tf.placeholder(tf.bool)\n    layer = inputs\n    for layer_i in range(1, 20):\n        layer = conv_layer(layer, layer_i, is_training)\n    orig_shape = layer.get_shape().as_list()\n    layer = tf.reshape(layer, shape=[(- 1), ((orig_shape[1] * orig_shape[2]) * orig_shape[3])])\n    layer = fully_connected(layer, 100, is_training)\n    logits = tf.layers.dense(layer, 10)\n    model_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=labels))\n    train_opt = tf.train.AdamOptimizer(learning_rate).minimize(model_loss)\n    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        for batch_i in range(num_batches):\n            (batch_xs, batch_ys) = mnist.train.next_batch(batch_size)\n            sess.run(train_opt, {inputs: batch_xs, labels: batch_ys, is_training: True})\n            if ((batch_i % 100) == 0):\n                (loss, acc) = sess.run([model_loss, accuracy], {inputs: mnist.validation.images, labels: mnist.validation.labels, is_training: False})\n                print('Batch: {:>2}: Validation loss: {:>3.5f}, Validation accuracy: {:>3.5f}'.format(batch_i, loss, acc))\n            elif ((batch_i % 25) == 0):\n                (loss, acc) = sess.run([model_loss, accuracy], {inputs: batch_xs, labels: batch_ys, is_training: False})\n                print('Batch: {:>2}: Training loss: {:>3.5f}, Training accuracy: {:>3.5f}'.format(batch_i, loss, acc))\n        acc = sess.run(accuracy, {inputs: mnist.validation.images, labels: mnist.validation.labels, is_training: False})\n        print('Final validation accuracy: {:>3.5f}'.format(acc))\n        acc = sess.run(accuracy, {inputs: mnist.test.images, labels: mnist.test.labels, is_training: False})\n        print('Final test accuracy: {:>3.5f}'.format(acc))\n        correct = 0\n        for i in range(100):\n            correct += sess.run(accuracy, feed_dict={inputs: [mnist.test.images[i]], labels: [mnist.test.labels[i]], is_training: False})\n        print('Accuracy on 100 samples:', (correct \/ 100))\n"}
{"label_name":"train","label":0,"method_name":"guide_constrained_model","method":"\n\ndef guide_constrained_model(data):\n    q = pyro.param('q', ops.exp(torch.randn(3)), constraint=constraints.simplex)\n    pyro.sample('x', dist.Categorical(q))\n"}
{"label_name":"process","label":2,"method_name":"process_fermi_hubbard_term","method":"\n\ndef process_fermi_hubbard_term(term):\n    constituents = term.split('_')\n    for c in constituents:\n        if (c == 'FH-hopping-sum'):\n            constituents.remove(c)\n            mtx = process_fermi_hubbard_hopping_sum(constituents)\n        elif (c == 'FHhop'):\n            constituents.remove(c)\n            mtx = process_fermi_hubbard_hopping(constituents)\n        elif (c == 'FH-onsite-sum'):\n            constituents.remove(c)\n            mtx = process_fermi_hubbard_onsite_sum(constituents)\n        elif (c == 'FHonsite'):\n            constituents.remove(c)\n            mtx = process_fermi_hubbard_onsite(constituents)\n        elif (c == 'FHchemical'):\n            constituents.remove(c)\n            mtx = process_fermi_hubbard_chemical(constituents)\n    return mtx\n"}
{"label_name":"predict","label":4,"method_name":"_run_skl_prediction","method":"\n\ndef _run_skl_prediction(obs, check_runtime, assume_finite, inst, method_name, predict_kwargs, X_test, benchmark, debug, verbose, time_kwargs, skip_long_test, time_kwargs_fact, fLOG):\n    if (not check_runtime):\n        return None\n    if ((verbose >= 2) and (fLOG is not None)):\n        fLOG('[enumerate_compatible_opset] check_runtime SKL {}-{}-{}-{}-{}'.format(id(inst), method_name, predict_kwargs, time_kwargs, time_kwargs_fact))\n    with sklearn.config_context(assume_finite=assume_finite):\n        obs['ort_version'] = ort_version\n        try:\n            meth = getattr(inst, method_name)\n        except AttributeError as e:\n            if debug:\n                raise\n            obs['_2skl_meth_exc'] = str(e)\n            return e\n        try:\n            (ypred, t4, ___) = _measure_time((lambda : meth(X_test, **predict_kwargs)))\n            obs['lambda-skl'] = ((lambda xo: meth(xo, **predict_kwargs)), X_test)\n        except (ValueError, AttributeError, TypeError, MemoryError, IndexError) as e:\n            if debug:\n                raise\n            obs['_3prediction_exc'] = str(e)\n            return e\n        obs['prediction_time'] = t4\n        obs['assume_finite'] = assume_finite\n        if (benchmark and ('lambda-skl' in obs)):\n            obs['bench-skl'] = benchmark_fct(*obs['lambda-skl'], obs=obs, time_kwargs=_multiply_time_kwargs(time_kwargs, time_kwargs_fact, inst), skip_long_test=skip_long_test)\n        if ((verbose >= 3) and (fLOG is not None)):\n            fLOG('[enumerate_compatible_opset] scikit-learn prediction')\n            _dispsimple(ypred, fLOG)\n        if ((verbose >= 2) and (fLOG is not None)):\n            fLOG('[enumerate_compatible_opset] predictions stored')\n    return ypred\n"}
{"label_name":"predict","label":4,"method_name":"predict_genders","method":"\n\ndef predict_genders(names: list, return_proba: bool=True, return_attention: bool=False, neutral_cutoff=CLASS2DEFAULT_CUTOFF[POSITIVE_CLASS]) -> Union[(list, tuple)]:\n    \"\\n    Predict genders of the given name strings.\\n\\n    :param names: list of names that you want to predict the gender\\n    :param return_proba: if True, return probability estimate of the names belonging to each gender\\n    :param return_attention: if True, return attentions (weight for each word)\\n    :param neutral_cutoff: if the probability is lower than this threshold for both genders, it\\n                           returns 'neutral'. [default: 0.8] (only relevant when return_proba=False)\\n    :return: list of str (male or female) or {'male': male_proba, 'female': female_proba} or\\n        tuple of aforementioned plus attentions\\n    \"\n    global _model\n    if (not _model):\n        _load_model()\n    high_cutoff = neutral_cutoff\n    low_cutoff = (1.0 - neutral_cutoff)\n    try:\n        return_value = _model.predict(names, return_proba, return_attention, low_cutoff=low_cutoff, high_cutoff=high_cutoff)\n        if return_attention:\n            (predictions, attentions) = return_value\n        else:\n            (predictions, attentions) = (return_value, None)\n    except UnseenCharacterException as exception:\n        message = '{}. Remove the invalid characters from yor inputs.'.format(exception.args[0].replace('Unseen', 'Invalid'))\n        raise InvalidCharacterException(message)\n    predictions = _filter(names, predictions, return_proba)\n    if attentions:\n        return (predictions, attentions)\n    else:\n        return predictions\n"}
{"label_name":"save","label":1,"method_name":"save_modules","method":"\n\n@contextlib.contextmanager\ndef save_modules():\n    '\\n    Context in which imported modules are saved.\\n\\n    Translates exceptions internal to the context into the equivalent exception\\n    outside the context.\\n    '\n    saved = sys.modules.copy()\n    with ExceptionSaver() as saved_exc:\n        (yield saved)\n    sys.modules.update(saved)\n    del_modules = (mod_name for mod_name in sys.modules if ((mod_name not in saved) and (not mod_name.startswith('encodings.'))))\n    _clear_modules(del_modules)\n    saved_exc.resume()\n"}
{"label_name":"process","label":2,"method_name":"post_process_metrics","method":"\n\ndef post_process_metrics(prefix, workers, metrics):\n    'Update current dataset metrics and filter out specific keys.\\n\\n    Args:\\n        prefix (str): Prefix string to be appended\\n        workers (WorkerSet): Set of workers\\n        metrics (dict): Current metrics dictionary\\n    '\n    res = collect_metrics(remote_workers=workers.remote_workers())\n    for key in METRICS_KEYS:\n        metrics[((prefix + '_') + key)] = res[key]\n    return metrics\n"}
{"label_name":"save","label":1,"method_name":"save_pil_img","method":"\n\ndef save_pil_img(pil_img, fpath):\n    pil_img.save(fpath)\n"}
{"label_name":"forward","label":3,"method_name":"_forward_op","method":"\n\ndef _forward_op(ref_call, args):\n    'forward the operator of ref_call with provided arguments'\n    return _expr.Call(ref_call.op, args, ref_call.attrs, ref_call.type_args)\n"}
{"label_name":"process","label":2,"method_name":"args_processor","method":"\n\ndef args_processor():\n    import argparse\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-i', '--input-dir', help='Path to data files (Extract images using video_to_image.py first')\n    parser.add_argument('-o', '--output-dir', help='Directory to store results')\n    parser.add_argument('--dataset', default='smartdoc', help=\"'smartdoc' or 'selfcollected' dataset\")\n    return parser.parse_args()\n"}
{"label_name":"forward","label":3,"method_name":"forward","method":"\n\ndef forward(model, X, is_train):\n    nF = model.get_dim('nF')\n    nO = model.get_dim('nO')\n    nP = model.get_dim('nP')\n    nI = model.get_dim('nI')\n    W = model.get_param('W')\n    Yf = model.ops.gemm(X, W.reshape((((nF * nO) * nP), nI)), trans2=True)\n    Yf = Yf.reshape((Yf.shape[0], nF, nO, nP))\n    Yf = model.ops.xp.vstack((model.get_param('pad'), Yf))\n\n    def backward(dY_ids):\n        (dY, ids) = dY_ids\n        assert (dY.ndim == 3)\n        assert (dY.shape[1] == nO), dY.shape\n        assert (dY.shape[2] == nP), dY.shape\n        model.inc_grad('pad', _backprop_precomputable_affine_padding(model, dY, ids))\n        Xf = X[ids]\n        Xf = Xf.reshape((Xf.shape[0], (nF * nI)))\n        model.inc_grad('b', dY.sum(axis=0))\n        dY = dY.reshape((dY.shape[0], (nO * nP)))\n        Wopfi = W.transpose((1, 2, 0, 3))\n        Wopfi = Wopfi.reshape(((nO * nP), (nF * nI)))\n        dXf = model.ops.gemm(dY.reshape((dY.shape[0], (nO * nP))), Wopfi)\n        dWopfi = model.ops.gemm(dY, Xf, trans1=True)\n        dWopfi = dWopfi.reshape((nO, nP, nF, nI))\n        dWopfi = dWopfi.transpose((2, 0, 1, 3))\n        model.inc_grad('W', dWopfi)\n        return dXf.reshape((dXf.shape[0], nF, nI))\n    return (Yf, backward)\n"}
{"label_name":"train","label":0,"method_name":"find_trainable_variables","method":"\n\ndef find_trainable_variables(key):\n    with tf.variable_scope(key):\n        return tf.trainable_variables()\n"}
{"label_name":"predict","label":4,"method_name":"generate_first_layer_predictions","method":"\n\ndef generate_first_layer_predictions():\n    x_train = np.array(x_train)\n    y_train = np.array(y_train)\n    kf = KFold(n_splits=4)\n    folds = list(kf.split(x_train, y_train))\n    first_layer_train_predictions = np.zeros((x_train.shape[0], len(models)))\n    for i in range(len(models)):\n        print('training baseline model')\n        for (j, (train_idx, test_idx)) in enumerate(folds):\n            x_train_fold = x_train[train_idx]\n            y_train_fold = y_train[train_idx]\n            x_holdout_fold = x_train[test_idx]\n            y_holdout_fold = y_train[test_idx]\n            models[i].fit(x_train_fold, y_train_fold)\n            first_layer_train_predictions[(test_idx, i)] = models[i].predict(x_holdout_fold)\n    print('first layer train predictions: ')\n    print(first_layer_train_predictions)\n    print('shape: ')\n    print(first_layer_train_predictions.shape)\n    print('building csv')\n    np.savetxt('predictions_first_layer.csv', first_layer_train_predictions, delimiter=',')\n"}
{"label_name":"save","label":1,"method_name":"save_obj_no_sort","method":"\n\ndef save_obj_no_sort(obj, name):\n    filename = (name + '.p')\n    if os.path.isfile(filename):\n        os.remove(filename)\n    pickle.dump(obj, open(filename, 'wb'))\n"}
{"label_name":"train","label":0,"method_name":"trainLinearReg","method":"\n\ndef trainLinearReg(X, y, Lambda, method='CG', maxiter=200):\n    'trains linear regression using\\n    the dataset (X, y) and regularization parameter lambda. Returns the\\n    trained parameters theta.\\n    '\n    initial_theta = np.zeros(X.shape[1])\n    costFunction = (lambda t: linearRegCostFunction(X, y, t, Lambda)[0])\n    gradFunction = (lambda t: linearRegCostFunction(X, y, t, Lambda)[1])\n    result = minimize(costFunction, initial_theta, method=method, jac=None, options={'disp': True, 'maxiter': maxiter})\n    return result.x\n"}
{"label_name":"train","label":0,"method_name":"train_knn","method":"\n\ndef train_knn(person_name_list, k=2):\n    '\\n    train_knn: Using the list of names it finds associated\\n    .npy files on system and trains KNN\\n    \\n    returns: KNN object\\n    '\n    person_to_labels = {}\n    ix = 0\n    for person in person_name_list:\n        labels[ix] = person\n        person_to_labels[person] = ix\n        ix += 1\n    labels_train = []\n    data = []\n    for person in person_name_list:\n        curr_data = np.load((person + '.npy'))\n        labels_train.append([person_to_labels[person] for i in range(curr_data.shape[0])])\n        data.append(curr_data.reshape((curr_data.shape[0], (- 1))))\n    features_train = np.concatenate(data)\n    labels_train = np.concatenate(labels_train)\n    knn = KNN(k)\n    knn.fit(features_train, labels_train)\n    return knn\n"}
{"label_name":"forward","label":3,"method_name":"feed_forward","method":"\n\ndef feed_forward(x, Wh, Wo):\n    Zh = (x * Wh)\n    H = relu(Zh)\n    Zo = (H * Wo)\n    output = relu(Zo)\n    return output\n"}
{"label_name":"process","label":2,"method_name":"bert_tokens_pre_processor","method":"\n\ndef bert_tokens_pre_processor(token_ids: List[int]) -> List[int]:\n    'Add BERT style special tokens(CLS and SEP).\\n\\n    Args:\\n        token_ids: List of token ids without any special tokens.\\n\\n    Returns:\\n        List of token ids augmented with special tokens.\\n    '\n    BERT_CLS_ID = 101\n    BERT_SEP_ID = 102\n    processed_tokens = token_ids\n    processed_tokens.insert(0, BERT_CLS_ID)\n    processed_tokens.append(BERT_SEP_ID)\n    return processed_tokens\n"}
{"label_name":"forward","label":3,"method_name":"kl_forward","method":"\n\ndef kl_forward(logu, self_normalized=False, name=None):\n    'The forward Kullback-Leibler Csiszar-function in log-space.\\n\\n  A Csiszar-function is a member of,\\n\\n  ```none\\n  F = { f:R_+ to R : f convex }.\\n  ```\\n\\n  When `self_normalized = True`, the KL-forward Csiszar-function is:\\n\\n  ```none\\n  f(u) = u log(u) - (u - 1)\\n  ```\\n\\n  When `self_normalized = False` the `(u - 1)` term is omitted.\\n\\n  Observe that as an f-Divergence, this Csiszar-function implies:\\n\\n  ```none\\n  D_f[p, q] = KL[p, q]\\n  ```\\n\\n  The KL is \"forward\" because in maximum likelihood we think of minimizing `q`\\n  as in `KL[p, q]`.\\n\\n  Warning: this function makes non-log-space calculations and may therefore be\\n  numerically unstable for `|logu| >> 0`.\\n\\n  Args:\\n    logu: `float`-like `Tensor` representing `log(u)` from above.\\n    self_normalized: Python `bool` indicating whether `f\\'(u=1)=0`. When\\n      `f\\'(u=1)=0` the implied Csiszar f-Divergence remains non-negative even\\n      when `p, q` are unnormalized measures.\\n    name: Python `str` name prefixed to Ops created by this function.\\n\\n  Returns:\\n    kl_forward_of_u: `float`-like `Tensor` of the Csiszar-function evaluated at\\n      `u = exp(logu)`.\\n\\n  Raises:\\n    TypeError: if `self_normalized` is `None` or a `Tensor`.\\n  '\n    with ops.name_scope(name, 'kl_forward', [logu]):\n        return amari_alpha(logu, alpha=1.0, self_normalized=self_normalized)\n"}
{"label_name":"process","label":2,"method_name":"process_rollouts","method":"\n\ndef process_rollouts(rollouts, gamma, lambda_=1.0):\n    'Convert a batch of rollouts into tensors ready to be fed into a model.\\n\\n  Lists from each episode are stacked into 2D tensors and padded with 0s up to\\n  the maximum timestep in the batch.\\n\\n  Args:\\n    rollouts: A list of Rollout instances.\\n    gamma: The discount factor. A number between 0 and 1 (inclusive). See gamma\\n        argument in discounted_advantage_and_rewards.\\n    lambda_: See lambda_ argument in discounted_advantage_and_rewards.\\n\\n  Returns:\\n    Batch instance. states, actions, discounted_adv, and discounted_r are\\n    numpy arrays with shape (batch_size, max_episode_length). episode_lengths\\n    is a list of ints. total_rewards is a list of floats (total reward in each\\n    episode). batch_size and max_time are ints.\\n\\n  Raises:\\n    ValueError: If any of the rollouts are not terminal.\\n  '\n    for ro in rollouts:\n        if (not ro.terminated):\n            raise ValueError('Can only process terminal rollouts.')\n    episode_lengths = [len(ro.states) for ro in rollouts]\n    batch_size = len(rollouts)\n    max_time = max(episode_lengths)\n    states = utils.stack_pad([ro.states for ro in rollouts], 0, max_time)\n    actions = utils.stack_pad([ro.actions for ro in rollouts], 0, max_time)\n    discounted_rewards = ([None] * batch_size)\n    discounted_adv = ([None] * batch_size)\n    for (i, ro) in enumerate(rollouts):\n        (disc_r, disc_adv) = discounted_advantage_and_rewards(ro.rewards, ro.values, gamma, lambda_)\n        discounted_rewards[i] = disc_r\n        discounted_adv[i] = disc_adv\n    discounted_rewards = utils.stack_pad(discounted_rewards, 0, max_time)\n    discounted_adv = utils.stack_pad(discounted_adv, 0, max_time)\n    total_rewards = [sum(ro.rewards) for ro in rollouts]\n    return Batch(states=states, actions=actions, discounted_adv=discounted_adv, discounted_r=discounted_rewards, total_rewards=total_rewards, episode_lengths=episode_lengths, batch_size=batch_size, max_time=max_time)\n"}
{"label_name":"save","label":1,"method_name":"save_model","method":"\n\ndef save_model(model, filepath, overwrite=True, include_optimizer=True):\n    \"Save a model to a HDF5 file.\\n\\n  The saved model contains:\\n      - the model's configuration (topology)\\n      - the model's weights\\n      - the model's optimizer's state (if any)\\n\\n  Thus the saved model can be reinstantiated in\\n  the exact same state, without any of the code\\n  used for model definition or training.\\n\\n  Arguments:\\n      model: Keras model instance to be saved.\\n      filepath: String, path where to save the model.\\n      overwrite: Whether we should overwrite any existing\\n          model at the target location, or instead\\n          ask the user with a manual prompt.\\n      include_optimizer: If True, save optimizer's state together.\\n\\n  Raises:\\n      ImportError: if h5py is not available.\\n  \"\n    if (h5py is None):\n        raise ImportError('`save_model` requires h5py.')\n\n    def get_json_type(obj):\n        'Serialize any object to a JSON-serializable structure.\\n\\n    Arguments:\\n        obj: the object to serialize\\n\\n    Returns:\\n        JSON-serializable structure representing `obj`.\\n\\n    Raises:\\n        TypeError: if `obj` cannot be serialized.\\n    '\n        if hasattr(obj, 'get_config'):\n            return {'class_name': obj.__class__.__name__, 'config': obj.get_config()}\n        if (type(obj).__module__ == np.__name__):\n            if isinstance(obj, np.ndarray):\n                return {'type': type(obj), 'value': obj.tolist()}\n            else:\n                return obj.item()\n        if callable(obj):\n            return obj.__name__\n        if (type(obj).__name__ == type.__name__):\n            return obj.__name__\n        raise TypeError('Not JSON Serializable:', obj)\n    from tensorflow.python.keras._impl.keras import __version__ as keras_version\n    if ((not overwrite) and os.path.isfile(filepath)):\n        proceed = ask_to_proceed_with_overwrite(filepath)\n        if (not proceed):\n            return\n    with h5py.File(filepath, mode='w') as f:\n        f.attrs['keras_version'] = str(keras_version).encode('utf8')\n        f.attrs['backend'] = K.backend().encode('utf8')\n        f.attrs['model_config'] = json.dumps({'class_name': model.__class__.__name__, 'config': model.get_config()}, default=get_json_type).encode('utf8')\n        model_weights_group = f.create_group('model_weights')\n        model_layers = model.layers\n        topology.save_weights_to_hdf5_group(model_weights_group, model_layers)\n        if (include_optimizer and hasattr(model, 'optimizer')):\n            if isinstance(model.optimizer, optimizers.TFOptimizer):\n                logging.warning('TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io\/optimizers).')\n            else:\n                f.attrs['training_config'] = json.dumps({'optimizer_config': {'class_name': model.optimizer.__class__.__name__, 'config': model.optimizer.get_config()}, 'loss': model.loss, 'metrics': model.metrics, 'sample_weight_mode': model.sample_weight_mode, 'loss_weights': model.loss_weights}, default=get_json_type).encode('utf8')\n                symbolic_weights = getattr(model.optimizer, 'weights')\n                if symbolic_weights:\n                    optimizer_weights_group = f.create_group('optimizer_weights')\n                    weight_values = K.batch_get_value(symbolic_weights)\n                    weight_names = []\n                    for (w, val) in zip(symbolic_weights, weight_values):\n                        name = str(w.name)\n                        weight_names.append(name.encode('utf8'))\n                    optimizer_weights_group.attrs['weight_names'] = weight_names\n                    for (name, val) in zip(weight_names, weight_values):\n                        param_dset = optimizer_weights_group.create_dataset(name, val.shape, dtype=val.dtype)\n                        if (not val.shape):\n                            param_dset[()] = val\n                        else:\n                            param_dset[:] = val\n        f.flush()\n"}
{"label_name":"process","label":2,"method_name":"get_preprocessor","method":"\n\n@PublicAPI\ndef get_preprocessor(space: gym.Space) -> type:\n    'Returns an appropriate preprocessor class for the given space.'\n    legacy_patch_shapes(space)\n    obs_shape = space.shape\n    if isinstance(space, (gym.spaces.Discrete, gym.spaces.MultiDiscrete)):\n        preprocessor = OneHotPreprocessor\n    elif (obs_shape == ATARI_OBS_SHAPE):\n        preprocessor = GenericPixelPreprocessor\n    elif (obs_shape == ATARI_RAM_OBS_SHAPE):\n        preprocessor = AtariRamPreprocessor\n    elif isinstance(space, gym.spaces.Tuple):\n        preprocessor = TupleFlatteningPreprocessor\n    elif isinstance(space, gym.spaces.Dict):\n        preprocessor = DictFlatteningPreprocessor\n    elif isinstance(space, Repeated):\n        preprocessor = RepeatedValuesPreprocessor\n    else:\n        preprocessor = NoPreprocessor\n    return preprocessor\n"}
{"label_name":"process","label":2,"method_name":"preprocess_image","method":"\n\ndef preprocess_image(image, output_height, output_width, is_training):\n    \"Preprocesses the given image.\\n\\n  Args:\\n    image: A `Tensor` representing an image of arbitrary size.\\n    output_height: The height of the image after preprocessing.\\n    output_width: The width of the image after preprocessing.\\n    is_training: `True` if we're preprocessing the image for training and\\n      `False` otherwise.\\n\\n  Returns:\\n    A preprocessed image.\\n  \"\n    image = tf.to_float(image)\n    image = tf.image.resize_image_with_crop_or_pad(image, output_width, output_height)\n    image = tf.subtract(image, 128.0)\n    image = tf.div(image, 128.0)\n    return image\n"}
{"label_name":"save","label":1,"method_name":"weights_save","method":"\n\ndef weights_save(model, filename, config):\n    'Saving the weights of a Keras model instance.\\n\\n    Args:\\n        model (Keras model instance): A Keras model instance.\\n        filename (str): Filename for the weights.\\n        config (Bunch object): The JSON configuration Bunch object.\\n\\n    Returns:\\n        A `.h5` file that holds weights.\\n\\n    '\n    out = os.path.join(config.checkpoint_dir, filename)\n    model.save_weights(filepath=out)\n    logging.info('The weights have been saved.')\n"}
{"label_name":"save","label":1,"method_name":"_save","method":"\n\ndef _save(im, fp, filename, save_all=False):\n    im.encoderinfo.update(im.info)\n    try:\n        palette = im.encoderinfo['palette']\n    except KeyError:\n        palette = None\n        im.encoderinfo['optimize'] = im.encoderinfo.get('optimize', True)\n    if ((not save_all) or (not _write_multiple_frames(im, fp, palette))):\n        _write_single_frame(im, fp, palette)\n    fp.write(b';')\n    if hasattr(fp, 'flush'):\n        fp.flush()\n"}
{"label_name":"process","label":2,"method_name":"preprocessing_data","method":"\n\ndef preprocessing_data(paras, df, LabelColumnName, one_hot_label_proc, array_format=True):\n    '\\n    df: pd.DataFrame\\n    X: np.array\\n    y: np.array\\n    convert df into X,y\\n    '\n    X = df.drop(LabelColumnName, 1)\n    y = np.array(df[LabelColumnName])\n    if (one_hot_label_proc == True):\n        y_normalized_T = one_hot_processing(y, paras.n_out_class)\n    else:\n        y_normalized_T = y.astype(int)\n    if array_format:\n        return (X.values, y_normalized_T)\n    return (X, y_normalized_T)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train(savefile, gridsearch=False):\n    (X_train, y_train) = load_xy_data(None, FEAT_JAMENDO_DIR, JAMENDO_LABEL_DIR, 'train')\n    (X_train_shuffled, _, y_train_shuffled, _) = train_test_split(X_train, y_train, test_size=0.0, random_state=42)\n    if gridsearch:\n        (X_val, y_val) = load_xy_data(None, FEAT_JAMENDO_DIR, JAMENDO_LABEL_DIR, 'valid')\n        X_train = X_train.reshape((X_train.shape[0], (- 1)))\n        print(X_train.shape, y_train.shape)\n        X_val = X_val.reshape((X_val.shape[0], (- 1)))\n        X_cv = np.concatenate((X_train, X_val), axis=0)\n        y_cv = np.concatenate((y_train, y_val), axis=0)\n        N = X_train.shape[0]\n        M = X_val.shape[0]\n        print(N, M)\n        idxs = ([(- 1) for i in range(N)] + [0 for i in range(M)])\n        print(len(idxs), (N + M))\n        cv_iter = PredefinedSplit(test_fold=idxs)\n        param_grid = {'max_features': [20], 'min_samples_leaf': [10], 'min_samples_split': [10, 30, 50], 'n_estimators': [50, 100, 200, 500]}\n        clf = RandomForestClassifier(bootstrap=True, random_state=1, criterion='gini', n_jobs=4)\n        grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=cv_iter, verbose=2)\n        grid_search.fit(X_cv, y_cv)\n        print(grid_search.best_params_)\n        pickle.dump(grid_search.best_params_, open('best_params.pkl', 'wb'))\n        pickle.dump(grid_search.cv_results_, open('results.pkl', 'wb'))\n        pickle.dump(grid_search.best_estimator_, open(savefile, 'wb'))\n    else:\n        clf = RandomForestClassifier(bootstrap=True, random_state=1, min_samples_leaf=10, min_samples_split=50, n_estimators=128, n_jobs=4)\n        clf.fit(X_train, y_train)\n        pickle.dump(clf, open(savefile, 'wb'))\n"}
{"label_name":"predict","label":4,"method_name":"run_core_ml_predict","method":"\n\ndef run_core_ml_predict(mlmodel, input_key_values, use_cpu_only=False):\n    for (k, v) in input_key_values.items():\n        if isinstance(v, PIL.Image.Image):\n            continue\n        elif ((not np.isscalar(v)) and (not (v.shape == ()))):\n            input_key_values[k] = v.astype(np.float32)\n        else:\n            input_key_values[k] = np.array([v], dtype=np.float32)\n    return mlmodel.predict(input_key_values, useCPUOnly=use_cpu_only)\n"}
{"label_name":"process","label":2,"method_name":"processImageForNeuralNet","method":"\n\ndef processImageForNeuralNet(arg1, image=False):\n    ' \\n\\tReceives as parameter arg1 the path of the image to be converted or the image already captured with\\n\\tcv2 (in that case, pass image=True as a parameter). The return of this function (x) should be passed as\\n\\tinput to a Network object by network.feedforward(x)\\n\\t'\n    SIDE_SIZE = 10\n    TOTAL_SIZE = 100\n    img = arg1\n    if (not image):\n        img = cv2.imread(arg1, 0)\n    img = cv2.resize(img, (SIDE_SIZE, SIDE_SIZE))\n    img = cv2.adaptiveThreshold(img, 1, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n    img = np.reshape(img, (TOTAL_SIZE, 1))\n    return np.array(img, dtype='f')\n"}
{"label_name":"train","label":0,"method_name":"create_trainer_program","method":"\n\ndef create_trainer_program(program, config, heter_ops, block_var_detail):\n    static_var = []\n    for device in heter_ops.keys():\n        for heter_block_index in sorted(heter_ops[device]):\n            static_var += replace_ops_by_communicate_op(program, config, heter_block_index, heter_ops[device][heter_block_index], block_var_detail)\n            remove_trainer_send_op(program, config, heter_block_index, block_var_detail)\n    deleter_trainer_useless_var(config, program, static_var)\n    check_op_device(program.global_block(), DEFAULT_DEVICE)\n"}
{"label_name":"process","label":2,"method_name":"get_preprocessing","method":"\n\ndef get_preprocessing(name, is_training=False):\n    'Returns preprocessing_fn(image, height, width, **kwargs).\\n\\n  Args:\\n    name: The name of the preprocessing function.\\n    is_training: `True` if the model is being used for training and `False`\\n      otherwise.\\n\\n  Returns:\\n    preprocessing_fn: A function that preprocessing a single image (pre-batch).\\n      It has the following signature:\\n        image = preprocessing_fn(image, output_height, output_width, ...).\\n\\n  Raises:\\n    ValueError: If Preprocessing `name` is not recognized.\\n  '\n    preprocessing_fn_map = {'cifarnet': cifarnet_preprocessing, 'inception': inception_preprocessing, 'inception_v1': inception_preprocessing, 'inception_v2': inception_preprocessing, 'inception_v3': inception_preprocessing, 'inception_v4': inception_preprocessing, 'inception_resnet_v2': inception_preprocessing, 'lenet': lenet_preprocessing, 'mobilenet_v1': inception_preprocessing, 'mobilenet_v2': inception_preprocessing, 'mobilenet_v2_035': inception_preprocessing, 'mobilenet_v2_140': inception_preprocessing, 'nasnet_mobile': inception_preprocessing, 'nasnet_large': inception_preprocessing, 'pnasnet_mobile': inception_preprocessing, 'pnasnet_large': inception_preprocessing, 'resnet_v1_50': vgg_preprocessing, 'resnet_v1_101': vgg_preprocessing, 'resnet_v1_152': vgg_preprocessing, 'resnet_v1_200': vgg_preprocessing, 'resnet_v2_50': vgg_preprocessing, 'resnet_v2_101': vgg_preprocessing, 'resnet_v2_152': vgg_preprocessing, 'resnet_v2_200': vgg_preprocessing, 'vgg': vgg_preprocessing, 'vgg_a': vgg_preprocessing, 'vgg_16': vgg_preprocessing, 'vgg_19': vgg_preprocessing}\n    if (name not in preprocessing_fn_map):\n        raise ValueError(('Preprocessing name [%s] was not recognized' % name))\n\n    def preprocessing_fn(image, output_height, output_width, **kwargs):\n        return preprocessing_fn_map[name].preprocess_image(image, output_height, output_width, is_training=is_training, **kwargs)\n    return preprocessing_fn\n"}
{"label_name":"train","label":0,"method_name":"lms_train","method":"\n\ndef lms_train(p0, Zi, Data):\n\n    def error(p, y, args):\n        l = len(p)\n        f = p[(l - 1)]\n        for i in range(len(args)):\n            f += (p[i] * args[i])\n        return (f - y)\n    Para = leastsq(error, p0, args=(Zi, Data))\n    return Para[0]\n"}
{"label_name":"train","label":0,"method_name":"load_train_data","method":"\n\ndef load_train_data(filename):\n    ext = filename.split('.')[(- 1)]\n    if (ext == 'csv'):\n        return read_smiles_csv(filename)\n    if (ext == 'smi'):\n        return read_smi(filename)\n    else:\n        raise ValueError('data is not smi or csv!')\n    return\n"}
{"label_name":"train","label":0,"method_name":"trainGradAscent","method":"\n\ndef trainGradAscent(intIterationSteps, arrayInputImageData, targetFunction, intRecordFrequent):\n    '\\n    Implement gradient ascent in targetFunction\\n    '\n    listFilterImages = []\n    floatLearningRate = 0.01\n    for i in range(intIterationSteps):\n        (floatLossValue, arrayGradientsValue) = targetFunction([arrayInputImageData, 0])\n        arrayInputImageData += (arrayGradientsValue * floatLearningRate)\n        if ((i % intRecordFrequent) == 0):\n            listFilterImages.append((arrayInputImageData, floatLossValue))\n            print('#{}, loss rate: {}'.format(i, floatLossValue))\n    return listFilterImages\n"}
{"label_name":"train","label":0,"method_name":"get_training_stats","method":"\n\ndef get_training_stats(trainer):\n    stats = OrderedDict()\n    if (trainer.get_meter('train_loss') is not None):\n        avg = trainer.get_meter('train_loss').avg\n        if (avg is not None):\n            stats['loss'] = f'{avg:.3f}'\n    if (trainer.get_meter('train_nll_loss').count > 0):\n        nll_loss = trainer.get_meter('train_nll_loss').avg\n        stats['nll_loss'] = f'{nll_loss:.3f}'\n    else:\n        nll_loss = trainer.get_meter('train_nll_loss').avg\n    stats['ppl'] = (get_perplexity(nll_loss) if (nll_loss is not None) else (- 1.0))\n    if (trainer.get_meter('wps') is not None):\n        stats['wps'] = (round(utils.item(trainer.get_meter('wps').avg)) if trainer.get_meter('wps').avg else None)\n    if (trainer.get_meter('ups') is not None):\n        stats['ups'] = (f\"{trainer.get_meter('ups').avg:.1f}\" if trainer.get_meter('ups').avg else None)\n    if (trainer.get_meter('wpb') is not None):\n        stats['wpb'] = (round(utils.item(trainer.get_meter('wpb').avg)) if trainer.get_meter('wpb').avg else None)\n    if (trainer.get_meter('bsz') is not None):\n        stats['bsz'] = (round(utils.item(trainer.get_meter('bsz').avg)) if trainer.get_meter('bsz').avg else None)\n    stats['num_updates'] = trainer.get_num_updates()\n    stats['lr'] = trainer.get_lr()\n    if (trainer.get_meter('gnorm') is not None):\n        stats['gnorm'] = (f\"{trainer.get_meter('gnorm').avg:.3f}\" if trainer.get_meter('gnorm').avg else None)\n    if (trainer.get_meter('clip') is not None):\n        stats['clip'] = (f\"{trainer.get_meter('clip').avg:.0%}\" if trainer.get_meter('clip').avg else None)\n    if (trainer.get_meter('oom') is not None):\n        stats['oom'] = (trainer.get_meter('oom').avg if trainer.get_meter('oom').avg else None)\n    if (trainer.get_meter('loss_scale') is not None):\n        stats['loss_scale'] = (f\"{trainer.get_meter('loss_scale').avg:.3f}\" if trainer.get_meter('loss_scale').avg else None)\n    if (trainer.get_meter('wall') is not None):\n        stats['wall'] = (round(utils.item(trainer.get_meter('wall').elapsed_time)) if trainer.get_meter('wall').elapsed_time else None)\n    if (trainer.get_meter('train_wall') is not None):\n        stats['train_wall'] = (round(utils.item(trainer.get_meter('train_wall').sum)) if trainer.get_meter('train_wall').sum else None)\n    return stats\n"}
{"label_name":"predict","label":4,"method_name":"rank_predictions","method":"\n\ndef rank_predictions(tf_prediction):\n    '\\n    Double-sortation serves as a ranking process\\n    The +1 is so the top-ranked has a non-zero rank\\n    :param tf_prediction:\\n    :return:\\n    '\n    tf_prediction_item_size = tf.shape(tf_prediction)[1]\n    tf_indices_of_ranks = tf.nn.top_k(tf_prediction, k=tf_prediction_item_size)[1]\n    return (tf.nn.top_k((- tf_indices_of_ranks), k=tf_prediction_item_size)[1] + 1)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train(config, inputs, args):\n    gan = setup_gan(config, inputs, args)\n    gan.name = config_name\n    trainable_gan = hg.TrainableGAN(gan, save_file=save_file, devices=args.devices, backend_name=args.backend)\n    gan.selected_sampler = ''\n    sampler = Sampler(gan)\n    samples = 0\n    for i in range(args.steps):\n        trainable_gan.step()\n        if ((args.action == 'train') and ((i % args.save_every) == 0) and (i > 0)):\n            print(('saving ' + save_file))\n            trainable_gan.save()\n        if ((i % args.sample_every) == 0):\n            sample_file = (('samples\/' + config_name) + ('\/%06d.png' % samples))\n            os.makedirs(os.path.expanduser(os.path.dirname(sample_file)), exist_ok=True)\n            samples += 1\n            sampler.sample(sample_file, args.save_samples)\n"}
{"label_name":"save","label":1,"method_name":"save_progress","method":"\n\ndef save_progress(save_dir, model, Delta_accountant, Accuracy_accountant, PrivacyAgent, FLAGS):\n    \"\\n    This function saves our progress either in an existing file structure or writes a new file.\\n    :param save_dir: STRING: The directory where to save the progress.\\n    :param model: DICTIONARY: The model that we wish to save.\\n    :param Delta_accountant: LIST: The list of deltas that we allocared so far.\\n    :param Accuracy_accountant: LIST: The list of accuracies that we allocated so far.\\n    :param PrivacyAgent: CLASS INSTANCE: The privacy agent that we used (specifically the m's that we used for Federated training.)\\n    :param FLAGS: CLASS INSTANCE: The FLAGS passed to the learning procedure.\\n    :return: nothing\\n    \"\n    filehandler = open((save_dir + '\/model.pkl'), 'wb')\n    pickle.dump(model, filehandler)\n    filehandler.close()\n    if (FLAGS.relearn == False):\n        with open((save_dir + '\/specs.csv'), 'wb') as csvfile:\n            writer = csv.writer(csvfile, delimiter=',')\n            if (FLAGS.priv_agent == True):\n                writer.writerow(([0] + [PrivacyAgent.get_m(r) for r in range((len(Delta_accountant) - 1))]))\n            if (FLAGS.priv_agent == False):\n                writer.writerow(([0] + ([FLAGS.m] * (len(Delta_accountant) - 1))))\n            writer.writerow(Delta_accountant)\n            writer.writerow(Accuracy_accountant)\n    if (FLAGS.relearn == True):\n        if ((len(Accuracy_accountant) > 1) or ((len(Accuracy_accountant) == 1) and (FLAGS.loaded is True))):\n            with open((save_dir + '\/specs.csv'), 'r+w') as csvfile:\n                csvReader = csv.reader(csvfile, delimiter=',')\n                lines = []\n                for row in csvReader:\n                    lines.append([float(i) for i in row])\n                lines = lines[:(- 1)]\n            with open((save_dir + '\/specs.csv'), 'wb') as csvfile:\n                writer = csv.writer(csvfile, delimiter=',')\n                for line in lines:\n                    writer.writerow(line)\n        with open((save_dir + '\/specs.csv'), 'a') as csvfile:\n            writer = csv.writer(csvfile, delimiter=',')\n            writer.writerow(Accuracy_accountant)\n"}
{"label_name":"forward","label":3,"method_name":"_apply_forwards","method":"\n\ndef _apply_forwards(fstruct, forward, fs_class, visited):\n    '\\n    Replace any feature structure that has a forward pointer with\\n    the target of its forward pointer (to preserve reentrancy).\\n    '\n    while (id(fstruct) in forward):\n        fstruct = forward[id(fstruct)]\n    if (id(fstruct) in visited):\n        return\n    visited.add(id(fstruct))\n    if _is_mapping(fstruct):\n        items = fstruct.items()\n    elif _is_sequence(fstruct):\n        items = enumerate(fstruct)\n    else:\n        raise ValueError('Expected mapping or sequence')\n    for (fname, fval) in items:\n        if isinstance(fval, fs_class):\n            while (id(fval) in forward):\n                fval = forward[id(fval)]\n            fstruct[fname] = fval\n            _apply_forwards(fval, forward, fs_class, visited)\n    return fstruct\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train(nbImg=0, cvScore=True):\n    import time\n    t0 = time.time()\n\n    def dt():\n        return round((time.time() - t0), 2)\n    print('+{}s: Importing libraries'.format(dt()))\n    import pickle\n    from sklearn.pipeline import Pipeline\n    from sklearn.decomposition import PCA\n    from sklearn.model_selection import StratifiedShuffleSplit\n    from sklearn.model_selection import StratifiedKFold\n    from sklearn.model_selection import GridSearchCV\n    from sklearn.svm import SVC\n    from sklearn.metrics import f1_score\n    from sklearn.metrics import confusion_matrix\n    from sklearn.metrics import classification_report\n    from rpscv import imgproc as imp\n    from rpscv import utils\n    print('+{}s: Generating image data'.format(dt()))\n    (features, labels) = imp.generateGrayFeatures(nbImg=nbImg, verbose=False, rs=rs)\n    (unique, count) = np.unique(labels, return_counts=True)\n    for (i, label) in enumerate(unique):\n        print('  {}: {} images'.format(utils.gestureTxt[label], count[i]))\n    print('+{}s: Generating test set'.format(dt()))\n    sssplit = StratifiedShuffleSplit(n_splits=1, test_size=0.15, random_state=rs)\n    for (train_index, test_index) in sssplit.split(features, labels):\n        features_train = features[train_index]\n        features_test = features[test_index]\n        labels_train = labels[train_index]\n        labels_test = labels[test_index]\n    print('+{}s: Defining pipeline'.format(dt()))\n    steps = [('pca', PCA()), ('clf', SVC(kernel='rbf'))]\n    pipe = Pipeline(steps)\n    print('+{}s: Defining cross-validation'.format(dt()))\n    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=rs)\n    print('+{}s: Defining grid search'.format(dt()))\n    grid_params = dict(pca__n_components=pca__n_components, clf__gamma=clf__gamma, clf__C=clf__C)\n    grid = GridSearchCV(pipe, grid_params, scoring=scoring, n_jobs=n_jobs, refit=True, cv=cv, verbose=1)\n    print('Grid search parameters:')\n    print(grid)\n    t0_train = time.time()\n    print('+{}s: Fitting classifier'.format(dt()))\n    grid.fit(features_train, labels_train)\n    dt_train = (time.time() - t0_train)\n    if cvScore:\n        cvres = grid.cv_results_\n        print('Cross-validation results:')\n        for (score, std, params) in zip(cvres['mean_test_score'], cvres['std_test_score'], cvres['params']):\n            print('  {}, {}, {}'.format(round(score, 4), round(std, 5), params))\n    print('Grid search best score: {}'.format(grid.best_score_))\n    print('Grid search best parameters:')\n    for (key, value) in grid.best_params_.items():\n        print('  {}: {}'.format(key, value))\n    print('+{}s: Validating classifier on test set'.format(dt()))\n    pred = grid.predict(features_test)\n    score = f1_score(labels_test, pred, average='micro')\n    print('Classifier f1-score on test set: {}'.format(score))\n    print('Confusion matrix:')\n    print(confusion_matrix(labels_test, pred))\n    print('Classification report:')\n    tn = [utils.gestureTxt[i] for i in range(3)]\n    print(classification_report(labels_test, pred, target_names=tn))\n    print('+{}s: Writing classifier to {}'.format(dt(), pklFilename))\n    with open(pklFilename, 'wb') as f:\n        f.flush()\n        pickle.dump(grid, f)\n    print('+{}s: Done!'.format(dt()))\n    return (grid.best_score_, score, dt_train)\n"}
{"label_name":"train","label":0,"method_name":"lms_train","method":"\n\ndef lms_train(p0, Zi, Data):\n\n    def error(p, y, args):\n        l = len(p)\n        f = p[(l - 1)]\n        for i in range(len(args)):\n            f += (p[i] * args[i])\n        return (f - y)\n    Para = leastsq(error, p0, args=(Zi, Data))\n    return Para[0]\n"}
{"label_name":"process","label":2,"method_name":"_preprocess_patch_list","method":"\n\ndef _preprocess_patch_list(plist):\n    plist = np.asarray(plist)\n    assert (plist.dtype != np.object)\n    if (plist.ndim == 3):\n        plist = plist[:, :, :, np.newaxis]\n    assert ((plist.ndim == 4) and (plist.shape[3] in [1, 3])), plist.shape\n    return plist\n"}
{"label_name":"predict","label":4,"method_name":"print_prediction_result","method":"\n\ndef print_prediction_result(val):\n    ' Prints in the console the content of results given as an \\n    argument (val) in a human-readable format \\n    '\n    if (len(val) < 3):\n        print('       ', val)\n    else:\n        v3 = val[2]\n        try:\n            v3 = float('{0:.4f}'.format(v3))\n        except:\n            pass\n        print(f'       {val[0]} ( {val[1]} ) : {v3}')\n"}
{"label_name":"train","label":0,"method_name":"check_pretrain","method":"\n\ndef check_pretrain(pt):\n    check_vocab(pt.vocab)\n    check_embedding(pt.emb)\n"}
{"label_name":"predict","label":4,"method_name":"predict_with_tcn","method":"\n\ndef predict_with_tcn(time_steps=None, padding='causal', return_sequences=True) -> list:\n    input_dim = 4\n    i = Input(batch_shape=(None, time_steps, input_dim))\n    o = TCN(nb_filters=NB_FILTERS, return_sequences=return_sequences, padding=padding)(i)\n    m = Model(inputs=[i], outputs=[o])\n    m.compile(optimizer='adam', loss='mse')\n    if (time_steps is None):\n        np.random.seed(123)\n        return [m(np.random.rand(1, SEQ_LEN_1, input_dim)), m(np.random.rand(1, SEQ_LEN_2, input_dim)), m(np.random.rand(1, SEQ_LEN_3, input_dim))]\n    else:\n        np.random.seed(123)\n        return [m(np.random.rand(1, time_steps, input_dim))]\n"}
{"label_name":"save","label":1,"method_name":"save","method":"\n\ndef save(ar, fileName):\n    from numpy import savetxt\n    savetxt(fileName, ar, precision=8)\n"}
{"label_name":"train","label":0,"method_name":"add_train_args","method":"\n\ndef add_train_args(parser):\n    arguments.add_config_arg(parser, nargs=1)\n    arguments.add_output_arg(parser, help_text='directory to persist the trained model in', required=True)\n    arguments.add_model_and_story_group(parser, allow_pretrained_model=False)\n    arguments.add_domain_arg(parser, required=True)\n"}
{"label_name":"train","label":0,"method_name":"train_core","method":"\n\ndef train_core(args: argparse.Namespace, train_path: Optional[Text]=None) -> Optional[Text]:\n    from rasa.train import train_core\n    import asyncio\n    loop = asyncio.get_event_loop()\n    output = (train_path or args.out)\n    args.domain = get_validated_path(args.domain, 'domain', DEFAULT_DOMAIN_PATH)\n    stories = get_validated_path(args.stories, 'stories', DEFAULT_DATA_PATH)\n    _train_path = (train_path or tempfile.mkdtemp())\n    if ((not isinstance(args.config, list)) or (len(args.config) == 1)):\n        if isinstance(args.config, list):\n            args.config = args.config[0]\n        config = get_validated_path(args.config, 'config', DEFAULT_CONFIG_PATH)\n        return train_core(args.domain, config, stories, output, train_path)\n    else:\n        from rasa.core.train import do_compare_training\n        loop.run_until_complete(do_compare_training(args, stories, None))\n        return None\n"}
{"label_name":"save","label":1,"method_name":"_save_model_with_obscurely_shaped_list_output","method":"\n\ndef _save_model_with_obscurely_shaped_list_output(export_dir):\n    'Writes SavedModel with hard-to-predict output shapes.'\n\n    def broadcast_obscurely_to(input, shape):\n        'Like tf.broadcast_to(), but hostile to static shape propagation.'\n        obscured_shape = tf.cast(((tf.cast(shape, tf.float32) + (0.1 * tf.sin(tf.random.uniform((), (- 3), (+ 3))))) + 0.3), tf.int32)\n        return tf.broadcast_to(input, obscured_shape)\n\n    @tf.function(input_signature=[tf.TensorSpec(shape=(None, 1), dtype=tf.float32)])\n    def call_fn(x):\n        batch_size = tf.shape(x)[0]\n        return [broadcast_obscurely_to(tf.reshape((i * x), ([batch_size] + ([1] * i))), tf.concat([[batch_size], ([i] * i)], axis=0)) for i in range(1, 4)]\n    obj = tf.train.Checkpoint()\n    obj.__call__ = call_fn\n    tf.saved_model.save(obj, export_dir)\n"}
{"label_name":"process","label":2,"method_name":"process_dataframe","method":"\n\ndef process_dataframe(client, hdfs_dir_input, hdfs_dir_output):\n    dask_df = client.persist(dd.read_parquet(hdfs_dir_input))\n    st = ScalerTransformer(dask_df)\n    scaled_features = st.get_transformed_data()\n    scaled_features.repartition(npartitions=32).to_parquet(hdfs_dir_output)\n"}
{"label_name":"train","label":0,"method_name":"visualize_training","method":"\n\ndef visualize_training(path_model, iteration_start_for_viz=0):\n    '\\n    :param path_model: path of the folder with the model parameters .ckpt\\n    :param iteration_start_for_viz: first iterations can reach extreme values,\\n        iteration_start_for_viz set a beginning other than epoch 0\\n    :return: matplotlib.figure.Figure\\n\\n    The returned figure represents the evolution of the loss and the accuracy \\n    evaluated on the validation set along the learning process.\\n    If the learning began from an initial model, the figure plots first the\\n    accuracy and loss evolution from this initial model and then stacks the\\n    evolution of the model.\\n    '\n    path_model = convert_path(path_model)\n\n    def _create_figure_helper(data_evolution):\n        fig = Figure()\n        FigureCanvas(fig)\n        ax1 = fig.subplots()\n        ax2 = ax1.twinx()\n        ax1.plot(data_evolution['steps'][iteration_start_for_viz:], data_evolution['accuracy'][iteration_start_for_viz:], '-', label='accuracy')\n        ax1.set_ylim(ymin=0)\n        ax2.plot(data_evolution['steps'][iteration_start_for_viz:], data_evolution['loss'][iteration_start_for_viz:], '-r', label='loss')\n        ax1.set_title('Accuracy and loss evolution')\n        ax1.set_xlabel('Epoch')\n        ax1.set_ylabel('Accuracy')\n        ax2.set_ylabel('Loss')\n        return fig\n    evolution = retrieve_training_data(path_model)\n    fig = _create_figure_helper(evolution)\n    return fig\n"}
{"label_name":"train","label":0,"method_name":"_get_train","method":"\n\ndef _get_train(config):\n    assert isinstance(config, TrainConfig), '`config` must be a an instance of `TrainConfig`'\n    input_fn = create_input_data_fn(mode=Modes.TRAIN, pipeline_config=config.data_pipeline)\n    return (input_fn, config.steps, config.hooks)\n"}
{"label_name":"save","label":1,"method_name":"model_save","method":"\n\ndef model_save(fn):\n    with open(fn, 'wb') as f:\n        torch.save([model, criterion, optimizer], f)\n"}
{"label_name":"predict","label":4,"method_name":"key_prediction_to_label","method":"\n\ndef key_prediction_to_label(prediction):\n    '\\n    Convert key class id to a human-readable key name.\\n\\n    Parameters\\n    ----------\\n    prediction : numpy array\\n        Array containing the probabilities of each key class.\\n\\n    Returns\\n    -------\\n    str\\n        Human-readable key name.\\n\\n    '\n    prediction = np.atleast_2d(prediction)\n    return KEY_LABELS[prediction[0].argmax()]\n"}
{"label_name":"process","label":2,"method_name":"data_preprocessing","method":"\n\ndef data_preprocessing(x_train, x_test):\n    x_train = x_train.astype('float32')\n    x_test = x_test.astype('float32')\n    x_train[:, :, :, 0] = ((x_train[:, :, :, 0] - np.mean(x_train[:, :, :, 0])) \/ np.std(x_train[:, :, :, 0]))\n    x_train[:, :, :, 1] = ((x_train[:, :, :, 1] - np.mean(x_train[:, :, :, 1])) \/ np.std(x_train[:, :, :, 1]))\n    x_train[:, :, :, 2] = ((x_train[:, :, :, 2] - np.mean(x_train[:, :, :, 2])) \/ np.std(x_train[:, :, :, 2]))\n    x_test[:, :, :, 0] = ((x_test[:, :, :, 0] - np.mean(x_test[:, :, :, 0])) \/ np.std(x_test[:, :, :, 0]))\n    x_test[:, :, :, 1] = ((x_test[:, :, :, 1] - np.mean(x_test[:, :, :, 1])) \/ np.std(x_test[:, :, :, 1]))\n    x_test[:, :, :, 2] = ((x_test[:, :, :, 2] - np.mean(x_test[:, :, :, 2])) \/ np.std(x_test[:, :, :, 2]))\n    return (x_train, x_test)\n"}
{"label_name":"forward","label":3,"method_name":"forward_random_state","method":"\n\n@deprecated('imgaug.random.advance_generator_')\ndef forward_random_state(random_state):\n    \"Advance a numpy random generator's internal state.\\n\\n    Parameters\\n    ----------\\n    random_state : numpy.random.Generator or numpy.random.RandomState\\n        Generator of which to advance the internal state.\\n\\n    \"\n    import imgaug.random\n    imgaug.random.advance_generator_(random_state)\n"}
{"label_name":"train","label":0,"method_name":"lms_train","method":"\n\ndef lms_train(p0, Zi, Data):\n\n    def error(p, y, args):\n        l = len(p)\n        f = p[(l - 1)]\n        for i in range(len(args)):\n            f += (p[i] * args[i])\n        return (f - y)\n    Para = leastsq(error, p0, args=(Zi, Data))\n    return Para[0]\n"}
{"label_name":"train","label":0,"method_name":"train_main","method":"\n\ndef train_main(use_cuda, is_sparse, is_local=True):\n    if (use_cuda and (not fluid.core.is_compiled_with_cuda())):\n        return\n    place = (fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace())\n    context = encoder(is_sparse)\n    rnn_out = decoder_train(context, is_sparse)\n    label = pd.data(name='target_language_next_word', shape=[1], dtype='int64', lod_level=1)\n    cost = pd.cross_entropy(input=rnn_out, label=label)\n    avg_cost = pd.mean(cost)\n    optimizer = fluid.optimizer.Adagrad(learning_rate=0.0001, regularization=fluid.regularizer.L2DecayRegularizer(regularization_coeff=0.1))\n    optimizer.minimize(avg_cost)\n    train_data = paddle.batch(paddle.reader.shuffle(paddle.dataset.wmt14.train(dict_size), buf_size=1000), batch_size=batch_size)\n    feed_order = ['src_word_id', 'target_language_word', 'target_language_next_word']\n    exe = Executor(place)\n\n    def train_loop(main_program):\n        exe.run(framework.default_startup_program())\n        feed_list = [main_program.global_block().var(var_name) for var_name in feed_order]\n        feeder = fluid.DataFeeder(feed_list, place)\n        batch_id = 0\n        for pass_id in range(1):\n            for data in train_data():\n                outs = exe.run(main_program, feed=feeder.feed(data), fetch_list=[avg_cost])\n                avg_cost_val = np.array(outs[0])\n                print(((((('pass_id=' + str(pass_id)) + ' batch=') + str(batch_id)) + ' avg_cost=') + str(avg_cost_val)))\n                if (batch_id > 3):\n                    break\n                batch_id += 1\n    if is_local:\n        train_loop(framework.default_main_program())\n    else:\n        port = os.getenv('PADDLE_PSERVER_PORT', '6174')\n        pserver_ips = os.getenv('PADDLE_PSERVER_IPS')\n        eplist = []\n        for ip in pserver_ips.split(','):\n            eplist.append(':'.join([ip, port]))\n        pserver_endpoints = ','.join(eplist)\n        trainers = int(os.getenv('PADDLE_TRAINERS'))\n        current_endpoint = ((os.getenv('POD_IP') + ':') + port)\n        trainer_id = int(os.getenv('PADDLE_TRAINER_ID'))\n        training_role = os.getenv('PADDLE_TRAINING_ROLE', 'TRAINER')\n        t = fluid.DistributeTranspiler()\n        t.transpile(trainer_id, pservers=pserver_endpoints, trainers=trainers)\n        if (training_role == 'PSERVER'):\n            pserver_prog = t.get_pserver_program(current_endpoint)\n            pserver_startup = t.get_startup_program(current_endpoint, pserver_prog)\n            exe.run(pserver_startup)\n            exe.run(pserver_prog)\n        elif (training_role == 'TRAINER'):\n            train_loop(t.get_trainer_program())\n"}
{"label_name":"predict","label":4,"method_name":"check_fit2d_predict1d","method":"\n\n@ignore_warnings(category=(DeprecationWarning, FutureWarning))\ndef check_fit2d_predict1d(name, estimator_orig):\n    rnd = np.random.RandomState(0)\n    X = (3 * rnd.uniform(size=(20, 3)))\n    y = X[:, 0].astype(np.int)\n    estimator = clone(estimator_orig)\n    y = multioutput_estimator_convert_y_2d(estimator, y)\n    if hasattr(estimator, 'n_components'):\n        estimator.n_components = 1\n    if hasattr(estimator, 'n_clusters'):\n        estimator.n_clusters = 1\n    set_random_state(estimator, 1)\n    estimator.fit(X, y)\n    for method in ['predict', 'transform', 'decision_function', 'predict_proba']:\n        if hasattr(estimator, method):\n            assert_raise_message(ValueError, 'Reshape your data', getattr(estimator, method), X[0])\n"}
{"label_name":"train","label":0,"method_name":"trainNB","method":"\n\ndef trainNB(data):\n    labels = data[:, (- 1)]\n    PGood = (sum([1 for l in labels if (l == '\u662f')]) \/ len(labels))\n    PBad = (1 - PGood)\n    NBClassify = {'\u662f': {}, '\u5426': {}}\n    for label in NBClassify.keys():\n        sub_data = data[(data[:, (- 1)] == label)]\n        sub_data = np.array(sub_data)\n        for k in range(sub_data.shape[1]):\n            NBClassify[label][k] = dict()\n            tags = list(set(data[:, k]))\n            d = sub_data[:, k]\n            for tag in tags:\n                NBClassify[label][k][tag] = ((sum([1 for i in d if (i == tag)]) + 1) \/ len(d))\n    return (PGood, PBad, NBClassify)\n"}
{"label_name":"process","label":2,"method_name":"process_names","method":"\n\ndef process_names(combined):\n    combined.drop('Name', axis=1, inplace=True)\n    titles_dummies = pd.get_dummies(combined['Title'], prefix='Title')\n    combined = pd.concat([combined, titles_dummies], axis=1)\n    combined.drop('Title', axis=1, inplace=True)\n    return combined\n"}
{"label_name":"train","label":0,"method_name":"train_main","method":"\n\ndef train_main():\n    model = PretrainedNet().to(device)\n    params = filter((lambda p: p.requires_grad), model.parameters())\n    optimizer = optim.SGD(params, lr=0.01)\n    criterion = nn.BCELoss()\n    print(model)\n    batch_size = 25\n    train_loader = get_train_loader(batch_size)\n    validation_loader = get_validation_loader(batch_size)\n    log = get_tensorboard('pretrained')\n    epochs = 10\n    start_time = datetime.now()\n    for epoch in range(1, (epochs + 1)):\n        train(model, train_loader, criterion, optimizer, epoch, log)\n        with torch.no_grad():\n            print('\\nValidation:')\n            evaluate(model, validation_loader, criterion, epoch, log)\n    end_time = datetime.now()\n    print('Total training time: {}.'.format((end_time - start_time)))\n    torch.save(model.state_dict(), model_file)\n    print('Wrote model to', model_file)\n    log = get_tensorboard('finetuned')\n    for (name, layer) in model.vgg_features.named_children():\n        note = ' '\n        for param in layer.parameters():\n            note = '-'\n            if (int(name) >= 24):\n                param.requires_grad = True\n                note = '+'\n        print(name, note, layer, len(param))\n    params = filter((lambda p: p.requires_grad), model.parameters())\n    optimizer = optim.RMSprop(params, lr=1e-05)\n    criterion = nn.BCELoss()\n    print(model)\n    prev_epochs = epoch\n    epochs = 20\n    start_time = datetime.now()\n    for epoch in range(1, (epochs + 1)):\n        train(model, train_loader, criterion, optimizer, (prev_epochs + epoch), log)\n        with torch.no_grad():\n            print('\\nValidation:')\n            evaluate(model, validation_loader, criterion, (prev_epochs + epoch), log)\n    end_time = datetime.now()\n    print('Total training time: {}.'.format((end_time - start_time)))\n    torch.save(model.state_dict(), model_file_ft)\n    print('Wrote finetuned model to', model_file_ft)\n"}
{"label_name":"train","label":0,"method_name":"build_train_parser","method":"\n\ndef build_train_parser(parser):\n    parser.add_argument('--engine', dest='engine', default='auto', choices=('auto', 'sgd', 'liblinear'), help='Which engine to use.')\n    parser.add_argument('--auto-weight', dest='auto_weight', default=32, type=int, help=\"When engine is 'auto', number of classes * max_leaf_size remaining to revert to SGD\")\n    parser.add_argument('--no-remap-labels', dest='noRemap', action='store_true', help='Whether to remap labels to an internal format.  Needed for string labels')\n    parser.add_argument('--trees', dest='trees', type=int, default=50, help='Number of trees to use')\n    parser.add_argument('--max_leaf_size', dest='max_leaf_size', type=int, default=10, help='Maximumum number of examples allowed per leaf')\n    parser.add_argument('--max_labels_per_leaf', dest='max_labels_per_leaf', type=int, default=50, help='Maximum number of classes to retaion for probability distribution per leaf')\n    parser.add_argument('--re_split', dest='re_split', type=int, default=1, help='After fitting a classifier, re-splits the data according to fitted classifier.  If greater than 1, it will re-fit and re-train a classifier the data if after splitting, it all ends in a leaf.  Will retry N times.')\n    parser.add_argument('--alpha', dest='alpha', type=float, default=0.001, help=\"L1 coefficient.  Too high and it won't learn a split, too low and it won't be sparse (larger file size, slower inference).\")\n    parser.add_argument('--C', dest='C', type=float, default=1, help='C value for when using auto, penalizing accuracy over fit')\n    parser.add_argument('--iters', dest='iters', type=(lambda x: (int(x) if (x != 'auto') else x)), default=2, help='Number of iterations to run over the dataset when fitting classifier')\n    parser.add_argument('--n_updates', dest='n_updates', type=int, default=100, help=\"If iters is 'auto', makes it use iters = n_update \/ N\")\n    parser.add_argument('--no_bias', dest='bias', action='store_false', help='Fits a bias for the classifier.  Not needed if data has E[X] = 0')\n    parser.add_argument('--subsample', dest='subsample', type=float, default=1.0, help='Subsample data per tree.  if less than 1, interpretted as a percentage.  If greater than one, taken as number of data points per tree.')\n    parser.add_argument('--loss', dest='loss', choices=('log', 'hinge'), default='log', help='Loss to minimize.')\n    parser.add_argument('--threads', dest='threads', type=int, default=multiprocessing.cpu_count(), help='Number of threads to use.  Will use min(threads, trees)')\n    parser.add_argument('--label-weight', dest='label_weight', choices=('uniform', 'nnllog', 'propensity', 'logexp'), default='propensity', help='Metric for computing label weighting.')\n    parser.add_argument('--label-weight-hp', dest='label_weight_hp', metavar='P', nargs=2, type=float, default=(None, None), help='Hyper parameters for label weight tuning')\n    parser.add_argument('--optimization', dest='optimization', choices=('fastxml', 'dsimec'), default='fastxml', help='optimization strategy to use for linear classifier')\n    parser.add_argument('--eps', dest='eps', type=float, help='Sparsity epsilon.  Weights lower than eps will suppress to zero')\n    parser.add_argument('--leaf-classifiers', dest='leaf_class', action='store_true', help='Whether to use and compute leaf classifiers')\n    parser.add_argument('--gamma', type=int, default=30, help='Gamma coefficient for hyper-sphere weighting')\n    parser.add_argument('--blend-factor', dest='blend_factor', type=float, default=0.5, help='blend * tree-probs + (1 - blend) * tail-classifiers')\n    parser.add_argument('--min-label-count', dest='mlc', type=int, default=5, help='Filter out labels with count < min-label-count')\n    parser.add_argument('--leaf-probs', dest='leafProbs', action='store_true', help='Computes probability: TP(X) * LP(X)')\n    return parser\n"}
{"label_name":"process","label":2,"method_name":"preprocess","method":"\n\ndef preprocess(text_string):\n    '\\n    Accepts a text string and replaces:\\n    1) urls with URLHERE\\n    2) lots of whitespace with one instance\\n    3) mentions with MENTIONHERE\\n\\n    This allows us to get standardized counts of urls and mentions\\n    Without caring about specific people mentioned\\n    '\n    space_pattern = '\\\\s+'\n    giant_url_regex = 'http[s]?:\/\/(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n    mention_regex = '@[\\\\w\\\\-]+'\n    parsed_text = re.sub(space_pattern, ' ', text_string)\n    parsed_text = re.sub(giant_url_regex, 'URLHERE', parsed_text)\n    parsed_text = re.sub(mention_regex, 'MENTIONHERE', parsed_text)\n    return parsed_text\n"}
{"label_name":"save","label":1,"method_name":"_save","method":"\n\ndef _save(im, fp, filename):\n    \"\\n    Saves the image as a series of PNG files,\\n    that are then converted to a .icns file\\n    using the macOS command line utility 'iconutil'.\\n\\n    macOS only.\\n    \"\n    if hasattr(fp, 'flush'):\n        fp.flush()\n    iconset = tempfile.mkdtemp('.iconset')\n    provided_images = {im.width: im for im in im.encoderinfo.get('append_images', [])}\n    last_w = None\n    for w in [16, 32, 128, 256, 512]:\n        prefix = 'icon_{}x{}'.format(w, w)\n        first_path = os.path.join(iconset, (prefix + '.png'))\n        if (last_w == w):\n            shutil.copyfile(second_path, first_path)\n        else:\n            im_w = provided_images.get(w, im.resize((w, w), Image.LANCZOS))\n            im_w.save(first_path)\n        second_path = os.path.join(iconset, (prefix + '@2x.png'))\n        im_w2 = provided_images.get((w * 2), im.resize(((w * 2), (w * 2)), Image.LANCZOS))\n        im_w2.save(second_path)\n        last_w = (w * 2)\n    from subprocess import Popen, PIPE, CalledProcessError\n    convert_cmd = ['iconutil', '-c', 'icns', '-o', filename, iconset]\n    with open(os.devnull, 'wb') as devnull:\n        convert_proc = Popen(convert_cmd, stdout=PIPE, stderr=devnull)\n    convert_proc.stdout.close()\n    retcode = convert_proc.wait()\n    shutil.rmtree(iconset)\n    if retcode:\n        raise CalledProcessError(retcode, convert_cmd)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train():\n    net.train()\n    loss_avg = 0.0\n    for (batch_idx, (data, target)) in enumerate(train_loader):\n        (data, target) = (V(data.cuda()), V(target.cuda()))\n        x = net(data)\n        optimizer.zero_grad()\n        loss = F.cross_entropy(x, target)\n        loss.backward()\n        optimizer.step()\n        loss_avg = ((loss_avg * 0.8) + (loss.data[0] * 0.2))\n        dt = (math.pi \/ float(args.epochs))\n        state['tt'] += (float(dt) \/ (len(train_loader.dataset) \/ float(args.batch_size)))\n        if (state['tt'] >= (math.pi - 0.01)):\n            state['tt'] = (math.pi - 0.01)\n        curT = ((math.pi \/ 2.0) + state['tt'])\n        new_lr = ((args.learning_rate * (1.0 + math.sin(curT))) \/ 2.0)\n        state['learning_rate'] = new_lr\n        for param_group in optimizer.param_groups:\n            param_group['lr'] = state['learning_rate']\n    state['train_loss'] = loss_avg\n"}
{"label_name":"predict","label":4,"method_name":"prediction_fidelity_after_iterative_fixing","method":"\n\ndef prediction_fidelity_after_iterative_fixing(train_documents, train_targets, test_documents, test_targets, test_idx, scores, batch_size, max_steps, **catboost_params):\n    prediction_original = catboost_fit_predict(train_documents, train_targets, test_documents, 'Probability', **catboost_params)\n    loss_on_test_idx_original = log_loss(y_true=test_targets[[test_idx]], y_pred=prediction_original[[test_idx]], labels=[0, 1])\n    losses_on_test_idx = []\n    batch_num = 0\n    harmful_idxs_queue = np.argsort((- scores))\n    idxs_to_remove = []\n    pbar = tqdm_notebook(total=(max_steps + 1))\n    while (((len(train_documents) - len(idxs_to_remove)) > batch_size) and (batch_num < (max_steps + 1))):\n        first_new_removed_idx = ((batch_num - 1) * batch_size)\n        idxs_to_remove_batch = harmful_idxs_queue[first_new_removed_idx:(first_new_removed_idx + batch_size)]\n        idxs_to_remove += list(idxs_to_remove_batch)\n        train_documents_reduced = np.delete(train_documents, idxs_to_remove, axis=0)\n        train_targets_reduced = np.delete(train_targets, idxs_to_remove, axis=0)\n        prediction = catboost_fit_predict(train_documents_reduced, train_targets_reduced, test_documents, 'Probability', **catboost_params)\n        loss_on_test_idx = log_loss(y_true=test_targets[[test_idx]], y_pred=prediction[[test_idx]], labels=[0, 1])\n        losses_on_test_idx.append(((loss_on_test_idx - loss_on_test_idx_original) \/ loss_on_test_idx_original))\n        batch_num += 1\n        pbar.update(1)\n    pbar.close()\n    return losses_on_test_idx\n"}
{"label_name":"process","label":2,"method_name":"_process_frame42","method":"\n\ndef _process_frame42(frame):\n    frame = frame[34:(34 + 160), :160]\n    frame = cv2.resize(frame, (80, 80))\n    frame = cv2.resize(frame, (42, 42))\n    frame = frame.mean(2)\n    frame = frame.astype(np.float32)\n    frame *= (1.0 \/ 255.0)\n    frame = np.reshape(frame, [42, 42, 1])\n    return frame\n"}
{"label_name":"process","label":2,"method_name":"xlm_tokens_pre_processor","method":"\n\ndef xlm_tokens_pre_processor(token_ids: List[int]) -> List[int]:\n    'Add XLM style special tokens.\\n\\n    Args:\\n        token_ids: List of token ids without any special tokens.\\n\\n    Returns:\\n        List of token ids augmented with special tokens.\\n    '\n    XLM_SEP_ID = 1\n    token_ids.insert(0, XLM_SEP_ID)\n    token_ids.append(XLM_SEP_ID)\n    return token_ids\n"}
{"label_name":"save","label":1,"method_name":"save_params","method":"\n\ndef save_params(net, best_map, current_map, epoch, save_interval, prefix):\n    current_map = float(current_map)\n    if (current_map > best_map[0]):\n        best_map[0] = current_map\n        net.save_params('{:s}_best.params'.format(prefix, epoch, current_map))\n        with open((prefix + '_best_map.log'), 'a') as f:\n            f.write('{:04d}:\\t{:.4f}\\n'.format(epoch, current_map))\n    if (save_interval and ((epoch % save_interval) == 0)):\n        net.save_params('{:s}_{:04d}_{:.4f}.params'.format(prefix, epoch, current_map))\n"}
{"label_name":"train","label":0,"method_name":"train_svm","method":"\n\ndef train_svm(features, c_param, kernel='linear'):\n    '\\n    Train a multi-class probabilitistic SVM classifier.\\n    Note:     This function is simply a wrapper to the sklearn functionality \\n              for SVM training\\n              See function trainSVM_feature() to use a wrapper on both the \\n              feature extraction and the SVM training\\n              (and parameter tuning) processes.\\n    ARGUMENTS:\\n        - features:         a list ([numOfClasses x 1]) whose elements \\n                            containt np matrices of features  each matrix \\n                            features[i] of class i is \\n                            [n_samples x numOfDimensions]\\n        - c_param:           SVM parameter C (cost of constraints violation)\\n    RETURNS:\\n        - svm:              the trained SVM variable\\n\\n    NOTE:\\n        This function trains a linear-kernel SVM for a given C value.\\n        For a different kernel, other types of parameters should be provided.\\n    '\n    (feature_matrix, labels) = features_to_matrix(features)\n    svm = sklearn.svm.SVC(C=c_param, kernel=kernel, probability=True, gamma='auto')\n    svm.fit(feature_matrix, labels)\n    return svm\n"}
{"label_name":"train","label":0,"method_name":"training","method":"\n\ndef training():\n    (train, train_label, val, val_label) = input_data.get_files(train_dir, RATIO)\n    (train_batch, train_label_batch) = input_data.get_batch(train, train_label, IMG_W, IMG_H, BATCH_SIZE, CAPACITY)\n    (val_batch, val_label_batch) = input_data.get_batch(val, val_label, IMG_W, IMG_H, BATCH_SIZE, CAPACITY)\n    logits = model2.inference(train_batch, BATCH_SIZE, N_CLASSES)\n    loss = model2.losses(logits, train_label_batch)\n    train_op = model2.trainning(loss, learning_rate)\n    acc = model2.evaluation(logits, train_label_batch)\n    x = tf.placeholder(tf.float32, shape=[BATCH_SIZE, IMG_W, IMG_H, 3])\n    y_ = tf.placeholder(tf.int16, shape=[BATCH_SIZE])\n    with tf.Session() as sess:\n        saver = tf.train.Saver()\n        sess.run(tf.global_variables_initializer())\n        ckpt = tf.train.get_checkpoint_state(train_logs_dir)\n        if (ckpt and ckpt.model_checkpoint_path):\n            global_step = ckpt.model_checkpoint_path.split('\/')[(- 1)].split('-')[(- 1)]\n            saver.restore(sess, '.\/logs2\/train\/model2.ckpt-3000')\n            print(('Loading success, global_step is %s' % global_step))\n        else:\n            print('No checkpoint file found')\n        coord = tf.train.Coordinator()\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n        summary_op = tf.summary.merge_all()\n        train_writer = tf.summary.FileWriter(train_logs_dir, sess.graph)\n        val_writer = tf.summary.FileWriter(val_logs_dir, sess.graph)\n        try:\n            for step in np.arange(3001, MAX_STEP):\n                if coord.should_stop():\n                    break\n                (tra_images, tra_labels) = sess.run([train_batch, train_label_batch])\n                (_, tra_loss, tra_acc) = sess.run([train_op, loss, acc], feed_dict={x: tra_images, y_: tra_labels})\n                if ((step % 50) == 0):\n                    print(('Step %d, train loss = %.2f, train accuracy = %.2f%%' % (step, tra_loss, (tra_acc * 100.0))))\n                    summary_str = sess.run(summary_op)\n                    train_writer.add_summary(summary_str, step)\n                if (((step % 200) == 0) or ((step + 1) == MAX_STEP)):\n                    (val_images, val_labels) = sess.run([val_batch, val_label_batch])\n                    (val_loss, val_acc) = sess.run([loss, acc], feed_dict={x: val_images, y_: val_labels})\n                    print(('**  Step %d, val loss = %.2f, val accuracy = %.2f%%  **' % (step, val_loss, (val_acc * 100.0))))\n                    summary_str = sess.run(summary_op)\n                    val_writer.add_summary(summary_str, step)\n                if (((step % 1000) == 0) or ((step + 1) == MAX_STEP)):\n                    checkpoint_path = os.path.join(train_logs_dir, 'model2.ckpt')\n                    saver.save(sess, checkpoint_path, global_step=step)\n        except tf.errors.OutOfRangeError:\n            print('Done training -- epoch limit reached')\n        finally:\n            coord.request_stop()\n        coord.join(threads)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train(train_data_path, test_data_path, args):\n    device = chainer.get_device(args.device)\n    device.use()\n    vocab = collections.defaultdict((lambda : len(vocab)))\n    vocab['<unk>'] = 0\n    train_data = babi.read_data(vocab, train_data_path)\n    test_data = babi.read_data(vocab, test_data_path)\n    print(('Training data: %s: %d' % (train_data_path, len(train_data))))\n    print(('Test data: %s: %d' % (test_data_path, len(test_data))))\n    train_data = memnn.convert_data(train_data, args.max_memory)\n    test_data = memnn.convert_data(test_data, args.max_memory)\n    encoder = memnn.make_encoder(args.sentence_repr)\n    network = memnn.MemNN(args.unit, len(vocab), encoder, args.max_memory, args.hop)\n    model = chainer.links.Classifier(network, label_key='answer')\n    opt = chainer.optimizers.Adam()\n    model.to_device(device)\n    opt.setup(model)\n    train_iter = chainer.iterators.SerialIterator(train_data, args.batchsize)\n    test_iter = chainer.iterators.SerialIterator(test_data, args.batchsize, repeat=False, shuffle=False)\n    updater = chainer.training.StandardUpdater(train_iter, opt, device=device)\n    trainer = chainer.training.Trainer(updater, (args.epoch, 'epoch'))\n\n    @chainer.training.make_extension()\n    def fix_ignore_label(trainer):\n        network.fix_ignore_label()\n    trainer.extend(fix_ignore_label)\n    trainer.extend(extensions.Evaluator(test_iter, model, device=device))\n    trainer.extend(extensions.LogReport())\n    trainer.extend(extensions.PrintReport(['epoch', 'main\/loss', 'validation\/main\/loss', 'main\/accuracy', 'validation\/main\/accuracy']))\n    trainer.extend(extensions.ProgressBar(update_interval=10))\n    trainer.run()\n    if args.model:\n        memnn.save_model(args.model, model, vocab)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train(lr, bsize, n_hidden):\n    x = random.random()\n    return (x, (x * 5))\n"}
{"label_name":"train","label":0,"method_name":"expand_training_data","method":"\n\ndef expand_training_data(images, labels):\n    expanded_images = []\n    expanded_labels = []\n    directory = os.path.dirname('data\/New')\n    if (not tf.gfile.Exists('data\/New')):\n        tf.gfile.MakeDirs('data\/New')\n    k = 0\n    for (x, y) in zip(images, labels):\n        k = (k + 1)\n        if ((k % 100) == 0):\n            print(('expanding data : %03d \/ %03d' % (k, np.size(images, 0))))\n        expanded_images.append(x)\n        expanded_labels.append(y)\n        bg_value = (- 0.5)\n        image = np.reshape(x, ((- 1), 28))\n        for i in range(4):\n            angle = np.random.randint((- 90), 90, 1)\n            new_img = ndimage.rotate(image, angle, reshape=False, cval=bg_value)\n            shift = np.random.randint((- 2), 2, 2)\n            new_img_ = ndimage.shift(new_img, shift, cval=bg_value)\n            image1 = ((image * 255) + (255 \/ 2.0))\n            new_img1 = ((new_img_ * 255) + (255 \/ 2.0))\n            '\\n            if k<50:\\n                NAME1 = DATA_DIRECTORY+\"\/New\"+\"\/\"+str(k)+\"_0.jpeg\"\\n                im = Image.fromarray(image1)\\n                im.convert(\\'RGB\\').save(NAME1)\\n                im = Image.fromarray(new_img1)\\n                NAME = DATA_DIRECTORY+\"\/New\"+\"\/\"+str(k)+\"_\"+str(i+1)+\".jpeg\"\\n                im.convert(\\'RGB\\').save(NAME)\\n            '\n            expanded_images.append(np.reshape(new_img_, 784))\n            expanded_labels.append(y)\n    expanded_train_total_data = np.concatenate((expanded_images, expanded_labels), axis=1)\n    np.random.shuffle(expanded_train_total_data)\n    return expanded_train_total_data\n"}
{"label_name":"predict","label":4,"method_name":"predict","method":"\n\ndef predict(args):\n    symbols = [symbol.upper() for symbol in args.symbols]\n    log.debug('symbols: %s', symbols)\n    transformer = StockDataTransformer()\n    forecaster = Forecaster(transformer)\n    forecaster.load_weights(args.weights)\n    [predict_future(symbol, transformer, forecaster) for symbol in symbols]\n"}
{"label_name":"forward","label":3,"method_name":"forward","method":"\n\ndef forward(inpd, layers):\n    out = inpd\n    for layer in layers:\n        (w, b) = layer\n        out = elu(((out @ w) + b))\n    return out\n"}
{"label_name":"predict","label":4,"method_name":"predict_cubes","method":"\n\ndef predict_cubes(model_path, continue_job, only_patient_id=None, luna16=False, magnification=1, flip=False, train_data=True, holdout_no=(- 1), ext_name='', fold_count=2):\n    if luna16:\n        dst_dir = settings.LUNA_NODULE_DETECTION_DIR\n    else:\n        dst_dir = settings.NDSB3_NODULE_DETECTION_DIR\n    if (not os.path.exists(dst_dir)):\n        os.makedirs(dst_dir)\n    holdout_ext = ''\n    flip_ext = ''\n    if flip:\n        flip_ext = '_flip'\n    dst_dir += (((((('predictions' + str(int((magnification * 10)))) + holdout_ext) + flip_ext) + '_') + ext_name) + '\/')\n    if (not os.path.exists(dst_dir)):\n        os.makedirs(dst_dir)\n    sw = helpers.Stopwatch.start_new()\n    model = step2_train_nodule_detector.get_net(input_shape=(CUBE_SIZE, CUBE_SIZE, CUBE_SIZE, 1), load_weight_path=model_path)\n    if (not luna16):\n        if train_data:\n            labels_df = pandas.read_csv('resources\/stage1_labels.csv')\n            labels_df.set_index(['id'], inplace=True)\n        else:\n            labels_df = pandas.read_csv('resources\/stage2_sample_submission.csv')\n            labels_df.set_index(['id'], inplace=True)\n    patient_ids = []\n    for file_name in os.listdir(settings.NDSB3_EXTRACTED_IMAGE_DIR):\n        if (not os.path.isdir((settings.NDSB3_EXTRACTED_IMAGE_DIR + file_name))):\n            continue\n        patient_ids.append(file_name)\n    all_predictions_csv = []\n    for (patient_index, patient_id) in enumerate(reversed(patient_ids)):\n        if (not luna16):\n            if (patient_id not in labels_df.index):\n                continue\n        if ('metadata' in patient_id):\n            continue\n        if ((only_patient_id is not None) and (only_patient_id != patient_id)):\n            continue\n        if ((holdout_no is not None) and train_data):\n            patient_fold = helpers.get_patient_fold(patient_id)\n            patient_fold %= fold_count\n            if (patient_fold != holdout_no):\n                continue\n        print(patient_index, ': ', patient_id)\n        csv_target_path = ((dst_dir + patient_id) + '.csv')\n        if (continue_job and (only_patient_id is None)):\n            if os.path.exists(csv_target_path):\n                continue\n        patient_img = helpers.load_patient_images(patient_id, settings.NDSB3_EXTRACTED_IMAGE_DIR, '*_i.png', [])\n        if (magnification != 1):\n            patient_img = helpers.rescale_patient_images(patient_img, (1, 1, 1), magnification)\n        patient_mask = helpers.load_patient_images(patient_id, settings.NDSB3_EXTRACTED_IMAGE_DIR, '*_m.png', [])\n        if (magnification != 1):\n            patient_mask = helpers.rescale_patient_images(patient_mask, (1, 1, 1), magnification, is_mask_image=True)\n        step = PREDICT_STEP\n        CROP_SIZE = CUBE_SIZE\n        predict_volume_shape_list = [0, 0, 0]\n        for dim in range(3):\n            dim_indent = 0\n            while ((dim_indent + CROP_SIZE) < patient_img.shape[dim]):\n                predict_volume_shape_list[dim] += 1\n                dim_indent += step\n        predict_volume_shape = (predict_volume_shape_list[0], predict_volume_shape_list[1], predict_volume_shape_list[2])\n        predict_volume = numpy.zeros(shape=predict_volume_shape, dtype=float)\n        print('Predict volume shape: ', predict_volume.shape)\n        done_count = 0\n        skipped_count = 0\n        batch_size = 128\n        batch_list = []\n        batch_list_coords = []\n        patient_predictions_csv = []\n        cube_img = None\n        annotation_index = 0\n        for z in range(0, predict_volume_shape[0]):\n            for y in range(0, predict_volume_shape[1]):\n                for x in range(0, predict_volume_shape[2]):\n                    cube_img = patient_img[(z * step):((z * step) + CROP_SIZE), (y * step):((y * step) + CROP_SIZE), (x * step):((x * step) + CROP_SIZE)]\n                    cube_mask = patient_mask[(z * step):((z * step) + CROP_SIZE), (y * step):((y * step) + CROP_SIZE), (x * step):((x * step) + CROP_SIZE)]\n                    if (cube_mask.sum() < 2000):\n                        skipped_count += 1\n                    else:\n                        if flip:\n                            cube_img = cube_img[:, :, ::(- 1)]\n                        if (CROP_SIZE != CUBE_SIZE):\n                            cube_img = helpers.rescale_patient_images2(cube_img, (CUBE_SIZE, CUBE_SIZE, CUBE_SIZE))\n                        img_prep = prepare_image_for_net3D(cube_img)\n                        batch_list.append(img_prep)\n                        batch_list_coords.append((z, y, x))\n                        if ((len(batch_list) % batch_size) == 0):\n                            batch_data = numpy.vstack(batch_list)\n                            p = model.predict(batch_data, batch_size=batch_size)\n                            for i in range(len(p[0])):\n                                p_z = batch_list_coords[i][0]\n                                p_y = batch_list_coords[i][1]\n                                p_x = batch_list_coords[i][2]\n                                nodule_chance = p[0][i][0]\n                                predict_volume[(p_z, p_y, p_x)] = nodule_chance\n                                if (nodule_chance > P_TH):\n                                    p_z = ((p_z * step) + (CROP_SIZE \/ 2))\n                                    p_y = ((p_y * step) + (CROP_SIZE \/ 2))\n                                    p_x = ((p_x * step) + (CROP_SIZE \/ 2))\n                                    p_z_perc = round((p_z \/ patient_img.shape[0]), 4)\n                                    p_y_perc = round((p_y \/ patient_img.shape[1]), 4)\n                                    p_x_perc = round((p_x \/ patient_img.shape[2]), 4)\n                                    diameter_mm = round(p[1][i][0], 4)\n                                    diameter_perc = round(((2 * step) \/ patient_img.shape[2]), 4)\n                                    diameter_perc = round((diameter_mm \/ patient_img.shape[2]), 4)\n                                    nodule_chance = round(nodule_chance, 4)\n                                    patient_predictions_csv_line = [annotation_index, p_x_perc, p_y_perc, p_z_perc, diameter_perc, nodule_chance, diameter_mm]\n                                    patient_predictions_csv.append(patient_predictions_csv_line)\n                                    all_predictions_csv.append(([patient_id] + patient_predictions_csv_line))\n                                    annotation_index += 1\n                            batch_list = []\n                            batch_list_coords = []\n                    done_count += 1\n                    if ((done_count % 10000) == 0):\n                        print('Done: ', done_count, ' skipped:', skipped_count)\n        df = pandas.DataFrame(patient_predictions_csv, columns=['anno_index', 'coord_x', 'coord_y', 'coord_z', 'diameter', 'nodule_chance', 'diameter_mm'])\n        filter_patient_nodules_predictions(df, patient_id, (CROP_SIZE * magnification))\n        df.to_csv(csv_target_path, index=False)\n        print(predict_volume.mean())\n        print('Done in : ', sw.get_elapsed_seconds(), ' seconds')\n"}
{"label_name":"process","label":2,"method_name":"preprocess","method":"\n\ndef preprocess(self, im, allobj=None):\n    '\\n    Takes an image, return it as a numpy tensor that is readily\\n    to be fed into tfnet. If there is an accompanied annotation (allobj),\\n    meaning this preprocessing is serving the train process, then this\\n    image will be transformed with random noise to augment training data,\\n    using scale, translation, flipping and recolor. The accompanied\\n    parsed annotation (allobj) will also be modified accordingly.\\n    '\n    if (type(im) is not np.ndarray):\n        im = cv2.imread(im)\n    if (allobj is not None):\n        result = imcv2_affine_trans(im)\n        (im, dims, trans_param) = result\n        (scale, offs, flip) = trans_param\n        for obj in allobj:\n            _fix(obj, dims, scale, offs)\n            if (not flip):\n                continue\n            obj_1_ = obj[1]\n            obj[1] = (dims[0] - obj[3])\n            obj[3] = (dims[0] - obj_1_)\n        im = imcv2_recolor(im)\n    im = self.resize_input(im)\n    if (allobj is None):\n        return im\n    return im\n"}
{"label_name":"train","label":0,"method_name":"validate_crp_constrained_input","method":"\n\ndef validate_crp_constrained_input(N, Cd, Ci, Rd, Ri):\n    validate_dependency_constraints(N, Cd, Ci)\n    for c in Rd:\n        col_dep = Rd[c]\n        row_dep = Ri.get(c, {})\n        validate_dependency_constraints(None, col_dep, row_dep)\n    for block in Cd:\n        for (a, b) in it.combinations(block, 2):\n            if (not check_compatible_customers(Cd, Ci, Ri, Rd, a, b)):\n                raise ValueError('Incompatible row constraints for dep cols.')\n    return True\n"}
{"label_name":"train","label":0,"method_name":"_get_train_op","method":"\n\ndef _get_train_op(loss_op, learning_rate, global_step):\n    return tf.train.AdamOptimizer(learning_rate).minimize(loss_op, global_step=global_step)\n"}
{"label_name":"train","label":0,"method_name":"add_training_operators","method":"\n\ndef add_training_operators(softmax, m, device_opts=DEVICE_OPTS, lr=LR, momentum=MOMENTUM):\n    with core.DeviceScope(device_opts):\n        xent = m.LabelCrossEntropy([softmax, 'label'], 'xent')\n        loss = m.AveragedLoss(xent, 'loss')\n        m.AddGradientOperators([loss])\n        opt = optimizer.build_sgd(m, base_learning_rate=lr, policy='fixed', momentum=momentum)\n"}
{"label_name":"forward","label":3,"method_name":"forward","method":"\n\ndef forward(model: Model[(InT, OutT)], X: InT, is_train: bool) -> Tuple[(OutT, Callable)]:\n    Y = model.ops.softmax(X, inplace=False)\n\n    def backprop(dY: OutT) -> InT:\n        return model.ops.backprop_softmax(Y, dY, axis=(- 1))\n    return (Y, backprop)\n"}
{"label_name":"save","label":1,"method_name":"save_run","method":"\n\ndef save_run(config, environment=None, comment=None, extra_config=None, filename=DEFAULT_FILENAME):\n    if (environment == 'cloud'):\n        return\n    diff = get_diff()\n    lumi_version = get_luminoth_version()\n    tf_version = get_tensorflow_version()\n    experiment = {'environment': environment, 'datetime': (str(datetime.datetime.utcnow()) + 'Z'), 'diff': diff, 'luminoth_version': lumi_version, 'tensorflow_version': tf_version, 'config': config, 'extra_config': extra_config}\n    path = get_luminoth_home()\n    file_path = os.path.join(path, filename)\n    tf.gfile.MakeDirs(path)\n    with tf.gfile.Open(file_path, 'a') as log:\n        log.write((json.dumps(experiment) + '\\n'))\n"}
{"label_name":"process","label":2,"method_name":"preprocess_for_eval","method":"\n\ndef preprocess_for_eval(image, output_height, output_width, resize_side):\n    'Preprocesses the given image for evaluation.\\n\\n  Args:\\n    image: A `Tensor` representing an image of arbitrary size.\\n    output_height: The height of the image after preprocessing.\\n    output_width: The width of the image after preprocessing.\\n    resize_side: The smallest side of the image for aspect-preserving resizing.\\n\\n  Returns:\\n    A preprocessed image.\\n  '\n    image = _aspect_preserving_resize(image, resize_side)\n    image = _central_crop([image], output_height, output_width)[0]\n    image.set_shape([output_height, output_width, 3])\n    image = tf.to_float(image)\n    return _mean_image_subtraction(image, [_R_MEAN, _G_MEAN, _B_MEAN])\n"}
{"label_name":"save","label":1,"method_name":"_build_saved_state_dict","method":"\n\ndef _build_saved_state_dict(state_dict):\n    save_dict = {}\n    name_table = {}\n    for (key, value) in state_dict.items():\n        if isinstance(value, (Variable, core.VarBase)):\n            save_dict[key] = value.numpy()\n            name_table[key] = value.name\n        else:\n            save_dict[key] = value\n    save_dict['StructuredToParameterName@@'] = name_table\n    return save_dict\n"}
{"label_name":"train","label":0,"method_name":"default_helper_train_hparams","method":"\n\ndef default_helper_train_hparams():\n    'Returns default hyperparameters of an RNN decoder helper in the training\\n    phase.\\n\\n    See also :meth:`~texar.tf.modules.decoders.rnn_decoder_helpers.get_helper`\\n    for information of the hyperparameters.\\n\\n    Returns:\\n        dict: A dictionary with following structure and values:\\n\\n        .. code-block:: python\\n\\n            {\\n                # The `helper_type` argument for `get_helper`, i.e., the name\\n                # or full path to the helper class.\\n                \"type\": \"TrainingHelper\",\\n\\n                # The `**kwargs` argument for `get_helper`, i.e., additional\\n                # keyword arguments for constructing the helper.\\n                \"kwargs\": {}\\n            }\\n    '\n    return {'type': 'TrainingHelper', 'kwargs': {}}\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n\ndef train():\n    'Train the model.'\n    batch_size = (FLAGS.batch_size * FLAGS.num_gpus)\n    (model, beam_model, min_length, max_length, checkpoint_dir, (train_set, dev_set, en_vocab_path, fr_vocab_path), sv, sess) = initialize()\n    with sess.as_default():\n        quant_op = model.quantize_op\n        max_cur_length = min((min_length + 3), max_length)\n        prev_acc_perp = [1000000 for _ in xrange(5)]\n        prev_seq_err = 1.0\n        is_chief = (FLAGS.task < 1)\n        do_report = False\n        while (not sv.ShouldStop()):\n            (global_step, max_cur_length, learning_rate) = sess.run([model.global_step, model.cur_length, model.lr])\n            (acc_loss, acc_l1, acc_total, acc_errors, acc_seq_err) = (0.0, 0.0, 0, 0, 0)\n            (acc_grad_norm, step_count, step_c1, step_time) = (0.0, 0, 0, 0.0)\n            bound1 = (FLAGS.steps_per_checkpoint - 1)\n            if (FLAGS.word_vector_file_en and (global_step < bound1) and is_chief):\n                assign_vectors(FLAGS.word_vector_file_en, 'embedding:0', en_vocab_path, sess)\n                if (FLAGS.max_target_vocab < 1):\n                    assign_vectors(FLAGS.word_vector_file_en, 'target_embedding:0', en_vocab_path, sess)\n            if (FLAGS.word_vector_file_fr and (global_step < bound1) and is_chief):\n                assign_vectors(FLAGS.word_vector_file_fr, 'embedding:0', fr_vocab_path, sess)\n                if (FLAGS.max_target_vocab < 1):\n                    assign_vectors(FLAGS.word_vector_file_fr, 'target_embedding:0', fr_vocab_path, sess)\n            for _ in xrange(FLAGS.steps_per_checkpoint):\n                step_count += 1\n                step_c1 += 1\n                global_step = int(model.global_step.eval())\n                train_beam_anneal = (global_step \/ float(FLAGS.train_beam_anneal))\n                train_beam_freq = (FLAGS.train_beam_freq * min(1.0, train_beam_anneal))\n                p = random.choice(FLAGS.problem.split('-'))\n                train_set = global_train_set[p][(- 1)]\n                bucket_id = get_bucket_id(train_buckets_scale[p][(- 1)], max_cur_length, train_set)\n                if ((np.random.randint(100) < 60) and (FLAGS.problem != 'wmt')):\n                    bucket1 = get_bucket_id(train_buckets_scale[p][(- 1)], max_cur_length, train_set)\n                    bucket_id = max(bucket1, bucket_id)\n                start_time = time.time()\n                (inp, target) = data.get_batch(bucket_id, batch_size, train_set, FLAGS.height)\n                noise_param = (math.sqrt((math.pow((global_step + 1), (- 0.55)) * prev_seq_err)) * FLAGS.grad_noise_scale)\n                (state, new_target, scores, history) = (None, None, None, [])\n                while ((FLAGS.beam_size > 1) and (train_beam_freq > np.random.random_sample())):\n                    (new_target, new_first, new_inp, scores) = get_best_beam(beam_model, sess, inp, target, batch_size, FLAGS.beam_size, bucket_id, history, p)\n                    history.append(new_first)\n                    (_, _, _, state) = model.step(sess, inp, new_target, FLAGS.do_train, noise_param, update_mem=True, state=state)\n                    inp = new_inp\n                    if (FLAGS.nprint > 1):\n                        print(scores)\n                    if ((sum(scores) \/ float(len(scores))) >= 10.0):\n                        break\n                (loss, res, gnorm, _) = model.step(sess, inp, target, FLAGS.do_train, noise_param, update_mem=True, state=state)\n                step_time += (time.time() - start_time)\n                acc_grad_norm += (0.0 if (gnorm is None) else float(gnorm))\n                acc_loss += loss\n                acc_l1 += loss\n                (errors, total, seq_err) = data.accuracy(inp, res, target, batch_size, 0, new_target, scores)\n                if (FLAGS.nprint > 1):\n                    print('seq_err: ', seq_err)\n                acc_total += total\n                acc_errors += errors\n                acc_seq_err += seq_err\n                if ((step_count + 3) > FLAGS.steps_per_checkpoint):\n                    do_report = True\n                if (is_chief and ((step_count % 10) == 1) and do_report):\n                    cur_loss = (acc_l1 \/ float(step_c1))\n                    (acc_l1, step_c1) = (0.0, 0)\n                    cur_perp = data.safe_exp(cur_loss)\n                    summary = tf.Summary()\n                    summary.value.extend([tf.Summary.Value(tag='log_perplexity', simple_value=cur_loss), tf.Summary.Value(tag='perplexity', simple_value=cur_perp)])\n                    sv.SummaryComputed(sess, summary, global_step)\n            acc_loss \/= step_count\n            step_time \/= FLAGS.steps_per_checkpoint\n            acc_seq_err = (float(acc_seq_err) \/ (step_count * batch_size))\n            prev_seq_err = max(0.0, (acc_seq_err - 0.02))\n            acc_errors = ((float(acc_errors) \/ acc_total) if (acc_total > 0) else 1.0)\n            t_size = (float(sum([len(x) for x in train_set])) \/ float(1000000))\n            msg = ('step %d step-time %.2f train-size %.3f lr %.6f grad-norm %.4f' % ((global_step + 1), step_time, t_size, learning_rate, (acc_grad_norm \/ FLAGS.steps_per_checkpoint)))\n            data.print_out(('%s len %d ppl %.6f errors %.2f sequence-errors %.2f' % (msg, max_cur_length, data.safe_exp(acc_loss), (100 * acc_errors), (100 * acc_seq_err))))\n            is_good = (FLAGS.curriculum_ppx > data.safe_exp(acc_loss))\n            is_good = (is_good and (FLAGS.curriculum_seq > acc_seq_err))\n            if (is_good and is_chief):\n                if FLAGS.quantize:\n                    data.print_out('  Quantizing parameters.')\n                    sess.run([quant_op])\n                sess.run(model.cur_length_incr_op)\n                if (max_cur_length < max_length):\n                    prev_acc_perp.append(1000000)\n            acc_perp = data.safe_exp(acc_loss)\n            if ((acc_perp > max(prev_acc_perp[(- 5):])) and is_chief):\n                sess.run(model.lr_decay_op)\n            prev_acc_perp.append(acc_perp)\n            if is_chief:\n                checkpoint_path = os.path.join(checkpoint_dir, 'neural_gpu.ckpt')\n                model.saver.save(sess, checkpoint_path, global_step=model.global_step)\n                bin_bound = 4\n                for p in FLAGS.problem.split('-'):\n                    (total_loss, total_err, tl_counter) = (0.0, 0.0, 0)\n                    for bin_id in xrange(len(data.bins)):\n                        if ((bin_id < bin_bound) or ((bin_id % FLAGS.eval_bin_print) == 1)):\n                            (err, _, loss) = single_test(bin_id, model, sess, FLAGS.nprint, (batch_size * 4), dev_set, p, beam_model=beam_model)\n                            if (loss > 0.0):\n                                total_loss += loss\n                                total_err += err\n                                tl_counter += 1\n                    test_loss = (total_loss \/ max(1, tl_counter))\n                    test_err = (total_err \/ max(1, tl_counter))\n                    test_perp = data.safe_exp(test_loss)\n                    summary = tf.Summary()\n                    summary.value.extend([tf.Summary.Value(tag=('test\/%s\/loss' % p), simple_value=test_loss), tf.Summary.Value(tag=('test\/%s\/error' % p), simple_value=test_err), tf.Summary.Value(tag=('test\/%s\/perplexity' % p), simple_value=test_perp)])\n                    sv.SummaryComputed(sess, summary, global_step)\n"}
{"label_name":"train","label":0,"method_name":"do_quantize_training_on_graphdef","method":"\n\ndef do_quantize_training_on_graphdef(input_graph, num_bits):\n    from tensorflow.core.framework.graph_pb2 import GraphDef\n    from tensorflow.python.framework import errors\n    with errors.raise_exception_on_not_ok_status() as status:\n        graph = GraphDef()\n        result_graph_string = DoQuantizeTrainingOnGraphDefHelper(input_graph.SerializeToString(), num_bits, status)\n    graph.ParseFromString(result_graph_string)\n    return graph\n"}
