{"label_name":"forward","label":3,"method_name":"forward","method":"\nZ = (X.dot(W1) + b1)\nZ = (Z * (Z > 0))\nactivation = (Z.dot(W2) + b2)\nY = (1 \/ (1 + np.exp((- activation))))\nreturn (Y, Z)\n"}
{"label_name":"train","label":0,"method_name":"load_yt_train_all_recent","method":"\nname = (((('yt_train_all_recent_' + str(t)) + str(o)) + str(l)) + '.txt')\nwith open(os.path.join(dir, name)) as fp:\n    dataSet = []\n    for line in fp:\n        line = line.strip('\\n')\n        features = line.split(',')\n        features = [float(x) for x in features]\n        dataSet.append(features)\nyt_train_all_recent = np.array(dataSet)\nreturn yt_train_all_recent\n"}
{"label_name":"process","label":2,"method_name":"preprocess_categorical","method":"\nreturn categorical(x).reshape(((- 1), 256, 8192))\n"}
{"label_name":"train","label":0,"method_name":"load_train_data","method":"\nwith open(filename, 'rU') as file:\n    data = []\n    line = file.readline()\n    ignore_chars = {'T', '%', 'S', 'M', 'K', 'P', 'L', '\"', '\\n', ' ', '(', ')', 'm', '-', '\\\\', '!', 't', 'r', 'i', 'l', 'z', '[', '+', 'n', 'o', '#'}\n    notes = {'C', 'D', 'E', 'F', 'G', 'A', 'B', 'c', 'd', 'e', 'f', 'g', 'a', 'b'}\n    prev_string = ''\n    same_note = False\n    on_bar = False\n    song = []\n    while (line != ''):\n        line = file.readline()\n        if ((not line) or (line[0] in ignore_chars)):\n            continue\n        if (line[0] == 'X'):\n            data.append(song)\n            song = []\n            continue\n        for c in line:\n            if (c in ignore_chars):\n                continue\n            elif (c in notes):\n                same_note = True\n                length = len(prev_string)\n                if on_bar:\n                    on_bar = False\n                    song.append(prev_string)\n                    prev_string = c\n                elif (length != 0):\n                    first = prev_string[(length - 1)]\n                    if (first in notes):\n                        song.append(prev_string)\n                        prev_string = c\n                    elif (first == '\/'):\n                        prev_string = prev_string[1:]\n                else:\n                    prev_string += c\n            elif (c in {'_', '^', '='}):\n                if (not same_note):\n                    same_note = True\n                song.append(prev_string)\n                prev_string = c\n            elif c.isdigit():\n                if same_note:\n                    song.append((prev_string + c))\n                    prev_string = ''\n                    same_note = False\n            elif (c in {'|', ':'}):\n                if same_note:\n                    song.append(prev_string)\n                    prev_string = ''\n                if on_bar:\n                    song.append((prev_string + c))\n                    prev_string = ''\n                    on_bar = False\n                else:\n                    on_bar = True\n                    song.append(prev_string)\n                    prev_string = c\n                same_note = False\n            else:\n                prev_string += c\nreturn data\n"}
{"label_name":"predict","label":4,"method_name":"scale_predictions","method":"\n'\\n    normalize range of predictions to 0-1.\\n    '\nyrange = (ypred.max() - ypred.min())\nypred -= ypred.min()\nypred \/= yrange\nypred[(ypred > 1)] = 1\nypred[(ypred < 0)] = 0\nreturn ypred\n"}
{"label_name":"process","label":2,"method_name":"_fake_model_preprocessor_fn","method":"\nreturn (image, tf.expand_dims(tf.shape(image)[1:], axis=0))\n"}
{"label_name":"predict","label":4,"method_name":"_predict","method":"\nexample = [('study', 'to', 'learn', 'me', 'study', 'to', 'learn', 'me', 'machine', 'learning')]\npr = model.predict_proba(example)\npr = list(pr[0])\npr.sort(reverse=True)\nassert (pr[0] > 0.33)\np = model.predict(example)\nif ((pr[0] - pr[1]) > 0.01):\n    assert ((p == ['aa']) or (p == ['b']))\n"}
{"label_name":"train","label":0,"method_name":"pretrain","method":"\ngen_data_loader = Gen_Data_loader(BATCH_SIZE)\ngen_data_loader.create_batches(positive_samples)\nresults = OrderedDict({'exp_name': PREFIX})\nprint('Start pre-training...')\nstart = time.time()\nfor epoch in tqdm(range(PRE_EPOCH_NUM)):\n    print(' gen pre-train')\n    loss = pre_train_epoch(sess, generator, gen_data_loader)\n    if ((epoch == 10) or ((epoch % 40) == 0)):\n        samples = generate_samples(sess, generator, BATCH_SIZE, SAMPLE_NUM)\n        likelihood_data_loader.create_batches(samples)\n        test_loss = target_loss(sess, target_lstm, likelihood_data_loader)\n        print('\\t test_loss {}, train_loss {}'.format(test_loss, loss))\n        mm.compute_results(samples, train_samples, ord_dict, results)\nsamples = generate_samples(sess, generator, BATCH_SIZE, SAMPLE_NUM)\nlikelihood_data_loader.create_batches(samples)\ntest_loss = target_loss(sess, target_lstm, likelihood_data_loader)\nsamples = generate_samples(sess, generator, BATCH_SIZE, SAMPLE_NUM)\nlikelihood_data_loader.create_batches(samples)\nprint('Start training discriminator...')\nfor i in tqdm(range(dis_alter_epoch)):\n    print(' discriminator pre-train')\n    (d_loss, acc, ypred_for_auc) = train_discriminator()\nend = time.time()\nprint('Total time was {:.4f}s'.format((end - start)))\nreturn\n"}
{"label_name":"save","label":1,"method_name":"save_param_dict","method":"\n'Save parameter dictionary to binary bytes.\\n\\n    The result binary bytes can be loaded by the\\n    GraphModule with API \"load_params\".\\n\\n    Parameters\\n    ----------\\n    params : dict of str to NDArray\\n        The parameter dictionary.\\n\\n    Returns\\n    -------\\n    param_bytes: bytearray\\n        Serialized parameters.\\n\\n    Examples\\n    --------\\n    .. code-block:: python\\n\\n       # set up the parameter dict\\n       params = {\"param0\": arr0, \"param1\": arr1}\\n       # save the parameters as byte array\\n       param_bytes = tvm.runtime.save_param_dict(params)\\n       # We can serialize the param_bytes and load it back later.\\n       # Pass in byte array to module to directly set parameters\\n       tvm.runtime.load_param_dict(param_bytes)\\n    '\ntransformed = {k: ndarray.array(v) for (k, v) in params.items()}\nreturn _ffi_api.SaveParams(transformed)\n"}
{"label_name":"predict","label":4,"method_name":"predict","method":"\n'Prediction'\nkmeans = joblib.load('kmeans.pkl')\ncontrol = tfidf.transform(req)\npreds = kmeans.predict(control)\nprint(preds)\n"}
{"label_name":"save","label":1,"method_name":"save_model","method":"\nagent.brain.model.save(name)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n'\\n  This function contains the loop that actually trains the model.\\n  :param images: a numpy array with the input data\\n  :param labels: a numpy array with the output labels\\n  :param ckpt_path: a path (including name) where model checkpoints are saved\\n  :param dropout: Boolean, whether to use dropout or not\\n  :return: True if everything went well\\n  '\nassert (len(images) == len(labels))\nassert (images.dtype == np.float32)\nassert (labels.dtype == np.int32)\nwith tf.Graph().as_default():\n    global_step = tf.Variable(0, trainable=False)\n    train_data_node = _input_placeholder()\n    train_labels_shape = (FLAGS.batch_size,)\n    train_labels_node = tf.placeholder(tf.int32, shape=train_labels_shape)\n    print('Done Initializing Training Placeholders')\n    if FLAGS.deeper:\n        logits = inference_deeper(train_data_node, dropout=dropout)\n    else:\n        logits = inference(train_data_node, dropout=dropout)\n    loss = loss_fun(logits, train_labels_node)\n    train_op = train_op_fun(loss, global_step)\n    saver = tf.train.Saver(tf.all_variables())\n    print('Graph constructed and saver created')\n    init = tf.global_variables_initializer()\n    sess = tf.Session(config=tf.ConfigProto(log_device_placement=FLAGS.log_device_placement))\n    sess.run(init)\n    print('Session ready, beginning training loop')\n    data_length = len(images)\n    nb_batches = math.ceil((data_length \/ FLAGS.batch_size))\n    for step in xrange(FLAGS.max_steps):\n        start_time = time.time()\n        batch_nb = (step % nb_batches)\n        (start, end) = utils.batch_indices(batch_nb, data_length, FLAGS.batch_size)\n        feed_dict = {train_data_node: images[start:end], train_labels_node: labels[start:end]}\n        (_, loss_value) = sess.run([train_op, loss], feed_dict=feed_dict)\n        duration = (time.time() - start_time)\n        assert (not np.isnan(loss_value)), 'Model diverged with loss = NaN'\n        if ((step % 100) == 0):\n            num_examples_per_step = FLAGS.batch_size\n            examples_per_sec = (num_examples_per_step \/ duration)\n            sec_per_batch = float(duration)\n            format_str = '%s: step %d, loss = %.2f (%.1f examples\/sec; %.3f sec\/batch)'\n            print((format_str % (datetime.now(), step, loss_value, examples_per_sec, sec_per_batch)))\n        if (((step % 1000) == 0) or ((step + 1) == FLAGS.max_steps)):\n            saver.save(sess, ckpt_path, global_step=step)\nreturn True\n"}
{"label_name":"save","label":1,"method_name":"_save_to","method":"\npath = os.path.join(dest_dir, name)\nwith open(path, 'w') as file_:\n    file_.write(data)\n    info(('Data saved: %s' % path))\n"}
{"label_name":"process","label":2,"method_name":"_preprocess_image","method":"\nreturn ((tf.to_float(image) \/ 255) - 0.5)\n"}
{"label_name":"train","label":0,"method_name":"_read_pretrained_embeddings_file","method":"\nu'\\n    Returns and embedding matrix for the given vocabulary using the pretrained embeddings\\n    contained in the given file. Embeddings for tokens not found in the pretrained embedding file\\n    are randomly initialized using a normal distribution with mean and standard deviation equal to\\n    those of the pretrained embeddings.\\n\\n    We support two file formats:\\n\\n        * text format - utf-8 encoded text file with space separated fields: [word] [dim 1] [dim 2] ...\\n          The text file can eventually be compressed, and even resides in an archive with multiple files.\\n          If the file resides in an archive with other files, then ``embeddings_filename`` must\\n          be a URI \"(archive_uri)#file_path_inside_the_archive\"\\n\\n        * hdf5 format - hdf5 file containing an embedding matrix in the form of a torch.Tensor.\\n\\n    If the filename ends with \\'.hdf5\\' or \\'.h5\\' then we load from hdf5, otherwise we assume\\n    text format.\\n\\n    Parameters\\n    ----------\\n    file_uri : str, required.\\n        It can be:\\n\\n        * a file system path or a URL of an eventually compressed text file or a zip\/tar archive\\n          containing a single file.\\n\\n        * URI of the type ``(archive_path_or_url)#file_path_inside_archive`` if the text file\\n          is contained in a multi-file archive.\\n\\n    vocab : Vocabulary, required.\\n        A Vocabulary object.\\n    namespace : str, (optional, default=tokens)\\n        The namespace of the vocabulary to find pretrained embeddings for.\\n    trainable : bool, (optional, default=True)\\n        Whether or not the embedding parameters should be optimized.\\n\\n    Returns\\n    -------\\n    A weight matrix with embeddings initialized from the read file.  The matrix has shape\\n    ``(vocab.get_vocab_size(namespace), embedding_dim)``, where the indices of words appearing in\\n    the pretrained embedding file are initialized to the pretrained embedding value.\\n    '\nfile_ext = get_file_extension(file_uri)\nif (file_ext in [u'.h5', u'.hdf5']):\n    return _read_embeddings_from_hdf5(file_uri, embedding_dim, vocab, namespace)\nreturn _read_embeddings_from_text_file(file_uri, embedding_dim, vocab, namespace)\n"}
{"label_name":"train","label":0,"method_name":"lms_train","method":"\n\ndef error(p, y, args):\n    l = len(p)\n    f = p[(l - 1)]\n    for i in range(len(args)):\n        f += (p[i] * args[i])\n    return (f - y)\nPara = leastsq(error, p0, args=(Zi, Data))\nreturn Para[0]\n"}
{"label_name":"train","label":0,"method_name":"run_train","method":"\nif (args.numpy_seed is not None):\n    print('Setting numpy random seed to {}...'.format(args.numpy_seed))\n    np.random.seed(args.numpy_seed)\nseed_from_numpy = np.random.randint(2147483648)\nprint('Manual seed for pytorch:', seed_from_numpy)\ntorch.manual_seed(seed_from_numpy)\nhparams.set_from_args(args)\nprint('Hyperparameters:')\nhparams.print()\nprint('Loading training trees from {}...'.format(args.train_path))\ntrain_treebank = treebanks.load_trees(args.train_path, args.train_path_text, args.text_processing)\nif (hparams.max_len_train > 0):\n    train_treebank = train_treebank.filter_by_length(hparams.max_len_train)\nprint('Loaded {:,} training examples.'.format(len(train_treebank)))\nprint('Loading development trees from {}...'.format(args.dev_path))\ndev_treebank = treebanks.load_trees(args.dev_path, args.dev_path_text, args.text_processing)\nif (hparams.max_len_dev > 0):\n    dev_treebank = dev_treebank.filter_by_length(hparams.max_len_dev)\nprint('Loaded {:,} development examples.'.format(len(dev_treebank)))\nprint('Constructing vocabularies...')\nlabel_vocab = decode_chart.ChartDecoder.build_vocab(train_treebank.trees)\nif hparams.use_chars_lstm:\n    char_vocab = char_lstm.RetokenizerForCharLSTM.build_vocab(train_treebank.sents)\nelse:\n    char_vocab = None\ntag_vocab = set()\nfor tree in train_treebank.trees:\n    for (_, tag) in tree.pos():\n        tag_vocab.add(tag)\ntag_vocab = (['UNK'] + sorted(tag_vocab))\ntag_vocab = {label: i for (i, label) in enumerate(tag_vocab)}\nif (hparams.force_root_constituent.lower() in ('true', 'yes', '1')):\n    hparams.force_root_constituent = True\nelif (hparams.force_root_constituent.lower() in ('false', 'no', '0')):\n    hparams.force_root_constituent = False\nelif (hparams.force_root_constituent.lower() == 'auto'):\n    hparams.force_root_constituent = decode_chart.ChartDecoder.infer_force_root_constituent(train_treebank.trees)\n    print('Set hparams.force_root_constituent to', hparams.force_root_constituent)\nprint('Initializing model...')\nparser = parse_chart.ChartParser(tag_vocab=tag_vocab, label_vocab=label_vocab, char_vocab=char_vocab, hparams=hparams)\nif args.parallelize:\n    parser.parallelize()\nelif torch.cuda.is_available():\n    parser.cuda()\nelse:\n    print('Not using CUDA!')\nprint('Initializing optimizer...')\ntrainable_parameters = [param for param in parser.parameters() if param.requires_grad]\noptimizer = torch.optim.Adam(trainable_parameters, lr=hparams.learning_rate, betas=(0.9, 0.98), eps=1e-09)\nscheduler = learning_rates.WarmupThenReduceLROnPlateau(optimizer, hparams.learning_rate_warmup_steps, mode='max', factor=hparams.step_decay_factor, patience=(hparams.step_decay_patience * hparams.checks_per_epoch), verbose=True)\nclippable_parameters = trainable_parameters\ngrad_clip_threshold = (np.inf if (hparams.clip_grad_norm == 0) else hparams.clip_grad_norm)\nprint('Training...')\ntotal_processed = 0\ncurrent_processed = 0\ncheck_every = (len(train_treebank) \/ hparams.checks_per_epoch)\nbest_dev_fscore = (- np.inf)\nbest_dev_model_path = None\nbest_dev_processed = 0\nstart_time = time.time()\n\ndef check_dev():\n    nonlocal best_dev_fscore\n    nonlocal best_dev_model_path\n    nonlocal best_dev_processed\n    dev_start_time = time.time()\n    dev_predicted = parser.parse(dev_treebank.without_gold_annotations(), subbatch_max_tokens=args.subbatch_max_tokens)\n    dev_fscore = evaluate.evalb(args.evalb_dir, dev_treebank.trees, dev_predicted)\n    print('dev-fscore {} dev-elapsed {} total-elapsed {}'.format(dev_fscore, format_elapsed(dev_start_time), format_elapsed(start_time)))\n    if (dev_fscore.fscore > best_dev_fscore):\n        if (best_dev_model_path is not None):\n            extensions = ['.pt']\n            for ext in extensions:\n                path = (best_dev_model_path + ext)\n                if os.path.exists(path):\n                    print('Removing previous model file {}...'.format(path))\n                    os.remove(path)\n        best_dev_fscore = dev_fscore.fscore\n        best_dev_model_path = '{}_dev={:.2f}'.format(args.model_path_base, dev_fscore.fscore)\n        best_dev_processed = total_processed\n        print('Saving new best model to {}...'.format(best_dev_model_path))\n        torch.save({'config': parser.config, 'state_dict': parser.state_dict(), 'optimizer': optimizer.state_dict()}, (best_dev_model_path + '.pt'))\ndata_loader = torch.utils.data.DataLoader(train_treebank, batch_size=hparams.batch_size, shuffle=True, collate_fn=functools.partial(parser.encode_and_collate_subbatches, subbatch_max_tokens=args.subbatch_max_tokens))\nfor epoch in itertools.count(start=1):\n    epoch_start_time = time.time()\n    for (batch_num, batch) in enumerate(data_loader, start=1):\n        optimizer.zero_grad()\n        parser.train()\n        batch_loss_value = 0.0\n        for (subbatch_size, subbatch) in batch:\n            loss = parser.compute_loss(subbatch)\n            loss_value = float(loss.data.cpu().numpy())\n            batch_loss_value += loss_value\n            if (loss_value > 0):\n                loss.backward()\n            del loss\n            total_processed += subbatch_size\n            current_processed += subbatch_size\n        grad_norm = torch.nn.utils.clip_grad_norm_(clippable_parameters, grad_clip_threshold)\n        optimizer.step()\n        print('epoch {:,} batch {:,}\/{:,} processed {:,} batch-loss {:.4f} grad-norm {:.4f} epoch-elapsed {} total-elapsed {}'.format(epoch, batch_num, int(np.ceil((len(train_treebank) \/ hparams.batch_size))), total_processed, batch_loss_value, grad_norm, format_elapsed(epoch_start_time), format_elapsed(start_time)))\n        if (current_processed >= check_every):\n            current_processed -= check_every\n            check_dev()\n            scheduler.step(metrics=best_dev_fscore)\n        else:\n            scheduler.step()\n    if ((total_processed - best_dev_processed) > (((hparams.step_decay_patience + 1) * hparams.max_consecutive_decays) * len(train_treebank))):\n        print('Terminating due to lack of improvement in dev fscore.')\n        break\n"}
{"label_name":"train","label":0,"method_name":"training_set_multiplication","method":"\n'\\n    Multiply the training set by all methods listed in mult_queue.\\n\\n    Parameters\\n    ----------\\n    training_set :\\n        set of all recordings that will be used for training\\n    mult_queue :\\n        list of all algorithms that will take one recording and generate more\\n        than one.\\n\\n    Returns\\n    -------\\n    mutliple recordings\\n    '\nlogger.info('Multiply data...')\nfor algorithm in mult_queue:\n    new_trning_set = []\n    for recording in training_set:\n        samples = algorithm(recording['handwriting'])\n        for sample in samples:\n            new_trning_set.append({'id': recording['id'], 'is_in_testset': 0, 'formula_id': recording['formula_id'], 'handwriting': sample, 'formula_in_latex': recording['formula_in_latex']})\n    training_set = new_trning_set\nreturn new_trning_set\n"}
{"label_name":"save","label":1,"method_name":"save_results","method":"\nif (results_rows is not None):\n    df = pd.DataFrame(results_rows)\n    df.to_csv('{}_results.csv'.format(folder), index=False)\nmodel_saver = tf.train.Saver()\nckpt_dir = os.path.join(params['CHK_PATH'], folder)\nif (not os.path.exists(ckpt_dir)):\n    os.makedirs(ckpt_dir)\nckpt_file = os.path.join(ckpt_dir, '{}.ckpt'.format(name))\npath = model_saver.save(sess, ckpt_file)\nprint('Model saved at {}'.format(path))\nreturn\n"}
{"label_name":"forward","label":3,"method_name":"avg_pool1D_forward_naive","method":"\n(N, C, L) = x.shape\nif (global_pool == 1):\n    ksize = [L]\nif adaptive:\n    L_out = ksize[0]\nelse:\n    L_out = (((((((L - ksize[0]) + (2 * paddings[0])) + strides[0]) - 1) \/\/ strides[0]) + 1) if ceil_mode else ((((L - ksize[0]) + (2 * paddings[0])) \/\/ strides[0]) + 1))\nout = np.zeros((N, C, L_out))\nfor i in range(L_out):\n    if adaptive:\n        r_start = adaptive_start_index(i, L, ksize[0])\n        r_end = adaptive_end_index(i, L, ksize[0])\n    else:\n        r_start = np.max((((i * strides[0]) - paddings[0]), 0))\n        r_end = np.min(((((i * strides[0]) + ksize[0]) - paddings[0]), L))\n    x_masked = x[:, :, r_start:r_end]\n    field_size = ((r_end - r_start) if (exclusive or adaptive) else ksize[0])\n    if ((data_type == np.int8) or (data_type == np.uint8)):\n        out[:, :, i] = np.rint((np.sum(x_masked, axis=(2, 3)) \/ field_size)).astype(data_type)\n    else:\n        out[:, :, i] = (np.sum(x_masked, axis=2) \/ field_size).astype(data_type)\nreturn out\n"}
{"label_name":"train","label":0,"method_name":"train_input_fn","method":"\nbatch_size = params['batch_size']\ndata_dir = params['data_dir']\nds = dataset.train(data_dir).cache().repeat().shuffle(buffer_size=50000).apply(tf.contrib.data.batch_and_drop_remainder(batch_size))\n(images, labels) = ds.make_one_shot_iterator().get_next()\nreturn (images, labels)\n"}
{"label_name":"process","label":2,"method_name":"_process_image_files","method":"\n'Process and save list of images as TFRecord of Example protos.\\n\\n  Args:\\n    name: string, unique identifier specifying the data set\\n    filenames: list of strings; each string is a path to an image file\\n    synsets: list of strings; each string is a unique WordNet ID\\n    labels: list of integer; each integer identifies the ground truth\\n    humans: list of strings; each string is a human-readable label\\n    bboxes: list of bounding boxes for each image. Note that each entry in this\\n      list might contain from 0+ entries corresponding to the number of bounding\\n      box annotations for the image.\\n    num_shards: integer number of shards for this data set.\\n  '\nassert (len(filenames) == len(synsets))\nassert (len(filenames) == len(labels))\nassert (len(filenames) == len(humans))\nassert (len(filenames) == len(bboxes))\nspacing = np.linspace(0, len(filenames), (FLAGS.num_threads + 1)).astype(np.int)\nranges = []\nthreads = []\nfor i in xrange((len(spacing) - 1)):\n    ranges.append([spacing[i], spacing[(i + 1)]])\nprint(('Launching %d threads for spacings: %s' % (FLAGS.num_threads, ranges)))\nsys.stdout.flush()\ncoord = tf.train.Coordinator()\ncoder = ImageCoder()\nthreads = []\nfor thread_index in xrange(len(ranges)):\n    args = (coder, thread_index, ranges, name, filenames, synsets, labels, humans, bboxes, num_shards)\n    t = threading.Thread(target=_process_image_files_batch, args=args)\n    t.start()\n    threads.append(t)\ncoord.join(threads)\nprint(('%s: Finished writing all %d images in data set.' % (datetime.now(), len(filenames))))\nsys.stdout.flush()\n"}
{"label_name":"process","label":2,"method_name":"multiprocess","method":"\n'concurrent way -- multiprocess, much faster'\nfiles = glob.glob('temp\/train-part*')\nremove(os.path.join(DATA_DIR, FM_TRAIN))\nwith futures.ProcessPoolExecutor() as executor:\n    for f in files:\n        executor.submit(convert_from_local, f, FM_TRAIN)\n"}
{"label_name":"predict","label":4,"method_name":"action_predictions_list","method":"\n'\\n    shows a table with the list of predictions \\n    '\npredictions_path = pathlib.Path(utils.predictions_repository_path())\nif (predictions_path.is_dir() is False):\n    return (False, 'the predictions repository path does not exist. Please run \"flame -c config\".')\ndirs = [x for x in predictions_path.iterdir() if x.is_dir()]\nresult = []\niresult = []\nfor d in dirs:\n    label = d.parts[(- 1)]\n    with open(d.joinpath('prediction-meta.pkl'), 'rb') as handle:\n        endpoint = pickle.load(handle)\n        version = pickle.load(handle)\n        ifile = pickle.load(handle)\n        time = pickle.load(handle)\n        timestamp = pickle.load(handle)\n        try:\n            modelID = pickle.load(handle)\n        except:\n            modelID = '*legacy*'\n    ifile = os.path.basename(ifile)\n    if (label[0:8] == 'ensemble'):\n        continue\n    iresult.append((label, endpoint, version, time, ifile, modelID))\n    line = f'{label:10} {endpoint:15}   {version}   {time}   {ifile} {modelID}'\n    result.append((timestamp, line))\nresult.sort(reverse=True, key=getdate)\n[print(i[1]) for i in result]\nreturn (True, iresult)\n"}
{"label_name":"save","label":1,"method_name":"buildsaveplot","method":"\nlabel = ['', '', '', '', '', '6 am', '', '', '', '', '', '12 noon', '', '', '', '', '', '6 Pm', '', '', '', '', '', 'Midnight']\nindex = np.arange(len(label))\nplt.bar(index, list_to_graph)\nplt.xticks(index, label, fontsize=10, rotation=30)\nplt.title(title)\nplt.plot()\nplt.ylim([0, 100.0])\nax = plt.gca()\nax.yaxis.set_major_formatter(FormatStrFormatter('%.0f%%'))\nplt.savefig((('output\/' + title.replace(' ', '')) + '.png'), bbox_inches='tight')\nplt.close()\n"}
{"label_name":"process","label":2,"method_name":"process_results","method":"\nbaseline = results.best_baseline()\n\ndef like_baseline(x):\n    for key in ('n_iter', 'batch_size', 'l2', 'learning_rate', 'loss', 'embedding_dim'):\n        if (x[key] != baseline[key]):\n            return False\n    return True\ndata = pd.DataFrame([x for x in results if like_baseline(x)])\nbest = data.sort_values('test_mrr', ascending=False).groupby('compression_ratio', as_index=False).first()\nbest['elapsed'] = (best['elapsed'] \/ best['n_iter'])\nif verbose:\n    print(best)\nbaseline_mrr = best[(best['compression_ratio'] == 1.0)]['validation_mrr'].values[0]\nbaseline_time = best[(best['compression_ratio'] == 1.0)]['elapsed'].values[0]\ncompression_ratio = best['compression_ratio'].values\nmrr = (best['validation_mrr'].values \/ baseline_mrr)\nelapsed = (best['elapsed'].values \/ baseline_time)\nreturn (compression_ratio[:(- 1)], mrr[:(- 1)], elapsed[:(- 1)])\n"}
{"label_name":"process","label":2,"method_name":"spark_py_processor","method":"\nspark_py_processor = PySparkProcessor(role='SageMakerRole', instance_count=2, instance_type=cpu_instance_type, sagemaker_session=sagemaker_session, framework_version='2.4')\nreturn spark_py_processor\n"}
{"label_name":"train","label":0,"method_name":"train_boosted_trees","method":"\n'Train boosted_trees estimator on HIGGS data.\\n\\n  Args:\\n    flags_obj: An object containing parsed flag values.\\n  '\nif tf.gfile.Exists(flags_obj.model_dir):\n    tf.gfile.DeleteRecursively(flags_obj.model_dir)\ntf.logging.info('## Data loading...')\n(train_data, eval_data) = read_higgs_data(flags_obj.data_dir, flags_obj.train_start, flags_obj.train_count, flags_obj.eval_start, flags_obj.eval_count)\ntf.logging.info('## Data loaded; train: {}{}, eval: {}{}'.format(train_data.dtype, train_data.shape, eval_data.dtype, eval_data.shape))\n(train_input_fn, feature_names, feature_columns) = make_inputs_from_np_arrays(features_np=train_data[:, 1:], label_np=train_data[:, 0:1])\neval_input_fn = make_eval_inputs_from_np_arrays(features_np=eval_data[:, 1:], label_np=eval_data[:, 0:1])\ntf.logging.info('## Features prepared. Training starts...')\nrun_params = {'train_start': flags_obj.train_start, 'train_count': flags_obj.train_count, 'eval_start': flags_obj.eval_start, 'eval_count': flags_obj.eval_count, 'n_trees': flags_obj.n_trees, 'max_depth': flags_obj.max_depth}\nbenchmark_logger = logger.config_benchmark_logger(flags_obj)\nbenchmark_logger.log_run_info(model_name='boosted_trees', dataset_name='higgs', run_params=run_params)\nclassifier = tf.contrib.estimator.boosted_trees_classifier_train_in_memory(train_input_fn, feature_columns, model_dir=(flags_obj.model_dir or None), n_trees=flags_obj.n_trees, max_depth=flags_obj.max_depth, learning_rate=flags_obj.learning_rate)\neval_results = classifier.evaluate(eval_input_fn)\nbenchmark_logger.log_evaluation_result(eval_results)\nif (flags_obj.export_dir is not None):\n    classifier.export_savedmodel(flags_obj.export_dir, _make_csv_serving_input_receiver_fn(column_names=feature_names, column_defaults=([[0.0]] * len(feature_names))))\n"}
{"label_name":"process","label":2,"method_name":"process_file","method":"\nweb_path = os.path.sep.join(dir_path.split(os.path.sep)[dir_path.split(os.path.sep).index(download_path.split(os.path.sep)[(- 1)]):])\ntry:\n    reader = get_reader(os.path.join(dir_path, file))\n    if reader.is_english_lang():\n        logger.info(('processing %s' % file))\n        save_sentences(('%s\/%s' % (web_path, file)), reader.split())\n    else:\n        logger.info('ignoring non english file')\nexcept Exception as error:\n    logger.info(error)\n"}
{"label_name":"save","label":1,"method_name":"saveBatchResultByField","method":"\nd = {res['label']: getattr(res['history'], field_name) for res in results}\ndf = pd.DataFrame(d)\nfn = (('b_' + field_name) + '.csv')\nfile_name = os.path.join(exp_name, fn)\ndf.to_csv(file_name)\n"}
{"label_name":"predict","label":4,"method_name":"predict","method":"\ndistances = np.zeros((test_data.shape[0], len(classes)))\nfor (i, clazz) in enumerate(np.array(classes)[:, 0]):\n    distances[:, i] = (np.sum(((np.tile(clazz, (test_data.shape[0], 1)) - test_data) ** 2), axis=1) ** 0.5)\nreturn distances.argmin(axis=1)\n"}
{"label_name":"save","label":1,"method_name":"saveCifarImage","method":"\narray = array.asnumpy().transpose(1, 2, 0)\narray = cv2.cvtColor(array, cv2.COLOR_RGB2BGR)\nreturn cv2.imwrite(((path + file) + '.png'), array)\n"}
{"label_name":"train","label":0,"method_name":"list_pretrained_xlmr","method":"\nreturn sorted(list(PRETRAINED_URL.keys()))\n"}
{"label_name":"train","label":0,"method_name":"train_detector","method":"\nTrainingDataUtil.extract_training_data()\nt = Trainer(TrainingDataUtil.training_data_dir, cpu_cores, window_size)\nt.train_object_detector()\n"}
{"label_name":"save","label":1,"method_name":"save_plot","method":"\nplot.save(safe_path(os.path.join(output_dir, guesser_name, name)), width=width, height=height)\n"}
{"label_name":"train","label":0,"method_name":"load_trainingDigits","method":"\nfilename = pkg_resources.resource_filename(__name__, ('data\/trainingDigits\/%s' % file_name_str))\nreturn filename\n"}
{"label_name":"predict","label":4,"method_name":"get_predictions","method":"\nassert (prediction_type in ['predict', 'predict_proba'])\nreturn perform_prediction((prediction_type == 'predict_proba'), pandas_orient)\n"}
{"label_name":"train","label":0,"method_name":"validate_dependency_constraints","method":"\n'Validates Cd and Ci constraints on N columns.'\nif (N is None):\n    N = 10000000000.0\ncounts = {}\nfor block in Cd:\n    if (len(block) == 1):\n        raise ValueError('Single customer in dependency constraint.')\n    for col in block:\n        if (N <= col):\n            raise ValueError('Dependence customer out of range.')\n        if (col not in counts):\n            counts[col] = 0\n        counts[col] += 1\n        if (counts[col] > 1):\n            raise ValueError('Multiple customer dependencies.')\n    for pair in Ci:\n        if ((pair[0] in block) and (pair[1] in block)):\n            raise ValueError('Contradictory customer independence.')\nfor pair in Ci:\n    if (len(pair) != 2):\n        raise ValueError('Independencies require two customers.')\n    if ((N <= pair[0]) or (N <= pair[1])):\n        raise ValueError('Independence customer of out range.')\n    if (pair[0] == pair[1]):\n        raise ValueError('Independency specified for same customer.')\nreturn True\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n'Train the model!'\nprint(('Preparing data in %s' % data_dir))\ntrain_dataset_path = '.\/train_data.txt'\neval_dataset_path = '.\/eval_dataset.txt'\nwith tf.Session() as sess:\n    print(('Creating %d layers of %d units.' % (num_layers, size)))\n    model = create_model(sess, False)\n    print(('Reading development and training data (limit: %d).' % max_train_data_size))\n    test_set = read_data(eval_dataset_path)\n    training_set = read_data(train_dataset_path, max_train_data_size)\n    train_bucket_sizes = [len(training_set[b]) for b in xrange(len(buckets))]\n    train_total_size = float(sum(train_bucket_sizes))\n    train_buckets_scale = [(sum(train_bucket_sizes[:(i + 1)]) \/ train_total_size) for i in xrange(len(train_bucket_sizes))]\n    (step_time, loss) = (0.0, 0.0)\n    current_step = 0\n    previous_losses = []\n    while True:\n        random_number_01 = np.random.random_sample()\n        bucket_id = min([i for i in xrange(len(train_buckets_scale)) if (train_buckets_scale[i] > random_number_01)])\n        start_time = time.time()\n        (encoder_inputs, decoder_inputs, target_weights) = model.get_batch(training_set, bucket_id)\n        (_, step_loss, _) = model.step(sess, encoder_inputs, decoder_inputs, target_weights, bucket_id, False)\n        step_time += ((time.time() - start_time) \/ steps_per_checkpoint)\n        loss += (step_loss \/ steps_per_checkpoint)\n        current_step += 1\n        if ((current_step % steps_per_checkpoint) == 0):\n            perplexity = (math.exp(float(loss)) if (loss < 300) else float('inf'))\n            print(('global step %d learning rate %.4f step-time %.2f perplexity %.2f' % (model.global_step.eval(), model.learning_rate.eval(), step_time, perplexity)))\n            if ((len(previous_losses) > 2) and (loss > max(previous_losses[(- 3):]))):\n                sess.run(model.learning_rate_decay_op)\n            previous_losses.append(loss)\n            checkpoint_path = os.path.join(train_dir, 'chars.ckpt')\n            model.saver.save(sess, checkpoint_path, global_step=model.global_step)\n            (step_time, loss) = (0.0, 0.0)\n            for bucket_id in xrange(len(buckets)):\n                if (len(test_set[bucket_id]) == 0):\n                    print(('  eval: empty bucket %d' % bucket_id))\n                    continue\n                (encoder_inputs, decoder_inputs, target_weights) = model.get_batch(test_set, bucket_id)\n                (_, eval_loss, _) = model.step(sess, encoder_inputs, decoder_inputs, target_weights, bucket_id, True)\n                eval_ppx = (math.exp(float(eval_loss)) if (eval_loss < 300) else float('inf'))\n                print(('  eval: bucket %d perplexity %.2f' % (bucket_id, eval_ppx)))\n            sys.stdout.flush()\n"}
{"label_name":"train","label":0,"method_name":"pre_train_epoch","method":"\nsupervised_g_losses = []\ndata_loader.reset_pointer()\nfor it in range(data_loader.num_batch):\n    batch = data_loader.next_batch()\n    (_, g_loss, g_pred) = trainable_model.pretrain_step(sess, batch)\n    supervised_g_losses.append(g_loss)\nreturn np.mean(supervised_g_losses)\n"}
{"label_name":"save","label":1,"method_name":"save_bytes","method":"\n'Save bytes to the file.'\nif (hasattr(f, 'write') and callable(cast(IO[bytes], f).write)):\n    cast(IO[bytes], f).write(str)\nelse:\n    with open(cast(Text, f), 'wb') as writable:\n        writable.write(str)\n"}
{"label_name":"process","label":2,"method_name":"process_arch_projected_map","method":"\nds = int(arch_vars.var3[2])\nargs.navtask.task_params.input_type = 'analytical_counts'\nargs.navtask.task_params.outputs.analytical_counts = True\nassert (args.navtask.task_params.modalities[0] == 'depth')\nargs.navtask.camera_param.img_channels = None\nanalytical_counts = utils.Foo(map_sizes=[(512 \/ ds)], xy_resolution=[(5.0 * ds)], z_bins=[[(- 10), 10, 150, 200]], non_linearity=[arch_vars.var2])\nargs.navtask.task_params.analytical_counts = analytical_counts\nsc = (1.0 \/ ds)\nargs.arch.vin_num_iters = 36\nargs.navtask.task_params.map_scales = [sc]\nargs.navtask.task_params.map_crop_sizes = [(512 \/ ds)]\nargs.arch.fr_stride = [1, 2]\nargs.arch.vin_action_neurons = 8\nargs.arch.vin_val_neurons = 3\nargs.arch.fr_inside_neurons = 32\nmap_channels = (len(analytical_counts.z_bins[0]) + 1)\nargs.navtask.task_params.map_channels = map_channels\nargs.solver.freeze_conv = False\nreturn args\n"}
{"label_name":"train","label":0,"method_name":"load_pretrained_embedding","method":"\n'load pre-trained embeddings from embedding file'\nif tf.gfile.Exists(embedding_file):\n    with codecs.getreader('utf-8')(tf.gfile.GFile(embedding_file, 'rb')) as file:\n        embedding = {}\n        for line in file:\n            items = line.strip().split(' ')\n            if (len(items) != (embedding_size + 1)):\n                continue\n            word = items[0]\n            vector = [float(x) for x in items[1:]]\n            if (word not in embedding):\n                embedding[word] = vector\n        if (unk not in embedding):\n            embedding[unk] = np.random.rand(embedding_size)\n        if (sos not in embedding):\n            embedding[sos] = np.random.rand(embedding_size)\n        if (eos not in embedding):\n            embedding[eos] = np.random.rand(embedding_size)\n        if (pad not in embedding):\n            embedding[pad] = np.random.rand(embedding_size)\n        return embedding\nelse:\n    raise FileNotFoundError('embedding file not found')\n"}
{"label_name":"process","label":2,"method_name":"_process_image_files_batch","method":"\n'Processes and saves list of images as TFRecord in 1 thread.\\n\\n  Args:\\n    coder: instance of ImageCoder to provide TensorFlow image coding utils.\\n    thread_index: integer, unique batch to run index is within [0, len(ranges)).\\n    ranges: list of pairs of integers specifying ranges of each batches to\\n      analyze in parallel.\\n    name: string, unique identifier specifying the data set\\n    filenames: list of strings; each string is a path to an image file\\n    synsets: list of strings; each string is a unique WordNet ID\\n    labels: list of integer; each integer identifies the ground truth\\n    humans: list of strings; each string is a human-readable label\\n    bboxes: list of bounding boxes for each image. Note that each entry in this\\n      list might contain from 0+ entries corresponding to the number of bounding\\n      box annotations for the image.\\n    num_shards: integer number of shards for this data set.\\n  '\nnum_threads = len(ranges)\nassert (not (num_shards % num_threads))\nnum_shards_per_batch = int((num_shards \/ num_threads))\nshard_ranges = np.linspace(ranges[thread_index][0], ranges[thread_index][1], (num_shards_per_batch + 1)).astype(int)\nnum_files_in_thread = (ranges[thread_index][1] - ranges[thread_index][0])\ncounter = 0\nfor s in range(num_shards_per_batch):\n    shard = ((thread_index * num_shards_per_batch) + s)\n    output_filename = ('%s-%.5d-of-%.5d' % (name, shard, num_shards))\n    output_file = os.path.join(FLAGS.output_directory, output_filename)\n    writer = tf.python_io.TFRecordWriter(output_file)\n    shard_counter = 0\n    files_in_shard = np.arange(shard_ranges[s], shard_ranges[(s + 1)], dtype=int)\n    for i in files_in_shard:\n        filename = filenames[i]\n        label = labels[i]\n        synset = synsets[i]\n        human = humans[i]\n        bbox = bboxes[i]\n        (image_buffer, height, width) = _process_image(filename, coder)\n        example = _convert_to_example(filename, image_buffer, label, synset, human, bbox, height, width)\n        writer.write(example.SerializeToString())\n        shard_counter += 1\n        counter += 1\n        if (not (counter % 1000)):\n            print(('%s [thread %d]: Processed %d of %d images in thread batch.' % (datetime.now(), thread_index, counter, num_files_in_thread)))\n            sys.stdout.flush()\n    writer.close()\n    print(('%s [thread %d]: Wrote %d images to %s' % (datetime.now(), thread_index, shard_counter, output_file)))\n    sys.stdout.flush()\n    shard_counter = 0\nprint(('%s [thread %d]: Wrote %d images to %d shards.' % (datetime.now(), thread_index, counter, num_files_in_thread)))\nsys.stdout.flush()\n"}
{"label_name":"train","label":0,"method_name":"_check_tmc_elbo_constraint","method":"\nnum_samples = frozenset((site['infer'].get('num_samples') for site in guide_trace.nodes.values() if ((site['type'] == 'sample') and (site['infer'].get('enumerate') == 'parallel') and (site['infer'].get('num_samples') is not None))))\nif (len(num_samples) > 1):\n    warnings.warn('\\n'.join(['Using different numbers of Monte Carlo samples for different guide sites in TraceEnum_ELBO.', 'This may be biased if the guide is not factorized']), UserWarning)\nfor (name, site) in model_trace.nodes.items():\n    if ((site['type'] == 'sample') and (site['infer'].get('enumerate', None) == 'parallel') and site['infer'].get('num_samples', None) and (name not in guide_trace)):\n        warnings.warn('\\n'.join(['Site {} is multiply sampled in model,'.format(site['name']), 'expect incorrect gradient estimates from TraceEnum_ELBO.', 'Consider using exact enumeration or guide sampling if possible.']), RuntimeWarning)\n"}
{"label_name":"train","label":0,"method_name":"on_start_training","method":"\n\" The :func:`on_start_training` decorator is used to initialise a :class:`.Callback` with :meth:`~.Callback.on_start_training`\\n    calling the decorated function\\n\\n    Example: ::\\n\\n        >>> from torchbearer import Trial\\n        >>> from torchbearer.callbacks import on_start_training\\n\\n        # Example callback running at start of the training pass\\n        >>> @on_start_training\\n        ... def print_callback(state):\\n        ...     print('Starting training.')\\n\\n        >>> trial = Trial(None, callbacks=[print_callback]).for_steps(1).run()\\n        Starting training.\\n\\n    Args:\\n        func (function): The function(state) to *decorate*\\n\\n    Returns:\\n        Callback: Initialised callback with :meth:`~.Callback.on_start_training` calling func\\n    \"\nreturn bind_to(Callback.on_start_training)(func)\n"}
{"label_name":"train","label":0,"method_name":"train_step","method":"\nloss = 0\nhidden = decoder.reset_state(batch_size=target.shape[0])\ndec_input = tf.expand_dims(([tokenizer.word_index['<start>']] * target.shape[0]), 1)\nwith tf.GradientTape() as tape:\n    features = encoder(img_tensor)\n    for i in range(1, target.shape[1]):\n        (predictions, hidden, _) = decoder(dec_input, features, hidden)\n        loss += loss_function(target[:, i], predictions)\n        dec_input = tf.expand_dims(target[:, i], 1)\ntotal_loss = (loss \/ int(target.shape[1]))\ntrainable_variables = (encoder.trainable_variables + decoder.trainable_variables)\ngradients = tape.gradient(loss, trainable_variables)\noptimizer.apply_gradients(zip(gradients, trainable_variables))\nreturn (loss, total_loss)\n"}
{"label_name":"process","label":2,"method_name":"image_preprocessing","method":"\n'Decode and preprocess one image for evaluation or training.\\n\\n  Args:\\n    image_buffer: JPEG encoded string Tensor\\n    bbox: 3-D float Tensor of bounding boxes arranged [1, num_boxes, coords]\\n      where each coordinate is [0, 1) and the coordinates are arranged as\\n      [ymin, xmin, ymax, xmax].\\n    train: boolean\\n    thread_id: integer indicating preprocessing thread\\n\\n  Returns:\\n    3-D float Tensor containing an appropriately scaled image\\n\\n  Raises:\\n    ValueError: if user does not provide bounding box\\n  '\nif (bbox is None):\n    raise ValueError('Please supply a bounding box.')\nimage = decode_jpeg(image_buffer)\nheight = FLAGS.image_size\nwidth = FLAGS.image_size\nif train:\n    image = distort_image(image, height, width, bbox, thread_id)\nelse:\n    image = eval_image(image, height, width)\nimage = tf.subtract(image, 0.5)\nimage = tf.multiply(image, 2.0)\nreturn image\n"}
{"label_name":"process","label":2,"method_name":"_process_scalar_value","method":"\n'Update results_dictionary with a scalar value.\\n\\n  Used to update the results_dictionary to be returned by parse_values when\\n  encountering a clause with a scalar RHS (e.g.  \"s=5\" or \"arr[0]=5\".)\\n\\n  Mutates results_dictionary.\\n\\n  Args:\\n    name: Name of variable in assignment (\"s\" or \"arr\").\\n    parse_fn: Function for parsing the actual value.\\n    var_type: Type of named variable.\\n    m_dict: Dictionary constructed from regex parsing.\\n      m_dict[\\'val\\']: RHS value (scalar)\\n      m_dict[\\'index\\']: List index value (or None)\\n    values: Full expression being parsed\\n    results_dictionary: The dictionary being updated for return by the parsing\\n      function.\\n\\n  Raises:\\n    ValueError: If the name has already been used.\\n  '\ntry:\n    parsed_value = parse_fn(m_dict['val'])\nexcept ValueError:\n    _parse_fail(name, var_type, m_dict['val'], values)\nif (not m_dict['index']):\n    if (name in results_dictionary):\n        _reuse_fail(name, values)\n    results_dictionary[name] = parsed_value\nelse:\n    if (name in results_dictionary):\n        if (not isinstance(results_dictionary.get(name), dict)):\n            _reuse_fail(name, values)\n    else:\n        results_dictionary[name] = {}\n    index = int(m_dict['index'])\n    if (index in results_dictionary[name]):\n        _reuse_fail('{}[{}]'.format(name, index), values)\n    results_dictionary[name][index] = parsed_value\n"}
{"label_name":"save","label":1,"method_name":"save","method":"\n'Save a Python object into a Pickle file at the given path.'\nwith open(path, 'wb') as f:\n    pickle.dump(obj, f)\n"}
{"label_name":"train","label":0,"method_name":"train_model","method":"\ntrain = list(read_corpus(train))\nmodel = Doc2Vec(size=30, window=10, min_count=1, workers=11, alpha=0.025, min_alpha=0.025)\nmodel.build_vocab(train)\nmodel.train(train, total_examples=model.corpus_count, epochs=model.iter)\nreturn model\n"}
{"label_name":"train","label":0,"method_name":"train_mnist","method":"\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(('cuda' if use_cuda else 'cpu'))\n(train_loader, test_loader) = get_data_loaders()\nmodel = ConvNet().to(device)\noptimizer = optim.SGD(model.parameters(), lr=config['lr'], momentum=config['momentum'])\nwhile True:\n    train(model, optimizer, train_loader, device)\n    acc = test(model, test_loader, device)\n    tune.report(mean_accuracy=acc)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\ndevice = (device or torch.device('cpu'))\nmodel.train()\nfor (batch_idx, (data, target)) in enumerate(train_loader):\n    (data, target) = (data.to(device), target.to(device))\n    optimizer.zero_grad()\n    output = model(data)\n    loss = F.nll_loss(output, target)\n    loss.backward()\n    optimizer.step()\n"}
{"label_name":"process","label":2,"method_name":"process","method":"\ndicdir = os.popen('mecab-config --dicdir').readlines()[0][:(- 1)]\nif os.path.isdir(os.path.join(dicdir, 'mecab-ipadic-neologd')):\n    dicdir += '\/mecab-ipadic-neologd'\nelse:\n    dicdir += '\/ipadic'\ntokenizer = MeCabTokenizer(dicdir)\ntext = cleaning(text)\ntext = normalization(text)\nwords = tokenizer.wakati_baseform(text)\nwords = [w.lower() for w in words]\nreturn words\n"}
{"label_name":"process","label":2,"method_name":"process_string_tensor_event","method":"\n'Convert a TensorEvent into a JSON-compatible response.'\nstring_arr = tf.make_ndarray(event.tensor_proto)\nhtml = text_array_to_html(string_arr)\nreturn {'wall_time': event.wall_time, 'step': event.step, 'text': html}\n"}
{"label_name":"train","label":0,"method_name":"_trainer","method":"\nreturn tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step=step)\n"}
{"label_name":"train","label":0,"method_name":"train_xgboost","method":"\nimport train_xgboost as xgboost\nteam_data = get_team_representations(opt.team_data_type)\nxgboost.train(team_data, opt)\n"}
{"label_name":"predict","label":4,"method_name":"_gmm_discretizing_predict","method":"\nmeans = self.means_.ravel()\nids = self._estimate_weighted_log_prob(X).argmax(axis=1)\nreturn np.expand_dims(np.argsort(means)[ids], axis=1)\n"}
{"label_name":"train","label":0,"method_name":"train_step","method":"\nwith tf.GradientTape() as tape:\n    y_pred = model(x)\n    loss = mse_loss(y_pred, y)\nwith summary_writer.as_default():\n    tf.summary.scalar('loss', loss, step=optimizer.iterations)\ngradients = tape.gradient(loss, model.trainable_variables)\noptimizer.apply_gradients(zip(gradients, model.trainable_variables))\n"}
{"label_name":"predict","label":4,"method_name":"_problem_for_predictor_multi_regression","method":"\n'\\n    Returns *X, y, intial_types, method, name, X runtime* for a\\n    mregression problem.\\n    It is based on Iris dataset.\\n    '\ndata = load_iris()\nX = data.data\nstate = numpy.random.RandomState(seed=34)\nrnd = (state.randn(*X.shape) \/ 3)\nX += rnd\nX = _modify_dimension(X, n_features)\ny = (data.target.astype(float) + (numpy.arange(len(data.target)) \/ 100))\nmeth = ('predict' if (kwargs is None) else ('predict', kwargs))\nitt = [('X', X[:1].astype(dtype))]\nif (n_features is not None):\n    X = X[:, :n_features]\n    itt = [('X', X[:1].astype(dtype))]\nif (nbrows is not None):\n    X = X[:nbrows, :]\n    y = y[:nbrows]\n    itt = [('X', X[:1].astype(dtype))]\nif (options is not None):\n    itt = (itt, options)\ny2 = numpy.empty((y.shape[0], 2))\ny2[:, 0] = y\ny2[:, 1] = (y + 0.5)\nX = X.astype(dtype)\ny2 = y2.astype(dtype)\nreturn (X, y2, itt, meth, ('all' if many_output else 0), X.astype(dtype))\n"}
{"label_name":"save","label":1,"method_name":"save_and_evaluate_checkpoints","method":"\nif args.do_train:\n    if (not os.path.exists(args.output_dir)):\n        os.makedirs(args.output_dir)\n    logger.info('Saving model checkpoint to %s', args.output_dir)\n    model_to_save = (model.module if hasattr(model, 'module') else model)\n    model_to_save.save_pretrained(args.output_dir)\n    tokenizer.save_pretrained(args.output_dir)\n    torch.save(args, os.path.join(args.output_dir, 'training_args.bin'))\n    model = AutoModelForSequenceClassification.from_pretrained(args.output_dir)\n    tokenizer = AutoTokenizer.from_pretrained(args.output_dir)\n    model.to(args.device)\nresults = {}\nif args.do_eval:\n    tokenizer = AutoTokenizer.from_pretrained(args.output_dir)\n    checkpoints = [args.output_dir]\n    if args.eval_all_checkpoints:\n        checkpoints = list((os.path.dirname(c) for c in sorted(glob.glob(((args.output_dir + '\/**\/') + WEIGHTS_NAME), recursive=True))))\n        logging.getLogger('transformers.modeling_utils').setLevel(logging.WARN)\n    logger.info('Evaluate the following checkpoints: %s', checkpoints)\n    for checkpoint in checkpoints:\n        global_step = (checkpoint.split('-')[(- 1)] if (len(checkpoints) > 1) else '')\n        prefix = (checkpoint.split('\/')[(- 1)] if (checkpoint.find('checkpoint') != (- 1)) else '')\n        model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n        model.to(args.device)\n        result = evaluate(args, model, tokenizer, prefix=prefix)\n        result = dict((((k + f'_{global_step}'), v) for (k, v) in result.items()))\n        results.update(result)\nreturn results\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\ntrain_loader = train_corpus.batch_generator()\ntotal_loss = 0\ntotal_word_count = 0\nstart_time = time.time()\nhidden = net.init_hidden((args.batch_size * args.scale))\nfor (batch, item) in enumerate(train_loader):\n    net.train()\n    (data, targets, word_cnt, batch_len) = get_batch(item)\n    hidden = repackage_hidden(hidden)\n    optimizer.zero_grad()\n    emb = encoder(data)\n    (output, hidden) = net(emb, hidden)\n    (logits, new_targets) = ss(output, targets)\n    loss = criterion(logits.view((- 1), (nsampled + 1)), new_targets)\n    loss.backward()\n    torch.nn.utils.clip_grad_norm_(net.rnn.parameters(), args.clip)\n    torch.nn.utils.clip_grad_norm_(encoder.parameters(), args.clip)\n    torch.nn.utils.clip_grad_norm_(ss.parameters(), args.clip)\n    if args.proj:\n        torch.nn.utils.clip_grad_norm_(net.proj.parameters(), args.clip)\n    optimizer.step()\n    scheduler.step()\n    total_loss += (word_cnt * loss.data)\n    total_word_count += word_cnt\n    interval = max(10, (1000 \/\/ args.scale))\n    if ((batch % interval) == 0):\n        elapsed = (time.time() - start_time)\n        print('Epoch: {:3d} | {:5d}\/{:5d} batches | lr {:.6f} | ms\/batch {:5.2f} | loss {:5.2f} | ppl {:8.2f}'.format(epoch, batch, batch_len, scheduler.lr, ((elapsed * 1000) \/ interval), loss.item(), math.exp(loss.item())))\n        start_time = time.time()\n        sys.stdout.flush()\n"}
{"label_name":"save","label":1,"method_name":"save_images","method":"\nmerged = merge(inverse_transform(images), size)\nreturn scipy.misc.imsave(image_path, merged)\n"}
{"label_name":"process","label":2,"method_name":"preprocess_input","method":"\n'Preprocesses a tensor encoding a batch of images.\\n\\n    # Arguments\\n        x: input Numpy tensor, 4D.\\n        data_format: data format of the image tensor.\\n\\n    # Returns\\n        Preprocessed tensor.\\n    '\nif (data_format is None):\n    data_format = K.image_data_format()\nassert (data_format in {'channels_last', 'channels_first'})\nif (data_format == 'channels_first'):\n    if (x.ndim == 3):\n        x = x[::(- 1), ...]\n        x[0, :, :] -= 103.939\n        x[1, :, :] -= 116.779\n        x[2, :, :] -= 123.68\n    else:\n        x = x[:, ::(- 1), ...]\n        x[:, 0, :, :] -= 103.939\n        x[:, 1, :, :] -= 116.779\n        x[:, 2, :, :] -= 123.68\nelse:\n    x = x[..., ::(- 1)]\n    x[(..., 0)] -= 103.939\n    x[(..., 1)] -= 116.779\n    x[(..., 2)] -= 123.68\nreturn x\n"}
{"label_name":"process","label":2,"method_name":"preprocess_data","method":"\n(X, Y) = zip(*dataset)\nX = np.array([string_to_int(i, Tx, human_vocab) for i in X])\nY = [string_to_int(t, Ty, machine_vocab) for t in Y]\nXoh = np.array(list(map((lambda x: to_categorical(x, num_classes=len(human_vocab))), X)))\nYoh = np.array(list(map((lambda x: to_categorical(x, num_classes=len(machine_vocab))), Y)))\nreturn (X, np.array(Y), Xoh, Yoh)\n"}
{"label_name":"save","label":1,"method_name":"save_image","method":"\n'\\n    Saves unscaled Tensor Images.\\n    Args:\\n      image: 3D image tensor. [height, width, channels]\\n      filename: Name of the file to save to.\\n  '\nif (not isinstance(image, Image.Image)):\n    image = tf.clip_by_value(image, 0, 255)\n    image = Image.fromarray(tf.cast(image, tf.uint8).numpy())\nimage.save(('%s.jpg' % filename))\nprint(('Saved as %s.jpg' % filename))\n"}
{"label_name":"process","label":2,"method_name":"pre_post_process_layer","method":"\n'\\n    Add residual connection, layer normalization and droput to the out tensor\\n    optionally according to the value of process_cmd.\\n    This will be used before or after multi-head attention and position-wise\\n    feed-forward networks.\\n    '\nfor cmd in process_cmd:\n    if (cmd == 'a'):\n        out = ((out + prev_out) if prev_out else out)\n    elif (cmd == 'n'):\n        out = layers.layer_norm(out, begin_norm_axis=(len(out.shape) - 1), param_attr=fluid.initializer.Constant(1.0), bias_attr=fluid.initializer.Constant(0.0))\n    elif (cmd == 'd'):\n        if dropout_rate:\n            out = layers.dropout(out, dropout_prob=dropout_rate, seed=ModelHyperParams.dropout_seed, is_test=False)\nreturn out\n"}
{"label_name":"process","label":2,"method_name":"async_process","method":"\n' This create and asynchronized result using multi-Processing\\n  Also check: `odin.utils.mpi.async` for multi-Threading\\n  decorator\\n\\n  Parameters\\n  ----------\\n  func: call-able\\n      main workload executed in this function and return the\\n      results.\\n\\n  callback: call-able\\n      a callback function triggered when the task finished\\n\\n  Example\\n  -------\\n  >>> from odin.utils import async\\n  ...\\n  >>> def test_fn(idx):\\n  ...   path = \\'\/tmp\/tmp%d.txt\\' % idx\\n  ...   with open(path, \\'w\\') as f:\\n  ...     for i in range(100000):\\n  ...       f.write(str(i))\\n  ...     print(\"FINISH!\", path)\\n  ...\\n  >>> f = async(test_fn)\\n  >>> x1 = f(1)\\n  >>> x2 = f(2)\\n  >>> x3 = f(3)\\n  ...\\n  >>> count = 0\\n  >>> while not x1.finished or not x2.finished or not x3.finished:\\n  ...   count += 1\\n  ...   print(\"Iteration:\", count)\\n  ...   print(x1)\\n  ...   print(x2)\\n  ...   print(x3)\\n\\n  '\n\n@decorator\ndef _decorator_func_(func, *args, **kwargs):\n    kwargs['_is_threading'] = False\n    task = _async_task(func, *args, **kwargs)\n    return task\nif (inspect.isfunction(func) or inspect.ismethod(func)):\n    return _decorator_func_(func)\nreturn _decorator_func_\n"}
{"label_name":"train","label":0,"method_name":"_retrieve_kuzushiji_mnist_training","method":"\nbase_url = 'http:\/\/codh.rois.ac.jp\/'\nurls = [(base_url + 'kmnist\/dataset\/kmnist\/train-images-idx3-ubyte.gz'), (base_url + 'kmnist\/dataset\/kmnist\/train-labels-idx1-ubyte.gz')]\nreturn _retrieve_kuzushiji_mnist('train.npz', urls)\n"}
{"label_name":"process","label":2,"method_name":"deprocess","method":"\nx = ((x - x.mean()) \/ (x.std() + 1e-05))\nx *= 0.1\nx += 0.5\nx = np.clip(x, 0, 1)\nx *= 255\nx = np.clip(x, 0, 255).astype('uint8')\nreturn x\n"}
{"label_name":"save","label":1,"method_name":"save_png","method":"\npngfile = open(filename, 'wb')\npngWriter = Writer(array.shape[1], array.shape[0], greyscale=True)\npngWriter.write(pngfile, array)\npngfile.close()\n"}
{"label_name":"train","label":0,"method_name":"create_train_model","method":"\ngraph = tf.Graph()\nwith graph.as_default():\n    logger.log_print('# prepare train data')\n    (input_data, word_embed_data, word_vocab_size, word_vocab_index, word_vocab_inverted_index, char_vocab_size, char_vocab_index, char_vocab_inverted_index) = prepare_data(logger, hyperparams.data_train_file, hyperparams.data_word_vocab_file, hyperparams.data_word_vocab_size, hyperparams.data_word_vocab_threshold, hyperparams.model_word_embed_dim, hyperparams.data_embedding_file, hyperparams.data_full_embedding_file, hyperparams.data_word_unk, hyperparams.data_word_pad, hyperparams.data_word_sos, hyperparams.data_word_eos, hyperparams.model_word_feat_enable, hyperparams.model_word_embed_pretrained, hyperparams.data_char_vocab_file, hyperparams.data_char_vocab_size, hyperparams.data_char_vocab_threshold, hyperparams.data_char_unk, hyperparams.data_char_pad, hyperparams.model_char_feat_enable, hyperparams.data_large_file_train)\n    data_size = (len(input_data) if (input_data is not None) else None)\n    external_data = {}\n    if (word_embed_data is not None):\n        external_data['word_embedding'] = word_embed_data\n    if (hyperparams.data_pipeline_mode == 'dynamic'):\n        logger.log_print('# create train text dataset')\n        text_placeholder = tf.placeholder(shape=[None], dtype=tf.string)\n        text_dataset = tf.data.Dataset.from_tensor_slices(text_placeholder)\n        (input_text_word_dataset, input_text_char_dataset) = create_text_dataset(text_dataset, word_vocab_index, hyperparams.data_max_word_size, hyperparams.data_word_pad, hyperparams.data_word_sos, hyperparams.data_word_eos, hyperparams.model_word_feat_enable, char_vocab_index, hyperparams.data_max_char_size, hyperparams.data_char_pad, hyperparams.model_char_feat_enable, hyperparams.data_num_parallel)\n        logger.log_print('# create train data pipeline')\n        data_size_placeholder = tf.placeholder(shape=[], dtype=tf.int64)\n        batch_size_placeholder = tf.placeholder(shape=[], dtype=tf.int64)\n        data_pipeline = create_dynamic_pipeline(input_text_word_dataset, input_text_char_dataset, word_vocab_size, word_vocab_index, word_vocab_inverted_index, hyperparams.data_word_pad, hyperparams.model_word_feat_enable, char_vocab_size, char_vocab_index, hyperparams.data_char_pad, hyperparams.model_char_feat_enable, hyperparams.train_random_seed, hyperparams.train_enable_shuffle, hyperparams.train_shuffle_buffer_size, text_placeholder, data_size_placeholder, batch_size_placeholder)\n    else:\n        logger.log_print('# create train text dataset')\n        text_dataset = get_text_dataset(hyperparams.data_train_file)\n        (input_text_word_dataset, input_text_char_dataset) = create_text_dataset(text_dataset, word_vocab_index, hyperparams.data_max_word_size, hyperparams.data_word_pad, hyperparams.data_word_sos, hyperparams.data_word_eos, hyperparams.model_word_feat_enable, char_vocab_index, hyperparams.data_max_char_size, hyperparams.data_char_pad, hyperparams.model_char_feat_enable, hyperparams.data_num_parallel)\n        logger.log_print('# create train data pipeline')\n        data_pipeline = create_data_pipeline(input_text_word_dataset, input_text_char_dataset, word_vocab_size, word_vocab_index, word_vocab_inverted_index, hyperparams.data_word_pad, hyperparams.model_word_feat_enable, char_vocab_size, char_vocab_index, hyperparams.data_char_pad, hyperparams.model_char_feat_enable, hyperparams.train_random_seed, hyperparams.train_enable_shuffle, hyperparams.train_shuffle_buffer_size, data_size, hyperparams.train_batch_size)\n    model_creator = get_model_creator(hyperparams.model_type)\n    model = model_creator(logger=logger, hyperparams=hyperparams, data_pipeline=data_pipeline, mode='train', external_data=external_data, scope=hyperparams.model_scope)\n    return TrainModel(graph=graph, model=model, data_pipeline=data_pipeline, input_data=input_data, word_embedding=word_embed_data)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\nwith open('gendistx.txt', 'r') as f:\n    lines = f.readlines()\nx1 = [x.strip() for x in lines]\nx1 = np.array([x1]).astype(float)\nf.close()\nwith open('gendisty.txt', 'r') as f:\n    lines = f.readlines()\ny1 = [x.strip() for x in lines]\ny1 = np.array([y1]).astype(float)\nf.close()\nwith open('fakedistx.txt', 'r') as f:\n    lines = f.readlines()\nx2 = [x.strip() for x in lines]\nx2 = np.array([x2]).astype(float)\nf.close()\nwith open('fakedisty.txt', 'r') as f:\n    lines = f.readlines()\ny2 = [x.strip() for x in lines]\ny2 = np.array([y2]).astype(float)\nf.close()\nx1 = np.divide(x1, np.max(x1))\nx2 = np.divide(x2, np.max(x2))\ny1 = np.divide(y1, np.max(y1))\ny2 = np.divide(y2, np.max(y2))\nX1 = np.hstack((x1, x2))\nX2 = np.hstack((y1, y2))\nX = np.vstack((X1, X2)).T\nprint(X)\nlength = X.shape[0]\ny = np.zeros((length, 1))\nno_of_dim = X.shape[1]\nfor i in range(length):\n    if (i < 2000):\n        y[i] = 1\n    else:\n        y[i] = 0\ntheta = np.zeros(((no_of_dim + 1), 1))\ntheta = grad_descent(X, y, length)\nprint(theta)\nreturn theta\n"}
{"label_name":"train","label":0,"method_name":"_train_val_split_indices","method":"\nsplit = StratifiedShuffleSplit(labels, n_iter=1, test_size=VAL_SIZE, random_state=42)\n(indices_tr, indices_val) = next(iter(split))\n_save_organized_data_info(split.classes, indices_tr, indices_val, multi_crop=False)\n_save_organized_data_info(split.classes, indices_tr, indices_val, multi_crop=True)\nreturn (indices_tr, indices_val, split.classes)\n"}
{"label_name":"train","label":0,"method_name":"trainingNaiveBayes","method":"\nnumTrainDoc = len(train_mood_array)\nnumWords = len(train_mood_array[0])\n(prior_Pos, prior_Neg, prior_Neutral) = (0.0, 0.0, 0.0)\nfor i in label:\n    if (i == 1):\n        prior_Pos = (prior_Pos + 1)\n    elif (i == 2):\n        prior_Neg = (prior_Neg + 1)\n    else:\n        prior_Neutral = (prior_Neutral + 1)\nprior_Pos = (prior_Pos \/ float(numTrainDoc))\nprior_Neg = (prior_Neg \/ float(numTrainDoc))\nprior_Neutral = (prior_Neutral \/ float(numTrainDoc))\nwordsInPosNum = np.ones(numWords)\nwordsInNegNum = np.ones(numWords)\nwordsInNeutralNum = np.ones(numWords)\nPosWordsNum = 2.0\nNegWordsNum = 2.0\nNeutralWordsNum = 2.0\nfor i in range(0, numTrainDoc):\n    try:\n        if (label[i] == 1):\n            wordsInPosNum += train_mood_array[i]\n            PosWordsNum += sum(train_mood_array[i])\n        elif (label[i] == 2):\n            wordsInNegNum += train_mood_array[i]\n            NegWordsNum += sum(train_mood_array[i])\n        else:\n            wordsInNeutralNum += train_mood_array[i]\n            NeutralWordsNum += sum(train_mood_array[i])\n    except Exception as e:\n        traceback.print_exc(e)\npWordsPosicity = np.log((wordsInPosNum \/ PosWordsNum))\npWordsNegy = np.log((wordsInNegNum \/ NegWordsNum))\npWordsNeutral = np.log((wordsInNeutralNum \/ NeutralWordsNum))\nreturn (pWordsPosicity, pWordsNegy, pWordsNeutral, prior_Pos, prior_Neg, prior_Neutral)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\ncnn_optimizer.zero_grad()\nloss = 0\ncnn_output = cnn(input_variable)\nloss = criterion(cnn_output, target_variable)\nloss.backward()\ncnn_optimizer.step()\nreturn loss.data[0]\n"}
{"label_name":"train","label":0,"method_name":"train_linear_start","method":"\ntrain_config = general_config.train_config\nfor i in range(general_config.nhops):\n    memory[i].mod_query.modules.pop()\nnepochs2 = general_config.nepochs\nlrate_decay_step2 = general_config.lrate_decay_step\ninit_lrate2 = train_config['init_lrate']\ngeneral_config.nepochs = general_config.ls_nepochs\ngeneral_config.lrate_decay_step = general_config.ls_lrate_decay_step\ntrain_config['init_lrate'] = general_config.ls_init_lrate\ntrain(train_story, train_questions, train_qstory, memory, model, loss, general_config)\nfor i in range(general_config.nhops):\n    memory[i].mod_query.add(Softmax())\ngeneral_config.nepochs = nepochs2\ngeneral_config.lrate_decay_step = lrate_decay_step2\ntrain_config['init_lrate'] = init_lrate2\ntrain(train_story, train_questions, train_qstory, memory, model, loss, general_config)\n"}
{"label_name":"train","label":0,"method_name":"mxnet_training_job","method":"\nwith timeout(minutes=TRAINING_DEFAULT_TIMEOUT_MINUTES):\n    s3_prefix = 'integ-test-data\/mxnet_mnist'\n    data_path = os.path.join(DATA_DIR, 'mxnet_mnist')\n    s3_source = sagemaker_session.upload_data(path=os.path.join(data_path, 'sourcedir.tar.gz'), key_prefix='{}\/src'.format(s3_prefix))\n    mx = MXNet(entry_point='mxnet_mnist\/mnist.py', source_dir=s3_source, role='SageMakerRole', framework_version=mxnet_training_latest_version, py_version=mxnet_training_latest_py_version, instance_count=1, instance_type=cpu_instance_type, sagemaker_session=sagemaker_session)\n    train_input = mx.sagemaker_session.upload_data(path=os.path.join(data_path, 'train'), key_prefix='{}\/train'.format(s3_prefix))\n    test_input = mx.sagemaker_session.upload_data(path=os.path.join(data_path, 'test'), key_prefix='{}\/test'.format(s3_prefix))\n    mx.fit({'train': train_input, 'test': test_input})\n    return mx.latest_training_job.name\n"}
{"label_name":"process","label":2,"method_name":"process_tweets","method":"\nwhile work:\n    tweet = queue.get()['text'].replace('\\n', ' ')\n    extracted_emojis = emoji_regexp.findall(tweet)\n    for extracted_emoji in extracted_emojis:\n        tweet = tweet.replace(extracted_emoji, emoji.unicode_codes.UNICODE_EMOJI[extracted_emoji])\n    store.write('{}\\n'.format(tweet))\n    store.flush()\n"}
{"label_name":"train","label":0,"method_name":"create_train_parser","method":"\nparser = subparsers.add_parser('train', help='train skipgram model to learn embeddings')\nparser.add_argument('inputs', nargs='+')\nparser.add_argument('-o', '--output-dir', required=True)\nparser.add_argument('--vocab-size', type=int, required=True)\nparser.add_argument('--emb-size', type=int, default=100)\nparser.add_argument('--batch-size', type=int, default=1024)\nparser.add_argument('--l2-value', type=float, default=0.0)\nparser.add_argument('--num-sampled', type=int, default=10)\nparser.add_argument('--optimizer', default='adam')\nparser.add_argument('--epochs', type=int, default=5)\nparser.add_argument('--learning-rate', type=float, default=0.001)\nparser.add_argument('--threads-count', type=int, default=multiprocessing.cpu_count())\nparser.add_argument('--no-clipping', action='store_true', default=False)\nparser.add_argument('--checkpoint', default=None)\nreturn parser\n"}
{"label_name":"save","label":1,"method_name":"save_images","method":"\nif isinstance(X.flatten()[0], np.floating):\n    X = (255.99 * X).astype('uint8')\nn_samples = X.shape[0]\nrows = int(np.sqrt(n_samples))\nwhile ((n_samples % rows) != 0):\n    rows -= 1\n(nh, nw) = (rows, (n_samples \/ rows))\nif (X.ndim == 2):\n    X = np.reshape(X, (X.shape[0], int(np.sqrt(X.shape[1])), int(np.sqrt(X.shape[1]))))\nif (X.ndim == 4):\n    X = X.transpose(0, 2, 3, 1)\n    (h, w) = X[0].shape[:2]\n    img = np.zeros(((h * nh), (w * nw), 3))\nelif (X.ndim == 3):\n    (h, w) = X[0].shape[:2]\n    img = np.zeros(((h * nh), (w * nw)))\nfor (n, x) in enumerate(X):\n    j = (n \/ nw)\n    i = (n % nw)\n    img[(j * h):((j * h) + h), (i * w):((i * w) + w)] = x\nimsave(save_path, img)\n"}
{"label_name":"save","label":1,"method_name":"save_checkpoint_vars","method":"\n\"\\n    Save variables in dic to path.\\n\\n    Args:\\n        dic: {name: value}\\n        path: save as npz if the name ends with '.npz', otherwise save as a checkpoint.\\n    \"\nlogger.info('Variables to save to {}:'.format(path))\nkeys = sorted(dic.keys())\nlogger.info(pprint.pformat(keys))\nassert (not path.endswith('.npy'))\nif path.endswith('.npz'):\n    np.savez_compressed(path, **dic)\nelse:\n    with tfv1.Graph().as_default(), tfv1.Session() as sess:\n        for (k, v) in six.iteritems(dic):\n            k = get_op_tensor_name(k)[0]\n            _ = tfv1.Variable(name=k, initial_value=v)\n        sess.run(tfv1.global_variables_initializer())\n        saver = tfv1.train.Saver()\n        saver.save(sess, path, write_meta_graph=False)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\nmodel.train()\nfor (batch_idx, (data, target)) in enumerate(train_loader):\n    (data, target) = (data.to(device), target.to(device))\n    optimizer.zero_grad()\n    output = model(data)\n    loss = F.nll_loss(output, target)\n    loss.backward()\n    optimizer.step()\n    if (((batch_idx % args.log_interval) == 0) and (args.rank == 0)):\n        print('Train Epoch: {} [{}\/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, ((batch_idx * len(data)) * args.world_size), len(train_loader.dataset), ((100.0 * batch_idx) \/ len(train_loader)), loss.item()))\n    if args.verbose:\n        print('Batch', batch_idx, 'from rank', args.rank)\n"}
{"label_name":"process","label":2,"method_name":"is_main_process","method":"\nreturn (get_rank() == 0)\n"}
{"label_name":"predict","label":4,"method_name":"bql_row_predictive_relevance","method":"\nif (rowid_target is None):\n    raise BQLError(bdb, 'No such target row for SIMILARITY')\nrowid_query = json.loads(rowid_query)\nmodelnos = _retrieve_modelnos(modelnos)\nsplits = ([(- 1)] + [i for (i, x) in enumerate(constraint_args) if (x is None)])\nassert (splits[(- 1)] == (len(constraint_args) - 1))\nrows_list = [constraint_args[(splits[i] + 1):splits[(i + 1)]] for i in range((len(splits) - 1))]\nassert all((((len(row) % 2) == 0) for row in rows_list))\nhypotheticals = [zip(row[::2], row[1::2]) for row in rows_list]\nif ((len(rowid_query) == 0) and (len(hypotheticals) == 0)):\n    raise BQLError(bdb, 'No matching rows for PREDICTIVE RELEVANCE.')\n\ndef generator_similarity(generator_id):\n    backend = core.bayesdb_generator_backend(bdb, generator_id)\n    return backend.predictive_relevance(bdb, generator_id, modelnos, rowid_target, rowid_query, hypotheticals, colno)\ngenerator_ids = _retrieve_generator_ids(bdb, population_id, generator_id)\nsims = map(generator_similarity, generator_ids)\nreturn stats.arithmetic_mean([stats.arithmetic_mean(s) for s in sims])\n"}
{"label_name":"predict","label":4,"method_name":"_parallel_predict_log_proba","method":"\n'Private function used to compute log probabilities within a job.'\nn_samples = X.shape[0]\nlog_proba = np.empty((n_samples, n_classes))\nlog_proba.fill((- np.inf))\nall_classes = np.arange(n_classes, dtype=np.int)\nfor (estimator, features) in zip(estimators, estimators_features):\n    log_proba_estimator = estimator.predict_log_proba(X[:, features])\n    if (n_classes == len(estimator.classes_)):\n        log_proba = np.logaddexp(log_proba, log_proba_estimator)\n    else:\n        log_proba[:, estimator.classes_] = np.logaddexp(log_proba[:, estimator.classes_], log_proba_estimator[:, range(len(estimator.classes_))])\n        missing = np.setdiff1d(all_classes, estimator.classes_)\n        log_proba[:, missing] = np.logaddexp(log_proba[:, missing], (- np.inf))\nreturn log_proba\n"}
{"label_name":"predict","label":4,"method_name":"predictOneVsAll","method":"\nm = X.shape[0]\nX = hstack((ones((m, 1)), X))\nreal_all_theta = all_theta.transpose()\nall_predict = sigmoid(dot(X, real_all_theta))\nacc = all_predict.max(1)\np = argmax(all_predict, axis=1)\nreturn (acc, p)\n"}
{"label_name":"forward","label":3,"method_name":"forward","method":"\nvectors = cast(Floats2d, model.get_param('E'))\nnV = vectors.shape[0]\nnO = vectors.shape[1]\nif (len(ids) == 0):\n    output: Floats2d = model.ops.alloc((0, nO), dtype=vectors.dtype)\nelse:\n    ids = model.ops.as_contig(ids, dtype='uint64')\n    nN = ids.shape[0]\n    seed: int = model.attrs['seed']\n    keys = (model.ops.hash(ids, seed) % nV)\n    output = vectors[keys].sum(axis=1)\n    drop_mask = None\n    if is_train:\n        dropout: Optional[float] = model.attrs.get('dropout_rate')\n        drop_mask = cast(Floats1d, model.ops.get_dropout_mask((nO,), dropout))\n        if (drop_mask is not None):\n            output *= drop_mask\n\ndef backprop(d_vectors: OutT) -> Ints1d:\n    if (drop_mask is not None):\n        d_vectors *= drop_mask\n    dE = model.ops.alloc2f(*vectors.shape)\n    keysT = model.ops.as_contig(keys.T, dtype='i')\n    for i in range(keysT.shape[0]):\n        model.ops.scatter_add(dE, keysT[i], d_vectors)\n    model.inc_grad('E', dE)\n    dX = model.ops.alloc1i(nN)\n    return dX\nreturn (output, backprop)\n"}
{"label_name":"train","label":0,"method_name":"cnn_train","method":"\n'\\n    \u521b\u5efaCNN\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u8bad\u7ec3\u6570\u636e\\n    :return:\\n    '\nW_conv1 = weight_variable([5, 5, 1, 32])\nb_conv1 = bias_variable([32])\nx = tf.placeholder(tf.float32, [None, 784])\nx_image = tf.reshape(x, [(- 1), 28, 28, 1])\nh_conv1 = tf.nn.relu((conv2d(x_image, W_conv1) + b_conv1))\nh_pool1 = max_pool_2x2(h_conv1)\n"}
{"label_name":"train","label":0,"method_name":"prepare_pretrain_text_dataset","method":"\n'Create dataset based on the raw text files'\nif (not isinstance(filenames, (list, tuple))):\n    filenames = [filenames]\nif cached_file_path:\n    suffix = re.split('\\\\.|\/', filenames[0])[(- 2)]\n    output_file = os.path.join(cached_file_path, '{}-pretrain-record.npz'.format(suffix))\nelse:\n    output_file = None\nnp_features = get_all_features((filenames, output_file, tokenizer, max_seq_length, short_seq_prob))\nreturn ArrayDataset(*np_features)\n"}
{"label_name":"train","label":0,"method_name":"_translate_train_sizes","method":"\n\"Determine absolute sizes of training subsets and validate 'train_sizes'.\\n\\n    Examples:\\n        _translate_train_sizes([0.5, 1.0], 10) -> [5, 10]\\n        _translate_train_sizes([5, 10], 10) -> [5, 10]\\n\\n    Parameters\\n    ----------\\n    train_sizes : array-like, shape (n_ticks,), dtype float or int\\n        Numbers of training examples that will be used to generate the\\n        learning curve. If the dtype is float, it is regarded as a\\n        fraction of 'n_max_training_samples', i.e. it has to be within (0, 1].\\n\\n    n_max_training_samples : int\\n        Maximum number of training samples (upper bound of 'train_sizes').\\n\\n    Returns\\n    -------\\n    train_sizes_abs : array, shape (n_unique_ticks,), dtype int\\n        Numbers of training examples that will be used to generate the\\n        learning curve. Note that the number of ticks might be less\\n        than n_ticks because duplicate entries will be removed.\\n    \"\ntrain_sizes_abs = np.asarray(train_sizes)\nn_ticks = train_sizes_abs.shape[0]\nn_min_required_samples = np.min(train_sizes_abs)\nn_max_required_samples = np.max(train_sizes_abs)\nif np.issubdtype(train_sizes_abs.dtype, np.floating):\n    if ((n_min_required_samples <= 0.0) or (n_max_required_samples > 1.0)):\n        raise ValueError(('train_sizes has been interpreted as fractions of the maximum number of training samples and must be within (0, 1], but is within [%f, %f].' % (n_min_required_samples, n_max_required_samples)))\n    train_sizes_abs = (train_sizes_abs * n_max_training_samples).astype(dtype=np.int, copy=False)\n    train_sizes_abs = np.clip(train_sizes_abs, 1, n_max_training_samples)\nelif ((n_min_required_samples <= 0) or (n_max_required_samples > n_max_training_samples)):\n    raise ValueError(('train_sizes has been interpreted as absolute numbers of training samples and must be within (0, %d], but is within [%d, %d].' % (n_max_training_samples, n_min_required_samples, n_max_required_samples)))\ntrain_sizes_abs = np.unique(train_sizes_abs)\nif (n_ticks > train_sizes_abs.shape[0]):\n    warnings.warn((\"Removed duplicate entries from 'train_sizes'. Number of ticks will be less than the size of 'train_sizes' %d instead of %d).\" % (train_sizes_abs.shape[0], n_ticks)), RuntimeWarning)\nreturn train_sizes_abs\n"}
{"label_name":"train","label":0,"method_name":"train_features","method":"\nnorm = (faces_dist.sum() + background_dist.sum())\nfaces_dist \/= norm\nbackground_dist \/= norm\n(t_face, t_back) = (faces_dist.sum(), background_dist.sum())\ntogether = np.concatenate((faces, background))\nindicator = np.concatenate((faces_dist, ((- 1) * background_dist)))\nNUM_PROCS = (cpu_count() * 3)\nargs = []\nchunk = (len(features) \/\/ NUM_PROCS)\nfor cpu in range(cpu_count()):\n    if ((cpu + 1) == NUM_PROCS):\n        args.append((features[(cpu * chunk):], together, indicator, t_face, t_back, False))\n    else:\n        args.append((features[(cpu * chunk):((cpu + 1) * chunk)], together, indicator, t_face, t_back, False))\nresult = [y for x in threadpool.starmap_async(_train_features, args).get() for y in x]\nresult.sort(key=(lambda x: x[(- 1)]))\nreturn result\n"}
{"label_name":"process","label":2,"method_name":"preprocess_image","method":"\n\"Preprocesses the given image.\\n\\n  Args:\\n    image: A `Tensor` representing an image of arbitrary size.\\n    output_height: The height of the image after preprocessing.\\n    output_width: The width of the image after preprocessing.\\n    is_training: `True` if we're preprocessing the image for training and\\n      `False` otherwise.\\n\\n  Returns:\\n    A preprocessed image.\\n  \"\nif is_training:\n    return preprocess_for_train(image, output_height, output_width)\nelse:\n    return preprocess_for_eval(image, output_height, output_width)\n"}
{"label_name":"process","label":2,"method_name":"process_results","method":"\n'Extract useful information from given metrics.\\n\\n  Args:\\n    metrics: List of results dicts. These should have been written to disk by\\n        training jobs.\\n\\n  Returns:\\n    Dict mapping stats names to values.\\n\\n  Raises:\\n    ValueError: If max_npe or max_global_repetitions values are inconsistant\\n        across dicts in the `metrics` list.\\n  '\ncount = len(metrics)\nsuccess_count = 0\ntotal_npe = 0\nsuccess_npe = 0\nmax_npe = 0\nmax_repetitions = 0\nfor metric_dict in metrics:\n    if (not max_npe):\n        max_npe = metric_dict['max_npe']\n    elif (max_npe != metric_dict['max_npe']):\n        raise ValueError('Invalid experiment. Different reps have different max-NPE settings.')\n    if (not max_repetitions):\n        max_repetitions = metric_dict['max_global_repetitions']\n    elif (max_repetitions != metric_dict['max_global_repetitions']):\n        raise ValueError('Invalid experiment. Different reps have different num-repetition settings.')\n    if metric_dict['found_solution']:\n        success_count += 1\n        success_npe += metric_dict['npe']\n    total_npe += metric_dict['npe']\nstats = {}\nstats['max_npe'] = max_npe\nstats['max_repetitions'] = max_repetitions\nstats['repetitions'] = count\nstats['successes'] = success_count\nstats['failures'] = (count - success_count)\nstats['success_npe'] = success_npe\nstats['total_npe'] = total_npe\nif success_count:\n    stats['avg_success_npe'] = (stats['success_npe'] \/ float(success_count))\nelse:\n    stats['avg_success_npe'] = 0.0\nif count:\n    stats['success_rate'] = (success_count \/ float(count))\n    stats['avg_total_npe'] = (stats['total_npe'] \/ float(count))\nelse:\n    stats['success_rate'] = 0.0\n    stats['avg_total_npe'] = 0.0\nreturn stats\n"}
{"label_name":"train","label":0,"method_name":"wrap_train","method":"\nfrom baselines.common.atari_wrappers import wrap_deepmind, FrameStack\nenv = wrap_deepmind(env, clip_rewards=False)\nenv = FrameStack(env, 3)\nreturn env\n"}
{"label_name":"predict","label":4,"method_name":"_fit_and_predict","method":"\n\"Fit estimator and predict values for a given dataset split.\\n\\n    Read more in the :ref:`User Guide <cross_validation>`.\\n\\n    Parameters\\n    ----------\\n    estimator : estimator object implementing 'fit' and 'predict'\\n        The object to use to fit the data.\\n\\n    X : array-like of shape at least 2D\\n        The data to fit.\\n\\n    y : array-like, optional, default: None\\n        The target variable to try to predict in the case of\\n        supervised learning.\\n\\n    train : array-like, shape (n_train_samples,)\\n        Indices of training samples.\\n\\n    test : array-like, shape (n_test_samples,)\\n        Indices of test samples.\\n\\n    verbose : integer\\n        The verbosity level.\\n\\n    fit_params : dict or None\\n        Parameters that will be passed to ``estimator.fit``.\\n\\n    Returns\\n    -------\\n    preds : sequence\\n        Result of calling 'estimator.predict'\\n\\n    test : array-like\\n        This is the value of the test parameter\\n    \"\nfit_params = (fit_params if (fit_params is not None) else {})\nfit_params = dict([(k, _index_param_value(X, v, train)) for (k, v) in fit_params.items()])\n(X_train, y_train) = _safe_split(estimator, X, y, train)\n(X_test, _) = _safe_split(estimator, X, y, test, train)\nif (y_train is None):\n    estimator.fit(X_train, **fit_params)\nelse:\n    estimator.fit(X_train, y_train, **fit_params)\npreds = estimator.predict(X_test)\nreturn (preds, test)\n"}
{"label_name":"process","label":2,"method_name":"process_urlencoded","method":"\n'Read application\/x-www-form-urlencoded data into entity.params.'\nqs = entity.fp.read()\nfor charset in entity.attempt_charsets:\n    try:\n        params = {}\n        for aparam in qs.split(b'&'):\n            for pair in aparam.split(b';'):\n                if (not pair):\n                    continue\n                atoms = pair.split(b'=', 1)\n                if (len(atoms) == 1):\n                    atoms.append(b'')\n                key = unquote_plus(atoms[0]).decode(charset)\n                value = unquote_plus(atoms[1]).decode(charset)\n                if (key in params):\n                    if (not isinstance(params[key], list)):\n                        params[key] = [params[key]]\n                    params[key].append(value)\n                else:\n                    params[key] = value\n    except UnicodeDecodeError:\n        pass\n    else:\n        entity.charset = charset\n        break\nelse:\n    raise cherrypy.HTTPError(400, ('The request entity could not be decoded. The following charsets were attempted: %s' % repr(entity.attempt_charsets)))\nfor (key, value) in params.items():\n    if (key in entity.params):\n        if (not isinstance(entity.params[key], list)):\n            entity.params[key] = [entity.params[key]]\n        entity.params[key].append(value)\n    else:\n        entity.params[key] = value\n"}
{"label_name":"predict","label":4,"method_name":"output_predictions","method":"\nparagraphs = []\nfor (i, p) in enumerate(data_generator.sentences):\n    start = (0 if (i == 0) else paragraphs[(- 1)][2])\n    length = sum([len(x[0]) for x in p])\n    paragraphs += [(i, start, (start + length), (length + 1))]\nparagraphs = list(sorted(paragraphs, key=(lambda x: x[3]), reverse=True))\nall_preds = ([None] * len(paragraphs))\nall_raw = ([None] * len(paragraphs))\neval_limit = max(3000, max_seqlen)\nbatch_size = trainer.args['batch_size']\nbatches = int((((len(paragraphs) + batch_size) - 1) \/ batch_size))\nt = 0\nfor i in range(batches):\n    batchparas = paragraphs[(i * batch_size):((i + 1) * batch_size)]\n    offsets = [x[1] for x in batchparas]\n    t += sum([x[3] for x in batchparas])\n    batch = data_generator.next(eval_offsets=offsets)\n    raw = batch[3]\n    N = len(batch[3][0])\n    if (N <= eval_limit):\n        pred = np.argmax(trainer.predict(batch), axis=2)\n    else:\n        idx = ([0] * len(batchparas))\n        adv = ([0] * len(batchparas))\n        Ns = [p[3] for p in batchparas]\n        pred = [[] for _ in batchparas]\n        while True:\n            ens = [min((N - idx1), eval_limit) for (idx1, N) in zip(idx, Ns)]\n            en = max(ens)\n            batch1 = (batch[0][:, :en], batch[1][:, :en], batch[2][:, :en], [x[:en] for x in batch[3]])\n            pred1 = np.argmax(trainer.predict(batch1), axis=2)\n            for j in range(len(batchparas)):\n                sentbreaks = np.where(((pred1[j] == 2) + (pred1[j] == 4)))[0]\n                if ((len(sentbreaks) <= 0) or (idx[j] >= (Ns[j] - eval_limit))):\n                    advance = ens[j]\n                else:\n                    advance = (np.max(sentbreaks) + 1)\n                pred[j] += [pred1[j, :advance]]\n                idx[j] += advance\n                adv[j] = advance\n            if all([(idx1 >= N) for (idx1, N) in zip(idx, Ns)]):\n                break\n            batch = data_generator.next(eval_offsets=adv, old_batch=batch)\n        pred = [np.concatenate(p, 0) for p in pred]\n    for (j, p) in enumerate(batchparas):\n        len1 = len([1 for x in raw[j] if (x != '<PAD>')])\n        if (pred[j][(len1 - 1)] < 2):\n            pred[j][(len1 - 1)] = 2\n        elif (pred[j][(len1 - 1)] > 2):\n            pred[j][(len1 - 1)] = 4\n        if use_regex_tokens:\n            all_preds[p[0]] = update_pred_regex(raw[j], pred[j][:len1])\n        else:\n            all_preds[p[0]] = pred[j][:len1]\n        all_raw[p[0]] = raw[j]\noffset = 0\noov_count = 0\ndoc = []\ntext = (SPACE_RE.sub(' ', orig_text) if (orig_text is not None) else None)\nchar_offset = 0\nuse_la_ittb_shorthand = (trainer.args['shorthand'] == 'la_ittb')\nfor j in range(len(paragraphs)):\n    raw = all_raw[j]\n    pred = all_preds[j]\n    current_tok = ''\n    current_sent = []\n    for (t, p) in zip(raw, pred):\n        if (t == '<PAD>'):\n            break\n        if (use_la_ittb_shorthand and (t in (':', ';'))):\n            p = 2\n        offset += 1\n        if (vocab.unit2id(t) == vocab.unit2id('<UNK>')):\n            oov_count += 1\n        current_tok += t\n        if (p >= 1):\n            tok = vocab.normalize_token(current_tok)\n            assert ('\\t' not in tok), tok\n            if (len(tok) <= 0):\n                current_tok = ''\n                continue\n            if (orig_text is not None):\n                st = (- 1)\n                tok_len = 0\n                for part in SPACE_SPLIT_RE.split(current_tok):\n                    if (len(part) == 0):\n                        continue\n                    st0 = (text.index(part, char_offset) - char_offset)\n                    lstripped = part.lstrip()\n                    if (st < 0):\n                        st = ((char_offset + st0) + (len(part) - len(lstripped)))\n                    char_offset += (st0 + len(part))\n                additional_info = {START_CHAR: st, END_CHAR: char_offset}\n            else:\n                additional_info = dict()\n            current_sent.append((tok, p, additional_info))\n            current_tok = ''\n            if (((p == 2) or (p == 4)) and (not no_ssplit)):\n                doc.append(process_sentence(current_sent, mwt_dict))\n                current_sent = []\n    assert (len(current_tok) == 0)\n    if len(current_sent):\n        doc.append(process_sentence(current_sent, mwt_dict))\nif output_file:\n    CoNLL.dict2conll(doc, output_file)\nreturn (oov_count, offset, all_preds, doc)\n"}
{"label_name":"predict","label":4,"method_name":"predict_analysis_inference","method":"\noutput = PredictorTools(MODEL_SAVE_DIR, MODEL_FILENAME, PARAMS_FILENAME, data)\nout = output()\nreturn out\n"}
{"label_name":"train","label":0,"method_name":"get_train_image","method":"\nimg_data = np.uint8(model._train_images[image_id])\nreturn return_image(img_data)\n"}
{"label_name":"train","label":0,"method_name":"train_population","method":"\n'\\n    Runs the training for members in pop\\n    :param pop: population of config dicts\\n    :param args: config arguments\\n    :return:\\n    '\nassert (type(pop) is list)\nwrite_population_configs(pop)\ncreate_train_scripts(pop, args)\nexecute_train_scripts(pop)\nreturn\n"}
{"label_name":"train","label":0,"method_name":"train_step","method":"\nwith tf.GradientTape() as tape:\n    (y_pred, logits) = model(x)\n    loss = cross_entropy_loss(logits, y)\ngradients = tape.gradient(loss, model.trainable_variables)\noptimizer.apply_gradients(zip(gradients, model.trainable_variables))\n"}
{"label_name":"predict","label":4,"method_name":"predict_example1","method":"\nX = add_one(data_X)\nC = ((X.T * X).I * (X.T * Y))\npredict = (X * C)\nmse = mean_squared_error(Y, predict)\n(b, w) = (C[0], C[1:])\nshow_result(b, w, mse)\nreturn predict\n"}
{"label_name":"process","label":2,"method_name":"process_exp_rm","method":"\n'Delete the given experiment node and all its children.'\ntrials_total = 0\nexp_total = 0\nfor node in root:\n    count = storage.delete_trials(uid=node.item.id)\n    trials_total += count\n    logger.debug('%d trials deleted in experiment %s-v%d', count, node.item.name, node.item.version)\n    count = storage.delete_experiment(uid=node.item.id)\n    logger.debug('%s experiment %s-v%d deleted', count, node.item.name, node.item.version)\n    exp_total += count\nprint(f'{trials_total} trials deleted')\nprint(f'{exp_total} experiments deleted')\n"}
{"label_name":"train","label":0,"method_name":"_check_train_ids","method":"\nif (train_ids is None):\n    raise Exception('Please download the data using download_data() before attempting to access it.')\n"}
{"label_name":"save","label":1,"method_name":"_save","method":"\nreturn JpegImagePlugin._save(im, fp, filename)\n"}
{"label_name":"forward","label":3,"method_name":"forwardOnly","method":"\nreturn left.dir().is_forward()\n"}
{"label_name":"train","label":0,"method_name":"build_training_generator","method":"\nwhile True:\n    inputs = next(gen)\n    if (batch_size > 1):\n        target = np.concatenate(([add_axis(np.zeros(1))] * batch_size), 0)\n    else:\n        target = add_axis(np.zeros(1))\n    (yield (inputs, target))\n"}
{"label_name":"train","label":0,"method_name":"add_final_training_ops","method":"\n\"Adds a new softmax and fully-connected layer for training.\\n\\n  We need to retrain the top layer to identify our new classes, so this function\\n  adds the right operations to the graph, along with some variables to hold the\\n  weights, and then sets up all the gradients for the backward pass.\\n\\n  The set up for the softmax and fully-connected layers is based on:\\n  https:\/\/www.tensorflow.org\/versions\/master\/tutorials\/mnist\/beginners\/index.html\\n\\n  Args:\\n    class_count: Integer of how many categories of things we're trying to\\n    recognize.\\n    final_tensor_name: Name string for the new final node that produces results.\\n    bottleneck_tensor: The output of the main CNN graph.\\n    bottleneck_tensor_size: How many entries in the bottleneck vector.\\n\\n  Returns:\\n    The tensors for the training and cross entropy results, and tensors for the\\n    bottleneck input and ground truth input.\\n  \"\nwith tf.name_scope('input'):\n    bottleneck_input = tf.placeholder_with_default(bottleneck_tensor, shape=[None, bottleneck_tensor_size], name='BottleneckInputPlaceholder')\n    ground_truth_input = tf.placeholder(tf.float32, [None, class_count], name='GroundTruthInput')\nlayer_name = 'final_training_ops'\nwith tf.name_scope(layer_name):\n    with tf.name_scope('weights'):\n        initial_value = tf.truncated_normal([bottleneck_tensor_size, class_count], stddev=0.001)\n        layer_weights = tf.Variable(initial_value, name='final_weights')\n        variable_summaries(layer_weights)\n    with tf.name_scope('biases'):\n        layer_biases = tf.Variable(tf.zeros([class_count]), name='final_biases')\n        variable_summaries(layer_biases)\n    with tf.name_scope('Wx_plus_b'):\n        logits = (tf.matmul(bottleneck_input, layer_weights) + layer_biases)\n        tf.summary.histogram('pre_activations', logits)\nfinal_tensor = tf.nn.softmax(logits, name=final_tensor_name)\ntf.summary.histogram('activations', final_tensor)\nwith tf.name_scope('cross_entropy'):\n    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=ground_truth_input, logits=logits)\n    with tf.name_scope('total'):\n        cross_entropy_mean = tf.reduce_mean(cross_entropy)\ntf.summary.scalar('cross_entropy', cross_entropy_mean)\nwith tf.name_scope('train'):\n    optimizer = tf.train.GradientDescentOptimizer(FLAGS.learning_rate)\n    train_step = optimizer.minimize(cross_entropy_mean)\nreturn (train_step, cross_entropy_mean, bottleneck_input, ground_truth_input, final_tensor)\n"}
{"label_name":"process","label":2,"method_name":"process","method":"\nres = '|'.join(arr)\n"}
{"label_name":"process","label":2,"method_name":"_wing_nus_pdtb_process","method":"\n'Run Wing-NUS Penn Discourse Treebank parser on the passed string'\ntry:\n    with tempfile.TemporaryDirectory() as tmp_dir:\n        fn_in = os.path.join(tmp_dir, 'tmp.txt')\n        shutil.copyfile(filename, fn_in)\n        cwd = os.getcwd()\n        os.chdir(WINGNUS_PATH)\n        result = run(['java', '-jar', 'parser.jar', fn_in], stdout=PIPE, stderr=PIPE)\n        if (result.returncode == 0):\n            os.chdir(cwd)\n            fn_out = os.path.join(tmp_dir, 'output', 'tmp.txt.pipe')\n            shutil.copyfile(fn_out, (filename + '.pipe'))\n        else:\n            raise ValueError('WingNUS parser failed: {}'.format(result.stderr.decode()))\nfinally:\n    os.chdir(cwd)\n"}
{"label_name":"predict","label":4,"method_name":"plot_posterior_predictions","method":"\nf = plt.figure(figsize=(12, 6))\na1 = f.add_axes([0.05, 0.05, 0.9, 0.6])\na2 = f.add_axes([0.05, 0.7, 0.9, 0.1])\na3 = f.add_axes([0.05, 0.85, 0.9, 0.1])\nxx = np.linspace(X.min(), X.max(), 200).reshape((- 1), 1)\n(mu, var) = m.predict_f(xx)\n(p, _) = m.predict_y(xx)\na3.set_xticks([])\na3.set_yticks([])\nfor c in range(m.likelihood.num_classes):\n    x = X[(Y.flatten() == c)]\n    color = colors[c]\n    a3.plot(x, (x * 0), '.', color=color)\n    a1.plot(xx, mu[:, c], color=color, lw=2, label=('%d' % c))\n    a1.plot(xx, (mu[:, c] + (2 * np.sqrt(var[:, c]))), '--', color=color)\n    a1.plot(xx, (mu[:, c] - (2 * np.sqrt(var[:, c]))), '--', color=color)\n    a2.plot(xx, p[:, c], '-', color=color, lw=2)\na2.set_ylim((- 0.1), 1.1)\na2.set_yticks([0, 1])\na2.set_xticks([])\na3.set_title('inputs X')\na2.set_title('predicted mean label value                  $\\\\mathbb{E}_{q(\\\\mathbf{u})}[y^*|x^*, Z, \\\\mathbf{u}]$')\na1.set_title('posterior process                 $\\\\int d\\\\mathbf{u} q(\\\\mathbf{u})p(f^*|\\\\mathbf{u}, Z, x^*)$')\n(handles, labels) = a1.get_legend_handles_labels()\na1.legend(handles, labels)\nf.tight_layout()\nplt.show()\n"}
{"label_name":"train","label":0,"method_name":"backwardSxConstraint","method":"\nif ((not left.dir().can_cross()) and right.dir().can_cross()):\n    return False\nif (not bothForward(left, right)):\n    return False\nreturn (right.res().dir().is_backward() and right.arg().is_primitive())\n"}
{"label_name":"process","label":2,"method_name":"postprocess","method":"\n'\\n    Takes net output, draw predictions, save to disk\\n    '\n(meta, FLAGS) = (self.meta, self.FLAGS)\nthreshold = FLAGS.threshold\n(colors, labels) = (meta['colors'], meta['labels'])\nboxes = self.findboxes(net_out)\nif (type(im) is not np.ndarray):\n    imgcv = cv2.imread(im)\nelse:\n    imgcv = im\n(h, w, _) = imgcv.shape\nresultsForJSON = []\nfor b in boxes:\n    boxResults = self.process_box(b, h, w, threshold)\n    if (boxResults is None):\n        continue\n    (left, right, top, bot, mess, max_indx, confidence) = boxResults\n    thick = int(((h + w) \/\/ 300))\n    if self.FLAGS.json:\n        resultsForJSON.append({'label': mess, 'confidence': float(('%.2f' % confidence)), 'topleft': {'x': left, 'y': top}, 'bottomright': {'x': right, 'y': bot}})\n        continue\n    cv2.rectangle(imgcv, (left, top), (right, bot), self.meta['colors'][max_indx], thick)\n    cv2.putText(imgcv, mess, (left, (top - 12)), 0, (0.001 * h), self.meta['colors'][max_indx], (thick \/\/ 3))\nif (not save):\n    return imgcv\noutfolder = os.path.join(self.FLAGS.imgdir, 'out')\nimg_name = os.path.join(outfolder, os.path.basename(im))\nif self.FLAGS.json:\n    textJSON = json.dumps(resultsForJSON)\n    textFile = (os.path.splitext(img_name)[0] + '.json')\n    with open(textFile, 'w') as f:\n        f.write(textJSON)\n    return\ncv2.imwrite(img_name, imgcv)\n"}
{"label_name":"process","label":2,"method_name":"process_box","method":"\nmax_indx = np.argmax(b.probs)\nmax_prob = b.probs[max_indx]\nlabel = self.meta['labels'][max_indx]\nif (max_prob > threshold):\n    left = int(((b.x - (b.w \/ 2.0)) * w))\n    right = int(((b.x + (b.w \/ 2.0)) * w))\n    top = int(((b.y - (b.h \/ 2.0)) * h))\n    bot = int(((b.y + (b.h \/ 2.0)) * h))\n    if (left < 0):\n        left = 0\n    if (right > (w - 1)):\n        right = (w - 1)\n    if (top < 0):\n        top = 0\n    if (bot > (h - 1)):\n        bot = (h - 1)\n    mess = '{}'.format(label)\n    return (left, right, top, bot, mess, max_indx, max_prob)\nreturn None\n"}
{"label_name":"save","label":1,"method_name":"_save_params","method":"\ncurrent_map = float(current_map)\nif (current_map > best_map[0]):\n    best_map[0] = current_map\n    net.save_parameters('{:s}_{:04d}_{:.4f}_best.params'.format(prefix, epoch, current_map))\n    with open((prefix + '_best_map.log'), 'a') as log_file:\n        log_file.write('{:04d}:\\t{:.4f}\\n'.format(epoch, current_map))\nif (save_interval and ((epoch % save_interval) == 0)):\n    net.save_parameters('{:s}_{:04d}_{:.4f}.params'.format(prefix, epoch, current_map))\n"}
{"label_name":"predict","label":4,"method_name":"predict","method":"\nreturn dot(x_i, beta)\n"}
{"label_name":"predict","label":4,"method_name":"_get_predictions_by_sensitive_feature","method":"\nlabels_and_predictions = defaultdict(list)\nsensitive_features_mapped = _map_into_single_column(sensitive_features)\nfor i in range(len(sensitive_features_mapped)):\n    labels_and_predictions[sensitive_features_mapped[i]].append(LabelAndPrediction(labels[i], adjusted_predictor([sensitive_features_mapped[i]], [scores[i]])))\nreturn labels_and_predictions\n"}
{"label_name":"predict","label":4,"method_name":"create_predict_input_fn","method":"\nreturn create_image_dataset_predict_input_fn(dataset_dir, prepare, RECORD_FILE_NAME_FORMAT, META_DATA_FILENAME_FORMAT)\n"}
{"label_name":"predict","label":4,"method_name":"predict","method":"\n'\\n    predict: It predicts the person in VideoCapture object using the KNN object\\n    '\nskip_frame = 10\ndata = []\nflag = False\nix = 0\nwhile True:\n    ix += 1\n    (faces, fr) = __get_data__()\n    for (x, y, w, h) in faces:\n        fc = fr[y:(y + h), x:(x + w), :]\n        roi = cv2.resize(fc, (64, 64))\n        pred = knn.predict(np.array([roi.flatten()]))\n        cv2.rectangle(fr, (x, y), ((x + w), (y + h)), (255, 0, 0))\n        cv2.putText(fr, labels[int(pred)], (x, y), cv2.FONT_HERSHEY_COMPLEX, 2, 255)\n    if (cv2.waitKey(1) == 27):\n        break\n    cv2.imshow('rgb', fr)\ncv2.destroyAllWindows()\n"}
{"label_name":"predict","label":4,"method_name":"predict","method":"\n(gp, norm_mean, norm_stddev) = fit_normalized_gaussian_process(X, y, nu=nu)\n(y_pred, y_std) = gp.predict([test_X], return_std=True)\ny_std_norm = (y_std * norm_stddev)\ny_pred_norm = ((y_pred * norm_stddev) + norm_mean)\nreturn (y_pred_norm[0], y_std_norm[0])\n"}
{"label_name":"process","label":2,"method_name":"process_skipna","method":"\nif (isinstance(skipna, ndarray) or (skipna is None)):\n    args = ((skipna,) + args)\n    skipna = True\nreturn (skipna, args)\n"}
{"label_name":"train","label":0,"method_name":"train_word2vec","method":"\nif (corpus == 'text8'):\n    sentences = Text8Corpus('data\/text8')\nelif (corpus == '1bil'):\n    sentences = OneBilCorpus()\n\ndef save_model(model, saven):\n    table = deepcopy(model.table)\n    model.table = None\n    pkl.dump(model, open(('data\/%s' % saven), 'wb'), (- 1))\n    model.table = table\nmodel = word2vec.Word2Vec(sentences, mtype='cbow', hs=0, neg=13, vector_size=200, alpha=0.025, min_alpha=0.01, seed=seed)\nfor i in range(1, it):\n    print(('####### ITERATION %i ########' % i))\n    _ = accuracy(model, 'data\/questions-words.txt')\n    if save_interm:\n        save_model(model, ('%s_cbow_200_hs0_neg13_seed%i_it%i.model' % (corpus, seed, i)))\n    model.train(sentences, alpha=0.025, min_alpha=0.01)\nsave_model(model, ('%s_cbow_200_hs0_neg13_seed%i_it%i.model' % (corpus, seed, it)))\nprint(('####### ITERATION %i ########' % it))\n_ = accuracy(model, 'data\/questions-words.txt')\naccuracy_examples(model)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\nprint('TRAIN: use train.py')\n"}
{"label_name":"process","label":2,"method_name":"preprocess_weights_for_loading","method":"\n'Converts layers weights from Keras 1 format to Keras 2.\\n\\n  Arguments:\\n      layer: Layer instance.\\n      weights: List of weights values (Numpy arrays).\\n      original_keras_version: Keras version for the weights, as a string.\\n      original_backend: Keras backend the weights were trained with,\\n          as a string.\\n\\n  Returns:\\n      A list of weights values (Numpy arrays).\\n  '\nif (original_keras_version == '1'):\n    if (layer.__class__.__name__ == 'Bidirectional'):\n        num_weights_per_layer = (len(weights) \/\/ 2)\n        forward_weights = preprocess_weights_for_loading(layer.forward_layer, weights[:num_weights_per_layer], original_keras_version, original_backend)\n        backward_weights = preprocess_weights_for_loading(layer.backward_layer, weights[num_weights_per_layer:], original_keras_version, original_backend)\n        weights = (forward_weights + backward_weights)\n    if (layer.__class__.__name__ == 'TimeDistributed'):\n        weights = preprocess_weights_for_loading(layer.layer, weights, original_keras_version, original_backend)\n    if (layer.__class__.__name__ == 'Conv1D'):\n        shape = weights[0].shape\n        if ((shape[:2] != (layer.kernel_size[0], 1)) or (shape[3] != layer.filters)):\n            assert ((shape[0] == layer.filters) and (shape[2:] == (layer.kernel_size[0], 1)))\n            weights[0] = np.transpose(weights[0], (2, 3, 1, 0))\n        weights[0] = weights[0][:, 0, :, :]\n    if (layer.__class__.__name__ == 'Conv2D'):\n        if (layer.data_format == 'channels_first'):\n            weights[0] = np.transpose(weights[0], (2, 3, 1, 0))\n    if (layer.__class__.__name__ == 'Conv2DTranspose'):\n        if (layer.data_format == 'channels_last'):\n            weights[0] = np.transpose(weights[0], (0, 1, 3, 2))\n        if (layer.data_format == 'channels_first'):\n            weights[0] = np.transpose(weights[0], (2, 3, 0, 1))\n    if (layer.__class__.__name__ == 'Conv3D'):\n        if (layer.data_format == 'channels_first'):\n            weights[0] = np.transpose(weights[0], (2, 3, 4, 1, 0))\n    if (layer.__class__.__name__ == 'GRU'):\n        if (len(weights) == 9):\n            kernel = np.concatenate([weights[0], weights[3], weights[6]], axis=(- 1))\n            recurrent_kernel = np.concatenate([weights[1], weights[4], weights[7]], axis=(- 1))\n            bias = np.concatenate([weights[2], weights[5], weights[8]], axis=(- 1))\n            weights = [kernel, recurrent_kernel, bias]\n    if (layer.__class__.__name__ == 'LSTM'):\n        if (len(weights) == 12):\n            kernel = np.concatenate([weights[0], weights[6], weights[3], weights[9]], axis=(- 1))\n            recurrent_kernel = np.concatenate([weights[1], weights[7], weights[4], weights[10]], axis=(- 1))\n            bias = np.concatenate([weights[2], weights[8], weights[5], weights[11]], axis=(- 1))\n            weights = [kernel, recurrent_kernel, bias]\n    if (layer.__class__.__name__ == 'ConvLSTM2D'):\n        if (len(weights) == 12):\n            kernel = np.concatenate([weights[0], weights[6], weights[3], weights[9]], axis=(- 1))\n            recurrent_kernel = np.concatenate([weights[1], weights[7], weights[4], weights[10]], axis=(- 1))\n            bias = np.concatenate([weights[2], weights[8], weights[5], weights[11]], axis=(- 1))\n            if (layer.data_format == 'channels_first'):\n                kernel = np.transpose(kernel, (2, 3, 1, 0))\n                recurrent_kernel = np.transpose(recurrent_kernel, (2, 3, 1, 0))\n            weights = [kernel, recurrent_kernel, bias]\n    if (layer.__class__.__name__ in ['Model', 'Sequential']):\n        new_weights = []\n        for sublayer in layer.layers:\n            num_weights = len(sublayer.trainable_weights)\n            if (num_weights > 0):\n                new_weights.extend(preprocess_weights_for_loading(layer=sublayer, weights=weights[:num_weights], original_keras_version=original_keras_version, original_backend=original_backend))\n                weights = weights[num_weights:]\n        for sublayer in layer.layers:\n            num_weights = len([l for l in sublayer.weights if (l not in sublayer.trainable_weights)])\n            if (num_weights > 0):\n                new_weights.extend(preprocess_weights_for_loading(layer=sublayer, weights=weights[:num_weights], original_keras_version=original_keras_version, original_backend=original_backend))\n                weights = weights[num_weights:]\n        weights = new_weights\nconv_layers = ['Conv1D', 'Conv2D', 'Conv3D', 'Conv2DTranspose', 'ConvLSTM2D']\nif (layer.__class__.__name__ in conv_layers):\n    if (original_backend and (K.backend() != original_backend)):\n        weights[0] = conv_utils.convert_kernel(weights[0])\n        if (layer.__class__.__name__ == 'ConvLSTM2D'):\n            weights[1] = conv_utils.convert_kernel(weights[1])\n    if (K.int_shape(layer.weights[0]) != weights[0].shape):\n        weights[0] = np.transpose(weights[0], (3, 2, 0, 1))\n        if (layer.__class__.__name__ == 'ConvLSTM2D'):\n            weights[1] = np.transpose(weights[1], (3, 2, 0, 1))\nreturn weights\n"}
{"label_name":"train","label":0,"method_name":"trainSparseModel","method":"\nsparse_model = getSparseModel(Xtrain, Ytrain, isFITC)\nsparse_model.likelihood.variance = exact_model.likelihood.variance.numpy()\nsparse_model.kern.lengthscales = exact_model.kern.lengthscales.numpy()\nsparse_model.kern.variance = exact_model.kern.variance.numpy()\nreturn (sparse_model, repeatMinimization(sparse_model, Xtest, Ytest))\n"}
{"label_name":"save","label":1,"method_name":"save_nb","method":"\n'\\n    write a notebook to a file\\n    '\nwith open(file_name, 'w') as f:\n    nbf.write(nb, f)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\ntrain_config = general_config.train_config\ndictionary = general_config.dictionary\nnepochs = general_config.nepochs\nnhops = general_config.nhops\nbatch_size = general_config.batch_size\nenable_time = general_config.enable_time\nrandomize_time = general_config.randomize_time\nlrate_decay_step = general_config.lrate_decay_step\ntrain_range = general_config.train_range\nval_range = general_config.val_range\ntrain_len = len(train_range)\nval_len = len(val_range)\nparams = {'lrate': train_config['init_lrate'], 'max_grad_norm': train_config['max_grad_norm']}\nfor ep in range(nepochs):\n    if (((ep + 1) % lrate_decay_step) == 0):\n        params['lrate'] *= 0.5\n    total_err = 0.0\n    total_cost = 0.0\n    total_num = 0\n    for _ in Progress(range(int(math.floor((train_len \/ batch_size))))):\n        batch = train_range[np.random.randint(train_len, size=batch_size)]\n        input_data = np.zeros((train_story.shape[0], batch_size), np.float32)\n        target_data = train_questions[(2, batch)]\n        memory[0].data[:] = dictionary['nil']\n        for b in range(batch_size):\n            d = train_story[:, :(1 + train_questions[(1, batch[b])]), train_questions[(0, batch[b])]]\n            offset = max(0, (d.shape[1] - train_config['sz']))\n            d = d[:, offset:]\n            memory[0].data[:d.shape[0], :d.shape[1], b] = d\n            if enable_time:\n                if (randomize_time > 0):\n                    nblank = np.random.randint(int(math.ceil((d.shape[1] * randomize_time))))\n                    rt = np.random.permutation((d.shape[1] + nblank))\n                    rt[(rt >= train_config['sz'])] = (train_config['sz'] - 1)\n                    memory[0].data[(- 1), :d.shape[1], b] = (np.sort(rt[:d.shape[1]])[::(- 1)] + len(dictionary))\n                else:\n                    memory[0].data[(- 1), :d.shape[1], b] = (np.arange(d.shape[1])[::(- 1)] + len(dictionary))\n            input_data[:, b] = train_qstory[:, batch[b]]\n        for i in range(1, nhops):\n            memory[i].data = memory[0].data\n        out = model.fprop(input_data)\n        total_cost += loss.fprop(out, target_data)\n        total_err += loss.get_error(out, target_data)\n        total_num += batch_size\n        grad = loss.bprop(out, target_data)\n        model.bprop(input_data, grad)\n        model.update(params)\n        for i in range(nhops):\n            memory[i].emb_query.weight.D[:, 0] = 0\n    total_val_err = 0.0\n    total_val_cost = 0.0\n    total_val_num = 0\n    for k in range(int(math.floor((val_len \/ batch_size)))):\n        batch = val_range[np.arange((k * batch_size), ((k + 1) * batch_size))]\n        input_data = np.zeros((train_story.shape[0], batch_size), np.float32)\n        target_data = train_questions[(2, batch)]\n        memory[0].data[:] = dictionary['nil']\n        for b in range(batch_size):\n            d = train_story[:, :(1 + train_questions[(1, batch[b])]), train_questions[(0, batch[b])]]\n            offset = max(0, (d.shape[1] - train_config['sz']))\n            d = d[:, offset:]\n            memory[0].data[:d.shape[0], :d.shape[1], b] = d\n            if enable_time:\n                memory[0].data[(- 1), :d.shape[1], b] = (np.arange(d.shape[1])[::(- 1)] + len(dictionary))\n            input_data[:, b] = train_qstory[:, batch[b]]\n        for i in range(1, nhops):\n            memory[i].data = memory[0].data\n        out = model.fprop(input_data)\n        total_val_cost += loss.fprop(out, target_data)\n        total_val_err += loss.get_error(out, target_data)\n        total_val_num += batch_size\n    train_error = (total_err \/ total_num)\n    val_error = (total_val_err \/ total_val_num)\n    print(('%d | train error: %g | val error: %g' % ((ep + 1), train_error, val_error)))\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n'\\n    WMT14 training set creator.\\n\\n    It returns a reader creator, each sample in the reader is source language\\n    word ID sequence, target language word ID sequence and next word ID\\n    sequence.\\n\\n    :return: Training reader creator\\n    :rtype: callable\\n    '\nreturn reader_creator(paddle.dataset.common.download(URL_TRAIN, 'wmt14', MD5_TRAIN), 'train\/train', dict_size)\n"}
{"label_name":"process","label":2,"method_name":"get_process_umask","method":"\nresult = os.umask(18)\nos.umask(result)\nreturn result\n"}
{"label_name":"process","label":2,"method_name":"image_preprocessing","method":"\n'Decode and preprocess one image for evaluation or training.\\n\\n  Args:\\n    image_buffer: JPEG encoded string Tensor\\n    bbox: 3-D float Tensor of bounding boxes arranged [1, num_boxes, coords]\\n      where each coordinate is [0, 1) and the coordinates are arranged as\\n      [ymin, xmin, ymax, xmax].\\n    train: boolean\\n    thread_id: integer indicating preprocessing thread\\n\\n  Returns:\\n    3-D float Tensor containing an appropriately scaled image\\n\\n  Raises:\\n    ValueError: if user does not provide bounding box\\n  '\nif (bbox is None):\n    raise ValueError('Please supply a bounding box.')\nimage = decode_jpeg(image_buffer)\nheight = FLAGS.image_size\nwidth = FLAGS.image_size\nif train:\n    image = distort_image(image, height, width, bbox, thread_id)\nelse:\n    image = eval_image(image, height, width)\nimage = tf.sub(image, 0.5)\nimage = tf.mul(image, 2.0)\nreturn image\n"}
{"label_name":"process","label":2,"method_name":"process_results","method":"\n'Extract useful information from given metrics.\\n\\n  Args:\\n    metrics: List of results dicts. These should have been written to disk by\\n        training jobs.\\n\\n  Returns:\\n    Dict mapping stats names to values.\\n\\n  Raises:\\n    ValueError: If max_npe or max_global_repetitions values are inconsistant\\n        across dicts in the `metrics` list.\\n  '\ncount = len(metrics)\nsuccess_count = 0\ntotal_npe = 0\nsuccess_npe = 0\nmax_npe = 0\nmax_repetitions = 0\nfor metric_dict in metrics:\n    if (not max_npe):\n        max_npe = metric_dict['max_npe']\n    elif (max_npe != metric_dict['max_npe']):\n        raise ValueError('Invalid experiment. Different reps have different max-NPE settings.')\n    if (not max_repetitions):\n        max_repetitions = metric_dict['max_global_repetitions']\n    elif (max_repetitions != metric_dict['max_global_repetitions']):\n        raise ValueError('Invalid experiment. Different reps have different num-repetition settings.')\n    if metric_dict['found_solution']:\n        success_count += 1\n        success_npe += metric_dict['npe']\n    total_npe += metric_dict['npe']\nstats = {}\nstats['max_npe'] = max_npe\nstats['max_repetitions'] = max_repetitions\nstats['repetitions'] = count\nstats['successes'] = success_count\nstats['failures'] = (count - success_count)\nstats['success_npe'] = success_npe\nstats['total_npe'] = total_npe\nif success_count:\n    stats['avg_success_npe'] = (stats['success_npe'] \/ float(success_count))\nelse:\n    stats['avg_success_npe'] = 0.0\nif count:\n    stats['success_rate'] = (success_count \/ float(count))\n    stats['avg_total_npe'] = (stats['total_npe'] \/ float(count))\nelse:\n    stats['success_rate'] = 0.0\n    stats['avg_total_npe'] = 0.0\nreturn stats\n"}
{"label_name":"train","label":0,"method_name":"check_freeze_layers_train_on_catdog_datasets_int","method":"\nwith TemporaryDirectory() as output_model_dir, TemporaryDirectory() as output_logs_dir:\n    trainer = Trainer(train_dataset_dir=train_path, val_dataset_dir=val_path, output_model_dir=output_model_dir, output_logs_dir=output_logs_dir, epochs=1, batch_size=1, model_kwargs={'alpha': 0.25}, freeze_layers_list=list(range(1, 10)), **trainer_args)\n    trainer.run()\n    for i in range(1, 10):\n        actual = trainer.model.layers[i].trainable\n        expected = False\n        assert (actual == expected)\n"}
{"label_name":"save","label":1,"method_name":"save_parameters_as_hdf5","method":"\nchainer.serializers.save_hdf5(filename, model)\nprint('model.h5 saved!\\n')\nprint('--- The list of saved params in model.h5 ---')\nf = h5py.File('model.h5', 'r')\nfor (param_key, param) in f.items():\n    msg = '{}:'.format(param_key)\n    if isinstance(param, h5py.Dataset):\n        msg += ' {}'.format(param.shape)\n    print(msg)\n    if isinstance(param, h5py.Group):\n        for (child_key, child) in param.items():\n            print('  {}:{}'.format(child_key, child.shape))\nprint('---------------------------------------------\\n')\n"}
{"label_name":"train","label":0,"method_name":"train_epoch_ch8","method":"\n'Train a model within one epoch (defined in Chapter 8).'\n(state, timer) = (None, d2l.Timer())\nmetric = d2l.Accumulator(2)\nfor (X, Y) in train_iter:\n    if ((state is None) or use_random_iter):\n        state = model.begin_state(batch_size=X.shape[0])\n    with tf.GradientTape(persistent=True) as g:\n        g.watch(params)\n        (y_hat, state) = model(X, state, params)\n        y = d2l.reshape(Y, (- 1))\n        l = loss(y, y_hat)\n    grads = g.gradient(l, params)\n    grads = grad_clipping(grads, 1)\n    updater.apply_gradients(zip(grads, params))\n    metric.add((l * d2l.size(y)), d2l.size(y))\nreturn (math.exp((metric[0] \/ metric[1])), (metric[1] \/ timer.stop()))\n"}
{"label_name":"train","label":0,"method_name":"_translate_train_sizes","method":"\n\"Determine absolute sizes of training subsets and validate 'train_sizes'.\\n\\n    Examples:\\n        _translate_train_sizes([0.5, 1.0], 10) -> [5, 10]\\n        _translate_train_sizes([5, 10], 10) -> [5, 10]\\n\\n    Parameters\\n    ----------\\n    train_sizes : array-like, shape (n_ticks,), dtype float or int\\n        Numbers of training examples that will be used to generate the\\n        learning curve. If the dtype is float, it is regarded as a\\n        fraction of 'n_max_training_samples', i.e. it has to be within (0, 1].\\n\\n    n_max_training_samples : int\\n        Maximum number of training samples (upper bound of 'train_sizes').\\n\\n    Returns\\n    -------\\n    train_sizes_abs : array, shape (n_unique_ticks,), dtype int\\n        Numbers of training examples that will be used to generate the\\n        learning curve. Note that the number of ticks might be less\\n        than n_ticks because duplicate entries will be removed.\\n    \"\ntrain_sizes_abs = np.asarray(train_sizes)\nn_ticks = train_sizes_abs.shape[0]\nn_min_required_samples = np.min(train_sizes_abs)\nn_max_required_samples = np.max(train_sizes_abs)\nif np.issubdtype(train_sizes_abs.dtype, np.floating):\n    if ((n_min_required_samples <= 0.0) or (n_max_required_samples > 1.0)):\n        raise ValueError(('train_sizes has been interpreted as fractions of the maximum number of training samples and must be within (0, 1], but is within [%f, %f].' % (n_min_required_samples, n_max_required_samples)))\n    train_sizes_abs = (train_sizes_abs * n_max_training_samples).astype(dtype=np.int, copy=False)\n    train_sizes_abs = np.clip(train_sizes_abs, 1, n_max_training_samples)\nelif ((n_min_required_samples <= 0) or (n_max_required_samples > n_max_training_samples)):\n    raise ValueError(('train_sizes has been interpreted as absolute numbers of training samples and must be within (0, %d], but is within [%d, %d].' % (n_max_training_samples, n_min_required_samples, n_max_required_samples)))\ntrain_sizes_abs = np.unique(train_sizes_abs)\nif (n_ticks > train_sizes_abs.shape[0]):\n    warnings.warn((\"Removed duplicate entries from 'train_sizes'. Number of ticks will be less than the size of 'train_sizes' %d instead of %d).\" % (train_sizes_abs.shape[0], n_ticks)), RuntimeWarning)\nreturn train_sizes_abs\n"}
{"label_name":"process","label":2,"method_name":"_process_name","method":"\nif ('.' in name):\n    newkeys = name.split('.')\n    name = newkeys.pop(0)\n    nested_dict = {newkeys.pop(): val}\n    for nk in reversed(newkeys):\n        nested_dict = {nk: nested_dict}\n    val = nested_dict\nreturn (name, val)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n'Train a model.'\nimport hwrt.train\nhwrt.train.main(model)\n"}
{"label_name":"process","label":2,"method_name":"process_text","method":"\nvocab = nltk.FreqDist()\nlens = []\nprev_perc = (- 1)\nprint('Processing text...')\nfor (i, row) in enumerate(rows):\n    perc = int((100 * (i \/ len(rows))))\n    if (perc != prev_perc):\n        if ((perc % 10) == 0):\n            print(perc, i)\n        prev_perc = perc\n    filename = row['Filename'][len('data\/'):].replace('.xml', '.fulltext.txt')\n    text_file = ((data_dir + 'text\/data\/') + filename)\n    with Path(text_file).open('r') as f:\n        text = tokenize(f.read().encode('ascii', errors='ignore').lower())\n    note_len = 0\n    for sent in text:\n        note_len += len(sent)\n        for word in sent:\n            vocab[word] += 1\n    lens.append(min(note_len, 4500))\nreturn (vocab, lens)\n"}
{"label_name":"predict","label":4,"method_name":"_register_prediction_method","method":"\n\ndef decorator(function):\n    aliases = set()\n    alias = normalise_string(name)\n    aliases.add(alias)\n    alias = alias.replace('_', '')\n    aliases.add(alias)\n    PREDICTION_METHODS[name] = {'aliases': aliases, 'function': function}\n    return function\nreturn decorator\n"}
{"label_name":"predict","label":4,"method_name":"predict","method":"\nx = para_data[:, :(- 1)]\nreturn np.array([predictOne(x[i, :], treeDict, compareMethod) for i in range(x.shape[0])])\n"}
{"label_name":"predict","label":4,"method_name":"_predict_gp","method":"\n(mu_gp, std_gp) = gp.predict(X, return_std=True)\nif subtract_noise:\n    noise = np.sqrt(gp.kernel_.get_params()['k2__noise_level'])\n    if (noise <= np.min(std_gp)):\n        std_gp = (std_gp - noise)\n    else:\n        std_gp = (std_gp - np.min(std_gp))\n        print('WARNING: GP noise is greater than prediction variances')\nreturn (mu_gp, std_gp)\n"}
{"label_name":"process","label":2,"method_name":"process_str","method":"\ncode = [header]\ncode.extend(parse_string(astr, global_names, 0, 1))\nreturn ''.join(code)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n(cfg, tokenizer, _, _) = nlp.models.bert.get_pretrained_bert(args.model_name, load_backbone=False, load_mlm=False)\ncfg = nlp.torch.models.bert.BertModel.get_cfg().clone_merge(cfg)\nmodel = nlp.torch.models.bert.QTBertForPretrain(cfg)\nmodel.to(args.device)\nif args.start_step:\n    logging.info('Restart training from {}'.format(args.start_step))\n    parameters_option(args.start_step, model, args, 'Loading')\nelse:\n    model.apply(nlp.torch.models.bert.init_weights)\nwriter = None\nif (args.local_rank in ((- 1), 0)):\n    writer = SummaryWriter(log_dir=os.path.join(args.ckpt_dir, 'tensorboard'))\nsampler = (RandomSampler(tbl) if (args.local_rank == (- 1)) else DistributedSampler(tbl, seed=args.seed))\ntrain_dataloader = DataLoader(np.arange(len(tbl)), sampler=sampler, collate_fn=functools.partial(collate_fn, args=args, tbl=tbl), batch_size=(args.batch_size \/\/ 2), num_workers=args.num_dataloader_workers, pin_memory=True)\nno_decay = ['bias', 'LayerNorm.weight']\noptimizer_grouped_parameters = [{'params': [p for (n, p) in model.named_parameters() if (not any(((nd in n) for nd in no_decay)))], 'weight_decay': args.weight_decay}, {'params': [p for (n, p) in model.named_parameters() if any(((nd in n) for nd in no_decay))], 'weight_decay': 0.0}]\noptimizer_arguments = {'lr': args.lr}\nif ((get_world_size(args) > 1) and args.ZeRO):\n    optimizer = OSS(params=model.parameters(), optim=nlp.torch.optimizers.FusedLANS, **optimizer_arguments)\n    model = ShardedDataParallel(model, optimizer)\nelif (get_world_size(args) > 1):\n    optimizer = nlp.torch.optimizers.FusedLANS(optimizer_grouped_parameters, **optimizer_arguments)\n    model = DistributedDataParallel(model, device_ids=[args.local_rank], output_device=args.local_rank, find_unused_parameters=True)\nelse:\n    optimizer = nlp.torch.optimizers.FusedLANS(optimizer_grouped_parameters, **optimizer_arguments)\nsave_interval = args.ckpt_interval\nlogging.info(f'#Total Training Steps={args.num_steps}, Warmup Steps={(args.warmup_ratio * args.num_steps)}, Save Interval={save_interval}')\nscheduler = nlp.torch.optimizers.schedules.get_warmup_linear_const_decay_poly_schedule(optimizer, total_steps=args.num_steps, warmup_ratio=args.warmup_ratio, const_ratio=args.const_ratio)\nif args.start_step:\n    logging.info(f'Restart training from {args.start_step}')\n    states_option(args.start_step, optimizer, args, 'Loading')\nce_loss_fn = th.nn.CrossEntropyLoss()\nstep_num = args.start_step\nif args.phase2:\n    step_num -= args.phase1_num_steps\n(running_num_tks, running_grad_norm) = (0, 0)\n(running_mlm_loss, running_qt_loss, running_mlm_acc, running_qt_acc) = (0, 0, 0, 0)\ntrain_start_time = time.time()\ntic = time.time()\nmodel.zero_grad()\nif ((get_world_size(args) > 1) and args.ZeRO):\n    scaler = (ShardedGradScaler() if args.fp16 else None)\nelse:\n    scaler = (th.cuda.amp.GradScaler() if args.fp16 else None)\ntrain_iter = repeat(train_dataloader, set_epoch=(args.local_rank != (- 1)))\nwhile (step_num < args.num_steps):\n    step_num += 1\n    for accum_step in range(args.num_accumulated):\n        (input_id, segment_id, valid_length, mlm_positions, mlm_labels) = next(train_iter)\n        (input_id, segment_id, valid_length, mlm_positions, mlm_labels) = (arr.to(args.device) for arr in next(train_iter))\n        model.train()\n        accumulation = (((accum_step + 1) % args.num_accumulated) != 0)\n        with (model.no_sync() if ((get_world_size(args) > 1) and accumulation) else suppress()):\n            with th.cuda.amp.autocast(enabled=args.fp16):\n                (_, pooled_out, mlm_scores, qt_similarity) = model(input_id, segment_id, valid_length, mlm_positions)\n                mlm_loss = ce_loss_fn(mlm_scores, mlm_labels)\n                qt_label = th.arange((len(input_id) \/\/ 2), device=args.device)\n                qt_loss = ce_loss_fn(qt_similarity, qt_label)\n                loss = (mlm_loss + qt_loss)\n            if (args.num_accumulated > 1):\n                loss = (loss \/ args.num_accumulated)\n            if args.fp16:\n                scaler.scale(loss).backward()\n            else:\n                loss.backward()\n            with th.no_grad():\n                qt_acc = ((qt_similarity.argmax(dim=1) == qt_label).sum() \/ (len(input_id) \/\/ 2))\n                mlm_acc = ((mlm_scores.argmax(dim=1) == mlm_labels).sum() \/ len(mlm_labels))\n        reduced_num_tokens = valid_length.sum()\n        if (get_world_size(args) > 1):\n            distributed.all_reduce(reduced_num_tokens)\n        reduced_num_mlm_tokens = th.tensor(len(mlm_labels), device=args.device)\n        if (get_world_size(args) > 1):\n            distributed.all_reduce(reduced_num_mlm_tokens)\n        reduced_loss_mlm = ((mlm_loss.detach().clone() * len(mlm_labels)) \/ reduced_num_mlm_tokens)\n        if (get_world_size(args) > 1):\n            distributed.all_reduce(reduced_loss_mlm)\n        reduced_acc_mlm = ((mlm_acc.detach().clone() * len(mlm_labels)) \/ reduced_num_mlm_tokens)\n        if (get_world_size(args) > 1):\n            distributed.all_reduce(reduced_acc_mlm)\n        reduced_bs = th.tensor(len(input_id), device=args.device)\n        if (get_world_size(args) > 1):\n            distributed.all_reduce(reduced_bs)\n        reduced_loss_qt = ((qt_loss.detach().clone() * len(input_id)) \/ reduced_bs)\n        if (get_world_size(args) > 1):\n            distributed.all_reduce(reduced_loss_qt)\n        reduced_acc_qt = ((qt_acc.detach().clone() * len(input_id)) \/ reduced_bs)\n        if (get_world_size(args) > 1):\n            distributed.all_reduce(reduced_acc_qt)\n        running_num_tks += reduced_num_tokens.item()\n        running_mlm_loss += reduced_loss_mlm.item()\n        running_mlm_acc += reduced_acc_mlm.item()\n        running_qt_loss += reduced_loss_qt.item()\n        running_qt_acc += reduced_acc_qt.item()\n        if (not accumulation):\n            if args.fp16:\n                scaler.unscale_(optimizer)\n            if ((get_world_size(args) > 1) and args.ZeRO):\n                total_norm = optimizer.clip_grad_norm(args.max_grad_norm)\n            else:\n                total_norm = th.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n                if (get_world_size(args) > 1):\n                    distributed.all_reduce(total_norm)\n                    total_norm \/= get_world_size(args)\n            running_grad_norm += total_norm\n            if args.fp16:\n                scaler.step(optimizer)\n                scaler.update()\n            else:\n                optimizer.step()\n            with warnings.catch_warnings():\n                warnings.simplefilter('ignore', UserWarning)\n                scheduler.step()\n            optimizer.zero_grad(set_to_none=True)\n    if ((step_num % args.log_interval) == 0):\n        toc = time.time()\n        wps = (running_num_tks \/ (toc - tic))\n        eta = (((args.num_steps - step_num) \/ (step_num \/ (toc - train_start_time))) \/ 3600)\n        interval = (args.log_interval * args.num_accumulated)\n        logging.info(f'[Step {step_num}], LR={scheduler.get_last_lr()[0]:.6f}, Loss MLM\/QT={(running_mlm_loss \/ interval):.4f}\/{(running_qt_loss \/ interval):.4f}, Acc MLM\/QT={(running_mlm_acc \/ interval):.4f}\/{(running_qt_acc \/ interval):.4f}, Grad_norm={(running_grad_norm \/ interval):.4f}, Time cost={(toc - tic):.2f}, Throughput={wps:.2f} tokens\/s, ETA={eta:.2f}h')\n        if (args.local_rank in ((- 1), 0)):\n            writer.add_scalar('Throughput_wps', wps, step_num)\n            writer.add_scalar('Loss\/MLM', (running_mlm_loss \/ interval), step_num)\n            writer.add_scalar('Loss\/QT', (running_qt_loss \/ interval), step_num)\n            writer.add_scalar('Acc\/MLM', (running_mlm_acc \/ interval), step_num)\n            writer.add_scalar('Acc\/QT', (running_qt_acc \/ interval), step_num)\n            writer.add_scalar('LR', scheduler.get_last_lr()[0], step_num)\n            writer.add_scalar('Grad_norm', (running_grad_norm \/ interval), step_num)\n        (running_num_tks, running_grad_norm) = (0, 0)\n        (running_mlm_loss, running_qt_loss, running_mlm_acc, running_qt_acc) = (0, 0, 0, 0)\n        tic = time.time()\n    if (((step_num % save_interval) == 0) or (step_num >= args.num_steps)):\n        states_option(step_num, optimizer, args, 'Saving')\n        if (args.local_rank in (0, (- 1))):\n            parameters_option(step_num, model, args, 'Saving')\nlogging.info('Finish training step: %d', step_num)\ntrain_end_time = time.time()\nlogging.info('Train cost={:.1f} s'.format((train_end_time - train_start_time)))\nif (args.local_rank in (0, (- 1))):\n    save_dir = os.path.join(args.ckpt_dir, args.model_name)\n    final_save(model, save_dir, tokenizer.vocab, cfg)\n"}
{"label_name":"process","label":2,"method_name":"preprocess_text","method":"\nnfkd_form = unicodedata.normalize('NFKD', text)\ntext = nfkd_form.encode('ASCII', 'ignore').decode('ASCII')\ntext = re.sub('http(s)?:\/\/\\\\S*', ' ', text)\nif to_lower:\n    text = text.lower()\nif norm_num:\n    text = re.sub('[0-9]', '1', text)\ntext = re.sub('[^A-Za-z0-9-]+', ' ', text)\ntext = re.sub('\\\\s+', ' ', text)\nreturn text.strip()\n"}
{"label_name":"train","label":0,"method_name":"train_step","method":"\nwith tf.GradientTape() as tape:\n    y_pred = softmax_regression(x)\n    loss = cross_entropy_loss(y_pred, y)\ngradients = tape.gradient(loss, [W, b])\noptimizer.apply_gradients(zip(gradients, [W, b]))\n"}
{"label_name":"train","label":0,"method_name":"_unconstrain","method":"\nwith torch.no_grad():\n    if callable(constrained_value):\n        constrained_value = constrained_value()\n    unconstrained_value = transform_to(constraint).inv(constrained_value.detach())\n    return torch.nn.Parameter(unconstrained_value)\n"}
{"label_name":"process","label":2,"method_name":"sample_MA_process_ARMA","method":"\nnp.random.seed(1234)\ndist = (lambda size: np.random.normal(0, 1, size))\narparams = np.array([])\nmaparams = np.array(theta)\narparams = np.r_[(1, arparams)]\nmaparams = np.r_[(1, maparams)]\narma_t = ArmaProcess(arparams, maparams)\nreturn arma_t.generate_sample(nsample=realisations, distrvs=dist)\n"}
{"label_name":"process","label":2,"method_name":"processing_output","method":"\nreturn ProcessingOutput(source='\/opt\/ml\/processing\/spark-events\/', destination=SPARK_EVENT_LOGS_S3_URI, s3_upload_mode='Continuous')\n"}
{"label_name":"process","label":2,"method_name":"_process_image","method":"\n\"Process a single image file.\\n\\n  Args:\\n    filename: string, path to an image file e.g., '\/path\/to\/example.JPG'.\\n    coder: instance of ImageCoder to provide TensorFlow image coding utils.\\n  Returns:\\n    image_buffer: string, JPEG encoding of RGB image.\\n    height: integer, image height in pixels.\\n    width: integer, image width in pixels.\\n  \"\nwith tf.gfile.FastGFile(filename, 'rb') as f:\n    image_data = f.read()\nif _is_png(filename):\n    print(('Converting PNG to JPEG for %s' % filename))\n    image_data = coder.png_to_jpeg(image_data)\nimage = coder.decode_jpeg(image_data)\nassert (len(image.shape) == 3)\nheight = image.shape[0]\nwidth = image.shape[1]\nassert (image.shape[2] == 3)\nreturn (image_data, height, width)\n"}
{"label_name":"train","label":0,"method_name":"_get_pretrain_model","method":"\ntagger = PerceptronTagger()\ntraining = _load_data_conll_format('english_ptb_train.conll')\ntesting = _load_data_conll_format('english_ptb_test.conll')\nprint('Size of training and testing (sentence)', len(training), len(testing))\ntagger.train(training, PICKLE)\nprint('Accuracy : ', tagger.evaluate(testing))\n"}
{"label_name":"predict","label":4,"method_name":"show_tables_predict","method":"\nif (uploaded_file != ''):\n    print('tuning>>>>>', uploaded_file)\n    metadata_folder = os.path.join(MARKET_PATH, uploaded_file.replace('.csv', ''))\n    metadata_filename = (uploaded_file.replace('.csv', '') + '_meta.json')\n    metadata_path = os.path.join(metadata_folder, metadata_filename)\n    with open(metadata_path, 'r') as f:\n        metadata = json.load(f)\n    filename_path = os.path.join(metadata_folder, uploaded_file)\n    df = pd.read_csv(filename_path)\n    df = df.sample(10)\n    df_predict = df.copy()\n    df_predict[metadata['response']] = np.zeros(len(df))\n    df_predict.rename(columns={metadata['response']: 'prediction'}, inplace=True)\n    columns_table = [{'name': i, 'id': i, 'deletable': True} for i in df.columns]\n    columns_table_predict = [{'name': i, 'id': i, 'deletable': True} for i in df_predict.columns]\n    return tuple([df.to_dict('rows'), columns_table, df_predict.to_dict('rows'), columns_table_predict])\nreturn tuple([None for _ in range(4)])\n"}
{"label_name":"process","label":2,"method_name":"grad_process_and_td_error_fn","method":"\nreturn apply_grad_clipping(policy, optimizer, loss)\n"}
{"label_name":"process","label":2,"method_name":"preprocess_price_data","method":"\n'\\n    Currently, the sp500 and stock price datasets we downloaded do not have any data for\\n    days when the market was closed (weekends and public holidays). We need to amend this so that\\n    all rows are included. Doing this now saves a lot of effort when we actually create the\\n    keystats dataset, which requires that we have stock data every day.\\n    :return: SP500 and stock dataframes, with no missing rows.\\n    '\nsp500_raw_data = pd.read_csv('sp500_index.csv', index_col='Date', parse_dates=True)\nstock_raw_data = pd.read_csv('stock_prices.csv', index_col='Date', parse_dates=True)\nstart_date = str(stock_raw_data.index[0])\nend_date = str(stock_raw_data.index[(- 1)])\nidx = pd.date_range(start_date, end_date)\nsp500_raw_data = sp500_raw_data.reindex(idx)\nstock_raw_data = stock_raw_data.reindex(idx)\nsp500_raw_data.ffill(inplace=True)\nstock_raw_data.ffill(inplace=True)\nreturn (sp500_raw_data, stock_raw_data)\n"}
{"label_name":"predict","label":4,"method_name":"combine_prediction_metadata_batches","method":"\n'Combines a list of dicts with the same keys and lists as values into a single dict with concatenated lists\\n        for each corresponding key\\n\\n    Args:\\n        metadata_list (list): list of dicts with matching keys and lists for values\\n\\n    Returns:\\n        dict: combined single dict\\n    '\ncombined_metadata = {}\nfor metadata_batch in metadata_list:\n    for meta_el in metadata_batch:\n        if (meta_el not in combined_metadata):\n            combined_metadata[meta_el] = []\n        combined_metadata[meta_el] += metadata_batch[meta_el]\nreturn combined_metadata\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n'\\n    Command to train ML model(s) locally\\n    '\nlogger.info(ASCII_LOGO)\nlogger.info('Started local training...\\n')\ntry:\n    config = ConfigManager(os.path.join('.sagify.json')).get_config()\n    api_local.train(dir=config.sagify_module_dir, docker_tag=obj['docker_tag'], image_name=config.image_name)\n    logger.info('Local training completed successfully!')\nexcept ValueError:\n    logger.info('This is not a sagify directory: {}'.format(dir))\n    sys.exit((- 1))\nexcept subprocess.CalledProcessError as e:\n    logger.debug(e.output)\n    raise\nexcept Exception as e:\n    logger.info('{}'.format(e))\n    sys.exit((- 1))\n"}
{"label_name":"process","label":2,"method_name":"process_dataset_splits","method":"\nsplits = defaultdict(list)\nfor (sample_id, sample) in dataset.samples:\n    sample_split = sample_split_fn(sample)\n    if (sample_split is not None):\n        splits[sample_split].append(sample_id)\nif log:\n    print('Processed {} samples'.format(len(dataset.samples)))\n    for (split_name, split_ids) in splits.items():\n        print('Found {} samples for {}'.format(len(split_ids), split_name))\nif save:\n    if log:\n        print('Saving data splits to: {}'.format(dataset.split_path))\n    dataset.splits = splits\n    dataset.dump_splits()\nreturn splits\n"}
{"label_name":"train","label":0,"method_name":"train_epoch","method":"\nfor metric in metrics:\n    metric.reset()\nmodel.train()\nlosses = []\ntotal_loss = 0\nfor (batch_idx, (data, target)) in enumerate(train_loader):\n    target = (target if (len(target) > 0) else None)\n    if (not (type(data) in (tuple, list))):\n        data = (data,)\n    if cuda:\n        data = tuple((d.cuda() for d in data))\n        if (target is not None):\n            target = target.cuda()\n    optimizer.zero_grad()\n    outputs = model(*data)\n    if (type(outputs) not in (tuple, list)):\n        outputs = (outputs,)\n    loss_inputs = outputs\n    if (target is not None):\n        target = (target,)\n        loss_inputs += target\n    loss_outputs = loss_fn(*loss_inputs)\n    loss = (loss_outputs[0] if (type(loss_outputs) in (tuple, list)) else loss_outputs)\n    losses.append(loss.item())\n    total_loss += loss.item()\n    loss.backward()\n    optimizer.step()\n    for metric in metrics:\n        metric(outputs, target, loss_outputs)\n    if ((batch_idx % log_interval) == 0):\n        message = 'Train: [{}\/{} ({:.0f}%)]\\tLoss: {:.6f}'.format((batch_idx * len(data[0])), len(train_loader.dataset), ((100.0 * batch_idx) \/ len(train_loader)), np.mean(losses))\n        for metric in metrics:\n            message += '\\t{}: {}'.format(metric.name(), metric.value())\n        print(message)\n        losses = []\ntotal_loss \/= (batch_idx + 1)\nreturn (total_loss, metrics)\n"}
{"label_name":"train","label":0,"method_name":"retrain","method":"\n'Train a language model on top of the given language model.'\nfrom langdist.langmodel import CharLSTM\nchar_lstm = CharLSTM.load(old_model_path)\nchar_lstm.train(**train_args)\n"}
{"label_name":"predict","label":4,"method_name":"_df_self_predict_proba","method":"\nreturn misc.self_predict_proba(clf, self, y, cv)\n"}
{"label_name":"train","label":0,"method_name":"get_standard_tsn_training_transform","method":"\n'\\n    This function return a composed transform ready to be pluged into the TSN dataset for training\\n    :param std:\\n    :param mean:\\n    :param input_size: the expected networks input size\\n    :param scales: scales in scale jittering\\n    :param is_flow: whether to flip the image in the flow style\\n    :return:\\n    '\n(mean, std) = parse_mean_std(mean, std, is_flow)\nif is_flow:\n    scales = (1, 0.875, 0.75)\nimage_wise = Compose([ToNumpy(), Normalize(mean=mean, std=std), ToCNNInput()])\ntransform = Compose([StackImage((2 if (not is_flow) else 3)), Compose([GroupMultiScaleCrop(input_size, scales), GroupRandomHorizontalFlip(is_flow=is_flow)]), GroupApply(image_wise)])\nreturn transform\n"}
{"label_name":"train","label":0,"method_name":"change_trainable","method":"\n\" Helper method that fixes some of Keras' issues with wrappers and\\n        trainability. Freezes or unfreezes a given layer.\\n\\n    # Arguments:\\n        layer: Layer to be modified.\\n        trainable: Whether the layer should be frozen or unfrozen.\\n        verbose: Verbosity flag.\\n    \"\nlayer.trainable = trainable\nif (type(layer) == Bidirectional):\n    layer.backward_layer.trainable = trainable\n    layer.forward_layer.trainable = trainable\nif (type(layer) == TimeDistributed):\n    layer.backward_layer.trainable = trainable\nif verbose:\n    action = ('Unfroze' if trainable else 'Froze')\n    print('{} {}'.format(action, layer.name))\n"}
{"label_name":"predict","label":4,"method_name":"_check_prediction_aligns_with_story","method":"\n'Emit a warning if predictions do not align with expected actions.'\n(p, a) = align_lists(last_prediction, actions_between_utterances)\nif (p != a):\n    warnings.warn('Model predicted different actions than the model used to create the story! Expected: {} but got {}.'.format(p, a))\n"}
{"label_name":"train","label":0,"method_name":"generate_train_samples","method":"\ntotal_start_points = ((len(x) - input_seq_len) - output_seq_len)\nstart_x_idx = np.random.choice(range(total_start_points), batch_size, replace=False)\ninput_batch_idxs = [list(range(i, (i + input_seq_len))) for i in start_x_idx]\ninput_seq = np.take(x, input_batch_idxs, axis=0)\noutput_batch_idxs = [list(range((i + input_seq_len), ((i + input_seq_len) + output_seq_len))) for i in start_x_idx]\noutput_seq = np.take(y, output_batch_idxs, axis=0)\nreturn (input_seq, output_seq)\n"}
{"label_name":"save","label":1,"method_name":"save_modules","method":"\n'\\n    Context in which imported modules are saved.\\n\\n    Translates exceptions internal to the context into the equivalent exception\\n    outside the context.\\n    '\nsaved = sys.modules.copy()\nwith ExceptionSaver() as saved_exc:\n    (yield saved)\nsys.modules.update(saved)\ndel_modules = (mod_name for mod_name in sys.modules if ((mod_name not in saved) and (not mod_name.startswith('encodings.'))))\n_clear_modules(del_modules)\nsaved_exc.resume()\n"}
{"label_name":"train","label":0,"method_name":"get_scaled_train_image","method":"\nreturn Image.open(get_train_image_path(ndx)).reduce(factor)\n"}
{"label_name":"train","label":0,"method_name":"add_final_training_ops","method":"\n\"Adds a new softmax and fully-connected layer for training.\\n\\n  We need to retrain the top layer to identify our new classes, so this function\\n  adds the right operations to the graph, along with some variables to hold the\\n  weights, and then sets up all the gradients for the backward pass.\\n\\n  The set up for the softmax and fully-connected layers is based on:\\n  https:\/\/tensorflow.org\/versions\/master\/tutorials\/mnist\/beginners\/index.html\\n\\n  Args:\\n    class_count: Integer of how many categories of things we're trying to\\n    recognize.\\n    final_tensor_name: Name string for the new final node that produces results.\\n    bottleneck_tensor: The output of the main CNN graph.\\n\\n  Returns:\\n    The tensors for the training and cross entropy results, and tensors for the\\n    bottleneck input and ground truth input.\\n  \"\nwith tf.name_scope('input'):\n    bottleneck_input = tf.placeholder_with_default(bottleneck_tensor, shape=[None, BOTTLENECK_TENSOR_SIZE], name='BottleneckInputPlaceholder')\n    ground_truth_input = tf.placeholder(tf.float32, [None, class_count], name='GroundTruthInput')\nlayer_name = 'final_training_ops'\nwith tf.name_scope(layer_name):\n    with tf.name_scope('weights'):\n        layer_weights = tf.Variable(tf.truncated_normal([BOTTLENECK_TENSOR_SIZE, class_count], stddev=0.001), name='final_weights')\n        variable_summaries(layer_weights)\n    with tf.name_scope('biases'):\n        layer_biases = tf.Variable(tf.zeros([class_count]), name='final_biases')\n        variable_summaries(layer_biases)\n    with tf.name_scope('Wx_plus_b'):\n        logits = (tf.matmul(bottleneck_input, layer_weights) + layer_biases)\n        tf.summary.histogram('pre_activations', logits)\nfinal_tensor = tf.nn.softmax(logits, name=final_tensor_name)\ntf.summary.histogram('activations', final_tensor)\nwith tf.name_scope('cross_entropy'):\n    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=ground_truth_input, logits=logits)\n    with tf.name_scope('total'):\n        cross_entropy_mean = tf.reduce_mean(cross_entropy)\ntf.summary.scalar('cross_entropy', cross_entropy_mean)\nwith tf.name_scope('train'):\n    train_step = tf.train.GradientDescentOptimizer(FLAGS.learning_rate).minimize(cross_entropy_mean)\nreturn (train_step, cross_entropy_mean, bottleneck_input, ground_truth_input, final_tensor)\n"}
{"label_name":"predict","label":4,"method_name":"make_prediction","method":"\n(server_name, server_port) = _tf_server_connection_params()\nlog.info('Connecting to TensorFlow server %s:%s', server_name, server_port)\nstub = _open_tf_server_channel(server_name, server_port)\nrequest = _create_prediction_request(state)\nreturn _make_prediction_and_prepare_results(stub, request)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\nLOG.info('Training ...')\ngym = GymRunnerRemote(name=multiprocessing.current_process().name, metrics_engine=metrics_engine, metrics_config=metrics_config)\nagent = Agent(hparams=hparams, model_config=model_config)\nreturn gym.train(agent, episodes, render=render, file_name=file_name)\n"}
{"label_name":"process","label":2,"method_name":"preprocess","method":"\ntext = text.lower()\ntext = text.replace('.', ' <PERIOD> ')\ntext = text.replace(',', ' <COMMA> ')\ntext = text.replace('\"', ' <QUOTATION_MARK> ')\ntext = text.replace(';', ' <SEMICOLON> ')\ntext = text.replace('!', ' <EXCLAMATION_MARK> ')\ntext = text.replace('?', ' <QUESTION_MARK> ')\ntext = text.replace('(', ' <LEFT_PAREN> ')\ntext = text.replace(')', ' <RIGHT_PAREN> ')\ntext = text.replace('--', ' <HYPHENS> ')\ntext = text.replace('?', ' <QUESTION_MARK> ')\ntext = text.replace(':', ' <COLON> ')\nwords = text.split()\nword_counts = Counter(words)\ntrimmed_words = [word for word in words if (word_counts[word] > 5)]\nreturn trimmed_words\n"}
{"label_name":"save","label":1,"method_name":"save_model","method":"\n'\\n    Save the model in standard SavedModel format.\\n    \\n    Args:\\n      model_path: The path to model.\\n      model_version: The version of model.\\n      sess: The TensorFlow Session object.\\n      signature_def_map: The map of TensorFlow SignatureDef object.\\n      is_save_graph: Should save graph file of not.\\n    \\n    Return:\\n      None\\n    '\nexport_path = os.path.join(model_path, str(model_version))\nif (os.path.isdir(export_path) == True):\n    logging.error('The model exists in path: {}'.format(export_path))\n    return\ntry:\n    legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')\n    builder = saved_model_builder.SavedModelBuilder(export_path)\n    builder.add_meta_graph_and_variables(sess, [tag_constants.SERVING], clear_devices=True, signature_def_map=signature_def_map, legacy_init_op=legacy_init_op)\n    logging.info('Save the model in: {}'.format(export_path))\n    builder.save()\n    if (is_save_graph == True):\n        graph_file_name = 'graph.pb'\n        logging.info('Save the graph file in: {}'.format(model_path))\n        tf.train.write_graph(sess.graph_def, model_path, graph_file_name, as_text=False)\nexcept Exception as e:\n    logging.error('Fail to export saved model, exception: {}'.format(e))\n"}
{"label_name":"predict","label":4,"method_name":"predictions_gt_images_handler","method":"\n\ndef wrapper(engine, logger, event_name):\n    batch = engine.state.batch\n    output = engine.state.output\n    (x, y) = batch\n    y_pred = output[0]\n    if ((y.shape == y_pred.shape) and (y.ndim == 4)):\n        y = torch.argmax(y, dim=1)\n    y_pred = torch.argmax(y_pred, dim=1).byte()\n    if (n_images is not None):\n        x = x[:n_images, ...]\n        y = y[:n_images, ...]\n        y_pred = y_pred[:n_images, ...]\n    grid_pred_gt = make_grid(x, y_pred, img_denormalize_fn, batch_gt=y)\n    state = (engine.state if (another_engine is None) else another_engine.state)\n    global_step = state.get_event_attrib_value(event_name)\n    tag = 'predictions_with_gt'\n    if (prefix_tag is not None):\n        tag = f'{prefix_tag}: {tag}'\n    logger.writer.add_image(tag=tag, img_tensor=grid_pred_gt, global_step=global_step, dataformats='HWC')\nreturn wrapper\n"}
{"label_name":"process","label":2,"method_name":"preprocess_imu_data","method":"\nfor file in imu_files:\n    if (check_file_not_empty(file) is True):\n        name = os.path.basename(file)\n        new_name = '-'.join([str(p_num), name])\n        new_path = os.path.join(processed_imu_data, new_name)\n        if (('orientationEuler' in file) or ('orientation' not in file)):\n            data = pd.read_csv(file, skiprows=1, header=None).as_matrix([1, 2, 3])\n        else:\n            data = pd.read_csv(file, skiprows=1, header=None).as_matrix([1, 2, 3, 4])\n        if contains_nans(data):\n            data = remove_nans(data)\n            if (len(data) > 0):\n                pass\n            else:\n                break\n        normalised_data = normalise_data(data)\n        scaled_data = scale_data(normalised_data)\n        df = DataFrame(scaled_data)\n        df.to_csv(new_path)\n        print(new_path)\n    else:\n        pass\n"}
{"label_name":"save","label":1,"method_name":"_savez","method":"\nimport zipfile\nimport tempfile\nif isinstance(file, basestring):\n    if (not file.endswith('.npz')):\n        file = (file + '.npz')\nelif is_pathlib_path(file):\n    if (not file.name.endswith('.npz')):\n        file = (file.parent \/ (file.name + '.npz'))\nnamedict = kwds\nfor (i, val) in enumerate(args):\n    key = ('arr_%d' % i)\n    if (key in namedict.keys()):\n        raise ValueError(('Cannot use un-named variables and keyword %s' % key))\n    namedict[key] = val\nif compress:\n    compression = zipfile.ZIP_DEFLATED\nelse:\n    compression = zipfile.ZIP_STORED\nzipf = zipfile_factory(file, mode='w', compression=compression)\n(file_dir, file_prefix) = (os.path.split(file) if _is_string_like(file) else (None, 'tmp'))\n(fd, tmpfile) = tempfile.mkstemp(prefix=file_prefix, dir=file_dir, suffix='-numpy.npy')\nos.close(fd)\ntry:\n    for (key, val) in namedict.items():\n        fname = (key + '.npy')\n        fid = open(tmpfile, 'wb')\n        try:\n            format.write_array(fid, np.asanyarray(val), allow_pickle=allow_pickle, pickle_kwargs=pickle_kwargs)\n            fid.close()\n            fid = None\n            zipf.write(tmpfile, arcname=fname)\n        except IOError as exc:\n            raise IOError(('Failed to write to %s: %s' % (tmpfile, exc)))\n        finally:\n            if fid:\n                fid.close()\nfinally:\n    os.remove(tmpfile)\nzipf.close()\n"}
{"label_name":"train","label":0,"method_name":"training_model","method":"\nmodel.fit(X_train, Y_train, epochs=10, verbose=0, callbacks=[his])\nvisual.update_line(his.loss, his.accuracy)\niterator = ((step_visual + 1) * 10)\nif ((iterator % 50) == 0):\n    print(('============= Iterator %d ================' % iterator))\n    scores = model.evaluate(X_train, Y_train, verbose=0)\n    print(('Evalute model: %s = %.4f' % (model.metrics_names[0], scores[0])))\n    print(('Evalute model: %s = %.4f' % (model.metrics_names[1], (scores[1] * 100))))\nreturn model\n"}
{"label_name":"process","label":2,"method_name":"_should_preprocess","method":"\nreturn (layer_type not in ['timing', 'pos_emb', 'att_memory_efficient'])\n"}
{"label_name":"save","label":1,"method_name":"save_obj_detect_image","method":"\ndset = (get_random_dset() if (dset is None) else dset)\nentry = data.make_obj_detect_entry(annos)\nfold = data.load_fold(project)\nif (id_ in fold[cfg.UNLABELED]):\n    data.move_unlabeled_to_labeled(fold, dset, id_, entry)\nelse:\n    for dset in [cfg.VAL, cfg.TRAIN]:\n        if (id_ in fold[dset]):\n            fold[dset][id_] = entry\n            break\n"}
{"label_name":"save","label":1,"method_name":"save_scores","method":"\nprint('Saving scores')\n(probs, preds) = get_preds(exp, loader)\ntargs = loader.dataset.targets\nloss = metric_utils.get_cross_entropy_loss(probs, targs)\nscores_fpath = get_scores_fpath(proj_name)\nscores = load_scores(scores_fpath)\nscores['experiments'][exp.name] = exp.history.metrics_history\nscores['counts'] = get_img_counts(proj_name)\nscores['experiments'][exp.name]['created'] = time.strftime('%m\/%d\/%Y %H:%M:%S', time.localtime())\nfor m in exp.metrics:\n    scores['latest'][m.name] = m.evaluate(loss, preds, probs, targs)\nutils.files.save_json(scores_fpath, scores)\n"}
{"label_name":"train","label":0,"method_name":"print_trainer_logs","method":"\navg_loss = engine.state.metrics['loss']\navg_bce = engine.state.metrics['bce']\navg_kld = engine.state.metrics['kld']\nprint('Trainer Results - Epoch {} - Avg loss: {:.2f} Avg bce: {:.2f} Avg kld: {:.2f}'.format(engine.state.epoch, avg_loss, avg_bce, avg_kld))\n"}
{"label_name":"process","label":2,"method_name":"call_subprocess","method":"\nif show_stdout:\n    stdout = None\nelse:\n    stdout = subprocess.PIPE\nif (command_desc is None):\n    cmd_parts = []\n    for part in cmd:\n        if ((' ' in part) or ('\\n' in part) or ('\"' in part) or (\"'\" in part)):\n            part = ('\"%s\"' % part.replace('\"', '\\\\\"'))\n        cmd_parts.append(part)\n    command_desc = ' '.join(cmd_parts)\nlogger.debug('Running command %s', command_desc)\nenv = os.environ.copy()\nif extra_environ:\n    env.update(extra_environ)\ntry:\n    proc = subprocess.Popen(cmd, stderr=subprocess.STDOUT, stdin=None, stdout=stdout, cwd=cwd, env=env)\nexcept Exception as exc:\n    logger.critical('Error %s while executing command %s', exc, command_desc)\n    raise\nif (stdout is not None):\n    all_output = []\n    while True:\n        line = console_to_str(proc.stdout.readline())\n        if (not line):\n            break\n        line = line.rstrip()\n        all_output.append((line + '\\n'))\n        if (logger.getEffectiveLevel() <= std_logging.DEBUG):\n            logger.debug(line)\n        elif (spinner is not None):\n            spinner.spin()\nproc.wait()\nif (spinner is not None):\n    if proc.returncode:\n        spinner.finish('error')\n    else:\n        spinner.finish('done')\nif proc.returncode:\n    if (on_returncode == 'raise'):\n        if ((logger.getEffectiveLevel() > std_logging.DEBUG) and (not show_stdout)):\n            logger.info('Complete output from command %s:', command_desc)\n            logger.info((''.join(all_output) + '\\n----------------------------------------'))\n        raise InstallationError(('Command \"%s\" failed with error code %s in %s' % (command_desc, proc.returncode, cwd)))\n    elif (on_returncode == 'warn'):\n        logger.warning('Command \"%s\" had error code %s in %s', command_desc, proc.returncode, cwd)\n    elif (on_returncode == 'ignore'):\n        pass\n    else:\n        raise ValueError(('Invalid value: on_returncode=%s' % repr(on_returncode)))\nif (not show_stdout):\n    return ''.join(all_output)\n"}
{"label_name":"forward","label":3,"method_name":"forward","method":"\n\ndef backprop(d_output: InT) -> InT:\n    dX = backprop_layer(d_output)\n    if isinstance(d_output, list):\n        return [(d_output[i] + dX[i]) for i in range(len(d_output))]\n    elif isinstance(d_output, Ragged):\n        return Ragged((d_output.data + dX.data), dX.lengths)\n    elif isinstance(X, Padded):\n        dX.data += d_output.data\n        return dX\n    else:\n        return (d_output + dX)\n(Y, backprop_layer) = model.layers[0](X, is_train)\nif isinstance(X, list):\n    return ([(X[i] + Y[i]) for i in range(len(X))], backprop)\nelif isinstance(X, Ragged):\n    return (Ragged((X.data + Y.data), X.lengths), backprop)\nelif isinstance(X, Padded):\n    Y.data += X.data\n    return (Y, backprop)\nelse:\n    return ((X + Y), backprop)\n"}
{"label_name":"save","label":1,"method_name":"save_abc","method":"\nfolder = 'epoch_data'\nif (not os.path.exists(folder)):\n    os.makedirs(folder)\nsmi_file = os.path.join(folder, (name + '.abc'))\nwith open(smi_file, 'w') as afile:\n    afile.write('\\n'.join(smiles))\nreturn\n"}
{"label_name":"save","label":1,"method_name":"save_axes","method":"\n'Save matplotlib axes `ax` to an image `filename`.'\nfig = plt.gcf()\nfig.add_axes(ax)\nfig.savefig(filename)\n"}
{"label_name":"train","label":0,"method_name":"mock_train_regressor","method":"\n'Mock the train_regressor to return the mocked regressor instead'\n\ndef train_regressor(model, data, **kwargs):\n    'Return the mocked model, and then model argument if requested'\n    if assert_model:\n        assert (model == assert_model)\n    if assert_model_kwargs:\n        assert (kwargs == assert_model_kwargs)\n    return mock_model()\nmonkeypatch.setattr('orion.analysis.partial_dependency_utils.train_regressor', train_regressor)\n"}
{"label_name":"save","label":1,"method_name":"save_images","method":"\nfig = plt.figure(1)\nfig.clf()\nax = fig.add_subplot(111)\nplot_images(images, ax, **kwargs)\nfig.patch.set_visible(False)\nax.patch.set_visible(False)\nplt.savefig(filename)\n"}
{"label_name":"predict","label":4,"method_name":"compute_batch_predictions","method":"\n'\\n    Format predictions from different heads\\n    '\nbatch_prediction_dict = col.OrderedDict([((label_name, view_angle), np.exp(y_hat[view_angle][:, i].cpu().detach().numpy())) for (i, label_name) in enumerate(LABELS.LIST) for view_angle in VIEWANGLES.LIST])\nreturn batch_prediction_dict\n"}
{"label_name":"save","label":1,"method_name":"make_save_path","method":"\n\"\\n    Generate the base save path for a classifier's model and metrics files,\\n    based on the classifier's dataset name and hyperparameters.\\n    \"\nrun_name = ''.join([c for c in classifier.datarun.dataset.name if (c.isalnum() or (c in (' ', '-', '_')))]).rstrip()\nparams_hash = hash_dict(classifier.hyperparameter_values)[:8]\nfilename = ('%s-%s.%s' % (run_name, params_hash, suffix))\nreturn os.path.join(dir, filename)\n"}
{"label_name":"train","label":0,"method_name":"expand_training_data","method":"\nexpanded_images = []\nexpanded_labels = []\ndirectory = os.path.dirname('data\/New')\nif (not tf.gfile.Exists('data\/New')):\n    tf.gfile.MakeDirs('data\/New')\nk = 0\nfor (x, y) in zip(images, labels):\n    k = (k + 1)\n    if ((k % 100) == 0):\n        print(('expanding data : %03d \/ %03d' % (k, np.size(images, 0))))\n    expanded_images.append(x)\n    expanded_labels.append(y)\n    bg_value = (- 0.5)\n    image = np.reshape(x, ((- 1), 28))\n    for i in range(4):\n        angle = np.random.randint((- 90), 90, 1)\n        new_img = ndimage.rotate(image, angle, reshape=False, cval=bg_value)\n        shift = np.random.randint((- 2), 2, 2)\n        new_img_ = ndimage.shift(new_img, shift, cval=bg_value)\n        image1 = ((image * 255) + (255 \/ 2.0))\n        new_img1 = ((new_img_ * 255) + (255 \/ 2.0))\n        new_img2 = np.reshape(new_img_, (28, 28, 1))\n        expanded_images.append(new_img2)\n        expanded_labels.append(y)\nexpandedX = np.asarray(expanded_images)\nexpandedY = np.asarray(expanded_labels)\nreturn (expandedX, expandedY)\n"}
{"label_name":"train","label":0,"method_name":"training_cross_valid","method":"\nkf = KFold(n_splits=10, shuffle=True)\ncvscores = []\nfor (train, test) in kf.split(x_train):\n    model.fit(x_train[train], y_train[train], epochs=epochs, batch_size=batch_size, verbose=0)\n    scores = model.evaluate(x_train[test], y_train[test], verbose=0)\n    print(('%s: %.2f%%' % (model.metrics_names[1], (scores[1] * 100))))\n    print(('%s: %f' % (model.metrics_names[0], scores[0])))\n    cvscores.append((scores[1] * 100))\nprint(('%.2f%% (+\/- %.2f%%)' % (np.mean(cvscores), np.std(cvscores))))\nreturn model\n"}
{"label_name":"predict","label":4,"method_name":"create_predictions_df","method":"\nsubmission = meta[['id']]\npredictions_ = pd.DataFrame(predictions, columns=columns)\nsubmission.reset_index(drop=True, inplace=True)\npredictions_.reset_index(drop=True, inplace=True)\nsubmission = pd.concat([submission, predictions_], axis=1)\nreturn submission\n"}
{"label_name":"train","label":0,"method_name":"load_train_data","method":"\next = filename.split('.')[(- 1)]\nif (ext == 'csv'):\n    return read_smiles_csv(filename)\nif (ext == 'smi'):\n    return read_smi(filename)\nelse:\n    raise ValueError('data is not smi or csv!')\nreturn\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\noptimizer.zero_grad()\noutput = model(input)\nloss = criterion(output, label)\nloss.backward()\noptimizer.step()\nreturn (output, loss.data[0])\n"}
{"label_name":"train","label":0,"method_name":"recurse_train","method":"\nglobal total_class\nLEAF = 'leaf'\nINTERNAL = 'internal'\nlabel_set = set(train_label)\nif (len(label_set) == 1):\n    return Tree(LEAF, Class=label_set.pop())\n(max_class, max_len) = max([(i, len(list(filter((lambda x: (x == i)), train_label)))) for i in range(total_class)], key=(lambda x: x[1]))\nif (len(features) == 0):\n    return Tree(LEAF, Class=max_class)\nmax_feature = 0\nmax_gda = 0\nfor feature in features:\n    A = np.array(train_set[:, feature].flat)\n    gda = calc_ent_grap(A, train_label)\n    if (gda > max_gda):\n        (max_gda, max_feature) = (gda, feature)\nif (max_gda < epsilon):\n    return Tree(LEAF, Class=max_class)\nsub_features = list(filter((lambda x: (x != max_feature)), features))\ntree = Tree(INTERNAL, feature=max_feature)\nfeature_col = np.array(train_set[:, max_feature].flat)\nfeature_value_list = set([feature_col[i] for i in range(feature_col.shape[0])])\nfor feature_value in feature_value_list:\n    index = []\n    for i in range(len(train_label)):\n        if (train_set[i][max_feature] == feature_value):\n            index.append(i)\n    sub_train_set = train_set[index]\n    sub_train_label = train_label[index]\n    sub_tree = recurse_train(sub_train_set, sub_train_label, sub_features, epsilon)\n    tree.add_tree(feature_value, sub_tree)\nreturn tree\n"}
{"label_name":"predict","label":4,"method_name":"predict","method":"\nimage_np = np.array(image)\nimage_np_expanded = np.expand_dims(image_np, axis=0)\n(boxes, scores, classes, num) = sess.run([detection_boxes, detection_scores, detection_classes, num_detections], feed_dict={image_tensor: image_np_expanded})\nmin_score_thresh = 0.01\n'\\n        \"1478019952686311006\": {\\n            \"img_id\": \"1478019952686311006\",\\n            \"bboxes\": [\\n                {\\n                    \"label\": \"pedestrian\",\\n                    \"score\": 0.326338529586792,\\n                    \"xmin\": 1725.1727294921875,\\n                    \"ymin\": 484.7314453125,\\n                    \"xmax\": 1812.0869140625,\\n                    \"ymax\": 718.4708862304688\\n                }\\n            ]\\n        },\\n      '\ndata[img_id] = {'img_id': img_id, 'bboxes': []}\n(width, height) = image.size\nscores2 = np.squeeze(scores)\nboxes2 = np.squeeze(boxes)\nclasses2 = np.squeeze(classes).astype(np.int32)\nboxes = []\nfor i in range(boxes2.shape[0]):\n    if ((scores2 is None) or (scores2[i] > min_score_thresh)):\n        box = tuple(boxes2[i].tolist())\n        if (classes2[i] in category_index.keys()):\n            class_name = category_index[classes2[i]]['name']\n        x = int(round((box[1] * width)))\n        y = int(round((box[0] * height)))\n        x2 = int(round((box[3] * width)))\n        y2 = int(round((box[2] * height)))\n        onebox = {'label': class_name, 'score': float(scores2[i]), 'xmin': x, 'ymin': y, 'xmax': x2, 'ymax': y2}\n        boxes.append(onebox)\ndata[img_id]['bboxes'] = boxes\n"}
{"label_name":"train","label":0,"method_name":"get_train_data","method":"\n'\\n    \u8ba1\u7b97\u8bad\u7ec3\u6570\u636e\u7279\u5f81\uff0c\u8fd4\u56de\u7279\u5f81\u77e9\u9635\u548c\u5bf9\u5e94\u7684\u7c7b\u522b\u6807\u7b7e\\n    '\n(traces, labels) = readdata('data_train.txt')\nx = apply_all(functions, traces)\nreturn (x, labels)\n"}
{"label_name":"train","label":0,"method_name":"train_rest_subscore","method":"\nbiz = df.loc[(df['business_id'] == bizid)]\nrating = biz['stars']\npreference = biz['preference']\nresult = min_loss(preference.values, rating.values)\nreturn result.x\n"}
{"label_name":"train","label":0,"method_name":"train_step","method":"\nwith tf.GradientTape() as tape:\n    y_pred = model(x)\n    loss = cross_entropy_loss(y_pred, y)\ngradients = tape.gradient(loss, vars(model).values())\noptimizer.apply_gradients(zip(gradients, vars(model).values()))\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\nhidden = rnn.initHidden()\nrnn.zero_grad()\nfor i in range(line_tensor.size()[0]):\n    (output, hidden) = rnn(line_tensor[i], hidden)\nloss = criterion(output, category_tensor)\nloss.backward()\nfor p in rnn.parameters():\n    p.data.add_((- learning_rate), p.grad.data)\nreturn (output, loss.data[0])\n"}
{"label_name":"train","label":0,"method_name":"load_trained_model","method":"\nmodel_path = locate_model(model_name_or_path)\nfrom ..parse_chart import ChartParser\nparser = ChartParser.from_trained(model_path)\nreturn parser\n"}
{"label_name":"process","label":2,"method_name":"get_process_umask","method":"\nresult = os.umask(18)\nos.umask(result)\nreturn result\n"}
{"label_name":"save","label":1,"method_name":"save_accuracy","method":"\nplt.figure(figsize=(10, 8))\nplt.plot(acc_dis, label='discriminitive accuracy')\nplt.plot(acc_gen, label='generative accuracy')\nplt.legend()\nplt.savefig('MNIST_ACCURACY.png')\n"}
{"label_name":"save","label":1,"method_name":"save_image","method":"\n'\\n    Save a batch of phrases to a single image grid.\\n\\n    Arguments\\n    ---------\\n    filepath : str\\n        Path to save the image grid.\\n    phrases : np.array, ndim=5\\n        The phrase array. Shape is (num_phrase, num_bar, num_time_step,\\n        num_pitch, num_track).\\n    shape : list or tuple of int\\n        Shape of the image grid. (height, width)\\n    inverted : bool\\n        True to invert the colors. Default to False.\\n    grid_width : int\\n        Width of the grid lines. Default to 2.\\n    grid_color : int\\n        Color of the grid lines. Available values are 0 (black) to\\n        255 (white). Default to 255.\\n    frame : bool\\n        True to add frame. Default to False.\\n    '\nif (phrases.dtype == np.bool_):\n    if inverted:\n        phrases = np.logical_not(phrases)\n    clipped = (phrases * 255).astype(np.uint8)\nelse:\n    if inverted:\n        phrases = (1.0 - phrases)\n    clipped = (phrases * 255.0).clip(0, 255).astype(np.uint8)\nmerged = get_image_grid(clipped, shape, grid_width, grid_color, frame)\nimageio.imwrite(filepath, merged)\n"}
{"label_name":"process","label":2,"method_name":"pre_process_dialouge","method":"\nprint('Extracting file')\nstart = time.time()\ndelete_all_file_dir(pre_processed_dir, type_d)\n(dialogue_file1, dialogue_file2) = dialouge_seperator_cornell_movie(raw_dialogue_file_path, dialogue_file1, dialogue_file2, symbol_seq, max_dialouge_count, max_len)\n(train_file1, train_file2, test_file1, test_file2, dev_file1, dev_file2) = train_test_split(dialogue_file1, dialogue_file2, max_dialouge_count_train_test, train_percentile, train_file1, train_file2, test_file1, test_file2, dev_file1, dev_file2, max_test_dev_count)\nend = time.time()\ntime_lib.elapsed_time(start, end)\nreturn (train_file1, train_file2, test_file1, test_file2, dev_file1, dev_file2)\n"}
{"label_name":"train","label":0,"method_name":"_load_trained_cnn_layer","method":"\nmodel = load_model(model_path)\ndense_output = K.function([model.layers[0].input, K.learning_phase()], [model.layers[layer_index].output])\nreturn (lambda X: dense_output([X, 0])[0])\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\ndefault_rf = RandomForestClassifier()\ndefault_rf.fit(x_train, y_train)\nbest_rf = default_rf\nmax_accuracy = default_rf.score(x_test, y_test)\nbest_params = 'Default'\nmethod_params_found = 'Default'\ny_score = default_rf.predict(x_test)\ndate_time = datetime.datetime.now()\nmsg = '{0}: The best RF classifier was trained with the parameters {1} which produced an accuracy score of: {2}for {3} data. These parameters were found using the {4} method.'.format(str(date_time), str(best_params), str(max_accuracy), str(sensor_data), str(method_params_found))\nprint(msg)\nlogging.info(msg)\nreturn_values[1] = {'model': best_rf, 'model_type': 'RF', 'sensor_data': sensor_data, 'max_accuracy': max_accuracy, 'best_params': best_params, 'method': method_params_found, 'y_score': y_score, 'y_test': y_test}\n"}
{"label_name":"process","label":2,"method_name":"img_preprocess","method":"\nmean = [103.939, 116.779, 123.68]\nimg = imread(img_path)\nif augment:\n    img = randomizer(img)\nif (len(img.shape) == 2):\n    img = np.dstack([img, img, img])\nresFac = (256.0 \/ min(img.shape[:2]))\nnewSize = list(map(int, ((img.shape[0] * resFac), (img.shape[1] * resFac))))\nimg = resize(img, newSize, mode='constant', preserve_range=True)\noffset = [((newSize[0] \/ 2.0) - np.floor((size \/ 2.0))), ((newSize[1] \/ 2.0) - np.floor((size \/ 2.0)))]\nimg = img[int(offset[0]):(int(offset[0]) + size), int(offset[1]):(int(offset[1]) + size), :]\nimg[:, :, 0] -= mean[2]\nimg[:, :, 1] -= mean[1]\nimg[:, :, 2] -= mean[0]\nimg[:, :, [0, 1, 2]] = img[:, :, [2, 1, 0]]\nimg = np.reshape(img, [1, size, size, 3])\nreturn img\n"}
{"label_name":"train","label":0,"method_name":"train_dataset_from_algorithm","method":"\n'Trains a dataset given an algorithm\\n\\n    It is able to save the progress of training.\\n    :param str dataset_path: The path where binary dataset is located\\n    :param dict algorithm: An algorithm to be used in dataset training\\n    '\ndataset_dao = data_access.DatasetDAO()\ndataset_dao.set_algorithm(dataset_id, algorithm_dict['id'])\ndataset_dao.update_status(dataset_id, (RUNNING_TASK_MASK | TRAINED_MASK))\n(dataset_dto, err) = dataset_dao.get_dataset_by_id(dataset_id)\ndtset_path = dataset_dto.get_binary_dataset()\ndtset = dataset.Dataset()\ndtset.load_from_binary(dtset_path)\nredis = self.app.backend\ncelery_uuid = ('celery-task-progress-' + self.request.id)\nprogress = {'current': (- 1), 'total': algorithm_dict['max_epochs'], 'current_steps': None, 'total_steps': None}\nredis.set(celery_uuid, json.dumps({'progress': progress}).encode('utf-8'))\n\ndef status_callback(trainer):\n    'Saves the progress of the task on redis db'\n    print('Status Callback. Trainer {}'.format(trainer.epoch))\n    task = redis.get(celery_uuid).decode('utf-8')\n    task = json.loads(task)\n    task['progress']['current'] = trainer.epoch\n    task = json.dumps(task).encode('utf-8')\n    redis.set(celery_uuid, task)\n    return\nkwargs = {'train_all': True, 'test_all': (- 1), 'model_type': skge.TransE, 'ncomp': algorithm_dict['embedding_size'], 'margin': algorithm_dict['margin'], 'max_epochs': algorithm_dict['max_epochs'], 'external_callback': status_callback}\nmodel = algorithm.ModelTrainer(dtset, **kwargs)\nmodeloentrenado = model.run()\nmodel_path = (dtset_path[:(- 4)] + '_model.bin')\nmodeloentrenado.save(model_path)\ndataset_dao.update_status(dataset_id, TRAINED_MASK, statusAnd=14)\ndataset_dao.set_model(dataset_id, model_path)\nreturn False\n"}
{"label_name":"train","label":0,"method_name":"attention_decoder_fn_train","method":"\n'Attentional decoder function for `dynamic_rnn_decoder` during training.\\n\\n  The `attention_decoder_fn_train` is a training function for an\\n  attention-based sequence-to-sequence model. It should be used when\\n  `dynamic_rnn_decoder` is in the training mode.\\n\\n  The `attention_decoder_fn_train` is called with a set of the user arguments\\n  and returns the `decoder_fn`, which can be passed to the\\n  `dynamic_rnn_decoder`, such that\\n\\n  ```\\n  dynamic_fn_train = attention_decoder_fn_train(encoder_state)\\n  outputs_train, state_train = dynamic_rnn_decoder(\\n      decoder_fn=dynamic_fn_train, ...)\\n  ```\\n\\n  Further usage can be found in the `kernel_tests\/seq2seq_test.py`.\\n\\n  Args:\\n    encoder_state: The encoded state to initialize the `dynamic_rnn_decoder`.\\n    attention_keys: to be compared with target states.\\n    attention_values: to be used to construct context vectors.\\n    attention_score_fn: to compute similarity between key and target states.\\n    attention_construct_fn: to build attention states.\\n    name: (default: `None`) NameScope for the decoder function;\\n      defaults to \"simple_decoder_fn_train\"\\n\\n  Returns:\\n    A decoder function with the required interface of `dynamic_rnn_decoder`\\n    intended for training.\\n  '\nwith tf.name_scope(name, 'attention_decoder_fn_train', [encoder_state, attention_keys, attention_values, attention_score_fn, attention_construct_fn]):\n    pass\n\ndef decoder_fn(time, cell_state, cell_input, cell_output, context_state):\n    'Decoder function used in the `dynamic_rnn_decoder` for training.\\n\\n    Args:\\n      time: positive integer constant reflecting the current timestep.\\n      cell_state: state of RNNCell.\\n      cell_input: input provided by `dynamic_rnn_decoder`.\\n      cell_output: output of RNNCell.\\n      context_state: context state provided by `dynamic_rnn_decoder`.\\n\\n    Returns:\\n      A tuple (done, next state, next input, emit output, next context state)\\n      where:\\n\\n      done: `None`, which is used by the `dynamic_rnn_decoder` to indicate\\n      that `sequence_lengths` in `dynamic_rnn_decoder` should be used.\\n\\n      next state: `cell_state`, this decoder function does not modify the\\n      given state.\\n\\n      next input: `cell_input`, this decoder function does not modify the\\n      given input. The input could be modified when applying e.g. attention.\\n\\n      emit output: `cell_output`, this decoder function does not modify the\\n      given output.\\n\\n      next context state: `context_state`, this decoder function does not\\n      modify the given context state. The context state could be modified when\\n      applying e.g. beam search.\\n    '\n    with tf.name_scope(name, 'attention_decoder_fn_train', [time, cell_state, cell_input, cell_output, context_state]):\n        if (cell_state is None):\n            cell_state = encoder_state\n            attention = _init_attention(encoder_state)\n        else:\n            attention = attention_construct_fn(cell_output, attention_keys, attention_values)\n            cell_output = attention\n        next_input = tf.concat([cell_input, attention], 1)\n        return (None, cell_state, next_input, cell_output, context_state)\nreturn decoder_fn\n"}
{"label_name":"predict","label":4,"method_name":"predict","method":"\nn = data[0].shape[0]\nresult = list()\nfor i in range(n):\n    result.append(list())\npredictions = model.predict(data, batch_size=batch_size, verbose=1)\nfor i in range(n):\n    pred = (predictions[i] >= threshold).astype('int32')\n    for j in range(len(functions)):\n        if (pred[j] == 1):\n            result[i].append(((((model_name + '_') + functions[j]) + '|') + ('%.2f' % predictions[i][j])))\nreturn result\n"}
{"label_name":"save","label":1,"method_name":"save_json","method":"\nwith open(fpath, 'w') as f:\n    json.dump(dict_, f, indent=4, ensure_ascii=False)\n"}
{"label_name":"process","label":2,"method_name":"_process_images_dir","method":"\nlogger.info(\"Loading ImageSetLabels from '%s'\", data.image_set_labels_path)\nimage_set_labels = etai.ImageSetLabels.from_json(data.image_set_labels_path)\nimage_filenames = set(etau.list_files(data.images_dir))\nfor image_labels in image_set_labels:\n    filename = image_labels.filename\n    if (not filename):\n        logger.warning('Skipping ImageLabels with no `filename`')\n        continue\n    if (filename not in image_filenames):\n        logger.warning(\"Skipping '%s'; not found in '%s'\", filename, data.images_dir)\n        continue\n    inpath = os.path.join(data.images_dir, filename)\n    outpath = os.path.join(data.output_dir, filename)\n    logger.info(\"Annotating image '%s'\", inpath)\n    img = etai.read(inpath)\n    img_anno = etaa.annotate_image(img, image_labels, annotation_config=annotation_config)\n    logger.info(\"Writing annotated image to '%s'\", outpath)\n    etai.write(img_anno, outpath)\n"}
{"label_name":"process","label":2,"method_name":"process_clarans","method":"\ninstance = clarans(sample, NUMBER_CLUSTERS, 10, 3)\n(ticks, _) = timedcall(instance.process)\nreturn ticks\n"}
{"label_name":"process","label":2,"method_name":"process_comment","method":"\nresult = ''\nleading_spaces = float('inf')\nfor s in comment.expandtabs(tabsize=4).splitlines():\n    s = s.strip()\n    if s.startswith('\/*'):\n        s = s[2:].lstrip('*')\n    elif s.endswith('*\/'):\n        s = s[:(- 2)].rstrip('*')\n    elif s.startswith('\/\/\/'):\n        s = s[3:]\n    if s.startswith('*'):\n        s = s[1:]\n    if (len(s) > 0):\n        leading_spaces = min(leading_spaces, (len(s) - len(s.lstrip())))\n    result += (s + '\\n')\nif (leading_spaces != float('inf')):\n    result2 = ''\n    for s in result.splitlines():\n        result2 += (s[leading_spaces:] + '\\n')\n    result = result2\ncpp_group = '([\\\\w:]+)'\nparam_group = '([\\\\[\\\\w:\\\\]]+)'\ns = result\ns = re.sub(('\\\\\\\\c\\\\s+%s' % cpp_group), '``\\\\1``', s)\ns = re.sub(('\\\\\\\\a\\\\s+%s' % cpp_group), '*\\\\1*', s)\ns = re.sub(('\\\\\\\\e\\\\s+%s' % cpp_group), '*\\\\1*', s)\ns = re.sub(('\\\\\\\\em\\\\s+%s' % cpp_group), '*\\\\1*', s)\ns = re.sub(('\\\\\\\\b\\\\s+%s' % cpp_group), '**\\\\1**', s)\ns = re.sub(('\\\\\\\\ingroup\\\\s+%s' % cpp_group), '', s)\ns = re.sub(('\\\\\\\\param%s?\\\\s+%s' % (param_group, cpp_group)), '\\\\n\\\\n$Parameter ``\\\\2``:\\\\n\\\\n', s)\ns = re.sub(('\\\\\\\\tparam%s?\\\\s+%s' % (param_group, cpp_group)), '\\\\n\\\\n$Template parameter ``\\\\2``:\\\\n\\\\n', s)\nfor (in_, out_) in {'return': 'Returns', 'author': 'Author', 'authors': 'Authors', 'copyright': 'Copyright', 'date': 'Date', 'remark': 'Remark', 'sa': 'See also', 'see': 'See also', 'extends': 'Extends', 'throw': 'Throws', 'throws': 'Throws'}.items():\n    s = re.sub(('\\\\\\\\%s\\\\s*' % in_), ('\\\\n\\\\n$%s:\\\\n\\\\n' % out_), s)\ns = re.sub('\\\\\\\\details\\\\s*', '\\\\n\\\\n', s)\ns = re.sub('\\\\\\\\brief\\\\s*', '', s)\ns = re.sub('\\\\\\\\short\\\\s*', '', s)\ns = re.sub('\\\\\\\\ref\\\\s*', '', s)\ns = re.sub('\\\\\\\\code\\\\s?(.*?)\\\\s?\\\\\\\\endcode', '```\\\\n\\\\1\\\\n```\\\\n', s, flags=re.DOTALL)\ns = re.sub('<tt>(.*?)<\/tt>', '``\\\\1``', s, flags=re.DOTALL)\ns = re.sub('<pre>(.*?)<\/pre>', '```\\\\n\\\\1\\\\n```\\\\n', s, flags=re.DOTALL)\ns = re.sub('<em>(.*?)<\/em>', '*\\\\1*', s, flags=re.DOTALL)\ns = re.sub('<b>(.*?)<\/b>', '**\\\\1**', s, flags=re.DOTALL)\ns = re.sub('\\\\\\\\f\\\\$(.*?)\\\\\\\\f\\\\$', '$\\\\1$', s, flags=re.DOTALL)\ns = re.sub('<li>', '\\\\n\\\\n* ', s)\ns = re.sub('<\/?ul>', '', s)\ns = re.sub('<\/li>', '\\\\n\\\\n', s)\ns = s.replace('``true``', '``True``')\ns = s.replace('``false``', '``False``')\nwrapper = textwrap.TextWrapper()\nwrapper.expand_tabs = True\nwrapper.replace_whitespace = True\nwrapper.drop_whitespace = True\nwrapper.width = 70\nwrapper.initial_indent = wrapper.subsequent_indent = ''\nresult = ''\nin_code_segment = False\nfor x in re.split('(```)', s):\n    if (x == '```'):\n        if (not in_code_segment):\n            result += '```\\n'\n        else:\n            result += '\\n```\\n\\n'\n        in_code_segment = (not in_code_segment)\n    elif in_code_segment:\n        result += x.strip()\n    else:\n        for y in re.split('(?: *\\\\n *){2,}', x):\n            wrapped = wrapper.fill(re.sub('\\\\s+', ' ', y).strip())\n            if ((len(wrapped) > 0) and (wrapped[0] == '$')):\n                result += (wrapped[1:] + '\\n')\n                wrapper.initial_indent = wrapper.subsequent_indent = (' ' * 4)\n            else:\n                if (len(wrapped) > 0):\n                    result += (wrapped + '\\n\\n')\n                wrapper.initial_indent = wrapper.subsequent_indent = ''\nreturn result.rstrip().lstrip('\\n')\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\n'train this model with a specific learning rate\\n    '\ntf.summary.scalar('loss', loss)\nglobal_step = tf.Variable(0, name='gloal_step', trainable=False)\ntraining = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss=loss, global_step=global_step, name='training_phrase')\nreturn training\n"}
{"label_name":"process","label":2,"method_name":"preprocess","method":"\n'Selects the subset of viewpoints to train on.'\nshp = raw_inputs['images'].get_shape().as_list()\nquantity = shp[0]\nnum_views = shp[1]\nimage_size = shp[2]\ndel image_size\nbatch_rot = np.zeros((quantity, 3), dtype=np.float32)\ninputs = dict()\nfor n in xrange((step_size + 1)):\n    inputs[('images_%d' % n)] = []\n    inputs[('masks_%d' % n)] = []\nfor n in xrange(quantity):\n    view_in = np.random.randint(0, num_views)\n    rng_rot = np.random.randint(0, 2)\n    if (step_size == 1):\n        rng_rot = np.random.randint(0, 3)\n    delta = 0\n    if (rng_rot == 0):\n        delta = (- 1)\n        batch_rot[(n, 2)] = 1\n    elif (rng_rot == 1):\n        delta = 1\n        batch_rot[(n, 0)] = 1\n    else:\n        delta = 0\n        batch_rot[(n, 1)] = 1\n    inputs['images_0'].append(raw_inputs['images'][n, view_in, :, :, :])\n    inputs['masks_0'].append(raw_inputs['masks'][n, view_in, :, :, :])\n    view_out = view_in\n    for k in xrange(1, (step_size + 1)):\n        view_out += delta\n        if (view_out >= num_views):\n            view_out = 0\n        if (view_out < 0):\n            view_out = (num_views - 1)\n        inputs[('images_%d' % k)].append(raw_inputs['images'][n, view_out, :, :, :])\n        inputs[('masks_%d' % k)].append(raw_inputs['masks'][n, view_out, :, :, :])\nfor n in xrange((step_size + 1)):\n    inputs[('images_%d' % n)] = tf.stack(inputs[('images_%d' % n)])\n    inputs[('masks_%d' % n)] = tf.stack(inputs[('masks_%d' % n)])\ninputs['actions'] = tf.constant(batch_rot, dtype=tf.float32)\nreturn inputs\n"}
{"label_name":"train","label":0,"method_name":"train_stateless","method":"\nmodel = create_model_stateless(args['seq_len'], args['seq_dim'], hidden_units=params['hidden_units'], activation=params['activation'], hidden_layers=params['hidden_layers'], kernel_initializer=params['kernel_initializer'], kernel_regularizer=params['kernel_regularizer'])\nmodel.fit(x_train, y_train, epochs=params['epochs'], batch_size=params['batch_size'], verbose=False)\nreturn (model.get_config(), model.get_weights(), params)\n"}
{"label_name":"train","label":0,"method_name":"train_ch6","method":"\n'Train a model with a GPU (defined in Chapter 6).'\ndevice_name = device._device_name\nstrategy = tf.distribute.OneDeviceStrategy(device_name)\nwith strategy.scope():\n    optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n    net = net_fn()\n    net.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\ncallback = TrainCallback(net, train_iter, test_iter, num_epochs, device_name)\nnet.fit(train_iter, epochs=num_epochs, verbose=0, callbacks=[callback])\nreturn net\n"}
{"label_name":"predict","label":4,"method_name":"predict_gender","method":"\n\"\\n    Predict the gender of the given name string.\\n\\n    :param name: name string that you want to predict the gender\\n    :param return_proba: if True, return probability estimate of the name belonging to each gender\\n    :param return_attention: if True, return attention (weight for each word)\\n    :param neutral_cutoff: if the probability is lower than this threshold for both genders, it\\n                           returns 'neutral'. [default: 0.8] (only relevant when return_proba=False)\\n    :return: str (male or female) or dict of {'male': male_proba, 'female': female_proba} or\\n        tuple of aforementioned plus attentions\\n    \"\nreturn_value = predict_genders([name], return_proba, return_attention, neutral_cutoff)\nif return_attention:\n    (predictions, attentions) = return_value\nelse:\n    (predictions, attentions) = (return_value, None)\nif attentions:\n    return (predictions[0], attentions[0])\nelse:\n    return predictions[0]\n"}
{"label_name":"train","label":0,"method_name":"train_model","method":"\n(train_generator, validation_generator) = generators\nmodel.fit_generator(train_generator, steps_per_epoch=100, validation_data=validation_generator, validation_steps=10, epochs=nb_epoch, callbacks=callbacks)\nreturn model\n"}
{"label_name":"process","label":2,"method_name":"pre_process_dialouge","method":"\nprint('Extracting file')\nstart = time.time()\ndelete_all_file_dir(pre_processed_dir, type_d)\nif (movie_dir_name == cornell_movie_dir):\n    (dialogue_file1, dialogue_file2) = dialouge_seperator_cornell_movie(raw_dialogue_file_path, dialogue_file1, dialogue_file2, symbol_seq, max_dialouge_count, max_len)\nelif (movie_dir_name == open_subtitles_dir):\n    (dialogue_file1, dialogue_file2) = dialouge_seperator_open_subtitle(raw_dialogue_file_path, dialogue_file1, dialogue_file2, max_dialouge_count)\nelif (movie_dir_name == movie_subtitles_dir):\n    (dialogue_file1, dialogue_file2) = dialouge_seperator_movie_subtitle(raw_dialogue_file_path, dialogue_file1, dialogue_file2, max_dialouge_count)\nelse:\n    print('directory match not found')\n    return\n(train_file1, train_file2, test_file1, test_file2, dev_file1, dev_file2) = train_test_split(dialogue_file1, dialogue_file2, max_dialouge_count_train_test, train_percentile, train_file1, train_file2, test_file1, test_file2, dev_file1, dev_file2, max_test_dev_count)\n'\\n\\tvocab_dict1 = get_vocab(train_file1)\\n\\tvocab_dict2 = get_vocab(train_file2)\\n\\n\\twrite_dict(vocab_file1, vocab_dict1, \"key\")\\n\\twrite_dict(vocab_file2, vocab_dict2, \"key\")\\n    '\ncompare_chat_reply(dialogue_file1, dialogue_file2, compare_count, type_rand)\nend = time.time()\ntime_lib.elapsed_time(start, end)\n"}
{"label_name":"save","label":1,"method_name":"savemat","method":"\n\"\\n    Save a dictionary of names and arrays into a MATLAB-style .mat file.\\n\\n    This saves the array objects in the given dictionary to a MATLAB-\\n    style .mat file.\\n\\n    Parameters\\n    ----------\\n    file_name : str or file-like object\\n        Name of the .mat file (.mat extension not needed if ``appendmat ==\\n        True``).\\n        Can also pass open file_like object.\\n    mdict : dict\\n        Dictionary from which to save matfile variables.\\n    appendmat : bool, optional\\n        True (the default) to append the .mat extension to the end of the\\n        given filename, if not already present.\\n    format : {'5', '4'}, string, optional\\n        '5' (the default) for MATLAB 5 and up (to 7.2),\\n        '4' for MATLAB 4 .mat files.\\n    long_field_names : bool, optional\\n        False (the default) - maximum field name length in a structure is\\n        31 characters which is the documented maximum length.\\n        True - maximum field name length in a structure is 63 characters\\n        which works for MATLAB 7.6+.\\n    do_compression : bool, optional\\n        Whether or not to compress matrices on write.  Default is False.\\n    oned_as : {'row', 'column'}, optional\\n        If 'column', write 1-D numpy arrays as column vectors.\\n        If 'row', write 1-D numpy arrays as row vectors.\\n\\n    See also\\n    --------\\n    mio4.MatFile4Writer\\n    mio5.MatFile5Writer\\n    \"\nfile_opened = False\nif hasattr(file_name, 'write'):\n    file_stream = file_name\nelse:\n    if isinstance(file_name, string_types):\n        if (appendmat and (not file_name.endswith('.mat'))):\n            file_name = (file_name + '.mat')\n    file_stream = open(file_name, 'wb')\n    file_opened = True\nif (format == '4'):\n    if long_field_names:\n        raise ValueError('Long field names are not available for version 4 files')\n    MW = MatFile4Writer(file_stream, oned_as)\nelif (format == '5'):\n    MW = MatFile5Writer(file_stream, do_compression=do_compression, unicode_strings=True, long_field_names=long_field_names, oned_as=oned_as)\nelse:\n    raise ValueError(\"Format should be '4' or '5'\")\nMW.put_variables(mdict)\nif file_opened:\n    file_stream.close()\n"}
{"label_name":"save","label":1,"method_name":"save_image","method":"\nimage = (image + MEAN_VALUES)\nimage = image[0]\nimage = np.clip(image, 0, 255).astype('uint8')\nscipy.misc.imsave(path, image)\n"}
{"label_name":"train","label":0,"method_name":"train_on_experience","method":"\nworker = multiprocessing.Process(target=train_worker, args=(learning_agent, output_file, experience_file, lr, batch_size))\nworker.start()\nworker.join()\n"}
{"label_name":"process","label":2,"method_name":"ornsteinuhlenbeck_process","method":"\n'Builds an exploration based on the Ornstein-Uhlenbeck process\\n\\n    The process adds time-correlated noise to the actions taken by the deterministic policy.\\n    The OU process satisfies the following stochastic differential equation:\\n    `dxt = theta*(mu - xt)*dt + sigma*dWt`, where Wt denotes the Wiener process.\\n    '\nstate = (tf.ones([num_actions]) * mu)\ndx = ((theta * (mu - state)) + (sigma * tf.random_uniform([num_actions], 0, 1).eval()))\nreturn tf.assign(state, (state + dx))\n"}
{"label_name":"save","label":1,"method_name":"_save","method":"\nreturn JpegImagePlugin._save(im, fp, filename)\n"}
{"label_name":"train","label":0,"method_name":"train_model","method":"\nlog.info('Training Model')\ndx = np.shape(X)[1]\ndu = np.shape(U)[1]\ndt = np.shape(dX)[1]\nif (model_cfg.training.dx != (- 1)):\n    assert (model_cfg.training.dx == dx), 'model dimensions in cfg do not match data given'\nif (model_cfg.training.du != (- 1)):\n    assert (model_cfg.training.dx == du), 'model dimensions in cfg do not match data given'\nif (model_cfg.training.dt != (- 1)):\n    assert (model_cfg.training.dx == dt), 'model dimensions in cfg do not match data given'\ntrain_log = dict()\nnn_params = {'dx': dx, 'du': du, 'dt': dt, 'hid_width': model_cfg.training.hid_width, 'hid_depth': model_cfg.training.hid_depth, 'bayesian_flag': model_cfg.training.probl, 'activation': Swish(), 'dropout': model_cfg.training.extra.dropout, 'split_flag': False, 'ensemble': model_cfg.ensemble}\ntrain_params = {'epochs': model_cfg.optimizer.epochs, 'batch_size': model_cfg.optimizer.batch, 'optim': model_cfg.optimizer.name, 'split': model_cfg.optimizer.split, 'lr': model_cfg.optimizer.lr, 'lr_schedule': model_cfg.optimizer.lr_schedule, 'test_loss_fnc': [], 'preprocess': model_cfg.optimizer.preprocess}\ntrain_log['nn_params'] = nn_params\ntrain_log['train_params'] = train_params\nif model_cfg.ensemble:\n    newNN = EnsembleNN(nn_params, model_cfg.training.E)\n    (acctest, acctrain) = newNN.train_cust((X, U, dX), train_params)\nelse:\n    newNN = GeneralNN(nn_params)\n    newNN.init_weights_orth()\n    if nn_params['bayesian_flag']:\n        newNN.init_loss_fnc(dX, l_mean=1, l_cov=1)\n    (acctest, acctrain) = newNN.train_cust((X, U, dX), train_params)\nif model_cfg.ensemble:\n    min_err = np.min(acctrain, 0)\n    min_err_test = np.min(acctest, 0)\nelse:\n    min_err = np.min(acctrain)\n    min_err_test = np.min(acctest)\ntrain_log['testerror'] = acctest\ntrain_log['trainerror'] = acctrain\ntrain_log['min_trainerror'] = min_err\ntrain_log['min_testerror'] = min_err_test\nreturn (newNN, train_log)\n"}
{"label_name":"process","label":2,"method_name":"pre_process","method":"\nmean = np.mean(X_train, axis=0)\nstd = np.std(X_train, axis=0)\nfor i in range(len(X_train[0])):\n    for j in range(len(X_train)):\n        if (X_train[j][i] > (mean[i] + (ratio[0] * std[i]))):\n            X_train[j][i] = (mean[i] + (ratio[0] * std[i]))\n        elif (X_train[j][i] < (mean[i] - (ratio[0] * std[i]))):\n            X_train[j][i] = (mean[i] - (ratio[0] * std[i]))\n        else:\n            pass\nmean = np.mean(y_train, axis=0)\nstd = np.std(y_train, axis=0)\nfor i in range(len(y_train)):\n    if (y_train[i] > (mean + (ratio[1] * std))):\n        y_train[i] = (mean + (ratio[1] * std))\n    elif (y_train[i] < (mean - (ratio[1] * std))):\n        y_train[i] = (mean - (ratio[1] * std))\n    else:\n        pass\nreturn (X_train, y_train)\n"}
{"label_name":"train","label":0,"method_name":"train_online","method":"\n(state_dim, action_dim) = env_dims(env)\nreplay_buffer = SampleBuffer(state_dim, action_dim, max_buffer)\nrandom_policy = RandomPolicy(env.action_space)\n(state, done) = (env.reset(), False)\nepisode_num = 0\nmax_episode_steps = (get_max_episode_steps(env) if (max_episode_steps is None) else max_episode_steps)\nepisode_data = SampleBuffer(state_dim, action_dim, max_episode_steps)\nfor t in range(max_timesteps):\n    if (len(replay_buffer) < start_timesteps):\n        action = random_policy.act1(state)\n    else:\n        action = exploration_policy.act1(state)\n    (next_state, reward, done, info) = env.step(action)\n    episode_data.append(state, action, next_state, reward, done)\n    replay_buffer.append(state, action, next_state, reward, done)\n    state = next_state\n    if (len(replay_buffer) >= start_timesteps):\n        solver.update(replay_buffer)\n    if (done or (len(episode_data) == max_episode_steps)):\n        if (post_episode_callback is not None):\n            post_episode_callback(episode_num, episode_data)\n        (state, done) = (env.reset(), False)\n        episode_num += 1\n        episode_data = SampleBuffer(state_dim, action_dim, max_episode_steps)\n"}
{"label_name":"predict","label":4,"method_name":"get_predictions","method":"\ndocs = [model.tokenizer(text) for text in texts]\ntextcat = model.get_pipe('textcat')\n(scores, _) = textcat.predict(docs)\npredicted_labels = scores.argmax(axis=1)\npredicted_class = [textcat.labels[label] for label in predicted_labels]\nreturn predicted_class\n"}
{"label_name":"save","label":1,"method_name":"save_images","method":"\nif isinstance(X.flatten()[0], np.floating):\n    X = (255.99 * X).astype('uint8')\nn_samples = X.shape[0]\nrows = int(np.sqrt(n_samples))\nwhile ((n_samples % rows) != 0):\n    rows -= 1\n(nh, nw) = (rows, (n_samples \/ rows))\nif (X.ndim == 2):\n    X = np.reshape(X, (X.shape[0], int(np.sqrt(X.shape[1])), int(np.sqrt(X.shape[1]))))\nif (X.ndim == 4):\n    X = X.transpose(0, 2, 3, 1)\n    (h, w) = X[0].shape[:2]\n    img = np.zeros(((h * nh), (w * nw), 3))\nelif (X.ndim == 3):\n    (h, w) = X[0].shape[:2]\n    img = np.zeros(((h * nh), (w * nw)))\nfor (n, x) in enumerate(X):\n    j = (n \/ nw)\n    i = (n % nw)\n    img[(j * h):((j * h) + h), (i * w):((i * w) + w)] = x\nimsave(save_path, img)\n"}
{"label_name":"train","label":0,"method_name":"train_model","method":"\nlosses = {}\nrandom.seed(1)\nfor epoch in range(epochs):\n    random.shuffle(train_data)\n    batches = minibatch(train_data, size=batch_size)\n    for batch in batches:\n        (texts, labels) = zip(*batch)\n        model.update(texts, labels, sgd=optimizer, losses=losses)\nreturn losses['textcat']\n"}
{"label_name":"process","label":2,"method_name":"postprocess_trajectory","method":"\n\"Postprocesses a trajectory and returns the processed trajectory.\\n\\n    The trajectory contains only data from one episode and from one agent.\\n    - If  `config.batch_mode=truncate_episodes` (default), sample_batch may\\n    contain a truncated (at-the-end) episode, in case the\\n    `config.rollout_fragment_length` was reached by the sampler.\\n    - If `config.batch_mode=complete_episodes`, sample_batch will contain\\n    exactly one episode (no matter how long).\\n    New columns can be added to sample_batch and existing ones may be altered.\\n\\n    Args:\\n        policy (Policy): The Policy used to generate the trajectory\\n            (`sample_batch`)\\n        sample_batch (SampleBatch): The SampleBatch to postprocess.\\n        other_agent_batches (Optional[Dict[PolicyID, SampleBatch]]): Optional\\n            dict of AgentIDs mapping to other agents' trajectory data (from the\\n            same episode). NOTE: The other agents use the same policy.\\n        episode (Optional[MultiAgentEpisode]): Optional multi-agent episode\\n            object in which the agents operated.\\n\\n    Returns:\\n        SampleBatch: The postprocessed, modified SampleBatch (or a new one).\\n    \"\nif (not policy.config['vtrace']):\n    sample_batch = compute_gae_for_sample_batch(policy, sample_batch, other_agent_batches, episode)\ndel sample_batch['new_obs']\nreturn sample_batch\n"}
{"label_name":"predict","label":4,"method_name":"predict","method":"\ndata = request.get_json()\ndf_predict = pd.DataFrame(data)\npredictions = IRIS_MODEL.predict(df_predict)\npredictions = predictions.tolist()\nreturn jsonify({'version': IRIS_MODEL.version, 'status': 'success', 'predictions': predictions})\n"}
{"label_name":"train","label":0,"method_name":"classify_train_data","method":"\nweather = pd.read_csv('..\/Data\/train\/output\/weather_airport_vec.csv')\nprint(weather.head())\nweather_set = set()\nfor (index, value) in weather.iterrows():\n    key_from = ((str(value['\u57ce\u5e02']) + '||') + str(value['\u65e5\u671f']))\n    weather_set.add(key_from)\ndata = pd.read_csv('..\/Feature\/data_with_last_flight_feature.csv', encoding='gbk')\nprint(data.head())\ndata = data.fillna({u'\u98de\u673a\u7f16\u53f7': 0})\ncols = data.columns.values.tolist()\nno_lastflight_no_weather = []\nno_lastflight_has_weather = []\nhas_lastflight_no_weather = []\nhas_lastflight_has_weather = []\nnum = len(data)\nfor (index, value) in data.iterrows():\n    print(index, '\/', num)\n    if pd.isnull(value[u'lastFlight']):\n        key_from = ((str(value[u'\u51fa\u53d1\u673a\u573a']) + '||') + str(value[u'date']))\n        key_to = ((str(value[u'\u5230\u8fbe\u673a\u573a']) + '||') + str(value[u'date']))\n        if ((key_from not in weather_set) or (key_to not in weather_set)):\n            no_lastflight_no_weather.append(value)\n        else:\n            no_lastflight_has_weather.append(value)\n    else:\n        key_from = ((str(value[u'\u51fa\u53d1\u673a\u573a']) + '||') + str(value[u'date']))\n        key_to = ((str(value[u'\u5230\u8fbe\u673a\u573a']) + '||') + str(value[u'date']))\n        if ((key_from not in weather_set) or (key_to not in weather_set)):\n            has_lastflight_no_weather.append(value)\n        else:\n            has_lastflight_has_weather.append(value)\nno_lastflight_no_weather_df = pd.DataFrame(no_lastflight_no_weather, columns=cols)\nno_lastflight_no_weather_df.to_csv('..\/Data\/train\/output\/no_lastflight_no_weather.csv', index=False, encoding='gbk')\nno_lastflight_has_weather_df = pd.DataFrame(no_lastflight_has_weather, columns=cols)\nno_lastflight_has_weather_df.to_csv('..\/Data\/train\/output\/no_lastflight_has_weather.csv', index=False, encoding='gbk')\nhas_lastflight_no_weather_df = pd.DataFrame(has_lastflight_no_weather, columns=cols)\nhas_lastflight_no_weather_df.to_csv('..\/Data\/train\/output\/has_lastflight_no_weather.csv', index=False, encoding='gbk')\nhas_lastflight_has_weather_df = pd.DataFrame(has_lastflight_has_weather, columns=cols)\nhas_lastflight_has_weather_df.to_csv('..\/Data\/train\/output\/has_lastflight_has_weather.csv', index=False, encoding='gbk')\nprint('===> classify train data finished.')\n"}
{"label_name":"save","label":1,"method_name":"plot_save_show","method":"\nplot_save(path, figs, dpi, tight_plot, clear_all, log)\nos.system(('open -a \/Applications\/Preview.app %s' % path))\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\nresult = []\n(source, target) = (list(enumerate(source_loader)), list(enumerate(target_loader)))\ntrain_steps = min(len(source), len(target))\nfor batch_idx in range(train_steps):\n    (_, (source_data, source_label)) = source[batch_idx]\n    (_, (target_data, _)) = target[batch_idx]\n    if CUDA:\n        source_data = source_data.cuda()\n        source_label = source_label.cuda()\n        target_data = target_data.cuda()\n    (source_data, source_label) = (Variable(source_data), Variable(source_label))\n    target_data = Variable(target_data)\n    optimizer.zero_grad()\n    (out1, out2) = model(source_data, target_data)\n    classification_loss = torch.nn.functional.cross_entropy(out1, source_label)\n    coral_loss = models.CORAL(out1, out2)\n    sum_loss = ((_lambda * coral_loss) + classification_loss)\n    sum_loss.backward()\n    optimizer.step()\n    result.append({'epoch': epoch, 'step': (batch_idx + 1), 'total_steps': train_steps, 'lambda': _lambda, 'coral_loss': coral_loss.data[0], 'classification_loss': classification_loss.data[0], 'total_loss': sum_loss.data[0]})\n    print('Train Epoch: {:2d} [{:2d}\/{:2d}]\\tLambda: {:.4f}, Class: {:.6f}, CORAL: {:.6f}, Total_Loss: {:.6f}'.format(epoch, (batch_idx + 1), train_steps, _lambda, classification_loss.data[0], coral_loss.data[0], sum_loss.data[0]))\nreturn result\n"}
{"label_name":"save","label":1,"method_name":"save_any_file","method":"\n'\\n    Determines a Saver based on the the file extension. Returns whether successfully saved.\\n\\n    :param filename: the name of the file to save\\n    :type filename: str\\n    :param data: the data to save\\n    :type data: Instances\\n    :return: whether successfully saved\\n    :rtype: bool\\n    '\nsaver = saver_for_file(filename)\nif (saver is None):\n    return False\nelse:\n    saver.save_file(data, filename)\n    return True\n"}
{"label_name":"process","label":2,"method_name":"process","method":"\nconllu_lines = open(input_conllu).readlines()\ntxt_lines = open(input_txt).readlines()\ninserts = []\nnew_conllu_lines = list(conllu_lines)\nline_idx = 0\ntext_idx = 0\nwhile (line_idx < len(conllu_lines)):\n    line_idx = (line_idx + 1)\n    text_line = conllu_lines[line_idx]\n    assert text_line.startswith('# text = '), ('Unexpected format: %s,%d is not # text' % (input_txt, line_idx))\n    text_line = text_line[9:(- 1)]\n    text_idx = (text_idx + len(text_line))\n    line_idx = (line_idx + 1)\n    assert conllu_lines[line_idx].startswith('1'), ('Unexpected format: %s,%d is not a word' % (input_txt, line_idx))\n    while conllu_lines[line_idx].strip():\n        line_idx = (line_idx + 1)\n    last_word_idx = (line_idx - 1)\n    new_line = conllu_lines[last_word_idx].replace('SpaceAfter=No|', '')\n    assert (new_line.find('SpaceAfter=') < 0), ('Unexpected format: %s,%d has unusual SpaceAfter' % (input_txt, line_idx))\n    if (new_line != conllu_lines[last_word_idx]):\n        inserts.append(text_idx)\n        conllu_lines[last_word_idx] = new_line\n    text_idx = (text_idx + 1)\n    while ((line_idx < len(conllu_lines)) and (not conllu_lines[line_idx].strip())):\n        line_idx = (line_idx + 1)\ncurrent_txt_len = 0\ncurrent_txt_idx = 0\nfor insert in inserts:\n    line = txt_lines[current_txt_idx]\n    while ((len(line) + current_txt_len) < insert):\n        current_txt_len = (current_txt_len + len(line))\n        current_txt_idx = (current_txt_idx + 1)\n        line = txt_lines[current_txt_idx]\n    new_line = ((line[:(insert - current_txt_len)] + ' ') + line[(insert - current_txt_len):])\n    txt_lines[current_txt_idx] = new_line\nwith open(input_txt_copy, 'w') as fout:\n    for line in txt_lines:\n        fout.write(line)\nwith open(input_conllu_copy, 'w') as fout:\n    for line in conllu_lines:\n        fout.write(line)\n"}
{"label_name":"train","label":0,"method_name":"make_train_op","method":"\n'\\n  Use gradients from local network to update the global network\\n  '\n(local_grads, _) = zip(*local_net.grads_and_vars)\n(local_grads, _) = tf.clip_by_global_norm(local_grads, 5.0)\n(_, global_vars) = zip(*global_net.grads_and_vars)\nlocal_grads_global_vars = list(zip(local_grads, global_vars))\nreturn global_net.optimizer.apply_gradients(local_grads_global_vars, global_step=tf.train.get_global_step())\n"}
{"label_name":"save","label":1,"method_name":"save_xlsx","method":"\nif os.path.isfile(fname):\n    warnings.warn('File is being overwritten: {}.'.format(fname))\nif isinstance(dfs, list):\n    writer = pd.ExcelWriter(fname)\n    for (i, df) in enumerate(dfs):\n        df.to_excel(writer, ('Image' + str((i + 1))))\nelse:\n    dfs.to_excel(fname, 'Image1')\n"}
{"label_name":"process","label":2,"method_name":"preprocess_array","method":"\nimg = Image.fromarray(np.uint8(img_array))\nimg = img.resize(target_size)\nx = image.img_to_array(img)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\nreturn np.squeeze(np.array(x, dtype=np.float32))\n"}
{"label_name":"train","label":0,"method_name":"get_untrained_performance","method":"\nagent = Agent(env, 0.001)\nwith tf.Session() as sess:\n    sess.run(agent.brain.tf_init)\n    (avg_reward, avg_frame, reward_std, frame_std, mean_episode_score, std_episode_score) = agent.act(sess, 100)\n    print((((((((((((' Agv Agent Reward: ' + str(avg_reward)) + ' Avg Agent Frames: ') + str(avg_frame)) + ' SD Agent Reward: ') + str(reward_std)) + ' SD Agent Frames: ') + str(frame_std)) + ' Agv Agent Score: ') + str(mean_episode_score)) + ' SD Agent Score: ') + str(std_episode_score)))\n    performance_dict = {'Agv Agent Reward': [avg_reward], 'Avg Agent Frames': [avg_frame], 'SD Agent Reward': [reward_std], 'SD Agent Frames': [frame_std], 'Agv Agent Score': [mean_episode_score], 'SD Agent Score': [std_episode_score]}\n    pd.DataFrame(performance_dict).to_csv((('..\/outputs\/B_' + AGENT) + '-2.csv'))\n"}
{"label_name":"save","label":1,"method_name":"_pickle_save","method":"\nif (not isinstance(protocol, int)):\n    raise ValueError(\"The 'protocol' MUST be `int`, but received {}\".format(type(protocol)))\nif ((protocol < 2) or (protocol > 4)):\n    raise ValueError(\"Expected 1<'protocol'<5, but received protocol={}\".format(protocol))\nif (not isinstance(obj, (core.LoDTensor, core.VarBase))):\n    raise NotImplementedError(\"Support 'paddle.Tensor' or 'paddle.core.LoDTensor', but received {}.\".format(type(obj)))\n\ndef reudce_varbase(self):\n    data = self.numpy()\n    name = self.name\n    return (tuple, ((name, data),))\n\ndef reduce_LoDTensor(self):\n    data = np.array(self)\n    return (eval, ('data', {'data': data}))\n\ndef add_dispatch_table():\n    pickle.dispatch_table[core.VarBase] = reudce_varbase\n    pickle.dispatch_table[ParamBase] = reudce_varbase\n    pickle.dispatch_table[core.LoDTensor] = reduce_LoDTensor\n\ndef pop_dispatch_table():\n    pickle.dispatch_table.pop(core.VarBase)\n    pickle.dispatch_table.pop(core.LoDTensor)\n    pickle.dispatch_table.pop(ParamBase)\nif ((sys.platform == 'darwin') and (sys.version_info.major == 3)):\n    add_dispatch_table()\n    pickle_bytes = pickle.dumps(obj)\n    pop_dispatch_table()\n    max_bytes = (2 ** 30)\n    for i in range(0, len(pickle_bytes), max_bytes):\n        f.write(pickle_bytes[i:(i + max_bytes)])\nelif six.PY2:\n    add_dispatch_table()\n    pickle_bytes = pickle.dump(obj, f, protocol)\n    pop_dispatch_table()\nelse:\n    pickler = pickle.Pickler(f, protocol)\n    pickler.dispatch_table = copyreg.dispatch_table.copy()\n    pickler.dispatch_table[core.VarBase] = reudce_varbase\n    pickler.dispatch_table[core.LoDTensor] = reduce_LoDTensor\n    pickler.dispatch_table[ParamBase] = reudce_varbase\n    pickler.dump(obj)\n"}
{"label_name":"train","label":0,"method_name":"read_train_data","method":"\nfile_path = os.path.normpath(path)\nreader = Reader(line_format='timestamp user item rating', sep=',')\ndata = Dataset.load_from_file(file_path, reader=reader)\nreturn data\n"}
{"label_name":"train","label":0,"method_name":"format_train","method":"\nXtrain = pad_sequences(encoded_docs[0:train_range], maxlen=max_length, padding='post')\nYtrain = []\nfor emoji in labels[0:train_range]:\n    num = int(emoji)\n    bit_vec = np.zeros(20)\n    bit_vec[num] = 1\n    Ytrain.append(bit_vec)\nYtrain = np.asarray(Ytrain)\nreturn (Xtrain, Ytrain)\n"}
{"label_name":"train","label":0,"method_name":"train_net","method":"\n'Train a Fast R-CNN network.'\nroidb = filter_roidb(roidb)\nsaver = tf.train.Saver(max_to_keep=100)\nwith tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n    sw = SolverWrapper(sess, saver, network, imdb, roidb, output_dir, pretrained_model=pretrained_model)\n    print('Solving...')\n    sw.train_model(sess, max_iters)\n    print('done solving')\n"}
{"label_name":"process","label":2,"method_name":"data_preprocessing","method":"\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train[:, :, :, 0] = ((x_train[:, :, :, 0] - np.mean(x_train[:, :, :, 0])) \/ np.std(x_train[:, :, :, 0]))\nx_train[:, :, :, 1] = ((x_train[:, :, :, 1] - np.mean(x_train[:, :, :, 1])) \/ np.std(x_train[:, :, :, 1]))\nx_train[:, :, :, 2] = ((x_train[:, :, :, 2] - np.mean(x_train[:, :, :, 2])) \/ np.std(x_train[:, :, :, 2]))\nx_test[:, :, :, 0] = ((x_test[:, :, :, 0] - np.mean(x_test[:, :, :, 0])) \/ np.std(x_test[:, :, :, 0]))\nx_test[:, :, :, 1] = ((x_test[:, :, :, 1] - np.mean(x_test[:, :, :, 1])) \/ np.std(x_test[:, :, :, 1]))\nx_test[:, :, :, 2] = ((x_test[:, :, :, 2] - np.mean(x_test[:, :, :, 2])) \/ np.std(x_test[:, :, :, 2]))\nreturn (x_train, x_test)\n"}
{"label_name":"save","label":1,"method_name":"save_argv","method":"\nsaved = sys.argv[:]\nif (repl is not None):\n    sys.argv[:] = repl\ntry:\n    (yield saved)\nfinally:\n    sys.argv[:] = saved\n"}
{"label_name":"save","label":1,"method_name":"save_response_content","method":"\nCHUNK_SIZE = 32768\nwith open(destination, 'wb') as f:\n    for chunk in response.iter_content(CHUNK_SIZE):\n        if chunk:\n            f.write(chunk)\n"}
{"label_name":"train","label":0,"method_name":"find_entities_in_training_example","method":"\n'Extracts entities from an intent example.\\n\\n    Args:\\n        example: Intent example.\\n\\n    Returns:\\n        Extracted entities.\\n    '\nentities = []\noffset = 0\nfor match in re.finditer(ENTITY_REGEX, example):\n    entity_attributes = extract_entity_attributes(match)\n    start_index = (match.start() - offset)\n    end_index = (start_index + len(entity_attributes.text))\n    offset += (len(match.group(0)) - len(entity_attributes.text))\n    entity = rasa.shared.nlu.training_data.util.build_entity(start_index, end_index, entity_attributes.value, entity_attributes.type, entity_attributes.role, entity_attributes.group)\n    entities.append(entity)\nreturn entities\n"}
{"label_name":"train","label":0,"method_name":"build_trainer","method":"\n'Helper function for defining a custom trainer.\\n\\n    Functions will be run in this order to initialize the trainer:\\n        1. Config setup: validate_config, get_policy\\n        2. Worker setup: before_init, execution_plan\\n        3. Post setup: after_init\\n\\n    Args:\\n        name (str): name of the trainer (e.g., \"PPO\")\\n        default_config (Optional[TrainerConfigDict]): The default config dict\\n            of the algorithm, otherwise uses the Trainer default config.\\n        validate_config (Optional[Callable[[TrainerConfigDict], None]]):\\n            Optional callable that takes the config to check for correctness.\\n            It may mutate the config as needed.\\n        default_policy (Optional[Type[Policy]]): The default Policy class to\\n            use if `get_policy_class` returns None.\\n        get_policy_class (Optional[Callable[\\n            TrainerConfigDict, Optional[Type[Policy]]]]): Optional callable\\n            that takes a config and returns the policy class or None. If None\\n            is returned, will use `default_policy` (which must be provided\\n            then).\\n        validate_env (Optional[Callable[[EnvType, EnvContext], None]]):\\n            Optional callable to validate the generated environment (only\\n            on worker=0).\\n        before_init (Optional[Callable[[Trainer], None]]): Optional callable to\\n            run before anything is constructed inside Trainer (Workers with\\n            Policies, execution plan, etc..). Takes the Trainer instance as\\n            argument.\\n        after_init (Optional[Callable[[Trainer], None]]): Optional callable to\\n            run at the end of trainer init (after all Workers and the exec.\\n            plan have been constructed). Takes the Trainer instance as\\n            argument.\\n        before_evaluate_fn (Optional[Callable[[Trainer], None]]): Callback to\\n            run before evaluation. This takes the trainer instance as argument.\\n        mixins (list): list of any class mixins for the returned trainer class.\\n            These mixins will be applied in order and will have higher\\n            precedence than the Trainer class.\\n        execution_plan (Optional[Callable[[WorkerSet, TrainerConfigDict],\\n            Iterable[ResultDict]]]): Optional callable that sets up the\\n            distributed execution workflow.\\n\\n    Returns:\\n        Type[Trainer]: A Trainer sub-class configured by the specified args.\\n    '\noriginal_kwargs = locals().copy()\nbase = add_mixins(Trainer, mixins)\n\nclass trainer_cls(base):\n    _name = name\n    _default_config = (default_config or COMMON_CONFIG)\n    _policy_class = default_policy\n\n    def __init__(self, config=None, env=None, logger_creator=None):\n        Trainer.__init__(self, config, env, logger_creator)\n\n    def _init(self, config: TrainerConfigDict, env_creator: Callable[([EnvConfigDict], EnvType)]):\n        if validate_config:\n            validate_config(config)\n        if (get_policy_class is None):\n            if (not config['multiagent']['policies']):\n                assert (default_policy is not None)\n            self._policy_class = default_policy\n        else:\n            self._policy_class = get_policy_class(config)\n            if (self._policy_class is None):\n                assert (default_policy is not None)\n                self._policy_class = default_policy\n        if before_init:\n            before_init(self)\n        self.workers = self._make_workers(env_creator=env_creator, validate_env=validate_env, policy_class=self._policy_class, config=config, num_workers=self.config['num_workers'])\n        self.execution_plan = execution_plan\n        self.train_exec_impl = execution_plan(self.workers, config)\n        if after_init:\n            after_init(self)\n\n    @override(Trainer)\n    def step(self):\n        res = next(self.train_exec_impl)\n        if (self.config['evaluation_interval'] and (((self._iteration + 1) % self.config['evaluation_interval']) == 0)):\n            evaluation_metrics = self._evaluate()\n            assert isinstance(evaluation_metrics, dict), '_evaluate() needs to return a dict.'\n            res.update(evaluation_metrics)\n        return res\n\n    @override(Trainer)\n    def _before_evaluate(self):\n        if before_evaluate_fn:\n            before_evaluate_fn(self)\n\n    @override(Trainer)\n    def __getstate__(self):\n        state = Trainer.__getstate__(self)\n        state['train_exec_impl'] = self.train_exec_impl.shared_metrics.get().save()\n        return state\n\n    @override(Trainer)\n    def __setstate__(self, state):\n        Trainer.__setstate__(self, state)\n        self.train_exec_impl.shared_metrics.get().restore(state['train_exec_impl'])\n\n    @staticmethod\n    @override(Trainer)\n    def with_updates(**overrides) -> Type[Trainer]:\n        'Build a copy of this trainer class with the specified overrides.\\n\\n            Keyword Args:\\n                overrides (dict): use this to override any of the arguments\\n                    originally passed to build_trainer() for this policy.\\n\\n            Returns:\\n                Type[Trainer]: A the Trainer sub-class using `original_kwargs`\\n                    and `overrides`.\\n\\n            Examples:\\n                >>> MyClass = SomeOtherClass.with_updates({\"name\": \"Mine\"})\\n                >>> issubclass(MyClass, SomeOtherClass)\\n                ... False\\n                >>> issubclass(MyClass, Trainer)\\n                ... True\\n            '\n        return build_trainer(**dict(original_kwargs, **overrides))\ntrainer_cls.__name__ = name\ntrainer_cls.__qualname__ = name\nreturn trainer_cls\n"}
{"label_name":"save","label":1,"method_name":"save_path","method":"\nsaved = sys.path[:]\ntry:\n    (yield saved)\nfinally:\n    sys.path[:] = saved\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\nlabel = paddle.layer.data(name='label', type=paddle.data_type.integer_value(CLASS_DIM))\nloss = paddle.layer.classification_cost(input=output, label=label)\nparameters = paddle.parameters.create(loss)\noptimizer = paddle.optimizer.Adam(learning_rate=0.001, regularization=paddle.optimizer.L2Regularization(rate=0.0008))\ntrainer = paddle.trainer.SGD(cost=loss, parameters=parameters, update_equation=optimizer)\nfeeding = dict()\nfeeding['label'] = 1\nfeeding['image'] = 0\n\ndef event_handler(event):\n    if isinstance(event, paddle.event.EndIteration):\n        class_error_rate = event.metrics['classification_error_evaluator']\n        with open('output\/train_error1', 'a+') as f:\n            f.write(('%f\\n' % class_error_rate))\n        if ((event.batch_id % 50) == 0):\n            print(('\\n pass %d, Batch: %d cost: %f metrics: %s' % (event.pass_id, event.batch_id, event.cost, event.metrics)))\n        else:\n            sys.stdout.write('.')\n            sys.stdout.flush()\n    if isinstance(event, paddle.event.EndPass):\n        with gzip.open(('output\/params_pass_%d.tar.gz' % event.pass_id), 'w') as f:\n            parameters.to_tar(f)\n        test_reader = data_provider.create_reader('test', 10000)\n        result = trainer.test(reader=paddle.batch(test_reader, batch_size=128), feeding=feeding)\n        class_error_rate = result.metrics['classification_error_evaluator']\n        with open('output\/error1', 'a+') as f:\n            f.write(('%f\\n' % class_error_rate))\n        print(('\\nTest with Pass %d, cost: %s ratio: %f' % (event.pass_id, result.cost, class_error_rate)))\nreader = data_provider.create_reader('train', 60000)\ntrainer.train(paddle.batch(reader=reader, batch_size=128), num_passes=200, event_handler=event_handler, feeding=feeding)\n"}
{"label_name":"predict","label":4,"method_name":"predictOneEstimator","method":"\n[no_runs, no_ests, no_vers] = validCosts.shape\ncosts = validCosts[:, num, :]\ncosts = np.reshape(costs, (no_runs, no_vers))\ncostsMean = np.mean(costs, axis=0)\ncostsStd = np.std(costs, axis=0)\ncostsDecide = (costsMean * costsStd)\nclf_best = clfs[num][np.argmin(np.abs(costsDecide))]\nestTrained = clf_best\nestTrained = estTrained.fit(X[np.argmin(np.abs(costsDecide))], y)\ndataTest_optVer = dataTest[np.argmin(np.abs(costsDecide))]\nnoBins = numsBins[np.argmin(np.abs(costsDecide))]\ny_pred = estTrained.predict(dataTest_optVer)\nsaveresult(y_pred, estimatorsStr[num])\nlogging.info('{}'.format(estTrained))\nlogging.info('No. bins = {}'.format(noBins))\nplotPerformance(estimatorsStr, costs, numsBins, num=num)\nreturn (y_pred, estTrained)\n"}
{"label_name":"train","label":0,"method_name":"train_method3","method":"\nX = X.reshape((- 1))\nY = Y.reshape((- 1))\n(w1, w0) = np.polyfit(X, Y, 1)\nFX = ((w1 * X) + [w0])\nmse = mean_squared_error(Y, FX)\nshow_result(w0, w1, mse)\n"}
{"label_name":"process","label":2,"method_name":"processRadiantData","method":"\ndata_frame = _pb.CMsgBotWorldState()\ndata_frame.ParseFromString(data)\n"}
{"label_name":"process","label":2,"method_name":"_process_index","method":"\n'Process and normalize the index.'\nif (not isinstance(item, (slice, tuple))):\n    if (not isinstance(item, int)):\n        raise ValueError('The index should be a integer.')\n    item = (item,)\nif (not isinstance(item, tuple)):\n    item = tuple([item])\n(starts, sizes) = ([], [])\nfor (i, ele) in enumerate(item):\n    if isinstance(ele, slice):\n        if (ele.start is None):\n            starts.append(0)\n        else:\n            starts.append(ele.start)\n        if (ele.stop is None):\n            sizes.append((- 1))\n        else:\n            sizes.append((ele.stop - starts[(- 1)]))\n            if (sizes[(- 1)] == 0):\n                raise ValueError('The starts and ends of axis {} can not be equal, got {}:{}.'.format(i, starts[(- 1)], ele.stop))\n        if (ele.step is not None):\n            raise NotImplementedError\n    elif isinstance(ele, int):\n        starts.append(ele)\n        sizes.append(0)\n    else:\n        raise TypeError('Unsupported index type: {}'.format(type(ele)))\nreturn (starts, sizes)\n"}
{"label_name":"predict","label":4,"method_name":"transformer_error_tag_prediction_layer","method":"\n'Layer that predicts the error tag.'\nwith tf.variable_scope('error_tag_prediction'):\n    x = maybe_flatten4d3d(x)\n    vocab_size = hparams.problem.feature_info['targets_error_tag'].vocab_size\n    labels = features['targets_error_tag_raw']\n    with tf.variable_scope('projection'):\n        bottleneck = common_layers.dense(x, hparams.error_tag_embed_size, layer_collection=layer_collection, name='bottleneck')\n        logits = common_layers.dense(bottleneck, vocab_size, use_bias=False, layer_collection=layer_collection, name='logits')\n        xent = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels)\n        loss = tf.reduce_sum((xent * loss_mask))\n    with tf.variable_scope('embedding'):\n        embed_mat = get_error_tag_embedding_matrix()\n        y = common_layers.layer_preprocess(common_layers.embedding(labels, vocab_size, hparams.hidden_size, embedding_var=embed_mat), hparams, layer_collection=layer_collection)\n        x = common_layers.layer_postprocess(x, y, hparams)\n    return (x, logits, loss)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\nopt = parser.parse_args()\nif opt.cuda:\n    batcher.use_cuda = True\n    models.use_cuda = True\nif (opt.name is None):\n    opt.name = '{}_{}_{}_{}'.format(opt.numGlimpses, opt.glimpseSize, opt.numStates, ('cuda' if opt.cuda else 'cpu'))\nprint('Will start training {} with parameters:\\n{}\\n\\n'.format(opt.name, opt))\nmodels_path = os.path.join('saved_models', opt.name)\nos.makedirs(models_path, exist_ok=True)\ndiscriminator = ArcBinaryClassifier(num_glimpses=opt.numGlimpses, glimpse_h=opt.glimpseSize, glimpse_w=opt.glimpseSize, controller_out=opt.numStates)\nif opt.cuda:\n    discriminator.cuda()\nif (opt.load is not None):\n    discriminator.load_state_dict(torch.load(os.path.join(models_path, opt.load)))\nbce = torch.nn.BCELoss()\nif opt.cuda:\n    bce = bce.cuda()\noptimizer = torch.optim.Adam(params=discriminator.parameters(), lr=opt.lr)\nloader = Batcher(batch_size=opt.batchSize, image_size=opt.imageSize)\nbest_validation_loss = None\nsaving_threshold = 1.02\nlast_saved = datetime.utcnow()\nsave_every = timedelta(minutes=10)\ni = (- 1)\nwhile True:\n    i += 1\n    (X, Y) = loader.fetch_batch('train')\n    pred = discriminator(X)\n    loss = bce(pred, Y.float())\n    if ((i % 10) == 0):\n        (X_val, Y_val) = loader.fetch_batch('val')\n        pred_val = discriminator(X_val)\n        loss_val = bce(pred_val, Y_val.float())\n        training_loss = loss.data[0]\n        validation_loss = loss_val.data[0]\n        print('Iteration: {} \\t Train: Acc={}%, Loss={} \\t\\t Validation: Acc={}%, Loss={}'.format(i, get_pct_accuracy(pred, Y), training_loss, get_pct_accuracy(pred_val, Y_val), validation_loss))\n        if (best_validation_loss is None):\n            best_validation_loss = validation_loss\n        if (best_validation_loss > (saving_threshold * validation_loss)):\n            print('Significantly improved validation loss from {} --> {}. Saving...'.format(best_validation_loss, validation_loss))\n            discriminator.save_to_file(os.path.join(models_path, str(validation_loss)))\n            best_validation_loss = validation_loss\n            last_saved = datetime.utcnow()\n        if ((last_saved + save_every) < datetime.utcnow()):\n            print(\"It's been too long since we last saved the model. Saving...\")\n            discriminator.save_to_file(os.path.join(models_path, str(validation_loss)))\n            last_saved = datetime.utcnow()\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n"}
{"label_name":"forward","label":3,"method_name":"dense_forward","method":"\nreturn (np.dot(X, W) + b)\n"}
{"label_name":"process","label":2,"method_name":"_validate_runtime_separate_process","method":"\nmodels = kwargs['models']\nif (models in (None, '')):\n    from ..onnxrt.validate.validate_helper import sklearn_operators\n    models = [_['name'] for _ in sklearn_operators(extended=True)]\nelif (not isinstance(models, list)):\n    models = models.strip().split(',')\nskip_models = kwargs['skip_models']\nskip_models = ({} if (skip_models in (None, '')) else skip_models.strip().split(','))\nverbose = kwargs['verbose']\nfLOG = kwargs['fLOG']\nall_rows = []\nskls = [m for m in models if (m not in skip_models)]\nskls.sort()\nif (verbose > 0):\n    from tqdm import tqdm\n    pbar = tqdm(skls)\nelse:\n    pbar = skls\nfor op in pbar:\n    if (not isinstance(pbar, list)):\n        pbar.set_description(('[%s]' % (op + (' ' * (25 - len(op))))))\n    if kwargs['out_raw']:\n        out_raw = os.path.splitext(kwargs['out_raw'])\n        out_raw = ''.join([out_raw[0], '_', op, out_raw[1]])\n    else:\n        out_raw = None\n    if kwargs['out_summary']:\n        out_summary = os.path.splitext(kwargs['out_summary'])\n        out_summary = ''.join([out_summary[0], '_', op, out_summary[1]])\n    else:\n        out_summary = None\n    new_kwargs = kwargs.copy()\n    if ('fLOG' in new_kwargs):\n        del new_kwargs['fLOG']\n    new_kwargs['out_raw'] = out_raw\n    new_kwargs['out_summary'] = out_summary\n    new_kwargs['models'] = op\n    new_kwargs['verbose'] = 0\n    new_kwargs['out_graph'] = None\n    with Pool(1) as p:\n        try:\n            result = p.apply_async(_validate_runtime_dict, [new_kwargs])\n            lrows = result.get(timeout=150)\n            all_rows.extend(lrows)\n        except Exception as e:\n            all_rows.append({'name': op, 'scenario': 'CRASH', 'ERROR-msg': str(e).replace('\\n', ' -- ')})\nreturn _finalize(all_rows, kwargs['out_raw'], kwargs['out_summary'], verbose, models, kwargs.get('out_graph', None), fLOG)\n"}
{"label_name":"save","label":1,"method_name":"save_embedding","method":"\n'\\n    Function to save the embedding.\\n    :param args: Arguments object.\\n    :param model: The embedding model object.\\n    :param counts: Number of nodes.\\n    '\nout = []\nfor node in range(1, counts[0]):\n    if (args.model == 'non-pooled'):\n        out.append(([(int(node) - 1)] + list(model.docvecs[node])))\n    else:\n        out.append(([(int(node) - 1)] + list(model.wv[str((node - 1))])))\ncolumns = (['node'] + [('x_' + str(x)) for x in range(args.dimensions)])\nout = pd.DataFrame(out, columns=columns)\nout = out.sort_values(['node'])\nout.to_csv(args.output, index=None)\n"}
{"label_name":"save","label":1,"method_name":"save_backend_key","method":"\n_zAI_base_dir = os.path.expanduser('~')\n_zAI_dir = os.path.join(_zAI_base_dir, '.zAI')\nconfig_file = os.path.join(_zAI_dir, 'config.json')\nif (not os.path.exists(config_file)):\n    raise Exception(('%s does not exist' % config_file))\nif (key_name not in get_available_keys()):\n    raise Exception(('%s is not currently available in zAI.' % key_name))\nwith open(config_file, 'r') as jsonFile:\n    data = json.load(jsonFile)\ndata[key_name] = key_value\nwith open(config_file, 'w') as jsonFile:\n    json.dump(data, jsonFile, indent=2)\n"}
{"label_name":"forward","label":3,"method_name":"linear_forward","method":"\n'\\n\\n    :param A:\\n    :param W:\\n    :param b:\\n    :return:\\n    '\nZ = (np.dot(W, A) + b)\ncache = (A, W, b)\nreturn (Z, cache)\n"}
{"label_name":"save","label":1,"method_name":"save_vocabulary","method":"\nwith open(path, 'w') as f:\n    for w in vocab:\n        ((print >> f), w)\n"}
{"label_name":"train","label":0,"method_name":"multivariate_train_and_sample","method":"\n'Trains, evaluates, and exports a multivariate model.'\nestimator = tf.contrib.timeseries.StructuralEnsembleRegressor(periodicities=[], num_features=5)\nreader = tf.contrib.timeseries.CSVReader(csv_file_name, column_names=((tf.contrib.timeseries.TrainEvalFeatures.TIMES,) + ((tf.contrib.timeseries.TrainEvalFeatures.VALUES,) * 5)))\ntrain_input_fn = tf.contrib.timeseries.RandomWindowInputFn(reader, batch_size=4, window_size=64)\nestimator.train(input_fn=train_input_fn, steps=training_steps)\nevaluation_input_fn = tf.contrib.timeseries.WholeDatasetInputFn(reader)\ncurrent_state = estimator.evaluate(input_fn=evaluation_input_fn, steps=1)\nvalues = [current_state['observed']]\ntimes = [current_state[tf.contrib.timeseries.FilteringResults.TIMES]]\nif (export_directory is None):\n    export_directory = tempfile.mkdtemp()\ninput_receiver_fn = estimator.build_raw_serving_input_receiver_fn()\nexport_location = estimator.export_savedmodel(export_directory, input_receiver_fn)\nwith tf.Graph().as_default():\n    numpy.random.seed(1)\n    with tf.Session() as session:\n        signatures = tf.saved_model.loader.load(session, [tf.saved_model.tag_constants.SERVING], export_location)\n        for _ in range(100):\n            current_prediction = tf.contrib.timeseries.saved_model_utils.predict_continuation(continue_from=current_state, signatures=signatures, session=session, steps=1)\n            next_sample = numpy.random.multivariate_normal(mean=numpy.squeeze(current_prediction['mean'], axis=[0, 1]), cov=numpy.squeeze(current_prediction['covariance'], axis=[0, 1]))\n            filtering_features = {tf.contrib.timeseries.TrainEvalFeatures.TIMES: current_prediction[tf.contrib.timeseries.FilteringResults.TIMES], tf.contrib.timeseries.TrainEvalFeatures.VALUES: next_sample[None, None, :]}\n            current_state = tf.contrib.timeseries.saved_model_utils.filter_continuation(continue_from=current_state, session=session, signatures=signatures, features=filtering_features)\n            values.append(next_sample[None, None, :])\n            times.append(current_state['times'])\nall_observations = numpy.squeeze(numpy.concatenate(values, axis=1), axis=0)\nall_times = numpy.squeeze(numpy.concatenate(times, axis=1), axis=0)\nreturn (all_times, all_observations)\n"}
{"label_name":"train","label":0,"method_name":"trainAndTestOneFold","method":"\n\"\\n    Trains and tests one fold\\n     \\n     @param trainData: a numpy array for training with first column labels and the others are features\\n     @param testPrefixes: str[]. A list that contains prefixes for all complexes to be tested\\n     @param testPath: str. Path to a dir where testing data files are stored\\n     @param outputPath: str. Path to a dir where predictions will be stored\\n     @param verbose: boolean. Whether or not print to stdout info\\n     @param ncpu: int. Number of cpu's to use in parallel\\n  \"\nresultsForEvaluation_list = []\ntestPrefixesNotEvaluated = []\nfinalResults = []\nfor testPrefix in testPrefixes:\n    if (outputPath is not None):\n        outName = os.path.join(outputPath, (testPrefix + '.res.tab'))\n        if (verbose and os.path.isfile(outName)):\n            print(('Complex already computed: %s' % outName))\n            resultsForEvaluation_list.append((testPrefix, ResultsManager.loadExistingResults(outName)))\n        else:\n            testPrefixesNotEvaluated.append(testPrefix)\n    else:\n        testPrefixesNotEvaluated.append(testPrefix)\nmodelo = None\nif ((len(testPrefixesNotEvaluated) > 0) or (len(testPrefixes) == 0)):\n    if verbose:\n        print('Testing:', testPrefixesNotEvaluated)\n        print('Training classifier')\n        verboseLevel = 1\n    else:\n        verboseLevel = 0\n    modelo = trainMethod(trainData[:, 1:], trainData[:, 0], verboseLevel=verboseLevel, ncpu=ncpu)\n    if (verbose == True):\n        print('Classifier fitted.')\n    for testPrefix in testPrefixesNotEvaluated:\n        prob_predictionsDir_list = []\n        prob_predictionsTrans_list = []\n        testlabels_list = []\n        testPairsIds_list = []\n        if (verbose == True):\n            print(('Computing predictions for %s' % testPrefix))\n        (testDataDirect, testDataTrans, testlabels, testPairsIds) = getDataForTestFromPrefix(testPrefix, testPath)\n        prob_predictionsDir = predictMethod(modelo, testDataDirect)\n        prob_predictionsTrans = predictMethod(modelo, testDataTrans)\n        resultEval = ResultsManager(testPrefix, prob_predictionsDir, prob_predictionsTrans, testPairsIds)\n        if (verbose == True):\n            print(('Evaluating predictions of %s' % testPrefix))\n        resultEval.getFullEvaluation()\n        if (verbose == True):\n            print(resultEval)\n        finalResults.append(resultEval)\n        if (not (outputPath is None)):\n            outName = os.path.join(outputPath, (testPrefix + '.res.tab'))\n            if (not os.path.isfile(outName)):\n                if (verbose == True):\n                    print(('Saving results at %s' % outName))\n                resultEval.writeResults(outName)\nfor (testPrefix, resultEval) in resultsForEvaluation_list:\n    if (verbose == True):\n        print(('Evaluating predictions for %s' % testPrefix))\n    resultEval.getFullEvaluation()\n    if (verbose == True):\n        print(resultEval)\n    finalResults.append(resultEval)\nreturn (finalResults, modelo)\n"}
{"label_name":"process","label":2,"method_name":"preprocess_images","method":"\n\"Preprocess a batch of images.\\n\\n  Args:\\n    images: A 4-D float32 `Tensor` holding raw images to be preprocessed.\\n    is_training: Boolean, whether to preprocess them for training or test.\\n    height: Int, height in pixels to resize image to.\\n    width: Int, width in pixels to resize image to.\\n    min_scale: Float, minimum scale augmentation allowed, as a fraction of the\\n      central min_side * min_side area of the original image.\\n    max_scale: Float, maximum scale augmentation allowed, as a fraction of the\\n      central min_side * min_side area of the original image.\\n    p_scale_up: Float, fraction of images scaled up.\\n    aug_color: Whether or not to do color augmentation.\\n    fast_mode: Boolean, avoids slower ops (random_hue and random_contrast).\\n    crop_strategy: String, name of the strategy used to crop test-time images.\\n      Can be: 'crop_center', 'pad', 'pad_200', 'pad_crop_central'.\\n  Returns:\\n    preprocessed_images: A 4-D float32 `Tensor` holding preprocessed images.\\n  \"\nif is_training:\n    return preprocess_training_images(images, height, width, min_scale, max_scale, p_scale_up, aug_color, fast_mode)\nelse:\n    return preprocess_test_images(images, height, width, crop_strategy)\n"}
{"label_name":"predict","label":4,"method_name":"decode_predictions","method":"\n'Decodes the prediction of an ImageNet model.\\n\\n    # Arguments\\n        preds: Numpy tensor encoding a batch of predictions.\\n        top: integer, how many top-guesses to return.\\n\\n    # Returns\\n        A list of lists of top class prediction tuples\\n        `(class_name, class_description, score)`.\\n        One list of tuples per sample in batch input.\\n\\n    # Raises\\n        ValueError: in case of invalid shape of the `pred` array\\n            (must be 2D).\\n    '\nglobal CLASS_INDEX\nif ((len(preds.shape) != 2) or (preds.shape[1] != 1000)):\n    raise ValueError(('`decode_predictions` expects a batch of predictions (i.e. a 2D array of shape (samples, 1000)). Found array with shape: ' + str(preds.shape)))\nif (CLASS_INDEX is None):\n    CLASS_INDEX = {'0': ['n01440764', 'tench'], '1': ['n01443537', 'goldfish'], '2': ['n01484850', 'great_white_shark'], '3': ['n01491361', 'tiger_shark'], '4': ['n01494475', 'hammerhead'], '5': ['n01496331', 'electric_ray'], '6': ['n01498041', 'stingray'], '7': ['n01514668', 'cock'], '8': ['n01514859', 'hen'], '9': ['n01518878', 'ostrich'], '10': ['n01530575', 'brambling'], '11': ['n01531178', 'goldfinch'], '12': ['n01532829', 'house_finch'], '13': ['n01534433', 'junco'], '14': ['n01537544', 'indigo_bunting'], '15': ['n01558993', 'robin'], '16': ['n01560419', 'bulbul'], '17': ['n01580077', 'jay'], '18': ['n01582220', 'magpie'], '19': ['n01592084', 'chickadee'], '20': ['n01601694', 'water_ouzel'], '21': ['n01608432', 'kite'], '22': ['n01614925', 'bald_eagle'], '23': ['n01616318', 'vulture'], '24': ['n01622779', 'great_grey_owl'], '25': ['n01629819', 'European_fire_salamander'], '26': ['n01630670', 'common_newt'], '27': ['n01631663', 'eft'], '28': ['n01632458', 'spotted_salamander'], '29': ['n01632777', 'axolotl'], '30': ['n01641577', 'bullfrog'], '31': ['n01644373', 'tree_frog'], '32': ['n01644900', 'tailed_frog'], '33': ['n01664065', 'loggerhead'], '34': ['n01665541', 'leatherback_turtle'], '35': ['n01667114', 'mud_turtle'], '36': ['n01667778', 'terrapin'], '37': ['n01669191', 'box_turtle'], '38': ['n01675722', 'banded_gecko'], '39': ['n01677366', 'common_iguana'], '40': ['n01682714', 'American_chameleon'], '41': ['n01685808', 'whiptail'], '42': ['n01687978', 'agama'], '43': ['n01688243', 'frilled_lizard'], '44': ['n01689811', 'alligator_lizard'], '45': ['n01692333', 'Gila_monster'], '46': ['n01693334', 'green_lizard'], '47': ['n01694178', 'African_chameleon'], '48': ['n01695060', 'Komodo_dragon'], '49': ['n01697457', 'African_crocodile'], '50': ['n01698640', 'American_alligator'], '51': ['n01704323', 'triceratops'], '52': ['n01728572', 'thunder_snake'], '53': ['n01728920', 'ringneck_snake'], '54': ['n01729322', 'hognose_snake'], '55': ['n01729977', 'green_snake'], '56': ['n01734418', 'king_snake'], '57': ['n01735189', 'garter_snake'], '58': ['n01737021', 'water_snake'], '59': ['n01739381', 'vine_snake'], '60': ['n01740131', 'night_snake'], '61': ['n01742172', 'boa_constrictor'], '62': ['n01744401', 'rock_python'], '63': ['n01748264', 'Indian_cobra'], '64': ['n01749939', 'green_mamba'], '65': ['n01751748', 'sea_snake'], '66': ['n01753488', 'horned_viper'], '67': ['n01755581', 'diamondback'], '68': ['n01756291', 'sidewinder'], '69': ['n01768244', 'trilobite'], '70': ['n01770081', 'harvestman'], '71': ['n01770393', 'scorpion'], '72': ['n01773157', 'black_and_gold_garden_spider'], '73': ['n01773549', 'barn_spider'], '74': ['n01773797', 'garden_spider'], '75': ['n01774384', 'black_widow'], '76': ['n01774750', 'tarantula'], '77': ['n01775062', 'wolf_spider'], '78': ['n01776313', 'tick'], '79': ['n01784675', 'centipede'], '80': ['n01795545', 'black_grouse'], '81': ['n01796340', 'ptarmigan'], '82': ['n01797886', 'ruffed_grouse'], '83': ['n01798484', 'prairie_chicken'], '84': ['n01806143', 'peacock'], '85': ['n01806567', 'quail'], '86': ['n01807496', 'partridge'], '87': ['n01817953', 'African_grey'], '88': ['n01818515', 'macaw'], '89': ['n01819313', 'sulphur-crested_cockatoo'], '90': ['n01820546', 'lorikeet'], '91': ['n01824575', 'coucal'], '92': ['n01828970', 'bee_eater'], '93': ['n01829413', 'hornbill'], '94': ['n01833805', 'hummingbird'], '95': ['n01843065', 'jacamar'], '96': ['n01843383', 'toucan'], '97': ['n01847000', 'drake'], '98': ['n01855032', 'red-breasted_merganser'], '99': ['n01855672', 'goose'], '100': ['n01860187', 'black_swan'], '101': ['n01871265', 'tusker'], '102': ['n01872401', 'echidna'], '103': ['n01873310', 'platypus'], '104': ['n01877812', 'wallaby'], '105': ['n01882714', 'koala'], '106': ['n01883070', 'wombat'], '107': ['n01910747', 'jellyfish'], '108': ['n01914609', 'sea_anemone'], '109': ['n01917289', 'brain_coral'], '110': ['n01924916', 'flatworm'], '111': ['n01930112', 'nematode'], '112': ['n01943899', 'conch'], '113': ['n01944390', 'snail'], '114': ['n01945685', 'slug'], '115': ['n01950731', 'sea_slug'], '116': ['n01955084', 'chiton'], '117': ['n01968897', 'chambered_nautilus'], '118': ['n01978287', 'Dungeness_crab'], '119': ['n01978455', 'rock_crab'], '120': ['n01980166', 'fiddler_crab'], '121': ['n01981276', 'king_crab'], '122': ['n01983481', 'American_lobster'], '123': ['n01984695', 'spiny_lobster'], '124': ['n01985128', 'crayfish'], '125': ['n01986214', 'hermit_crab'], '126': ['n01990800', 'isopod'], '127': ['n02002556', 'white_stork'], '128': ['n02002724', 'black_stork'], '129': ['n02006656', 'spoonbill'], '130': ['n02007558', 'flamingo'], '131': ['n02009229', 'little_blue_heron'], '132': ['n02009912', 'American_egret'], '133': ['n02011460', 'bittern'], '134': ['n02012849', 'crane'], '135': ['n02013706', 'limpkin'], '136': ['n02017213', 'European_gallinule'], '137': ['n02018207', 'American_coot'], '138': ['n02018795', 'bustard'], '139': ['n02025239', 'ruddy_turnstone'], '140': ['n02027492', 'red-backed_sandpiper'], '141': ['n02028035', 'redshank'], '142': ['n02033041', 'dowitcher'], '143': ['n02037110', 'oystercatcher'], '144': ['n02051845', 'pelican'], '145': ['n02056570', 'king_penguin'], '146': ['n02058221', 'albatross'], '147': ['n02066245', 'grey_whale'], '148': ['n02071294', 'killer_whale'], '149': ['n02074367', 'dugong'], '150': ['n02077923', 'sea_lion'], '151': ['n02085620', 'Chihuahua'], '152': ['n02085782', 'Japanese_spaniel'], '153': ['n02085936', 'Maltese_dog'], '154': ['n02086079', 'Pekinese'], '155': ['n02086240', 'Shih-Tzu'], '156': ['n02086646', 'Blenheim_spaniel'], '157': ['n02086910', 'papillon'], '158': ['n02087046', 'toy_terrier'], '159': ['n02087394', 'Rhodesian_ridgeback'], '160': ['n02088094', 'Afghan_hound'], '161': ['n02088238', 'basset'], '162': ['n02088364', 'beagle'], '163': ['n02088466', 'bloodhound'], '164': ['n02088632', 'bluetick'], '165': ['n02089078', 'black-and-tan_coonhound'], '166': ['n02089867', 'Walker_hound'], '167': ['n02089973', 'English_foxhound'], '168': ['n02090379', 'redbone'], '169': ['n02090622', 'borzoi'], '170': ['n02090721', 'Irish_wolfhound'], '171': ['n02091032', 'Italian_greyhound'], '172': ['n02091134', 'whippet'], '173': ['n02091244', 'Ibizan_hound'], '174': ['n02091467', 'Norwegian_elkhound'], '175': ['n02091635', 'otterhound'], '176': ['n02091831', 'Saluki'], '177': ['n02092002', 'Scottish_deerhound'], '178': ['n02092339', 'Weimaraner'], '179': ['n02093256', 'Staffordshire_bullterrier'], '180': ['n02093428', 'American_Staffordshire_terrier'], '181': ['n02093647', 'Bedlington_terrier'], '182': ['n02093754', 'Border_terrier'], '183': ['n02093859', 'Kerry_blue_terrier'], '184': ['n02093991', 'Irish_terrier'], '185': ['n02094114', 'Norfolk_terrier'], '186': ['n02094258', 'Norwich_terrier'], '187': ['n02094433', 'Yorkshire_terrier'], '188': ['n02095314', 'wire-haired_fox_terrier'], '189': ['n02095570', 'Lakeland_terrier'], '190': ['n02095889', 'Sealyham_terrier'], '191': ['n02096051', 'Airedale'], '192': ['n02096177', 'cairn'], '193': ['n02096294', 'Australian_terrier'], '194': ['n02096437', 'Dandie_Dinmont'], '195': ['n02096585', 'Boston_bull'], '196': ['n02097047', 'miniature_schnauzer'], '197': ['n02097130', 'giant_schnauzer'], '198': ['n02097209', 'standard_schnauzer'], '199': ['n02097298', 'Scotch_terrier'], '200': ['n02097474', 'Tibetan_terrier'], '201': ['n02097658', 'silky_terrier'], '202': ['n02098105', 'soft-coated_wheaten_terrier'], '203': ['n02098286', 'West_Highland_white_terrier'], '204': ['n02098413', 'Lhasa'], '205': ['n02099267', 'flat-coated_retriever'], '206': ['n02099429', 'curly-coated_retriever'], '207': ['n02099601', 'golden_retriever'], '208': ['n02099712', 'Labrador_retriever'], '209': ['n02099849', 'Chesapeake_Bay_retriever'], '210': ['n02100236', 'German_short-haired_pointer'], '211': ['n02100583', 'vizsla'], '212': ['n02100735', 'English_setter'], '213': ['n02100877', 'Irish_setter'], '214': ['n02101006', 'Gordon_setter'], '215': ['n02101388', 'Brittany_spaniel'], '216': ['n02101556', 'clumber'], '217': ['n02102040', 'English_springer'], '218': ['n02102177', 'Welsh_springer_spaniel'], '219': ['n02102318', 'cocker_spaniel'], '220': ['n02102480', 'Sussex_spaniel'], '221': ['n02102973', 'Irish_water_spaniel'], '222': ['n02104029', 'kuvasz'], '223': ['n02104365', 'schipperke'], '224': ['n02105056', 'groenendael'], '225': ['n02105162', 'malinois'], '226': ['n02105251', 'briard'], '227': ['n02105412', 'kelpie'], '228': ['n02105505', 'komondor'], '229': ['n02105641', 'Old_English_sheepdog'], '230': ['n02105855', 'Shetland_sheepdog'], '231': ['n02106030', 'collie'], '232': ['n02106166', 'Border_collie'], '233': ['n02106382', 'Bouvier_des_Flandres'], '234': ['n02106550', 'Rottweiler'], '235': ['n02106662', 'German_shepherd'], '236': ['n02107142', 'Doberman'], '237': ['n02107312', 'miniature_pinscher'], '238': ['n02107574', 'Greater_Swiss_Mountain_dog'], '239': ['n02107683', 'Bernese_mountain_dog'], '240': ['n02107908', 'Appenzeller'], '241': ['n02108000', 'EntleBucher'], '242': ['n02108089', 'boxer'], '243': ['n02108422', 'bull_mastiff'], '244': ['n02108551', 'Tibetan_mastiff'], '245': ['n02108915', 'French_bulldog'], '246': ['n02109047', 'Great_Dane'], '247': ['n02109525', 'Saint_Bernard'], '248': ['n02109961', 'Eskimo_dog'], '249': ['n02110063', 'malamute'], '250': ['n02110185', 'Siberian_husky'], '251': ['n02110341', 'dalmatian'], '252': ['n02110627', 'affenpinscher'], '253': ['n02110806', 'basenji'], '254': ['n02110958', 'pug'], '255': ['n02111129', 'Leonberg'], '256': ['n02111277', 'Newfoundland'], '257': ['n02111500', 'Great_Pyrenees'], '258': ['n02111889', 'Samoyed'], '259': ['n02112018', 'Pomeranian'], '260': ['n02112137', 'chow'], '261': ['n02112350', 'keeshond'], '262': ['n02112706', 'Brabancon_griffon'], '263': ['n02113023', 'Pembroke'], '264': ['n02113186', 'Cardigan'], '265': ['n02113624', 'toy_poodle'], '266': ['n02113712', 'miniature_poodle'], '267': ['n02113799', 'standard_poodle'], '268': ['n02113978', 'Mexican_hairless'], '269': ['n02114367', 'timber_wolf'], '270': ['n02114548', 'white_wolf'], '271': ['n02114712', 'red_wolf'], '272': ['n02114855', 'coyote'], '273': ['n02115641', 'dingo'], '274': ['n02115913', 'dhole'], '275': ['n02116738', 'African_hunting_dog'], '276': ['n02117135', 'hyena'], '277': ['n02119022', 'red_fox'], '278': ['n02119789', 'kit_fox'], '279': ['n02120079', 'Arctic_fox'], '280': ['n02120505', 'grey_fox'], '281': ['n02123045', 'tabby'], '282': ['n02123159', 'tiger_cat'], '283': ['n02123394', 'Persian_cat'], '284': ['n02123597', 'Siamese_cat'], '285': ['n02124075', 'Egyptian_cat'], '286': ['n02125311', 'cougar'], '287': ['n02127052', 'lynx'], '288': ['n02128385', 'leopard'], '289': ['n02128757', 'snow_leopard'], '290': ['n02128925', 'jaguar'], '291': ['n02129165', 'lion'], '292': ['n02129604', 'tiger'], '293': ['n02130308', 'cheetah'], '294': ['n02132136', 'brown_bear'], '295': ['n02133161', 'American_black_bear'], '296': ['n02134084', 'ice_bear'], '297': ['n02134418', 'sloth_bear'], '298': ['n02137549', 'mongoose'], '299': ['n02138441', 'meerkat'], '300': ['n02165105', 'tiger_beetle'], '301': ['n02165456', 'ladybug'], '302': ['n02167151', 'ground_beetle'], '303': ['n02168699', 'long-horned_beetle'], '304': ['n02169497', 'leaf_beetle'], '305': ['n02172182', 'dung_beetle'], '306': ['n02174001', 'rhinoceros_beetle'], '307': ['n02177972', 'weevil'], '308': ['n02190166', 'fly'], '309': ['n02206856', 'bee'], '310': ['n02219486', 'ant'], '311': ['n02226429', 'grasshopper'], '312': ['n02229544', 'cricket'], '313': ['n02231487', 'walking_stick'], '314': ['n02233338', 'cockroach'], '315': ['n02236044', 'mantis'], '316': ['n02256656', 'cicada'], '317': ['n02259212', 'leafhopper'], '318': ['n02264363', 'lacewing'], '319': ['n02268443', 'dragonfly'], '320': ['n02268853', 'damselfly'], '321': ['n02276258', 'admiral'], '322': ['n02277742', 'ringlet'], '323': ['n02279972', 'monarch'], '324': ['n02280649', 'cabbage_butterfly'], '325': ['n02281406', 'sulphur_butterfly'], '326': ['n02281787', 'lycaenid'], '327': ['n02317335', 'starfish'], '328': ['n02319095', 'sea_urchin'], '329': ['n02321529', 'sea_cucumber'], '330': ['n02325366', 'wood_rabbit'], '331': ['n02326432', 'hare'], '332': ['n02328150', 'Angora'], '333': ['n02342885', 'hamster'], '334': ['n02346627', 'porcupine'], '335': ['n02356798', 'fox_squirrel'], '336': ['n02361337', 'marmot'], '337': ['n02363005', 'beaver'], '338': ['n02364673', 'guinea_pig'], '339': ['n02389026', 'sorrel'], '340': ['n02391049', 'zebra'], '341': ['n02395406', 'hog'], '342': ['n02396427', 'wild_boar'], '343': ['n02397096', 'warthog'], '344': ['n02398521', 'hippopotamus'], '345': ['n02403003', 'ox'], '346': ['n02408429', 'water_buffalo'], '347': ['n02410509', 'bison'], '348': ['n02412080', 'ram'], '349': ['n02415577', 'bighorn'], '350': ['n02417914', 'ibex'], '351': ['n02422106', 'hartebeest'], '352': ['n02422699', 'impala'], '353': ['n02423022', 'gazelle'], '354': ['n02437312', 'Arabian_camel'], '355': ['n02437616', 'llama'], '356': ['n02441942', 'weasel'], '357': ['n02442845', 'mink'], '358': ['n02443114', 'polecat'], '359': ['n02443484', 'black-footed_ferret'], '360': ['n02444819', 'otter'], '361': ['n02445715', 'skunk'], '362': ['n02447366', 'badger'], '363': ['n02454379', 'armadillo'], '364': ['n02457408', 'three-toed_sloth'], '365': ['n02480495', 'orangutan'], '366': ['n02480855', 'gorilla'], '367': ['n02481823', 'chimpanzee'], '368': ['n02483362', 'gibbon'], '369': ['n02483708', 'siamang'], '370': ['n02484975', 'guenon'], '371': ['n02486261', 'patas'], '372': ['n02486410', 'baboon'], '373': ['n02487347', 'macaque'], '374': ['n02488291', 'langur'], '375': ['n02488702', 'colobus'], '376': ['n02489166', 'proboscis_monkey'], '377': ['n02490219', 'marmoset'], '378': ['n02492035', 'capuchin'], '379': ['n02492660', 'howler_monkey'], '380': ['n02493509', 'titi'], '381': ['n02493793', 'spider_monkey'], '382': ['n02494079', 'squirrel_monkey'], '383': ['n02497673', 'Madagascar_cat'], '384': ['n02500267', 'indri'], '385': ['n02504013', 'Indian_elephant'], '386': ['n02504458', 'African_elephant'], '387': ['n02509815', 'lesser_panda'], '388': ['n02510455', 'giant_panda'], '389': ['n02514041', 'barracouta'], '390': ['n02526121', 'eel'], '391': ['n02536864', 'coho'], '392': ['n02606052', 'rock_beauty'], '393': ['n02607072', 'anemone_fish'], '394': ['n02640242', 'sturgeon'], '395': ['n02641379', 'gar'], '396': ['n02643566', 'lionfish'], '397': ['n02655020', 'puffer'], '398': ['n02666196', 'abacus'], '399': ['n02667093', 'abaya'], '400': ['n02669723', 'academic_gown'], '401': ['n02672831', 'accordion'], '402': ['n02676566', 'acoustic_guitar'], '403': ['n02687172', 'aircraft_carrier'], '404': ['n02690373', 'airliner'], '405': ['n02692877', 'airship'], '406': ['n02699494', 'altar'], '407': ['n02701002', 'ambulance'], '408': ['n02704792', 'amphibian'], '409': ['n02708093', 'analog_clock'], '410': ['n02727426', 'apiary'], '411': ['n02730930', 'apron'], '412': ['n02747177', 'ashcan'], '413': ['n02749479', 'assault_rifle'], '414': ['n02769748', 'backpack'], '415': ['n02776631', 'bakery'], '416': ['n02777292', 'balance_beam'], '417': ['n02782093', 'balloon'], '418': ['n02783161', 'ballpoint'], '419': ['n02786058', 'Band_Aid'], '420': ['n02787622', 'banjo'], '421': ['n02788148', 'bannister'], '422': ['n02790996', 'barbell'], '423': ['n02791124', 'barber_chair'], '424': ['n02791270', 'barbershop'], '425': ['n02793495', 'barn'], '426': ['n02794156', 'barometer'], '427': ['n02795169', 'barrel'], '428': ['n02797295', 'barrow'], '429': ['n02799071', 'baseball'], '430': ['n02802426', 'basketball'], '431': ['n02804414', 'bassinet'], '432': ['n02804610', 'bassoon'], '433': ['n02807133', 'bathing_cap'], '434': ['n02808304', 'bath_towel'], '435': ['n02808440', 'bathtub'], '436': ['n02814533', 'beach_wagon'], '437': ['n02814860', 'beacon'], '438': ['n02815834', 'beaker'], '439': ['n02817516', 'bearskin'], '440': ['n02823428', 'beer_bottle'], '441': ['n02823750', 'beer_glass'], '442': ['n02825657', 'bell_cote'], '443': ['n02834397', 'bib'], '444': ['n02835271', 'bicycle-built-for-two'], '445': ['n02837789', 'bikini'], '446': ['n02840245', 'binder'], '447': ['n02841315', 'binoculars'], '448': ['n02843684', 'birdhouse'], '449': ['n02859443', 'boathouse'], '450': ['n02860847', 'bobsled'], '451': ['n02865351', 'bolo_tie'], '452': ['n02869837', 'bonnet'], '453': ['n02870880', 'bookcase'], '454': ['n02871525', 'bookshop'], '455': ['n02877765', 'bottlecap'], '456': ['n02879718', 'bow'], '457': ['n02883205', 'bow_tie'], '458': ['n02892201', 'brass'], '459': ['n02892767', 'brassiere'], '460': ['n02894605', 'breakwater'], '461': ['n02895154', 'breastplate'], '462': ['n02906734', 'broom'], '463': ['n02909870', 'bucket'], '464': ['n02910353', 'buckle'], '465': ['n02916936', 'bulletproof_vest'], '466': ['n02917067', 'bullet_train'], '467': ['n02927161', 'butcher_shop'], '468': ['n02930766', 'cab'], '469': ['n02939185', 'caldron'], '470': ['n02948072', 'candle'], '471': ['n02950826', 'cannon'], '472': ['n02951358', 'canoe'], '473': ['n02951585', 'can_opener'], '474': ['n02963159', 'cardigan'], '475': ['n02965783', 'car_mirror'], '476': ['n02966193', 'carousel'], '477': ['n02966687', \"carpenter's_kit\"], '478': ['n02971356', 'carton'], '479': ['n02974003', 'car_wheel'], '480': ['n02977058', 'cash_machine'], '481': ['n02978881', 'cassette'], '482': ['n02979186', 'cassette_player'], '483': ['n02980441', 'castle'], '484': ['n02981792', 'catamaran'], '485': ['n02988304', 'CD_player'], '486': ['n02992211', 'cello'], '487': ['n02992529', 'cellular_telephone'], '488': ['n02999410', 'chain'], '489': ['n03000134', 'chainlink_fence'], '490': ['n03000247', 'chain_mail'], '491': ['n03000684', 'chain_saw'], '492': ['n03014705', 'chest'], '493': ['n03016953', 'chiffonier'], '494': ['n03017168', 'chime'], '495': ['n03018349', 'china_cabinet'], '496': ['n03026506', 'Christmas_stocking'], '497': ['n03028079', 'church'], '498': ['n03032252', 'cinema'], '499': ['n03041632', 'cleaver'], '500': ['n03042490', 'cliff_dwelling'], '501': ['n03045698', 'cloak'], '502': ['n03047690', 'clog'], '503': ['n03062245', 'cocktail_shaker'], '504': ['n03063599', 'coffee_mug'], '505': ['n03063689', 'coffeepot'], '506': ['n03065424', 'coil'], '507': ['n03075370', 'combination_lock'], '508': ['n03085013', 'computer_keyboard'], '509': ['n03089624', 'confectionery'], '510': ['n03095699', 'container_ship'], '511': ['n03100240', 'convertible'], '512': ['n03109150', 'corkscrew'], '513': ['n03110669', 'cornet'], '514': ['n03124043', 'cowboy_boot'], '515': ['n03124170', 'cowboy_hat'], '516': ['n03125729', 'cradle'], '517': ['n03126707', 'crane'], '518': ['n03127747', 'crash_helmet'], '519': ['n03127925', 'crate'], '520': ['n03131574', 'crib'], '521': ['n03133878', 'Crock_Pot'], '522': ['n03134739', 'croquet_ball'], '523': ['n03141823', 'crutch'], '524': ['n03146219', 'cuirass'], '525': ['n03160309', 'dam'], '526': ['n03179701', 'desk'], '527': ['n03180011', 'desktop_computer'], '528': ['n03187595', 'dial_telephone'], '529': ['n03188531', 'diaper'], '530': ['n03196217', 'digital_clock'], '531': ['n03197337', 'digital_watch'], '532': ['n03201208', 'dining_table'], '533': ['n03207743', 'dishrag'], '534': ['n03207941', 'dishwasher'], '535': ['n03208938', 'disk_brake'], '536': ['n03216828', 'dock'], '537': ['n03218198', 'dogsled'], '538': ['n03220513', 'dome'], '539': ['n03223299', 'doormat'], '540': ['n03240683', 'drilling_platform'], '541': ['n03249569', 'drum'], '542': ['n03250847', 'drumstick'], '543': ['n03255030', 'dumbbell'], '544': ['n03259280', 'Dutch_oven'], '545': ['n03271574', 'electric_fan'], '546': ['n03272010', 'electric_guitar'], '547': ['n03272562', 'electric_locomotive'], '548': ['n03290653', 'entertainment_center'], '549': ['n03291819', 'envelope'], '550': ['n03297495', 'espresso_maker'], '551': ['n03314780', 'face_powder'], '552': ['n03325584', 'feather_boa'], '553': ['n03337140', 'file'], '554': ['n03344393', 'fireboat'], '555': ['n03345487', 'fire_engine'], '556': ['n03347037', 'fire_screen'], '557': ['n03355925', 'flagpole'], '558': ['n03372029', 'flute'], '559': ['n03376595', 'folding_chair'], '560': ['n03379051', 'football_helmet'], '561': ['n03384352', 'forklift'], '562': ['n03388043', 'fountain'], '563': ['n03388183', 'fountain_pen'], '564': ['n03388549', 'four-poster'], '565': ['n03393912', 'freight_car'], '566': ['n03394916', 'French_horn'], '567': ['n03400231', 'frying_pan'], '568': ['n03404251', 'fur_coat'], '569': ['n03417042', 'garbage_truck'], '570': ['n03424325', 'gasmask'], '571': ['n03425413', 'gas_pump'], '572': ['n03443371', 'goblet'], '573': ['n03444034', 'go-kart'], '574': ['n03445777', 'golf_ball'], '575': ['n03445924', 'golfcart'], '576': ['n03447447', 'gondola'], '577': ['n03447721', 'gong'], '578': ['n03450230', 'gown'], '579': ['n03452741', 'grand_piano'], '580': ['n03457902', 'greenhouse'], '581': ['n03459775', 'grille'], '582': ['n03461385', 'grocery_store'], '583': ['n03467068', 'guillotine'], '584': ['n03476684', 'hair_slide'], '585': ['n03476991', 'hair_spray'], '586': ['n03478589', 'half_track'], '587': ['n03481172', 'hammer'], '588': ['n03482405', 'hamper'], '589': ['n03483316', 'hand_blower'], '590': ['n03485407', 'hand-held_computer'], '591': ['n03485794', 'handkerchief'], '592': ['n03492542', 'hard_disc'], '593': ['n03494278', 'harmonica'], '594': ['n03495258', 'harp'], '595': ['n03496892', 'harvester'], '596': ['n03498962', 'hatchet'], '597': ['n03527444', 'holster'], '598': ['n03529860', 'home_theater'], '599': ['n03530642', 'honeycomb'], '600': ['n03532672', 'hook'], '601': ['n03534580', 'hoopskirt'], '602': ['n03535780', 'horizontal_bar'], '603': ['n03538406', 'horse_cart'], '604': ['n03544143', 'hourglass'], '605': ['n03584254', 'iPod'], '606': ['n03584829', 'iron'], '607': ['n03590841', \"jack-o'-lantern\"], '608': ['n03594734', 'jean'], '609': ['n03594945', 'jeep'], '610': ['n03595614', 'jersey'], '611': ['n03598930', 'jigsaw_puzzle'], '612': ['n03599486', 'jinrikisha'], '613': ['n03602883', 'joystick'], '614': ['n03617480', 'kimono'], '615': ['n03623198', 'knee_pad'], '616': ['n03627232', 'knot'], '617': ['n03630383', 'lab_coat'], '618': ['n03633091', 'ladle'], '619': ['n03637318', 'lampshade'], '620': ['n03642806', 'laptop'], '621': ['n03649909', 'lawn_mower'], '622': ['n03657121', 'lens_cap'], '623': ['n03658185', 'letter_opener'], '624': ['n03661043', 'library'], '625': ['n03662601', 'lifeboat'], '626': ['n03666591', 'lighter'], '627': ['n03670208', 'limousine'], '628': ['n03673027', 'liner'], '629': ['n03676483', 'lipstick'], '630': ['n03680355', 'Loafer'], '631': ['n03690938', 'lotion'], '632': ['n03691459', 'loudspeaker'], '633': ['n03692522', 'loupe'], '634': ['n03697007', 'lumbermill'], '635': ['n03706229', 'magnetic_compass'], '636': ['n03709823', 'mailbag'], '637': ['n03710193', 'mailbox'], '638': ['n03710637', 'maillot'], '639': ['n03710721', 'maillot'], '640': ['n03717622', 'manhole_cover'], '641': ['n03720891', 'maraca'], '642': ['n03721384', 'marimba'], '643': ['n03724870', 'mask'], '644': ['n03729826', 'matchstick'], '645': ['n03733131', 'maypole'], '646': ['n03733281', 'maze'], '647': ['n03733805', 'measuring_cup'], '648': ['n03742115', 'medicine_chest'], '649': ['n03743016', 'megalith'], '650': ['n03759954', 'microphone'], '651': ['n03761084', 'microwave'], '652': ['n03763968', 'military_uniform'], '653': ['n03764736', 'milk_can'], '654': ['n03769881', 'minibus'], '655': ['n03770439', 'miniskirt'], '656': ['n03770679', 'minivan'], '657': ['n03773504', 'missile'], '658': ['n03775071', 'mitten'], '659': ['n03775546', 'mixing_bowl'], '660': ['n03776460', 'mobile_home'], '661': ['n03777568', 'Model_T'], '662': ['n03777754', 'modem'], '663': ['n03781244', 'monastery'], '664': ['n03782006', 'monitor'], '665': ['n03785016', 'moped'], '666': ['n03786901', 'mortar'], '667': ['n03787032', 'mortarboard'], '668': ['n03788195', 'mosque'], '669': ['n03788365', 'mosquito_net'], '670': ['n03791053', 'motor_scooter'], '671': ['n03792782', 'mountain_bike'], '672': ['n03792972', 'mountain_tent'], '673': ['n03793489', 'mouse'], '674': ['n03794056', 'mousetrap'], '675': ['n03796401', 'moving_van'], '676': ['n03803284', 'muzzle'], '677': ['n03804744', 'nail'], '678': ['n03814639', 'neck_brace'], '679': ['n03814906', 'necklace'], '680': ['n03825788', 'nipple'], '681': ['n03832673', 'notebook'], '682': ['n03837869', 'obelisk'], '683': ['n03838899', 'oboe'], '684': ['n03840681', 'ocarina'], '685': ['n03841143', 'odometer'], '686': ['n03843555', 'oil_filter'], '687': ['n03854065', 'organ'], '688': ['n03857828', 'oscilloscope'], '689': ['n03866082', 'overskirt'], '690': ['n03868242', 'oxcart'], '691': ['n03868863', 'oxygen_mask'], '692': ['n03871628', 'packet'], '693': ['n03873416', 'paddle'], '694': ['n03874293', 'paddlewheel'], '695': ['n03874599', 'padlock'], '696': ['n03876231', 'paintbrush'], '697': ['n03877472', 'pajama'], '698': ['n03877845', 'palace'], '699': ['n03884397', 'panpipe'], '700': ['n03887697', 'paper_towel'], '701': ['n03888257', 'parachute'], '702': ['n03888605', 'parallel_bars'], '703': ['n03891251', 'park_bench'], '704': ['n03891332', 'parking_meter'], '705': ['n03895866', 'passenger_car'], '706': ['n03899768', 'patio'], '707': ['n03902125', 'pay-phone'], '708': ['n03903868', 'pedestal'], '709': ['n03908618', 'pencil_box'], '710': ['n03908714', 'pencil_sharpener'], '711': ['n03916031', 'perfume'], '712': ['n03920288', 'Petri_dish'], '713': ['n03924679', 'photocopier'], '714': ['n03929660', 'pick'], '715': ['n03929855', 'pickelhaube'], '716': ['n03930313', 'picket_fence'], '717': ['n03930630', 'pickup'], '718': ['n03933933', 'pier'], '719': ['n03935335', 'piggy_bank'], '720': ['n03937543', 'pill_bottle'], '721': ['n03938244', 'pillow'], '722': ['n03942813', 'ping-pong_ball'], '723': ['n03944341', 'pinwheel'], '724': ['n03947888', 'pirate'], '725': ['n03950228', 'pitcher'], '726': ['n03954731', 'plane'], '727': ['n03956157', 'planetarium'], '728': ['n03958227', 'plastic_bag'], '729': ['n03961711', 'plate_rack'], '730': ['n03967562', 'plow'], '731': ['n03970156', 'plunger'], '732': ['n03976467', 'Polaroid_camera'], '733': ['n03976657', 'pole'], '734': ['n03977966', 'police_van'], '735': ['n03980874', 'poncho'], '736': ['n03982430', 'pool_table'], '737': ['n03983396', 'pop_bottle'], '738': ['n03991062', 'pot'], '739': ['n03992509', \"potter's_wheel\"], '740': ['n03995372', 'power_drill'], '741': ['n03998194', 'prayer_rug'], '742': ['n04004767', 'printer'], '743': ['n04005630', 'prison'], '744': ['n04008634', 'projectile'], '745': ['n04009552', 'projector'], '746': ['n04019541', 'puck'], '747': ['n04023962', 'punching_bag'], '748': ['n04026417', 'purse'], '749': ['n04033901', 'quill'], '750': ['n04033995', 'quilt'], '751': ['n04037443', 'racer'], '752': ['n04039381', 'racket'], '753': ['n04040759', 'radiator'], '754': ['n04041544', 'radio'], '755': ['n04044716', 'radio_telescope'], '756': ['n04049303', 'rain_barrel'], '757': ['n04065272', 'recreational_vehicle'], '758': ['n04067472', 'reel'], '759': ['n04069434', 'reflex_camera'], '760': ['n04070727', 'refrigerator'], '761': ['n04074963', 'remote_control'], '762': ['n04081281', 'restaurant'], '763': ['n04086273', 'revolver'], '764': ['n04090263', 'rifle'], '765': ['n04099969', 'rocking_chair'], '766': ['n04111531', 'rotisserie'], '767': ['n04116512', 'rubber_eraser'], '768': ['n04118538', 'rugby_ball'], '769': ['n04118776', 'rule'], '770': ['n04120489', 'running_shoe'], '771': ['n04125021', 'safe'], '772': ['n04127249', 'safety_pin'], '773': ['n04131690', 'saltshaker'], '774': ['n04133789', 'sandal'], '775': ['n04136333', 'sarong'], '776': ['n04141076', 'sax'], '777': ['n04141327', 'scabbard'], '778': ['n04141975', 'scale'], '779': ['n04146614', 'school_bus'], '780': ['n04147183', 'schooner'], '781': ['n04149813', 'scoreboard'], '782': ['n04152593', 'screen'], '783': ['n04153751', 'screw'], '784': ['n04154565', 'screwdriver'], '785': ['n04162706', 'seat_belt'], '786': ['n04179913', 'sewing_machine'], '787': ['n04192698', 'shield'], '788': ['n04200800', 'shoe_shop'], '789': ['n04201297', 'shoji'], '790': ['n04204238', 'shopping_basket'], '791': ['n04204347', 'shopping_cart'], '792': ['n04208210', 'shovel'], '793': ['n04209133', 'shower_cap'], '794': ['n04209239', 'shower_curtain'], '795': ['n04228054', 'ski'], '796': ['n04229816', 'ski_mask'], '797': ['n04235860', 'sleeping_bag'], '798': ['n04238763', 'slide_rule'], '799': ['n04239074', 'sliding_door'], '800': ['n04243546', 'slot'], '801': ['n04251144', 'snorkel'], '802': ['n04252077', 'snowmobile'], '803': ['n04252225', 'snowplow'], '804': ['n04254120', 'soap_dispenser'], '805': ['n04254680', 'soccer_ball'], '806': ['n04254777', 'sock'], '807': ['n04258138', 'solar_dish'], '808': ['n04259630', 'sombrero'], '809': ['n04263257', 'soup_bowl'], '810': ['n04264628', 'space_bar'], '811': ['n04265275', 'space_heater'], '812': ['n04266014', 'space_shuttle'], '813': ['n04270147', 'spatula'], '814': ['n04273569', 'speedboat'], '815': ['n04275548', 'spider_web'], '816': ['n04277352', 'spindle'], '817': ['n04285008', 'sports_car'], '818': ['n04286575', 'spotlight'], '819': ['n04296562', 'stage'], '820': ['n04310018', 'steam_locomotive'], '821': ['n04311004', 'steel_arch_bridge'], '822': ['n04311174', 'steel_drum'], '823': ['n04317175', 'stethoscope'], '824': ['n04325704', 'stole'], '825': ['n04326547', 'stone_wall'], '826': ['n04328186', 'stopwatch'], '827': ['n04330267', 'stove'], '828': ['n04332243', 'strainer'], '829': ['n04335435', 'streetcar'], '830': ['n04336792', 'stretcher'], '831': ['n04344873', 'studio_couch'], '832': ['n04346328', 'stupa'], '833': ['n04347754', 'submarine'], '834': ['n04350905', 'suit'], '835': ['n04355338', 'sundial'], '836': ['n04355933', 'sunglass'], '837': ['n04356056', 'sunglasses'], '838': ['n04357314', 'sunscreen'], '839': ['n04366367', 'suspension_bridge'], '840': ['n04367480', 'swab'], '841': ['n04370456', 'sweatshirt'], '842': ['n04371430', 'swimming_trunks'], '843': ['n04371774', 'swing'], '844': ['n04372370', 'switch'], '845': ['n04376876', 'syringe'], '846': ['n04380533', 'table_lamp'], '847': ['n04389033', 'tank'], '848': ['n04392985', 'tape_player'], '849': ['n04398044', 'teapot'], '850': ['n04399382', 'teddy'], '851': ['n04404412', 'television'], '852': ['n04409515', 'tennis_ball'], '853': ['n04417672', 'thatch'], '854': ['n04418357', 'theater_curtain'], '855': ['n04423845', 'thimble'], '856': ['n04428191', 'thresher'], '857': ['n04429376', 'throne'], '858': ['n04435653', 'tile_roof'], '859': ['n04442312', 'toaster'], '860': ['n04443257', 'tobacco_shop'], '861': ['n04447861', 'toilet_seat'], '862': ['n04456115', 'torch'], '863': ['n04458633', 'totem_pole'], '864': ['n04461696', 'tow_truck'], '865': ['n04462240', 'toyshop'], '866': ['n04465501', 'tractor'], '867': ['n04467665', 'trailer_truck'], '868': ['n04476259', 'tray'], '869': ['n04479046', 'trench_coat'], '870': ['n04482393', 'tricycle'], '871': ['n04483307', 'trimaran'], '872': ['n04485082', 'tripod'], '873': ['n04486054', 'triumphal_arch'], '874': ['n04487081', 'trolleybus'], '875': ['n04487394', 'trombone'], '876': ['n04493381', 'tub'], '877': ['n04501370', 'turnstile'], '878': ['n04505470', 'typewriter_keyboard'], '879': ['n04507155', 'umbrella'], '880': ['n04509417', 'unicycle'], '881': ['n04515003', 'upright'], '882': ['n04517823', 'vacuum'], '883': ['n04522168', 'vase'], '884': ['n04523525', 'vault'], '885': ['n04525038', 'velvet'], '886': ['n04525305', 'vending_machine'], '887': ['n04532106', 'vestment'], '888': ['n04532670', 'viaduct'], '889': ['n04536866', 'violin'], '890': ['n04540053', 'volleyball'], '891': ['n04542943', 'waffle_iron'], '892': ['n04548280', 'wall_clock'], '893': ['n04548362', 'wallet'], '894': ['n04550184', 'wardrobe'], '895': ['n04552348', 'warplane'], '896': ['n04553703', 'washbasin'], '897': ['n04554684', 'washer'], '898': ['n04557648', 'water_bottle'], '899': ['n04560804', 'water_jug'], '900': ['n04562935', 'water_tower'], '901': ['n04579145', 'whiskey_jug'], '902': ['n04579432', 'whistle'], '903': ['n04584207', 'wig'], '904': ['n04589890', 'window_screen'], '905': ['n04590129', 'window_shade'], '906': ['n04591157', 'Windsor_tie'], '907': ['n04591713', 'wine_bottle'], '908': ['n04592741', 'wing'], '909': ['n04596742', 'wok'], '910': ['n04597913', 'wooden_spoon'], '911': ['n04599235', 'wool'], '912': ['n04604644', 'worm_fence'], '913': ['n04606251', 'wreck'], '914': ['n04612504', 'yawl'], '915': ['n04613696', 'yurt'], '916': ['n06359193', 'web_site'], '917': ['n06596364', 'comic_book'], '918': ['n06785654', 'crossword_puzzle'], '919': ['n06794110', 'street_sign'], '920': ['n06874185', 'traffic_light'], '921': ['n07248320', 'book_jacket'], '922': ['n07565083', 'menu'], '923': ['n07579787', 'plate'], '924': ['n07583066', 'guacamole'], '925': ['n07584110', 'consomme'], '926': ['n07590611', 'hot_pot'], '927': ['n07613480', 'trifle'], '928': ['n07614500', 'ice_cream'], '929': ['n07615774', 'ice_lolly'], '930': ['n07684084', 'French_loaf'], '931': ['n07693725', 'bagel'], '932': ['n07695742', 'pretzel'], '933': ['n07697313', 'cheeseburger'], '934': ['n07697537', 'hotdog'], '935': ['n07711569', 'mashed_potato'], '936': ['n07714571', 'head_cabbage'], '937': ['n07714990', 'broccoli'], '938': ['n07715103', 'cauliflower'], '939': ['n07716358', 'zucchini'], '940': ['n07716906', 'spaghetti_squash'], '941': ['n07717410', 'acorn_squash'], '942': ['n07717556', 'butternut_squash'], '943': ['n07718472', 'cucumber'], '944': ['n07718747', 'artichoke'], '945': ['n07720875', 'bell_pepper'], '946': ['n07730033', 'cardoon'], '947': ['n07734744', 'mushroom'], '948': ['n07742313', 'Granny_Smith'], '949': ['n07745940', 'strawberry'], '950': ['n07747607', 'orange'], '951': ['n07749582', 'lemon'], '952': ['n07753113', 'fig'], '953': ['n07753275', 'pineapple'], '954': ['n07753592', 'banana'], '955': ['n07754684', 'jackfruit'], '956': ['n07760859', 'custard_apple'], '957': ['n07768694', 'pomegranate'], '958': ['n07802026', 'hay'], '959': ['n07831146', 'carbonara'], '960': ['n07836838', 'chocolate_sauce'], '961': ['n07860988', 'dough'], '962': ['n07871810', 'meat_loaf'], '963': ['n07873807', 'pizza'], '964': ['n07875152', 'potpie'], '965': ['n07880968', 'burrito'], '966': ['n07892512', 'red_wine'], '967': ['n07920052', 'espresso'], '968': ['n07930864', 'cup'], '969': ['n07932039', 'eggnog'], '970': ['n09193705', 'alp'], '971': ['n09229709', 'bubble'], '972': ['n09246464', 'cliff'], '973': ['n09256479', 'coral_reef'], '974': ['n09288635', 'geyser'], '975': ['n09332890', 'lakeside'], '976': ['n09399592', 'promontory'], '977': ['n09421951', 'sandbar'], '978': ['n09428293', 'seashore'], '979': ['n09468604', 'valley'], '980': ['n09472597', 'volcano'], '981': ['n09835506', 'ballplayer'], '982': ['n10148035', 'groom'], '983': ['n10565667', 'scuba_diver'], '984': ['n11879895', 'rapeseed'], '985': ['n11939491', 'daisy'], '986': ['n12057211', \"yellow_lady's_slipper\"], '987': ['n12144580', 'corn'], '988': ['n12267677', 'acorn'], '989': ['n12620546', 'hip'], '990': ['n12768682', 'buckeye'], '991': ['n12985857', 'coral_fungus'], '992': ['n12998815', 'agaric'], '993': ['n13037406', 'gyromitra'], '994': ['n13040303', 'stinkhorn'], '995': ['n13044778', 'earthstar'], '996': ['n13052670', 'hen-of-the-woods'], '997': ['n13054560', 'bolete'], '998': ['n13133613', 'ear'], '999': ['n15075141', 'toilet_tissue']}\nresults = []\nfor pred in preds:\n    top_indices = pred.argsort()[(- top):][::(- 1)]\n    result = [(tuple(CLASS_INDEX[str(i)]) + (pred[i],)) for i in top_indices]\n    result.sort(key=(lambda x: x[2]), reverse=True)\n    results.append(result)\nreturn results\n"}
{"label_name":"process","label":2,"method_name":"_preprocess","method":"\n'Validate and pre-process inputs as follows:\\n\\n    * Check that the weights tensor has the correct shape.\\n    * Extract a wire list for the subroutines of this template.\\n    * Cast initial state to a numpy array.\\n\\n    Args:\\n        weights (tensor_like): trainable parameters of the template\\n        wires (Wires): wires that template acts on\\n        init_state (tensor_like): shape ``(len(wires),)`` tensor\\n\\n    Returns:\\n        int, list[Wires], array: number of times that the ansatz is repeated, wires pattern,\\n            and preprocessed initial state\\n    '\nif (len(wires) < 2):\n    raise ValueError('This template requires the number of qubits to be greater than one;got a wire sequence with {} elements'.format(len(wires)))\nshape = qml.math.shape(weights)\nif (len(shape) != 2):\n    raise ValueError(f'Weights tensor must be 2-dimensional; got shape {shape}')\nif (shape[1] != ((2 * len(wires)) - 1)):\n    raise ValueError(f'Weights tensor must have a second dimension of length {((2 * len(wires)) - 1)}; got {shape[1]}')\nrepeat = shape[0]\nnm_wires = [wires.subset([l, (l + 1)]) for l in range(0, (len(wires) - 1), 2)]\nnm_wires += [wires.subset([l, (l + 1)]) for l in range(1, (len(wires) - 1), 2)]\ninit_state = qml.math.toarray(init_state)\nreturn (repeat, nm_wires, init_state)\n"}
{"label_name":"process","label":2,"method_name":"ClangPreprocessWithShim","method":"\n'Preprocessor OpenCL source with OpenCL shim header injection.\\n\\n  Args:\\n    text: OpenCL source to preprocess.\\n\\n  Returns:\\n    Preprocessed source.\\n  '\nreturn _ClangPreprocess(text, True)\n"}
{"label_name":"predict","label":4,"method_name":"predict_slow","method":"\n'Like `predict()`, but slower.'\ntime.sleep(5)\nreturn predict(feature_a, feature_b)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\nmodel.train()\nx = Variable(x_val, requires_grad=False)\ny = Variable(y_val, requires_grad=False)\noptimizer.zero_grad()\nfx = model.forward(x)\noutput = loss.forward(fx, y)\noutput.backward()\noptimizer.step()\nreturn output.item()\n"}
{"label_name":"train","label":0,"method_name":"get_train_noval_sbdataset","method":"\nreturn SBDatasetOpencv(root_path, image_set='train_noval', mode='segmentation', return_meta=return_meta)\n"}
{"label_name":"predict","label":4,"method_name":"_predict","method":"\n'Download sample image and make predictions on it using the model bundle.\\n    '\nkey = exp_cfg['key']\nconsole_heading(f'Testing model bundle for {key}...')\nmodel_bundle_uri = join(collect_dir, 'bundle', 'model-bundle.zip')\nif (not exists(model_bundle_uri)):\n    console_failure(f'Bundle does not exist: {model_bundle_uri}', bold=True)\n    exit(1)\npred_dir = join(collect_dir, 'sample-predictions')\nsample_uri = exp_cfg['sample_img']\n(_, sample_ext) = splitext(basename(sample_uri))\nsample_final_uri = join(pred_dir, f'sample-img-{key}{sample_ext}')\nif (not exists(sample_final_uri)):\n    sample_downloaded_uri = download_or_copy(sample_uri, pred_dir)\n    sample_copied_uri = join(pred_dir, basename(sample_uri))\n    dl_dir = normpath(relpath(sample_downloaded_uri, pred_dir)).split(os.sep)[0]\n    shutil.rmtree(join(pred_dir, dl_dir))\n    if (sample_copied_uri != sample_final_uri):\n        os.rename(sample_copied_uri, sample_final_uri)\npred_ext = exp_cfg['pred_ext']\nout_uri = join(pred_dir, f'sample-pred-{key}{pred_ext}')\ncmd = ['rastervision', 'predict', model_bundle_uri, sample_final_uri, out_uri]\nrun_command(cmd)\n"}
{"label_name":"train","label":0,"method_name":"load_number_of_epochs_trained","method":"\nn_epoch = None\ndata_set_kind = 'training'\nloss = 'log_likelihood'\nloss_prefix = 'losses\/'\nif ('VAE' in model.type):\n    loss = 'lower_bound'\nloss = (loss_prefix + loss)\nlog_directory = model.log_directory(run_id=run_id, early_stopping=early_stopping, best_model=best_model)\nscalar_sets = _summary_reader(log_directory, data_set_kind, loss)\nif (scalar_sets and (data_set_kind in scalar_sets)):\n    data_set_scalars = scalar_sets[data_set_kind]\nelse:\n    data_set_scalars = None\nif (data_set_scalars and (loss in data_set_scalars)):\n    scalars = data_set_scalars[loss]\nelse:\n    scalars = None\nif scalars:\n    n_epoch = max([scalar.step for scalar in scalars])\nreturn n_epoch\n"}
{"label_name":"process","label":2,"method_name":"process","method":"\n(sample_rate, signal) = scipy.io.wavfile.read(input_filename)\nsignal = signal[:]\nemphasized_signal = numpy.append(signal[0], (signal[1:] - (pre_emphasis * signal[:(- 1)])))\n(frame_length, frame_step) = ((frame_size * sample_rate), (frame_stride * sample_rate))\nsignal_length = len(emphasized_signal)\nframe_length = int(round(frame_length))\nframe_step = int(round(frame_step))\nnum_frames = int(numpy.ceil((float(numpy.abs((signal_length - frame_length))) \/ frame_step)))\npad_signal_length = ((num_frames * frame_step) + frame_length)\nz = numpy.zeros((pad_signal_length - signal_length))\npad_signal = numpy.append(emphasized_signal, z)\nindices = (numpy.tile(numpy.arange(0, frame_length), (num_frames, 1)) + numpy.tile(numpy.arange(0, (num_frames * frame_step), frame_step), (frame_length, 1)).T)\nframes = pad_signal[indices.astype(numpy.int32, copy=False)]\nframes *= numpy.hamming(frame_length)\nmag_frames = numpy.absolute(numpy.fft.rfft(frames, NFFT))\npow_frames = ((1.0 \/ NFFT) * (mag_frames ** 2))\nlow_freq_mel = 0\nhigh_freq_mel = (2595 * numpy.log10((1 + ((sample_rate \/ 2) \/ 700))))\nmel_points = numpy.linspace(low_freq_mel, high_freq_mel, (nfilt + 2))\nhz_points = (700 * ((10 ** (mel_points \/ 2595)) - 1))\nbin = numpy.floor((((NFFT + 1) * hz_points) \/ sample_rate))\nfbank = numpy.zeros((nfilt, int(numpy.floor(((NFFT \/ 2) + 1)))))\nfor m in range(1, (nfilt + 1)):\n    f_m_minus = int(bin[(m - 1)])\n    f_m = int(bin[m])\n    f_m_plus = int(bin[(m + 1)])\n    for k in range(f_m_minus, f_m):\n        fbank[((m - 1), k)] = ((k - bin[(m - 1)]) \/ (bin[m] - bin[(m - 1)]))\n    for k in range(f_m, f_m_plus):\n        fbank[((m - 1), k)] = ((bin[(m + 1)] - k) \/ (bin[(m + 1)] - bin[m]))\nfilter_banks = numpy.dot(pow_frames, fbank.T)\nfilter_banks = numpy.where((filter_banks == 0), numpy.finfo(float).eps, filter_banks)\nfilter_banks = (20 * numpy.log10(filter_banks))\nreturn filter_banks\n"}
{"label_name":"train","label":0,"method_name":"create_supervised_tbptt_trainer","method":"\n\"Create a trainer for truncated backprop through time supervised models.\\n\\n    Training recurrent model on long sequences is computationally intensive as\\n    it requires to process the whole sequence before getting a gradient.\\n    However, when the training loss is computed over many outputs\\n    (`X to many <https:\/\/karpathy.github.io\/2015\/05\/21\/rnn-effectiveness\/>`_),\\n    there is an opportunity to compute a gradient over a subsequence. This is\\n    known as\\n    `truncated backpropagation through time <https:\/\/machinelearningmastery.com\/\\n    gentle-introduction-backpropagation-time\/>`_.\\n    This supervised trainer apply gradient optimization step every `tbtt_step`\\n    time steps of the sequence, while backpropagating through the same\\n    `tbtt_step` time steps.\\n\\n    Args:\\n        model: the model to train.\\n        optimizer: the optimizer to use.\\n        loss_fn: the loss function to use.\\n        tbtt_step: the length of time chunks (last one may be smaller).\\n        dim: axis representing the time dimension.\\n        device: device type specification (default: None).\\n            Applies to batches.\\n        non_blocking: if True and this copy is between CPU and GPU,\\n            the copy may occur asynchronously with respect to the host. For other cases,\\n            this argument has no effect.\\n        prepare_batch: function that receives `batch`, `device`,\\n            `non_blocking` and outputs tuple of tensors `(batch_x, batch_y)`.\\n\\n    Returns:\\n        a trainer engine with supervised update function.\\n\\n    .. warning::\\n\\n        The internal use of `device` has changed.\\n        `device` will now *only* be used to move the input data to the correct device.\\n        The `model` should be moved by the user before creating an optimizer.\\n\\n        For more information see:\\n\\n        * `PyTorch Documentation <https:\/\/pytorch.org\/docs\/stable\/optim.html#constructing-it>`_\\n        * `PyTorch's Explanation <https:\/\/github.com\/pytorch\/pytorch\/issues\/7844#issuecomment-503713840>`_\\n    \"\n\ndef _update(engine: Engine, batch: Sequence[torch.Tensor]) -> float:\n    loss_list = []\n    hidden = None\n    (x, y) = batch\n    for batch_t in zip(x.split(tbtt_step, dim=dim), y.split(tbtt_step, dim=dim)):\n        (x_t, y_t) = prepare_batch(batch_t, device=device, non_blocking=non_blocking)\n        engine.fire_event(Tbptt_Events.TIME_ITERATION_STARTED)\n        model.train()\n        optimizer.zero_grad()\n        if (hidden is None):\n            (y_pred_t, hidden) = model(x_t)\n        else:\n            hidden = _detach_hidden(hidden)\n            (y_pred_t, hidden) = model(x_t, hidden)\n        loss_t = loss_fn(y_pred_t, y_t)\n        loss_t.backward()\n        optimizer.step()\n        engine.state.output = loss_t.item()\n        loss_list.append(loss_t.item())\n        engine.fire_event(Tbptt_Events.TIME_ITERATION_COMPLETED)\n    return (sum(loss_list) \/ len(loss_list))\nengine = Engine(_update)\nengine.register_events(*Tbptt_Events)\nreturn engine\n"}
{"label_name":"process","label":2,"method_name":"preprocess_data","method":"\nout = []\nif isinstance(feature_columns, str):\n    feature_columns = [feature_columns]\ncls_id = tokenizer.vocab.cls_id\nsep_id = tokenizer.vocab.sep_id\niterator = (tqdm(df.iterrows(), total=len(df)) if use_tqdm else df.iterrows())\nfor (idx, row) in iterator:\n    encoded_text_l = [tokenizer.encode(row[col_name], int) for col_name in feature_columns]\n    trimmed_lengths = get_trimmed_lengths([len(ele) for ele in encoded_text_l], max_length=((max_length - len(feature_columns)) - 1), do_merge=True)\n    token_ids = ([cls_id] + sum([(ele[:length] + [sep_id]) for (length, ele) in zip(trimmed_lengths, encoded_text_l)], []))\n    token_types = ([0] + sum([([(i % 2)] * (length + 1)) for (i, length) in enumerate(trimmed_lengths)], []))\n    valid_length = len(token_ids)\n    feature = (token_ids, token_types, valid_length)\n    if use_label:\n        label = row[label_column]\n        if (task.task_name != 'sts'):\n            label = task.proj_label[label]\n        out.append((feature, label))\n    else:\n        out.append(feature)\nreturn out\n"}
{"label_name":"predict","label":4,"method_name":"plot_predictions","method":"\nplt.figure(figsize=fs)\nj = 1\nfor (idx, row) in df.iterrows():\n    plt.subplot(rows, cols, j)\n    plt.imshow(plt.imread(row['fpath']))\n    title = get_img_title_for_plot(df, idx, label_names)\n    plt.title(title)\n    plt.axis('off')\n    j += 1\n    if (j > n):\n        break\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\nglobal b0, b1\nfor i in range(iterations):\n    correction1 = 0\n    correction2 = 0\n    for j in range(len(age)):\n        correction1 += (sigmoid(round((b0 + (b1 * age[j])), 5)) - status[j])\n        correction2 += ((sigmoid(round((b0 + (b1 * age[j])), 5)) - status[j]) * age[j])\n    b0 = (b0 - (alpha * correction1))\n    b1 = (b1 - (alpha * correction2))\n"}
{"label_name":"forward","label":3,"method_name":"forward_backward","method":"\n'\\n    The forward_backward algorithm.\\n    Parameters\\n    ----------\\n    log_prob_initial : array-like of shape (k, )\\n        where k is the number of states of the HMM\\n        The log of the probability of initial state at timestamp 0.\\n        log_prob_initial_{i} is the log of the probability of being in state i\\n        at timestamp 0.\\n    log_prob_transition : array-like of shape (t-1, k, k)\\n        where t is the number of timestamps (length) of the sequence.\\n        log_prob_transition_{t, i, j} is the log of the probability of transferring\\n        to state j from state i at timestamp t.\\n    log_Ey : array-like of shape (t, k)\\n        log_Ey_{t, i} is the log of the probability of observing emission variables\\n        from state i at timestamp t.\\n    log_state: dict(int -> array-like of shape (k, ))\\n        timestamp i is a key of log_state if we know the state of that timestamp.\\n        Mostly used in semi-supervised and supervised IOHMM.\\n        log_state[t][i] is 0 and log_state[t][~i] is -np.Infinity\\n        if we know the state is i at timestamp t.\\n    Returns\\n    -------\\n    (1) posterior state log probability of each timestamp.\\n    (2) posterior \"transition\" log probability of each timestamp.\\n    (3) log likelihood of the sequence.\\n    see https:\/\/en.wikipedia.org\/wiki\/Forward-backward_algorithm for details.\\n    '\nlog_alpha = forward(log_prob_initial, log_prob_transition, log_Ey, log_state)\nlog_beta = backward(log_prob_transition, log_Ey, log_state)\nlog_likelihood = cal_log_likelihood(log_alpha)\nlog_gamma = cal_log_gamma(log_alpha, log_beta, log_likelihood, log_state)\nlog_epsilon = cal_log_epsilon(log_prob_transition, log_Ey, log_alpha, log_beta, log_likelihood, log_state)\nreturn (log_gamma, log_epsilon, log_likelihood)\n"}
{"label_name":"process","label":2,"method_name":"_preprocess_image","method":"\nreturn ((tf.to_float(image) \/ 255) - 0.5)\n"}
{"label_name":"process","label":2,"method_name":"Production_preprocessing","method":"\ndf = pd.read_excel(((path + '\\\\') + f))\ndf.drop(df.columns[[1, 3, 4, 6, 7, 9, 10, 12, 13, 15, 16, 18, 19, 21, 22, 24, 25, 27, 28, 30, 31, 33, 34, 36, 37, 39, 40, 42, 43, 45, 46, 48, 49, 51, 52, 54, 55, 57, 58, 60, 61, 63, 64, 66, 67, 69, 70, 72, 73, 75, 76, 77, 78]], axis=1, inplace=True)\ndf.drop([0, 1, 2, 3, 4, 5], inplace=True)\ndf.drop(df.tail(1).index, inplace=True)\ndf.columns = (['ID_unit', 'ID_node'] + [x for x in range(24)])\ndf['_datetime'] = f[:8]\ndf = pd.melt(df, id_vars=['ID_unit', 'ID_node', '_datetime'], value_vars=[x for x in range(24)])\ndf.rename(columns={'value': 'production', 'variable': 'hour'}, inplace=True)\ndf['_datetime'] = df[['_datetime', 'hour']].apply(func, axis=1)\ndf.drop(['hour'], axis=1, inplace=True)\nreturn df\n"}
{"label_name":"process","label":2,"method_name":"process_readme","method":"\nsys.path.append(os.getcwd())\nimport fairlearn\ntarget_version = fairlearn.__version__\n_logger.info('fairlearn version: %s', target_version)\ntext_lines = []\nwith _LogWrapper('reading file {}'.format(input_file_name)):\n    with open(input_file_name, 'r') as input_file:\n        text_lines = input_file.readlines()\nresult_lines = [_process_line(line, target_version) for line in text_lines]\nwith _LogWrapper('writing file {}'.format(output_file_name)):\n    with open(output_file_name, 'w') as output_file:\n        output_file.writelines(result_lines)\n"}
{"label_name":"train","label":0,"method_name":"run_training","method":"\n'Train MNIST for a number of steps.'\ndata_sets = input_data.read_data_sets(FLAGS.input_data_dir, FLAGS.fake_data)\nwith tf.Graph().as_default():\n    (images_placeholder, labels_placeholder) = placeholder_inputs(FLAGS.batch_size)\n    logits = mnist.inference(images_placeholder, FLAGS.hidden1, FLAGS.hidden2)\n    loss = mnist.loss(logits, labels_placeholder)\n    train_op = mnist.training(loss, FLAGS.learning_rate)\n    eval_correct = mnist.evaluation(logits, labels_placeholder)\n    summary = tf.summary.merge_all()\n    init = tf.global_variables_initializer()\n    saver = tf.train.Saver()\n    sess = tf.Session()\n    summary_writer = tf.summary.FileWriter(FLAGS.log_dir, sess.graph)\n    sess.run(init)\n    for step in xrange(FLAGS.max_steps):\n        start_time = time.time()\n        feed_dict = fill_feed_dict(data_sets.train, images_placeholder, labels_placeholder)\n        (_, loss_value) = sess.run([train_op, loss], feed_dict=feed_dict)\n        duration = (time.time() - start_time)\n        if ((step % 100) == 0):\n            print(('Step %d: loss = %.2f (%.3f sec)' % (step, loss_value, duration)))\n            summary_str = sess.run(summary, feed_dict=feed_dict)\n            summary_writer.add_summary(summary_str, step)\n            summary_writer.flush()\n        if ((((step + 1) % 1000) == 0) or ((step + 1) == FLAGS.max_steps)):\n            checkpoint_file = os.path.join(FLAGS.log_dir, 'model.ckpt')\n            saver.save(sess, checkpoint_file, global_step=step)\n            print('Training Data Eval:')\n            do_eval(sess, eval_correct, images_placeholder, labels_placeholder, data_sets.train)\n            print('Validation Data Eval:')\n            do_eval(sess, eval_correct, images_placeholder, labels_placeholder, data_sets.validation)\n            print('Test Data Eval:')\n            do_eval(sess, eval_correct, images_placeholder, labels_placeholder, data_sets.test)\n"}
{"label_name":"save","label":1,"method_name":"_parse_input_saver_proto","method":"\n'Parser input tensorflow Saver into SaverDef proto.'\nif (not gfile.Exists(input_saver)):\n    print(((\"Input saver file '\" + input_saver) + \"' does not exist!\"))\n    return (- 1)\nmode = ('rb' if input_binary else 'r')\nwith gfile.FastGFile(input_saver, mode) as f:\n    saver_def = saver_pb2.SaverDef()\n    if input_binary:\n        saver_def.ParseFromString(f.read())\n    else:\n        text_format.Merge(f.read(), saver_def)\nreturn saver_def\n"}
{"label_name":"save","label":1,"method_name":"save_all_obj_tfidf","method":"\nglobal term_doc_freq_vector\nglobal doc_term_freq_vector\nsave_obj_without_sort(term_doc_freq_vector, 'term_doc_freq_vector')\nsave_obj_without_sort(doc_term_freq_vector, 'doc_term_freq_vector')\nsave_obj_without_sort(doc_term_freq_vector_norm_new, 'doc_term_freq_vector_norm')\n"}
{"label_name":"process","label":2,"method_name":"_process_image_files_batch","method":"\n\"Processes and saves list of images as TFRecord in 1 thread.\\n\\n  Args:\\n    coder: instance of ImageCoder to provide TensorFlow image coding utils.\\n    thread_index: integer, unique batch to run index is within [0, len(ranges)).\\n    ranges: list of pairs of integers specifying ranges of each batches to\\n      analyze in parallel.\\n    name: string, unique identifier specifying the data set\\n    filenames: list of strings; each string is a path to an image file\\n    texts: list of strings; each string is human readable, e.g. 'dog'\\n    labels: list of integer; each integer identifies the ground truth\\n    num_shards: integer number of shards for this data set.\\n  \"\nnum_threads = len(ranges)\nassert (not (num_shards % num_threads))\nnum_shards_per_batch = int((num_shards \/ num_threads))\nshard_ranges = np.linspace(ranges[thread_index][0], ranges[thread_index][1], (num_shards_per_batch + 1)).astype(int)\nnum_files_in_thread = (ranges[thread_index][1] - ranges[thread_index][0])\ncounter = 0\nfor s in xrange(num_shards_per_batch):\n    shard = ((thread_index * num_shards_per_batch) + s)\n    output_filename = ('%s-%.5d-of-%.5d' % (name, shard, num_shards))\n    output_file = os.path.join(FLAGS.output_directory, output_filename)\n    writer = tf.python_io.TFRecordWriter(output_file)\n    shard_counter = 0\n    files_in_shard = np.arange(shard_ranges[s], shard_ranges[(s + 1)], dtype=int)\n    for i in files_in_shard:\n        filename = filenames[i]\n        label = labels[i]\n        text = texts[i]\n        (image_buffer, height, width) = _process_image(filename, coder)\n        example = _convert_to_example(filename, image_buffer, label, text, height, width)\n        writer.write(example.SerializeToString())\n        shard_counter += 1\n        counter += 1\n        if (not (counter % 1000)):\n            print(('%s [thread %d]: Processed %d of %d images in thread batch.' % (datetime.now(), thread_index, counter, num_files_in_thread)))\n            sys.stdout.flush()\n    writer.close()\n    print(('%s [thread %d]: Wrote %d images to %s' % (datetime.now(), thread_index, shard_counter, output_file)))\n    sys.stdout.flush()\n    shard_counter = 0\nprint(('%s [thread %d]: Wrote %d images to %d shards.' % (datetime.now(), thread_index, counter, num_files_in_thread)))\nsys.stdout.flush()\n"}
{"label_name":"process","label":2,"method_name":"process_gesture_folder","method":"\ngesture = []\nwith open(os.path.join(foldername, (feature_set_type + '.ordered_frames')), 'rb') as fp:\n    gesture = pickle.load(fp)\nframe_num = float(len(gesture))\nif average:\n    return [(sum(x) \/ frame_num) for x in zip(*gesture)]\nif (frame_num < frames_per_gesture):\n    return []\nif separate_frames:\n    return gesture[:frames_per_gesture]\nelse:\n    return list(chain.from_iterable(gesture[:frames_per_gesture]))\n"}
{"label_name":"predict","label":4,"method_name":"display_image_predictions","method":"\nn_classes = 10\nlabel_names = _load_label_names()\nlabel_binarizer = LabelBinarizer()\nlabel_binarizer.fit(range(n_classes))\nlabel_ids = label_binarizer.inverse_transform(np.array(labels))\n(fig, axies) = plt.subplots(nrows=4, ncols=2)\nfig.tight_layout()\nfig.suptitle('Softmax Predictions', fontsize=20, y=1.1)\nn_predictions = 3\nmargin = 0.05\nind = np.arange(n_predictions)\nwidth = ((1.0 - (2.0 * margin)) \/ n_predictions)\nfor (image_i, (feature, label_id, pred_indicies, pred_values)) in enumerate(zip(features, label_ids, predictions.indices, predictions.values)):\n    pred_names = [label_names[pred_i] for pred_i in pred_indicies]\n    correct_name = label_names[label_id]\n    axies[image_i][0].imshow(feature)\n    axies[image_i][0].set_title(correct_name)\n    axies[image_i][0].set_axis_off()\n    axies[image_i][1].barh((ind + margin), pred_values[::(- 1)], width)\n    axies[image_i][1].set_yticks((ind + margin))\n    axies[image_i][1].set_yticklabels(pred_names[::(- 1)])\n    axies[image_i][1].set_xticks([0, 0.5, 1.0])\n"}
{"label_name":"train","label":0,"method_name":"train_rllib_policy","method":"\n'Trains a DQNTrainer on MsPacman-v0 for n iterations.\\n\\n    Saves the trained Trainer to disk and returns the checkpoint path.\\n\\n    Returns:\\n        str: The saved checkpoint to restore the trainer DQNTrainer from.\\n    '\ntrainer = dqn.DQNTrainer(config=config)\nfor _ in range(args.train_iters):\n    print(trainer.train())\nreturn trainer.save()\n"}
{"label_name":"save","label":1,"method_name":"_save","method":"\nif (im.mode == 'P'):\n    rawmode = 'P'\n    bpp = 8\n    version = 1\nelif ((im.mode == 'L') and ('bpp' in im.encoderinfo) and (im.encoderinfo['bpp'] in (1, 2, 4))):\n    bpp = im.encoderinfo['bpp']\n    im = im.point((lambda x, shift=(8 - bpp), maxval=((1 << bpp) - 1): (maxval - (x >> shift))))\n    im.mode = 'P'\n    rawmode = ('P;' + str(bpp))\n    version = 1\nelif ((im.mode == 'L') and ('bpp' in im.info) and (im.info['bpp'] in (1, 2, 4))):\n    bpp = im.info['bpp']\n    im = im.point((lambda x, maxval=((1 << bpp) - 1): (maxval - (x & maxval))))\n    im.mode = 'P'\n    rawmode = ('P;' + str(bpp))\n    version = 1\nelif (im.mode == '1'):\n    rawmode = '1;I'\n    bpp = 1\n    version = 0\nelse:\n    raise IOError(('cannot write mode %s as Palm' % im.mode))\nim.load()\ncols = im.size[0]\nrows = im.size[1]\nrowbytes = (int(((cols + ((16 \/\/ bpp) - 1)) \/ (16 \/\/ bpp))) * 2)\ntransparent_index = 0\ncompression_type = _COMPRESSION_TYPES['none']\nflags = 0\nif ((im.mode == 'P') and ('custom-colormap' in im.info)):\n    flags = (flags & _FLAGS['custom-colormap'])\n    colormapsize = ((4 * 256) + 2)\n    colormapmode = im.palette.mode\n    colormap = im.getdata().getpalette()\nelse:\n    colormapsize = 0\nif ('offset' in im.info):\n    offset = (((((rowbytes * rows) + 16) + 3) + colormapsize) \/\/ 4)\nelse:\n    offset = 0\nfp.write((((o16b(cols) + o16b(rows)) + o16b(rowbytes)) + o16b(flags)))\nfp.write(o8(bpp))\nfp.write(o8(version))\nfp.write(o16b(offset))\nfp.write(o8(transparent_index))\nfp.write(o8(compression_type))\nfp.write(o16b(0))\nif (colormapsize > 0):\n    fp.write(o16b(256))\n    for i in range(256):\n        fp.write(o8(i))\n        if (colormapmode == 'RGB'):\n            fp.write(((o8(colormap[(3 * i)]) + o8(colormap[((3 * i) + 1)])) + o8(colormap[((3 * i) + 2)])))\n        elif (colormapmode == 'RGBA'):\n            fp.write(((o8(colormap[(4 * i)]) + o8(colormap[((4 * i) + 1)])) + o8(colormap[((4 * i) + 2)])))\nImageFile._save(im, fp, [('raw', ((0, 0) + im.size), 0, (rawmode, rowbytes, 1))])\nif hasattr(fp, 'flush'):\n    fp.flush()\n"}
{"label_name":"process","label":2,"method_name":"preprocess","method":"\n\" \\n     Input:\\n     Although this function doesn't have any input, you are required to load\\n     the MNIST data set from file 'mnist_all.mat'.\\n\\n     Output:\\n     train_data: matrix of training set. Each row of train_data contains \\n       feature vector of a image\\n     train_label: vector of label corresponding to each image in the training\\n       set\\n     validation_data: matrix of training set. Each row of validation_data \\n       contains feature vector of a image\\n     validation_label: vector of label corresponding to each image in the \\n       training set\\n     test_data: matrix of training set. Each row of test_data contains \\n       feature vector of a image\\n     test_label: vector of label corresponding to each image in the testing\\n       set\\n    \"\nmat = loadmat('mnist_all.mat')\nn_feature = mat.get('train1').shape[1]\nn_sample = 0\nfor i in range(10):\n    n_sample = (n_sample + mat.get(('train' + str(i))).shape[0])\nn_validation = 1000\nn_train = (n_sample - (10 * n_validation))\nvalidation_data = np.zeros(((10 * n_validation), n_feature))\nfor i in range(10):\n    validation_data[(i * n_validation):((i + 1) * n_validation), :] = mat.get(('train' + str(i)))[0:n_validation, :]\nvalidation_label = np.ones(((10 * n_validation), 1))\nfor i in range(10):\n    validation_label[(i * n_validation):((i + 1) * n_validation), :] = (i * np.ones((n_validation, 1)))\ntrain_data = np.zeros((n_train, n_feature))\ntrain_label = np.zeros((n_train, 1))\ntemp = 0\nfor i in range(10):\n    size_i = mat.get(('train' + str(i))).shape[0]\n    train_data[temp:((temp + size_i) - n_validation), :] = mat.get(('train' + str(i)))[n_validation:size_i, :]\n    train_label[temp:((temp + size_i) - n_validation), :] = (i * np.ones(((size_i - n_validation), 1)))\n    temp = ((temp + size_i) - n_validation)\nn_test = 0\nfor i in range(10):\n    n_test = (n_test + mat.get(('test' + str(i))).shape[0])\ntest_data = np.zeros((n_test, n_feature))\ntest_label = np.zeros((n_test, 1))\ntemp = 0\nfor i in range(10):\n    size_i = mat.get(('test' + str(i))).shape[0]\n    test_data[temp:(temp + size_i), :] = mat.get(('test' + str(i)))\n    test_label[temp:(temp + size_i), :] = (i * np.ones((size_i, 1)))\n    temp = (temp + size_i)\nsigma = np.std(train_data, axis=0)\nindex = np.array([])\nfor i in range(n_feature):\n    if (sigma[i] > 0.001):\n        index = np.append(index, [i])\ntrain_data = train_data[:, index.astype(int)]\nvalidation_data = validation_data[:, index.astype(int)]\ntest_data = test_data[:, index.astype(int)]\ntrain_data \/= 255.0\nvalidation_data \/= 255.0\ntest_data \/= 255.0\nreturn (train_data, train_label, validation_data, validation_label, test_data, test_label)\n"}
{"label_name":"predict","label":4,"method_name":"predict_classification_from_pickle","method":"\n'\\n    Given feature data and the filename of a pickled trained estimator, return a prediction\\n\\n    Args:\\n        x_test: \\n        pickle_filename (str): Name of file\\n\\n    Returns:\\n        a prediction\\n    '\ntrained_estimator = load_pickle_file(pickle_filename)\nreturn predict_classification(x_test, trained_estimator)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\nlines = []\nfor f_name in glob('\/mnt\/3F5127B6515F1249\/reddit\/linked_with_comments\/part-00*'):\n    f = open(f_name, 'r')\n    lines.extend(f.read().split('\\n')[:(- 1)])\ndf = pd.DataFrame.from_records(map(json.loads, lines))\ndf.drop(['borrower', 'author', 'currency', 'lender', 'repaid_thread_body', 'repaid_thread_id', 'repaid_thread_name', 'repaid_thread_start_date', 'repaid_thread_title'], 1, inplace=True)\ndf.fillna(0, inplace=True)\ndf['repaid'] = df['repaid'].map((lambda x: (1 if (x == 'true') else 0)))\ncolumns = df.drop('repaid', 1).columns.tolist()\npickle.dump(columns, open('sk1col.pkl', 'wb'))\nX = np.array(df.drop('repaid', 1))\ny = np.array(df['repaid'])\nprint(y.mean())\n(X_train, X_test, y_train, y_test) = model_selection.train_test_split(X, y, test_size=0.2)\nclf = svm.SVC(kernel='linear', class_weight={1: 1, 0: 400})\nclf.fit(X_train, y_train)\nexternals.joblib.dump(clf, 'predictor.pkl')\nreturn (X_test, y_test)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\nlinear_dim = model.linear_dim\nr = hparams.outputs_per_step\ndownsample_step = hparams.downsample_step\ncurrent_lr = init_lr\nbinary_criterion = nn.BCELoss()\nassert (train_seq2seq or train_postnet)\nglobal global_step, global_epoch\nwhile (global_epoch < nepochs):\n    running_loss = 0.0\n    for (step, (x, input_lengths, mel, y, positions, done, target_lengths, speaker_ids)) in tqdm(enumerate(data_loader)):\n        model.train()\n        ismultispeaker = (speaker_ids is not None)\n        if (hparams.lr_schedule is not None):\n            lr_schedule_f = getattr(lrschedule, hparams.lr_schedule)\n            current_lr = lr_schedule_f(init_lr, global_step, **hparams.lr_schedule_kwargs)\n            for param_group in optimizer.param_groups:\n                param_group['lr'] = current_lr\n        optimizer.zero_grad()\n        (text_positions, frame_positions) = positions\n        if (downsample_step > 1):\n            mel = mel[:, 0::downsample_step, :].contiguous()\n        input_lengths = input_lengths.long().numpy()\n        decoder_lengths = ((target_lengths.long().numpy() \/\/ r) \/\/ downsample_step)\n        max_seq_len = max(input_lengths.max(), decoder_lengths.max())\n        if (max_seq_len >= hparams.max_positions):\n            raise RuntimeError('max_seq_len ({}) >= max_posision ({})\\nInput text or decoder targget length exceeded the maximum length.\\nPlease set a larger value for ``max_position`` in hyper parameters.'.format(max_seq_len, hparams.max_positions))\n        if train_seq2seq:\n            x = x.to(device)\n            text_positions = text_positions.to(device)\n            frame_positions = frame_positions.to(device)\n        if train_postnet:\n            y = y.to(device)\n        (mel, done) = (mel.to(device), done.to(device))\n        target_lengths = target_lengths.to(device)\n        speaker_ids = (speaker_ids.to(device) if ismultispeaker else None)\n        if (hparams.masked_loss_weight > 0):\n            decoder_target_mask = sequence_mask((target_lengths \/\/ (r * downsample_step)), max_len=mel.size(1)).unsqueeze((- 1))\n            if (downsample_step > 1):\n                target_mask = sequence_mask(target_lengths, max_len=y.size(1)).unsqueeze((- 1))\n            else:\n                target_mask = decoder_target_mask\n            decoder_target_mask = decoder_target_mask[:, r:, :]\n            target_mask = target_mask[:, r:, :]\n        else:\n            (decoder_target_mask, target_mask) = (None, None)\n        if (train_seq2seq and train_postnet):\n            (mel_outputs, linear_outputs, attn, done_hat) = model(x, mel, speaker_ids=speaker_ids, text_positions=text_positions, frame_positions=frame_positions, input_lengths=input_lengths)\n        elif train_seq2seq:\n            assert (speaker_ids is None)\n            (mel_outputs, attn, done_hat, _) = model.seq2seq(x, mel, text_positions=text_positions, frame_positions=frame_positions, input_lengths=input_lengths)\n            mel_outputs = mel_outputs.view(len(mel), (- 1), mel.size((- 1)))\n            linear_outputs = None\n        elif train_postnet:\n            assert (speaker_ids is None)\n            linear_outputs = model.postnet(mel)\n            (mel_outputs, attn, done_hat) = (None, None, None)\n        w = hparams.binary_divergence_weight\n        if train_seq2seq:\n            (mel_l1_loss, mel_binary_div) = spec_loss(mel_outputs[:, :(- r), :], mel[:, r:, :], decoder_target_mask)\n            mel_loss = (((1 - w) * mel_l1_loss) + (w * mel_binary_div))\n        if train_seq2seq:\n            done_loss = binary_criterion(done_hat, done)\n        if train_postnet:\n            n_priority_freq = int(((hparams.priority_freq \/ (hparams.sample_rate * 0.5)) * linear_dim))\n            (linear_l1_loss, linear_binary_div) = spec_loss(linear_outputs[:, :(- r), :], y[:, r:, :], target_mask, priority_bin=n_priority_freq, priority_w=hparams.priority_freq_weight)\n            linear_loss = (((1 - w) * linear_l1_loss) + (w * linear_binary_div))\n        if (train_seq2seq and train_postnet):\n            loss = ((mel_loss + linear_loss) + done_loss)\n        elif train_seq2seq:\n            loss = (mel_loss + done_loss)\n        elif train_postnet:\n            loss = linear_loss\n        if (train_seq2seq and hparams.use_guided_attention):\n            soft_mask = guided_attentions(input_lengths, decoder_lengths, attn.size((- 2)), g=hparams.guided_attention_sigma)\n            soft_mask = torch.from_numpy(soft_mask).to(device)\n            attn_loss = (attn * soft_mask).mean()\n            loss += attn_loss\n        if ((global_step > 0) and ((global_step % checkpoint_interval) == 0)):\n            save_states(global_step, writer, mel_outputs, linear_outputs, attn, mel, y, input_lengths, checkpoint_dir)\n            save_checkpoint(model, optimizer, global_step, checkpoint_dir, global_epoch, train_seq2seq, train_postnet)\n        if ((global_step > 0) and ((global_step % hparams.eval_interval) == 0)):\n            eval_model(global_step, writer, device, model, checkpoint_dir, ismultispeaker)\n        loss.backward()\n        if (clip_thresh > 0):\n            grad_norm = torch.nn.utils.clip_grad_norm_(model.get_trainable_parameters(), clip_thresh)\n        optimizer.step()\n        writer.add_scalar('loss', float(loss.item()), global_step)\n        if train_seq2seq:\n            writer.add_scalar('done_loss', float(done_loss.item()), global_step)\n            writer.add_scalar('mel loss', float(mel_loss.item()), global_step)\n            writer.add_scalar('mel_l1_loss', float(mel_l1_loss.item()), global_step)\n            writer.add_scalar('mel_binary_div_loss', float(mel_binary_div.item()), global_step)\n        if train_postnet:\n            writer.add_scalar('linear_loss', float(linear_loss.item()), global_step)\n            writer.add_scalar('linear_l1_loss', float(linear_l1_loss.item()), global_step)\n            writer.add_scalar('linear_binary_div_loss', float(linear_binary_div.item()), global_step)\n        if (train_seq2seq and hparams.use_guided_attention):\n            writer.add_scalar('attn_loss', float(attn_loss.item()), global_step)\n        if (clip_thresh > 0):\n            writer.add_scalar('gradient norm', grad_norm, global_step)\n        writer.add_scalar('learning rate', current_lr, global_step)\n        global_step += 1\n        running_loss += loss.item()\n    averaged_loss = (running_loss \/ len(data_loader))\n    writer.add_scalar('loss (per epoch)', averaged_loss, global_epoch)\n    print('Loss: {}'.format((running_loss \/ len(data_loader))))\n    global_epoch += 1\n"}
{"label_name":"process","label":2,"method_name":"process_data_for_labels","method":"\nhm_days = 7\ndf = pd.read_csv('CompiledData1.csv', index_col=0)\ntickers = df.columns.values.tolist()\nfor i in range(1, (hm_days + 1)):\n    df['{}_{}d'.format(ticker, i)] = ((df[ticker].shift((- i)) - df[ticker]) \/ df[ticker])\nreturn (tickers, df)\n"}
{"label_name":"predict","label":4,"method_name":"predict_quadrant_shapes","method":"\nsplit_arr = np.array([])\nif (imgPath == None):\n    split_arr = split_pic(nrows, ncols, PILimg=PILimg, edges=edges)\nelse:\n    split_arr = split_pic(nrows, ncols, imgPath=imgPath, edges=edges)\nprint(split_arr.shape)\nshapes_arr = []\ni = 0\nwhile (i < split_arr.shape[0]):\n    test_img = split_arr[i]\n    test_img.shape = (1, (- 1))\n    print(test_img)\n    prediction = []\n    sess = tf.Session()\n    clf = tf.estimator.Estimator(model_fn=cnn_model_fn, model_dir='\/tmp\/model')\n    input_fn = tf.estimator.inputs.numpy_input_fn(x={'x': test_img}, num_epochs=1, shuffle=False)\n    prediction = list(clf.predict(input_fn=input_fn))\n    shapes_arr += [prediction]\n    i += 1\nreturn shapes_arr\n"}
{"label_name":"train","label":0,"method_name":"train_folds","method":"\nfold_size = (len(X) \/\/ fold_count)\nmodels = []\nfor fold_id in range(0, fold_count):\n    fold_start = (fold_size * fold_id)\n    fold_end = (fold_start + fold_size)\n    if (fold_id == (fold_size - 1)):\n        fold_end = len(X)\n    train_x = np.concatenate([X[:fold_start], X[fold_end:]])\n    train_y = np.concatenate([y[:fold_start], y[fold_end:]])\n    val_x = X[fold_start:fold_end]\n    val_y = y[fold_start:fold_end]\n    model = _train_model(get_model_func(), batch_size, train_x, train_y, val_x, val_y)\n    models.append(model)\nreturn models\n"}
{"label_name":"predict","label":4,"method_name":"_predictions","method":"\n\"Computes predictions by loading only the columns of the kmer matrix that are targetted by the model.\\n\\n    Parameters\\n    ----------\\n    model: BaseModel\\n        The model used for predicting.\\n\\n    kmer_matrix: BaseRuleClassifications\\n        The matrix containing the classifications of each rule on each learning example.\\n\\n    train_example_idx: array-like, dtype=uint\\n        The index of the rows of kmer_matrix corresponding to the training examples.\\n\\n    test_example_idx: array-like, dtype=uint\\n        The index of the rows of kmer_matrix corresponding to the testing examples.\\n\\n    progress_callback: function with arguments task, percent_completed\\n        A callback function used to keep track of the task's completion.\\n\\n    \"\nif (progress_callback is None):\n    progress_callback = (lambda t, p: None)\nprogress_callback('Testing', 0.0)\ncolumns_to_load = []\nreaddressed_model = deepcopy(model)\nfor (i, rule_idx) in enumerate(np.argsort([r.kmer_index for r in model.rules])):\n    rule = readdressed_model.rules[rule_idx]\n    columns_to_load.append(rule.kmer_index)\n    rule.kmer_index = i\nX = _unpack_binary_bytes_from_ints(kmer_matrix[:, columns_to_load])\ntrain_predictions = readdressed_model.predict(X[train_example_idx])\nprogress_callback('Testing', ((1.0 * len(train_example_idx)) \/ (len(train_example_idx) + len(test_example_idx))))\ntest_predictions = readdressed_model.predict(X[test_example_idx])\nprogress_callback('Testing', 1.0)\nreturn (train_predictions, test_predictions)\n"}
{"label_name":"save","label":1,"method_name":"save_phrases","method":"\npath_tosave = join(PATH_SAVE_PHR, save_dir)\nif (not os.path.exists(path_tosave)):\n    os.makedirs(path_tosave)\nbarsOfphrase_list = [[], [], [], [], [], []]\nfor song_idx in range(len(rnd_list)):\n    msd_id = song_list[tra_song_idx[song_idx]]\n    sys.stdout.write('{0}\/{1}\\r'.format(song_idx, len(rnd_list)))\n    sys.stdout.flush()\n    f = open(join(PATH_SEG, (msd_id + '.lab')), 'r')\n    info_list = []\n    for line in f.readlines():\n        line = line.strip().split(' ')\n        (st, ed, lab) = (int(float(line[0])), int(float(line[1])), line[2])\n        info_list.append((st, ed, lab, (ed - st)))\n    tmp_phr_num = len(info_list)\n    parsed_phrase_list = []\n    song_tracks = []\n    for pre_idx in range(5):\n        song_tracks.append(reshape_to_bar(csc_to_array(np.load(join(ROOT_TRACKS, prefix[pre_idx], (msd_id + '.npz'))))))\n    act_instr = np.load(join(PATH_INSTRU_ACT, (msd_id + '.npy')))\n    for pidx in range(1, (tmp_phr_num - 1)):\n        (st, ed, phr_len) = (info_list[pidx][0], info_list[pidx][1], info_list[pidx][3])\n        if (phr_len >= 8):\n            if ((phr_len % 4) == 1):\n                ed -= 1\n            if ((phr_len % 4) == 2):\n                st += 1\n                ed -= 1\n            if ((phr_len % 4) == 3):\n                ed = (ed + 1)\n            phr_len = (ed - st)\n            limit = (phr_len - 7)\n            for t in range(0, limit, 4):\n                parsed_phrase_list.append(((st + t), ((st + t) + 8)))\n        else:\n            if (phr_len == 7):\n                parsed_phrase_list.append((st, (ed + 1)))\n            if (phr_len == 6):\n                parsed_phrase_list.append(((st - 1), (ed + 1)))\n            else:\n                pass\n    for pidx in range(len(parsed_phrase_list)):\n        for pre_idx in range(5):\n            (st, ed) = parsed_phrase_list[pidx]\n            barsOfphrase_list[pre_idx].append(song_tracks[pre_idx][st:ed, :, :].astype(bool))\n        barsOfphrase_list[5].append(act_instr[st:ed, :].astype(bool))\n    f.close()\nprint('[*] Saving...')\nprint('\\n')\nfor idx in range(6):\n    track_list = barsOfphrase_list[idx]\n    tmp = np.asarray(track_list)\n    print(tmp.shape, tmp.dtype)\n    np.save(join(path_tosave, (prefix[idx] + '.npy')), tmp)\n"}
{"label_name":"process","label":2,"method_name":"process_str","method":"\ncode = [header]\ncode.extend(parse_string(astr, global_names, 0, 1))\nreturn ''.join(code)\n"}
{"label_name":"train","label":0,"method_name":"validate_crp_constrained_partition","method":"\n'Only tests the outer CRP partition Zv.'\nvalid = True\nN = len(Zv)\nfor block in Cd:\n    valid = (valid and all(((Zv[block[0]] == Zv[b]) for b in block)))\n    for (a, b) in it.combinations(block, 2):\n        valid = (valid and check_compatible_customers(Cd, Ci, Ri, Rd, a, b))\nfor (a, b) in Ci:\n    valid = (valid and (not (Zv[a] == Zv[b])))\nreturn valid\n"}
{"label_name":"process","label":2,"method_name":"preprocessing","method":"\n\" Prepare the original database to be processed.\\n    It'll backup the original database into a database called `preprocessed_database`, then'll clean this new database\\n    by applying a set of operations on it. Theses operations consist of :\\n        - Change its encoding, delimiter, format, quote character, quoting behavior and newline delimiter.\\n        - Add an ID column if it's not already present.\\n        - Move the ID column at the beginning of the database.\\n        - Move the class column at the end of the database.\\n        - Extract the header if it's present.\\n    \"\ncreate_dir(env.main_directory_path)\nvprint(Message.INITIAL_PREPROCESSING)\n_init_preprocessed_database(original_database_path=env.original_database_path, preprocessed_database_path=env.preprocessed_database_path, input_encoding=env.encoding_input, output_encoding=env.encoding_output, input_delimiter=env.delimiter_input, output_delimiter=env.delimiter_output, input_format=env.format_input, output_format=env.format_output, input_quote_char=env.quote_character_input, output_quote_char=env.quote_character_output, input_quoting=env.quoting_input, output_quoting=env.quoting_output, input_line_delimiter=env.line_delimiter_input, output_line_delimiter=env.line_delimiter_output)\nif (env.identifier is None):\n    vprint(Message.ADD_ID)\n    _add_id(input_path=env.preprocessed_database_path, output_path=env.preprocessed_database_path, id_name=gdv.identifier(), have_header=env.have_header, dialect=env.dialect_output)\n    env.have_header = True\n    env.identifier = 0\n    if (env.class_name >= 0):\n        env.class_name += 1\nif (not _identifier_at_beginning(path=env.preprocessed_database_path, have_header=env.have_header, identifier=env.identifier, dialect=env.dialect_output)):\n    vprint(Message.PREPEND_ID)\n    preprend_column(input_path=env.preprocessed_database_path, output_path=env.preprocessed_database_path, column=env.identifier, dialect=env.dialect_output)\n    env.identifier = 0\nif (not _class_at_end(path=env.preprocessed_database_path, class_name=env.class_name, have_header=env.have_header, dialect=env.dialect_output)):\n    vprint(Message.APPEND_CLASS)\n    append_column(input_path=env.preprocessed_database_path, output_path=env.preprocessed_database_path, column=env.class_name, dialect=env.dialect_output)\n    env.class_name = (get_number_of_columns(env.preprocessed_database_path, dialect=env.dialect_output) - 1)\nif env.have_header:\n    vprint(Message.EXTRACT_HEADER)\n    _extract_header(input_path=env.preprocessed_database_path, header_path=env.header_path, dialect=env.dialect_output)\n    env.have_header = False\n"}
{"label_name":"forward","label":3,"method_name":"rforwardsolve","method":"\n'\\n    Solve the system A*x = b for a lower triangular d-banded matrix A, \\n    using algorithm 2.6 (row-oriented forward substitution)\\n    The input vector b will be updated with the solution x (i.e. in-place).\\n    \\n    A: A lower triangular matrix\\n    b: The right hand side\\n    d: The band-width\\n    '\nn = len(b)\nb[0] \/= A[(0, 0)]\nfor k in range(1, n):\n    lk = array([0, (k - d)]).max()\n    b[k] = (b[k] - dot(A[k, lk:k], b[lk:k]))\n    b[k] \/= A[(k, k)]\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\nlogger.info('Begin training')\ntrain_feeder = DataIterator(data_dir='.\/data\/train\/')\ntest_feeder = DataIterator(data_dir='.\/data\/test\/')\nmodel_name = 'chinese-rec-model'\nwith tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, allow_soft_placement=True)) as sess:\n    (train_images, train_labels) = train_feeder.input_pipeline(batch_size=FLAGS.batch_size, aug=True)\n    (test_images, test_labels) = test_feeder.input_pipeline(batch_size=FLAGS.batch_size)\n    graph = build_graph(top_k=1)\n    saver = tf.train.Saver()\n    sess.run(tf.global_variables_initializer())\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n    train_writer = tf.summary.FileWriter((FLAGS.log_dir + '\/train'), sess.graph)\n    test_writer = tf.summary.FileWriter((FLAGS.log_dir + '\/val'))\n    start_step = 0\n    if FLAGS.restore:\n        ckpt = tf.train.latest_checkpoint(FLAGS.checkpoint_dir)\n        if ckpt:\n            saver.restore(sess, ckpt)\n            print('restore from the checkpoint {0}'.format(ckpt))\n            start_step += int(ckpt.split('-')[(- 1)])\n    logger.info(':::Training Start:::')\n    try:\n        i = 0\n        while (not coord.should_stop()):\n            i += 1\n            start_time = time.time()\n            (train_images_batch, train_labels_batch) = sess.run([train_images, train_labels])\n            feed_dict = {graph['images']: train_images_batch, graph['labels']: train_labels_batch, graph['keep_prob']: 0.8, graph['is_training']: True}\n            (_, loss_val, train_summary, step) = sess.run([graph['train_op'], graph['loss'], graph['merged_summary_op'], graph['global_step']], feed_dict=feed_dict)\n            train_writer.add_summary(train_summary, step)\n            end_time = time.time()\n            logger.info('the step {0} takes {1} loss {2}'.format(step, (end_time - start_time), loss_val))\n            if (step > FLAGS.max_steps):\n                break\n            if ((step % FLAGS.eval_steps) == 1):\n                (test_images_batch, test_labels_batch) = sess.run([test_images, test_labels])\n                feed_dict = {graph['images']: test_images_batch, graph['labels']: test_labels_batch, graph['keep_prob']: 1.0, graph['is_training']: False}\n                (accuracy_test, test_summary) = sess.run([graph['accuracy'], graph['merged_summary_op']], feed_dict=feed_dict)\n                if (step > 300):\n                    test_writer.add_summary(test_summary, step)\n                logger.info('===============Eval a batch=======================')\n                logger.info('the step {0} test accuracy: {1}'.format(step, accuracy_test))\n                logger.info('===============Eval a batch=======================')\n            if ((step % FLAGS.save_steps) == 1):\n                logger.info('Save the ckpt of {0}'.format(step))\n                saver.save(sess, os.path.join(FLAGS.checkpoint_dir, model_name), global_step=graph['global_step'])\n    except tf.errors.OutOfRangeError:\n        logger.info('==================Train Finished================')\n        saver.save(sess, os.path.join(FLAGS.checkpoint_dir, model_name), global_step=graph['global_step'])\n    finally:\n        coord.request_stop()\n    coord.join(threads)\n"}
{"label_name":"train","label":0,"method_name":"trainLinearReg","method":"\ninitial_theta = np.zeros(np.size(X, 1))\nres = minimize(linearRegCostFunction, initial_theta, args=(X, y, reg), jac=True, options={'maxiter': 400, 'disp': True})\nreturn res.x\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\nfor (batch_idx, (data, target)) in enumerate(train_loader):\n    if args.cuda:\n        (data, target) = (data.cuda(), target.cuda())\n    if args.binary:\n        target = (target % 2).float()\n    gpmodule.set_data(data, target)\n    optimizer.zero_grad()\n    loss = loss_fn(gpmodule.model, gpmodule.guide)\n    loss.backward()\n    optimizer.step()\n    batch_idx = (batch_idx + 1)\n    if ((batch_idx % args.log_interval) == 0):\n        print('Train Epoch: {:2d} [{:5d}\/{} ({:2.0f}%)]\\tLoss: {:.6f}'.format(epoch, (batch_idx * len(data)), len(train_loader.dataset), ((100.0 * batch_idx) \/ len(train_loader)), loss))\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\nwhoami = mpi_fork(num_cpu)\nif (whoami == 'parent'):\n    return\nimport baselines.common.tf_util as U\nlogger.session().__enter__()\nsess = U.single_threaded_session()\nsess.__enter__()\nrank = MPI.COMM_WORLD.Get_rank()\nif (rank != 0):\n    logger.set_level(logger.DISABLED)\nworkerseed = (seed + (10000 * MPI.COMM_WORLD.Get_rank()))\nset_global_seeds(workerseed)\nenv = gym.make(env_id)\n\ndef policy_fn(name, ob_space, ac_space):\n    return MlpPolicy(name=name, ob_space=env.observation_space, ac_space=env.action_space, hid_size=32, num_hid_layers=2)\nenv = bench.Monitor(env, osp.join(logger.get_dir(), ('%i.monitor.json' % rank)))\nenv.seed(workerseed)\ngym.logger.setLevel(logging.WARN)\ntrpo_mpi.learn(env, policy_fn, timesteps_per_batch=1024, max_kl=0.01, cg_iters=10, cg_damping=0.1, max_timesteps=num_timesteps, gamma=0.99, lam=0.98, vf_iters=5, vf_stepsize=0.001)\nenv.close()\n"}
{"label_name":"predict","label":4,"method_name":"collect_incorrect_entity_predictions","method":"\n'Get incorrect entity predictions.\\n\\n    Args:\\n        entity_results: entity evaluation results\\n        merged_predictions: list of predicted entity labels\\n        merged_targets: list of true entity labels\\n\\n    Returns: list of incorrect predictions\\n    '\nerrors = []\noffset = 0\nfor entity_result in entity_results:\n    for i in range(offset, (offset + len(entity_result.tokens))):\n        if (merged_targets[i] != merged_predictions[i]):\n            errors.append({'text': entity_result.message, 'entities': entity_result.entity_targets, 'predicted_entities': entity_result.entity_predictions})\n            break\n    offset += len(entity_result.tokens)\nreturn errors\n"}
{"label_name":"predict","label":4,"method_name":"nn_predict","method":"\nif ((image is not None) and (model is not None)):\n    pred = model.predict(image.reshape(1, 784))[0]\n    pred = np.argmax(pred, axis=0)\n    return pred\nelse:\n    return (- 1)\n"}
{"label_name":"process","label":2,"method_name":"_preprocess_const","method":"\nreturn x.dtype.type(value)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\nloss_averages_op = _add_loss_summaries(total_loss)\nwith tf.control_dependencies([loss_averages_op]):\n    if (optimizer == 'ADAGRAD'):\n        opt = tf.train.AdagradOptimizer(learning_rate)\n    elif (optimizer == 'ADADELTA'):\n        opt = tf.train.AdadeltaOptimizer(learning_rate, rho=0.9, epsilon=1e-06)\n    elif (optimizer == 'ADAM'):\n        opt = tf.train.AdamOptimizer(learning_rate, beta1=0.9, beta2=0.999, epsilon=0.1)\n    elif (optimizer == 'RMSPROP'):\n        opt = tf.train.RMSPropOptimizer(learning_rate, decay=0.9, momentum=0.9, epsilon=1.0)\n    elif (optimizer == 'MOM'):\n        opt = tf.train.MomentumOptimizer(learning_rate, 0.9, use_nesterov=True)\n    else:\n        raise ValueError('Invalid optimization algorithm')\n    grads = opt.compute_gradients(total_loss, update_gradient_vars)\napply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\nif log_histograms:\n    for var in tf.trainable_variables():\n        tf.summary.histogram(var.op.name, var)\nif log_histograms:\n    for (grad, var) in grads:\n        if (grad is not None):\n            tf.summary.histogram((var.op.name + '\/gradients'), grad)\nvariable_averages = tf.train.ExponentialMovingAverage(moving_average_decay, global_step)\nvariables_averages_op = variable_averages.apply(tf.trainable_variables())\nwith tf.control_dependencies([apply_gradient_op, variables_averages_op]):\n    train_op = tf.no_op(name='train')\nreturn train_op\n"}
{"label_name":"predict","label":4,"method_name":"_add_prediction","method":"\ndriver.refresh()\nproj_select = Select(driver.wait_for_xpath('\/\/select[@name=\"project\"]'))\nproj_select.select_by_value(str(proj_id))\ndriver.find_element_by_id('react-tabs-8').click()\ndriver.find_element_by_partial_link_text('Predict Targets').click()\ndriver.find_element_by_class_name('btn-primary').click()\ndriver.wait_for_xpath(\"\/\/div[contains(text(),'Model predictions begun')]\")\ntry:\n    driver.wait_for_xpath(\"\/\/td[contains(text(),'Completed')]\", 30)\nexcept:\n    driver.save_screenshot('\/tmp\/pred_fail.png')\n    raise\n"}
{"label_name":"train","label":0,"method_name":"load_train_data","method":"\nwith open(filename, 'rU') as file:\n    data = []\n    line = file.readline()\n    ignore_chars = {'T', '%', 'S', 'M', 'K', 'P', 'L', '\"', '\\n', ' ', '(', ')', 'm', '-', '\\\\', '!', 't', 'r', 'i', 'l', 'z', '[', '+', 'n', 'o', '#'}\n    notes = {'C', 'D', 'E', 'F', 'G', 'A', 'B', 'c', 'd', 'e', 'f', 'g', 'a', 'b'}\n    prev_string = ''\n    same_note = False\n    on_bar = False\n    song = []\n    while (line != ''):\n        line = file.readline()\n        if ((not line) or (line[0] in ignore_chars)):\n            continue\n        if (line[0] == 'X'):\n            data.append(song)\n            song = []\n            continue\n        for c in line:\n            if (c in ignore_chars):\n                continue\n            elif (c in notes):\n                same_note = True\n                length = len(prev_string)\n                if on_bar:\n                    on_bar = False\n                    song.append(prev_string)\n                    prev_string = c\n                elif (length != 0):\n                    first = prev_string[(length - 1)]\n                    if (first in notes):\n                        song.append(prev_string)\n                        prev_string = c\n                    elif (first == '\/'):\n                        prev_string = prev_string[1:]\n                else:\n                    prev_string += c\n            elif (c in {'_', '^', '='}):\n                if (not same_note):\n                    same_note = True\n                song.append(prev_string)\n                prev_string = c\n            elif c.isdigit():\n                if same_note:\n                    song.append((prev_string + c))\n                    prev_string = ''\n                    same_note = False\n            elif (c in {'|', ':'}):\n                if same_note:\n                    song.append(prev_string)\n                    prev_string = ''\n                if on_bar:\n                    song.append((prev_string + c))\n                    prev_string = ''\n                    on_bar = False\n                else:\n                    on_bar = True\n                    song.append(prev_string)\n                    prev_string = c\n                same_note = False\n            else:\n                prev_string += c\nreturn data\n"}
{"label_name":"process","label":2,"method_name":"process_question","method":"\n'multiprocessing worker that converts the guesser output of a single\\n        question into format used by the buzzer\\n    '\n(qid, q_rows) = item\nqid = q_rows.qanta_id.tolist()[0]\nanswer = questions[qid].page\nq_rows = q_rows.groupby('char_index')\nchar_indices = sorted(q_rows.groups.keys())\nguesses_sequence = []\nlabels = []\nfor idx in char_indices:\n    p = q_rows.get_group(idx).sort_values('score', ascending=False)\n    guesses_sequence.append(list(zip(p.guess, p.score))[:N_GUESSES])\n    labels.append(int((p.guess.tolist()[0] == answer)))\nvectors = vector_converter(guesses_sequence)\nreturn (qid, vectors, labels, char_indices)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\ninputs = tf.placeholder(tf.float32, [None, 28, 28, 1])\nlabels = tf.placeholder(tf.float32, [None, 10])\nlayer = inputs\nfor layer_i in range(1, 20):\n    layer = conv_layer(layer, layer_i)\norig_shape = layer.get_shape().as_list()\nlayer = tf.reshape(layer, shape=[(- 1), ((orig_shape[1] * orig_shape[2]) * orig_shape[3])])\nlayer = fully_connected(layer, 100)\nlogits = tf.layers.dense(layer, 10)\nmodel_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=labels))\ntrain_opt = tf.train.AdamOptimizer(learning_rate).minimize(model_loss)\ncorrect_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    for batch_i in range(num_batches):\n        (batch_xs, batch_ys) = mnist.train.next_batch(batch_size)\n        sess.run(train_opt, {inputs: batch_xs, labels: batch_ys})\n        if ((batch_i % 100) == 0):\n            (loss, acc) = sess.run([model_loss, accuracy], {inputs: mnist.validation.images, labels: mnist.validation.labels})\n            print('Batch: {:>2}: Validation loss: {:>3.5f}, Validation accuracy: {:>3.5f}'.format(batch_i, loss, acc))\n        elif ((batch_i % 25) == 0):\n            (loss, acc) = sess.run([model_loss, accuracy], {inputs: batch_xs, labels: batch_ys})\n            print('Batch: {:>2}: Training loss: {:>3.5f}, Training accuracy: {:>3.5f}'.format(batch_i, loss, acc))\n    acc = sess.run(accuracy, {inputs: mnist.validation.images, labels: mnist.validation.labels})\n    print('Final validation accuracy: {:>3.5f}'.format(acc))\n    acc = sess.run(accuracy, {inputs: mnist.test.images, labels: mnist.test.labels})\n    print('Final test accuracy: {:>3.5f}'.format(acc))\n    correct = 0\n    for i in range(100):\n        correct += sess.run(accuracy, feed_dict={inputs: [mnist.test.images[i]], labels: [mnist.test.labels[i]]})\n    print('Accuracy on 100 samples:', (correct \/ 100))\n"}
{"label_name":"predict","label":4,"method_name":"predict","method":"\nW1 = tf.convert_to_tensor(parameters['W1'])\nb1 = tf.convert_to_tensor(parameters['b1'])\nW2 = tf.convert_to_tensor(parameters['W2'])\nb2 = tf.convert_to_tensor(parameters['b2'])\nW3 = tf.convert_to_tensor(parameters['W3'])\nb3 = tf.convert_to_tensor(parameters['b3'])\nparams = {'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2, 'W3': W3, 'b3': b3}\nx = tf.placeholder('float', [12288, 1])\nz3 = forward_propagation_for_predict(x, params)\np = tf.argmax(z3)\nsess = tf.Session()\nprediction = sess.run(p, feed_dict={x: X})\nreturn prediction\n"}
{"label_name":"save","label":1,"method_name":"make_datasaver","method":"\n\"Create a `DataSaver` of a `learner_type` that can be instantiated\\n    with the `learner_type`'s key-word arguments.\\n\\n    Parameters\\n    ----------\\n    learner_type : `~adaptive.BaseLearner` type\\n        The learner type that needs to be wrapped.\\n    arg_picker : function\\n        Function that returns the argument that needs to be learned.\\n\\n    Example\\n    -------\\n    Imagine we have a function that returns a dictionary\\n    of the form: ``{'y': y, 'err_est': err_est}``.\\n\\n    >>> from operator import itemgetter\\n    >>> DataSaver = make_datasaver(Learner1D, arg_picker=itemgetter('y'))\\n    >>> learner = DataSaver(function=f, bounds=(-1.0, 1.0))\\n\\n    Or when using `adaptive.BalancingLearner.from_product`:\\n\\n    >>> learner_type = make_datasaver(adaptive.Learner1D,\\n    ...     arg_picker=itemgetter('y'))\\n    >>> learner = adaptive.BalancingLearner.from_product(\\n    ...     jacobi, learner_type, dict(bounds=(0, 1)), combos)\\n    \"\nreturn functools.partial(_ds, learner_type, arg_picker)\n"}
{"label_name":"train","label":0,"method_name":"train_dygraph","method":"\nprogram_translator.enable(False)\nreturn train(place)\n"}
{"label_name":"process","label":2,"method_name":"_process_observations","method":"\n\"Record new data from the environment and prepare for policy evaluation.\\n\\n    Args:\\n        worker (RolloutWorker): Reference to the current rollout worker.\\n        base_env (BaseEnv): Env implementing BaseEnv.\\n        policies (dict): Map of policy ids to Policy instances.\\n        batch_builder_pool (List[SampleBatchBuilder]): List of pooled\\n            SampleBatchBuilder object for recycling.\\n        active_episodes (Dict[str, MultiAgentEpisode]): Mapping from\\n            episode ID to currently ongoing MultiAgentEpisode object.\\n        unfiltered_obs (dict): Doubly keyed dict of env-ids -> agent ids\\n            -> unfiltered observation tensor, returned by a `BaseEnv.poll()`\\n            call.\\n        rewards (dict): Doubly keyed dict of env-ids -> agent ids ->\\n            rewards tensor, returned by a `BaseEnv.poll()` call.\\n        dones (dict): Doubly keyed dict of env-ids -> agent ids ->\\n            boolean done flags, returned by a `BaseEnv.poll()` call.\\n        infos (dict): Doubly keyed dict of env-ids -> agent ids ->\\n            info dicts, returned by a `BaseEnv.poll()` call.\\n        horizon (int): Horizon of the episode.\\n        preprocessors (dict): Map of policy id to preprocessor for the\\n            observations prior to filtering.\\n        obs_filters (dict): Map of policy id to filter used to process\\n            observations for the policy.\\n        rollout_fragment_length (int): Number of episode steps before\\n            `SampleBatch` is yielded. Set to infinity to yield complete\\n            episodes.\\n        multiple_episodes_in_batch (bool): Whether to pack multiple\\n            episodes into each batch. This guarantees batches will be exactly\\n            `rollout_fragment_length` in size.\\n        callbacks (DefaultCallbacks): User callbacks to run on episode events.\\n        soft_horizon (bool): Calculate rewards but don't reset the\\n            environment when the horizon is hit.\\n        no_done_at_end (bool): Ignore the done=True at the end of the episode\\n            and instead record done=False.\\n        observation_fn (ObservationFunction): Optional multi-agent\\n            observation func to use for preprocessing observations.\\n        sample_collector (SampleCollector): The SampleCollector object\\n            used to store and retrieve environment samples.\\n\\n    Returns:\\n        Tuple:\\n            - active_envs: Set of non-terminated env ids.\\n            - to_eval: Map of policy_id to list of agent PolicyEvalData.\\n            - outputs: List of metrics and samples to return from the sampler.\\n    \"\nactive_envs: Set[EnvID] = set()\nto_eval: Dict[(PolicyID, List[PolicyEvalData])] = defaultdict(list)\noutputs: List[Union[(RolloutMetrics, SampleBatchType)]] = []\nfor (env_id, all_agents_obs) in unfiltered_obs.items():\n    is_new_episode: bool = (env_id not in active_episodes)\n    episode: MultiAgentEpisode = active_episodes[env_id]\n    if (not is_new_episode):\n        sample_collector.episode_step(episode)\n        episode._add_agent_rewards(rewards[env_id])\n    if (dones[env_id]['__all__'] or (episode.length >= horizon)):\n        hit_horizon = ((episode.length >= horizon) and (not dones[env_id]['__all__']))\n        all_agents_done = True\n        atari_metrics: List[RolloutMetrics] = _fetch_atari_metrics(base_env)\n        if (atari_metrics is not None):\n            for m in atari_metrics:\n                outputs.append(m._replace(custom_metrics=episode.custom_metrics))\n        else:\n            outputs.append(RolloutMetrics(episode.length, episode.total_reward, dict(episode.agent_rewards), episode.custom_metrics, {}, episode.hist_data, episode.media))\n    else:\n        hit_horizon = False\n        all_agents_done = False\n        active_envs.add(env_id)\n    if observation_fn:\n        all_agents_obs: Dict[(AgentID, EnvObsType)] = observation_fn(agent_obs=all_agents_obs, worker=worker, base_env=base_env, policies=policies, episode=episode)\n        if (not isinstance(all_agents_obs, dict)):\n            raise ValueError('observe() must return a dict of agent observations')\n    for (agent_id, raw_obs) in all_agents_obs.items():\n        assert (agent_id != '__all__')\n        last_observation: EnvObsType = episode.last_observation_for(agent_id)\n        agent_done = bool((all_agents_done or dones[env_id].get(agent_id)))\n        if ((last_observation is None) and agent_done):\n            continue\n        policy_id: PolicyID = episode.policy_for(agent_id)\n        prep_obs: EnvObsType = _get_or_raise(preprocessors, policy_id).transform(raw_obs)\n        if log_once('prep_obs'):\n            logger.info('Preprocessed obs: {}'.format(summarize(prep_obs)))\n        filtered_obs: EnvObsType = _get_or_raise(obs_filters, policy_id)(prep_obs)\n        if log_once('filtered_obs'):\n            logger.info('Filtered obs: {}'.format(summarize(filtered_obs)))\n        episode._set_last_observation(agent_id, filtered_obs)\n        episode._set_last_raw_obs(agent_id, raw_obs)\n        agent_infos = infos[env_id].get(agent_id, {})\n        episode._set_last_info(agent_id, agent_infos)\n        if (last_observation is None):\n            sample_collector.add_init_obs(episode, agent_id, env_id, policy_id, (episode.length - 1), filtered_obs)\n        else:\n            values_dict = {'t': (episode.length - 1), 'env_id': env_id, 'agent_index': episode._agent_index(agent_id), 'actions': episode.last_action_for(agent_id), 'rewards': rewards[env_id][agent_id], 'dones': (False if (no_done_at_end or (hit_horizon and soft_horizon)) else agent_done), 'new_obs': filtered_obs}\n            pol = policies[policy_id]\n            for (key, value) in episode.last_pi_info_for(agent_id).items():\n                if (key in pol.view_requirements):\n                    values_dict[key] = value\n            if ('infos' in pol.view_requirements):\n                values_dict['infos'] = agent_infos\n            sample_collector.add_action_reward_next_obs(episode.episode_id, agent_id, env_id, policy_id, agent_done, values_dict)\n        if (not agent_done):\n            item = PolicyEvalData(env_id, agent_id, filtered_obs, agent_infos, (None if (last_observation is None) else episode.rnn_state_for(agent_id)), (None if (last_observation is None) else episode.last_action_for(agent_id)), (rewards[env_id][agent_id] or 0.0))\n            to_eval[policy_id].append(item)\n    callbacks.on_episode_step(worker=worker, base_env=base_env, episode=episode, env_index=env_id)\n    if all_agents_done:\n        is_done = dones[env_id]['__all__']\n        check_dones = (is_done and (not no_done_at_end))\n        ma_sample_batch = sample_collector.postprocess_episode(episode, is_done=(is_done or (hit_horizon and (not soft_horizon))), check_dones=check_dones, build=(not multiple_episodes_in_batch))\n        if ma_sample_batch:\n            outputs.append(ma_sample_batch)\n        for p in policies.values():\n            if (getattr(p, 'exploration', None) is not None):\n                p.exploration.on_episode_end(policy=p, environment=base_env, episode=episode, tf_sess=getattr(p, '_sess', None))\n        callbacks.on_episode_end(worker=worker, base_env=base_env, policies=policies, episode=episode, env_index=env_id)\n        if (hit_horizon and soft_horizon):\n            episode.soft_reset()\n            resetted_obs: Dict[(AgentID, EnvObsType)] = all_agents_obs\n        else:\n            del active_episodes[env_id]\n            resetted_obs: Dict[(AgentID, EnvObsType)] = base_env.try_reset(env_id)\n        if (resetted_obs is None):\n            if (horizon != float('inf')):\n                raise ValueError('Setting episode horizon requires reset() support from the environment.')\n        elif (resetted_obs != ASYNC_RESET_RETURN):\n            new_episode: MultiAgentEpisode = active_episodes[env_id]\n            if observation_fn:\n                resetted_obs: Dict[(AgentID, EnvObsType)] = observation_fn(agent_obs=resetted_obs, worker=worker, base_env=base_env, policies=policies, episode=new_episode)\n            for (agent_id, raw_obs) in resetted_obs.items():\n                policy_id: PolicyID = new_episode.policy_for(agent_id)\n                prep_obs: EnvObsType = _get_or_raise(preprocessors, policy_id).transform(raw_obs)\n                filtered_obs: EnvObsType = _get_or_raise(obs_filters, policy_id)(prep_obs)\n                new_episode._set_last_observation(agent_id, filtered_obs)\n                sample_collector.add_init_obs(new_episode, agent_id, env_id, policy_id, (new_episode.length - 1), filtered_obs)\n                item = PolicyEvalData(env_id, agent_id, filtered_obs, (episode.last_info_for(agent_id) or {}), episode.rnn_state_for(agent_id), None, 0.0)\n                to_eval[policy_id].append(item)\nif multiple_episodes_in_batch:\n    sample_batches = sample_collector.try_build_truncated_episode_multi_agent_batch()\n    if sample_batches:\n        outputs.extend(sample_batches)\nreturn (active_envs, to_eval, outputs)\n"}
{"label_name":"predict","label":4,"method_name":"predict_logistic","method":"\nlabels = (results > 0.5).astype(int).T\nreturn labels\n"}
{"label_name":"predict","label":4,"method_name":"predict","method":"\ninputs = Variable(inputs, requires_grad=False)\nlogits = model.forward(inputs)\nreturn logits.data.numpy().argmax(axis=1)\n"}
{"label_name":"train","label":0,"method_name":"get_wmt_enfr_train_set","method":"\n\"Download the WMT en-fr training corpus to directory unless it's there.\"\ntrain_path = os.path.join(directory, 'giga-fren.release2.fixed')\nif (not (tf.gfile.Exists((train_path + '.fr')) and tf.gfile.Exists((train_path + '.en')))):\n    corpus_file = maybe_download(directory, 'training-giga-fren.tar', _WMT_ENFR_TRAIN_URL)\n    print(('Extracting tar file %s' % corpus_file))\n    with tarfile.open(corpus_file, 'r') as corpus_tar:\n        corpus_tar.extractall(directory)\n    gunzip_file((train_path + '.fr.gz'), (train_path + '.fr'))\n    gunzip_file((train_path + '.en.gz'), (train_path + '.en'))\nreturn train_path\n"}
{"label_name":"process","label":2,"method_name":"process_frame","method":"\nframe = frame[34:(34 + 180), :160]\nframe = scipy.misc.imresize(frame, [84, 84])\nframe = frame.mean(2)\nframe *= (1.0 \/ 255.0)\nframe = np.reshape(frame, [np.prod(frame.shape)])\nreturn frame\n"}
{"label_name":"predict","label":4,"method_name":"model_predicted_label_config","method":"\nreturn ModelPredictedLabelConfig(label=INFERENCE_ATTRIBUTE, probability=PROBABILITY_ATTRIBUTE, probability_threshold=PROBABILITY_THRESHOLD_ATTRIBUTE)\n"}
{"label_name":"predict","label":4,"method_name":"collect_incorrect_entity_predictions","method":"\nerrors = []\noffset = 0\nfor entity_result in entity_results:\n    for i in range(offset, (offset + len(entity_result.tokens))):\n        if (merged_targets[i] != merged_predictions[i]):\n            errors.append({'text': entity_result.message, 'entities': entity_result.entity_targets, 'predicted_entities': entity_result.entity_predictions, 'entity_status': 'error'})\n            break\n    offset += len(entity_result.tokens)\nreturn errors\n"}
{"label_name":"train","label":0,"method_name":"read_train_data","method":"\nfile_path = '.\/data\/tags_token_results'\nwith codecs.open(file_path, 'r', 'utf-8') as f:\n    data = [line.strip().split() for line in f.read().split('\\n')]\nwith open((file_path + '_tag')) as f:\n    return (data[:(- 1)], list(map(int, f.read().split('\\n')[:(- 1)])))\n"}
{"label_name":"predict","label":4,"method_name":"_df_predict_proba","method":"\nreturn __df_clf_method_impl(self, clf, y, X_test, 'predict_proba')\n"}
{"label_name":"save","label":1,"method_name":"save_metrics","method":"\n'\\n    Saves the computed metrics in a json file.\\n    :param model_statistics_dict: Dict, the computed metrics to save.\\n    :param path_model_folder: Path to the folder containing the model to use.\\n    :param statistics_filename: Name of the file where we will store the computed statistics.\\n    :return:\\n    '\npath_model_folder = convert_path(path_model_folder)\npath_statistics_file = (path_model_folder \/ statistics_filename)\nif path_statistics_file.exists():\n    with open(path_statistics_file) as f:\n        original_stats_dict = json.load(f)\n        path_statistics_file.unlink()\nelse:\n    original_stats_dict = {}\nrec_update(original_stats_dict, model_statistics_dict)\nwith open(path_statistics_file, 'w') as f:\n    json.dump(original_stats_dict, f, indent=2)\n"}
{"label_name":"save","label":1,"method_name":"query_save_csv_path","method":"\npath = input(\"Output CSV name (default is '{}'): \".format(default))\nif (not path):\n    path = default\nif (not path.endswith('.csv')):\n    path += '.csv'\nreturn os.path.realpath(path)\n"}
{"label_name":"process","label":2,"method_name":"preprocess_omniglot","method":"\n'Download and prepare raw Omniglot data.\\n\\n  Downloads the data from GitHub if it does not exist.\\n  Then load the images, augment with rotations if desired.\\n  Resize the images and write them to a pickle file.\\n  '\nmaybe_download_data()\ndirectory = TRAIN_DIR\nwrite_file = (DATA_FILE_FORMAT % 'train')\nnum_labels = write_datafiles(directory, write_file, resize=True, rotate=True, new_width=IMAGE_NEW_SIZE, new_height=IMAGE_NEW_SIZE)\ndirectory = TEST_DIR\nwrite_file = (DATA_FILE_FORMAT % 'test')\nwrite_datafiles(directory, write_file, resize=True, rotate=False, new_width=IMAGE_NEW_SIZE, new_height=IMAGE_NEW_SIZE)\n"}
{"label_name":"predict","label":4,"method_name":"link_prediction_classifier","method":"\nlr_clf = LogisticRegressionCV(Cs=10, cv=10, scoring='roc_auc', max_iter=max_iter)\nreturn Pipeline(steps=[('sc', StandardScaler()), ('clf', lr_clf)])\n"}
{"label_name":"predict","label":4,"method_name":"predict","method":"\nlabels = []\nfor result in results:\n    labels.append(np.argmax(result))\nreturn labels\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\nfor epoch_id in range(EPOCH_NUM):\n    for (batch_id, (image, label)) in enumerate(loader()):\n        out = layer(image)\n        loss = loss_fn(out, label)\n        loss.backward()\n        opt.step()\n        opt.clear_grad()\n        print('Epoch {} batch {}: loss = {}'.format(epoch_id, batch_id, np.mean(loss.numpy())))\nreturn loss\n"}
{"label_name":"predict","label":4,"method_name":"model_predicted_label_config","method":"\nreturn ModelPredictedLabelConfig(probability_threshold=BIAS_PROBABILITY_THRESHOLD)\n"}
{"label_name":"save","label":1,"method_name":"savez_compressed","method":"\n'\\n    Save several arrays into a single file in compressed ``.npz`` format.\\n\\n    If keyword arguments are given, then filenames are taken from the keywords.\\n    If arguments are passed in with no keywords, then stored file names are\\n    arr_0, arr_1, etc.\\n\\n    Parameters\\n    ----------\\n    file : str or file\\n        Either the file name (string) or an open file (file-like object)\\n        where the data will be saved. If file is a string or a Path, the\\n        ``.npz`` extension will be appended to the file name if it is not\\n        already there.\\n    args : Arguments, optional\\n        Arrays to save to the file. Since it is not possible for Python to\\n        know the names of the arrays outside `savez`, the arrays will be saved\\n        with names \"arr_0\", \"arr_1\", and so on. These arguments can be any\\n        expression.\\n    kwds : Keyword arguments, optional\\n        Arrays to save to the file. Arrays will be saved in the file with the\\n        keyword names.\\n\\n    Returns\\n    -------\\n    None\\n\\n    See Also\\n    --------\\n    numpy.save : Save a single array to a binary file in NumPy format.\\n    numpy.savetxt : Save an array to a file as plain text.\\n    numpy.savez : Save several arrays into an uncompressed ``.npz`` file format\\n    numpy.load : Load the files created by savez_compressed.\\n\\n    Notes\\n    -----\\n    The ``.npz`` file format is a zipped archive of files named after the\\n    variables they contain.  The archive is compressed with\\n    ``zipfile.ZIP_DEFLATED`` and each file in the archive contains one variable\\n    in ``.npy`` format. For a description of the ``.npy`` format, see\\n    `numpy.lib.format` or the NumPy Enhancement Proposal\\n    http:\/\/docs.scipy.org\/doc\/numpy\/neps\/npy-format.html\\n\\n    When opening the saved ``.npz`` file with `load` a `NpzFile` object is\\n    returned. This is a dictionary-like object which can be queried for\\n    its list of arrays (with the ``.files`` attribute), and for the arrays\\n    themselves.\\n\\n    Examples\\n    --------\\n    >>> test_array = np.random.rand(3, 2)\\n    >>> test_vector = np.random.rand(4)\\n    >>> np.savez_compressed(\\'\/tmp\/123\\', a=test_array, b=test_vector)\\n    >>> loaded = np.load(\\'\/tmp\/123.npz\\')\\n    >>> print(np.array_equal(test_array, loaded[\\'a\\']))\\n    True\\n    >>> print(np.array_equal(test_vector, loaded[\\'b\\']))\\n    True\\n\\n    '\n_savez(file, args, kwds, True)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\npipeline_manager.start_experiment()\npipeline_manager.train(pipeline_name, dev_mode)\npipeline_manager.finish_experiment()\n"}
{"label_name":"process","label":2,"method_name":"process_solver_str","method":"\nsolver = utils.Foo(seed=0, learning_rate_decay=None, clip_gradient_norm=None, max_steps=None, initial_learning_rate=None, momentum=None, steps_per_decay=None, logdir=None, sync=False, adjust_lr_sync=True, wt_decay=0.0001, data_loss_wt=None, reg_loss_wt=None, freeze_conv=True, num_workers=1, task=0, ps_tasks=0, master='local', typ=None, momentum2=None, adam_eps=None)\nsolver_vars = get_solver_vars(solver_str)\nsolver.data_loss_wt = float(solver_vars.dlw[3:].replace('x', '.'))\nsolver.adam_eps = float(solver_vars.adam_eps[4:].replace('x', '.').replace('n', '-'))\nsolver.initial_learning_rate = float(solver_vars.init_lr[2:].replace('x', '.').replace('n', '-'))\nsolver.reg_loss_wt = float(solver_vars.rlw[3:].replace('x', '.'))\nsolver.isd_k = float(solver_vars.isdk[4:].replace('x', '.'))\nlong = solver_vars.long\nif (long == 'long'):\n    solver.steps_per_decay = 40000\n    solver.max_steps = 120000\nelif (long == 'long2'):\n    solver.steps_per_decay = 80000\n    solver.max_steps = 120000\nelif ((long == 'nolong') or (long == 'nol')):\n    solver.steps_per_decay = 20000\n    solver.max_steps = 60000\nelse:\n    logging.fatal('solver_vars.long should be long, long2, nolong or nol.')\n    assert False\nclip = solver_vars.clip\nif ((clip == 'noclip') or (clip == 'nocl')):\n    solver.clip_gradient_norm = 0\nelif (clip[:4] == 'clip'):\n    solver.clip_gradient_norm = float(clip[4:].replace('x', '.'))\nelse:\n    logging.fatal('Unknown solver_vars.clip: %s', clip)\n    assert False\ntyp = solver_vars.typ\nif (typ == 'adam'):\n    solver.typ = 'adam'\n    solver.momentum = 0.9\n    solver.momentum2 = 0.999\n    solver.learning_rate_decay = 1.0\nelif (typ == 'adam2'):\n    solver.typ = 'adam'\n    solver.momentum = 0.9\n    solver.momentum2 = 0.999\n    solver.learning_rate_decay = 0.1\nelif (typ == 'sgd'):\n    solver.typ = 'sgd'\n    solver.momentum = 0.99\n    solver.momentum2 = None\n    solver.learning_rate_decay = 0.1\nelse:\n    logging.fatal('Unknown solver_vars.typ: %s', typ)\n    assert False\nlogging.error('solver: %s', solver)\nreturn solver\n"}
{"label_name":"train","label":0,"method_name":"prepare_pretrain_text_dataset","method":"\n'Create dataset based on the raw text files'\nif (not isinstance(filenames, (list, tuple))):\n    filenames = [filenames]\nif cached_file_path:\n    suffix = re.split('\\\\.|\/', filenames[0])[(- 2)]\n    output_file = os.path.join(cached_file_path, '{}-pretrain-record.npz'.format(suffix))\nelse:\n    output_file = None\nnp_features = get_all_features((filenames, output_file, tokenizer, max_seq_length, short_seq_prob))\nreturn ArrayDataset(*np_features)\n"}
{"label_name":"predict","label":4,"method_name":"predicted_label","method":"\n\"\\n    Generates the predicted label by comparing the tensor prediction to `label_dict`.\\n\\n    Parameters:\\n        - prediction (np.ndarray)\\n            - The prediction as represented by the model's tensor output.\\n        - label_dict (dict, str --> np.ndarray)\\n            - See the parent function for details.\\n    Returns:\\n        - A string; the predicted label.\\n    \"\nclasses = list(label_dict.keys())\nlabels = list(label_dict.values())\ndifferences = []\nfor label in labels:\n    l2_difference = np.sqrt(np.sum(((label - prediction_tensor) ** 2)))\n    differences.append(l2_difference)\nindex_of_smallest_difference = differences.index(min(differences))\nreturn classes[index_of_smallest_difference]\n"}
{"label_name":"save","label":1,"method_name":"saveData","method":"\nif verbose:\n    print('saving data')\ndataFile = open(path, 'wb')\npickle.dump(data, dataFile)\n"}
{"label_name":"train","label":0,"method_name":"train2","method":"\nnp.random.seed(x)\nw.add_scalar('few_write_per_func\/1', np.random.randn())\ntime.sleep((0.05 * np.random.randint(0, 10)))\nw.add_scalar('few_write_per_func\/2', np.random.randn())\n"}
{"label_name":"save","label":1,"method_name":"save_weights","method":"\nroot = '\/'.join([weights_root, experiment_name])\nif (not os.path.exists(root)):\n    os.mkdir(root)\nif name_suffix:\n    print(('Saving weights to %s\/%s...' % (root, name_suffix)))\nelse:\n    print(('Saving weights to %s...' % root))\ntorch.save(G.state_dict(), ('%s\/%s.pth' % (root, join_strings('_', ['G', name_suffix]))))\ntorch.save(G.optim.state_dict(), ('%s\/%s.pth' % (root, join_strings('_', ['G_optim', name_suffix]))))\ntorch.save(D.state_dict(), ('%s\/%s.pth' % (root, join_strings('_', ['D', name_suffix]))))\ntorch.save(D.optim.state_dict(), ('%s\/%s.pth' % (root, join_strings('_', ['D_optim', name_suffix]))))\ntorch.save(state_dict, ('%s\/%s.pth' % (root, join_strings('_', ['state_dict', name_suffix]))))\nif (G_ema is not None):\n    torch.save(G_ema.state_dict(), ('%s\/%s.pth' % (root, join_strings('_', ['G_ema', name_suffix]))))\n"}
{"label_name":"predict","label":4,"method_name":"link_prediction_classifier","method":"\nlr_clf = LogisticRegressionCV(Cs=10, cv=10, scoring='roc_auc', max_iter=max_iter)\nreturn Pipeline(steps=[('sc', StandardScaler()), ('clf', lr_clf)])\n"}
{"label_name":"predict","label":4,"method_name":"catboost_fit_predict","method":"\nif ('gpu_ram_part' in catboost_params):\n    gpu_ram_part = catboost_params.pop('gpu_ram_part')\nelse:\n    gpu_ram_part = None\ncbc = CatBoostClassifier(**catboost_params)\nif (gpu_ram_part is not None):\n    cbc.set_params(gpu_ram_part=gpu_ram_part)\ncbc.fit(train_documents, train_targets)\nreturn cbc.predict(test_documents, prediction_type)\n"}
{"label_name":"train","label":0,"method_name":"read_train","method":"\n(X, Y) = ([], [])\nwith open(filename, 'r', encoding='big5') as f:\n    count = 0\n    for line in list(csv.reader(f))[1:]:\n        Y.append(float(line[0]))\n        X.append([float(x) for x in line[1].split()])\n        count += 1\n        print(('\\rX_train: ' + repr(count)), end='', flush=True)\n    print('', flush=True)\nreturn (np.array(X), np_utils.to_categorical(Y, CATEGORY))\n"}
{"label_name":"predict","label":4,"method_name":"link_prediction_classifier","method":"\nlr_clf = LogisticRegressionCV(Cs=10, cv=10, scoring='roc_auc', max_iter=max_iter)\nreturn Pipeline(steps=[('sc', StandardScaler()), ('clf', lr_clf)])\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\nglobal cur_batch_win\nnet.train()\n(loss_list, batch_list) = ([], [])\nfor (i, (images, labels)) in enumerate(data_train_loader):\n    optimizer.zero_grad()\n    output = net(images)\n    loss = criterion(output, labels)\n    loss_list.append(loss.detach().cpu().item())\n    batch_list.append((i + 1))\n    if ((i % 10) == 0):\n        print(('Train - Epoch %d, Batch: %d, Loss: %f' % (epoch, i, loss.detach().cpu().item())))\n    if viz.check_connection():\n        cur_batch_win = viz.line(torch.Tensor(loss_list), torch.Tensor(batch_list), win=cur_batch_win, name='current_batch_loss', update=(None if (cur_batch_win is None) else 'replace'), opts=cur_batch_win_opts)\n    loss.backward()\n    optimizer.step()\n"}
{"label_name":"train","label":0,"method_name":"train_maxent_classifier_with_gis","method":"\n'\\n    Train a new ``ConditionalExponentialClassifier``, using the given\\n    training samples, using the Generalized Iterative Scaling\\n    algorithm.  This ``ConditionalExponentialClassifier`` will encode\\n    the model that maximizes entropy from all the models that are\\n    empirically consistent with ``train_toks``.\\n\\n    :see: ``train_maxent_classifier()`` for parameter descriptions.\\n    '\ncutoffs.setdefault('max_iter', 100)\ncutoffchecker = CutoffChecker(cutoffs)\nif (encoding is None):\n    encoding = GISEncoding.train(train_toks, labels=labels)\nif (not hasattr(encoding, 'C')):\n    raise TypeError('The GIS algorithm requires an encoding that defines C (e.g., GISEncoding).')\nCinv = (1.0 \/ encoding.C)\nempirical_fcount = calculate_empirical_fcount(train_toks, encoding)\nunattested = set(numpy.nonzero((empirical_fcount == 0))[0])\nweights = numpy.zeros(len(empirical_fcount), 'd')\nfor fid in unattested:\n    weights[fid] = numpy.NINF\nclassifier = ConditionalExponentialClassifier(encoding, weights)\nlog_empirical_fcount = numpy.log2(empirical_fcount)\ndel empirical_fcount\nif (trace > 0):\n    print(('  ==> Training (%d iterations)' % cutoffs['max_iter']))\nif (trace > 2):\n    print()\n    print('      Iteration    Log Likelihood    Accuracy')\n    print('      ---------------------------------------')\ntry:\n    while True:\n        if (trace > 2):\n            ll = (cutoffchecker.ll or log_likelihood(classifier, train_toks))\n            acc = (cutoffchecker.acc or accuracy(classifier, train_toks))\n            iternum = cutoffchecker.iter\n            print(('     %9d    %14.5f    %9.3f' % (iternum, ll, acc)))\n        estimated_fcount = calculate_estimated_fcount(classifier, train_toks, encoding)\n        for fid in unattested:\n            estimated_fcount[fid] += 1\n        log_estimated_fcount = numpy.log2(estimated_fcount)\n        del estimated_fcount\n        weights = classifier.weights()\n        weights += ((log_empirical_fcount - log_estimated_fcount) * Cinv)\n        classifier.set_weights(weights)\n        if cutoffchecker.check(classifier, train_toks):\n            break\nexcept KeyboardInterrupt:\n    print('      Training stopped: keyboard interrupt')\nexcept:\n    raise\nif (trace > 2):\n    ll = log_likelihood(classifier, train_toks)\n    acc = accuracy(classifier, train_toks)\n    print(('         Final    %14.5f    %9.3f' % (ll, acc)))\nreturn classifier\n"}
{"label_name":"save","label":1,"method_name":"save_model","method":"\nmodel.save(FLAGS.model_file)\n"}
{"label_name":"process","label":2,"method_name":"process_samples","method":"\nfilter_keys = [SampleBatch.CUR_OBS, SampleBatch.ACTIONS, SampleBatch.NEXT_OBS]\nfiltered = {}\nfor key in filter_keys:\n    filtered[key] = samples[key]\nreturn SampleBatch(filtered)\n"}
{"label_name":"predict","label":4,"method_name":"_get_majority_prediction","method":"\nfrequency = {}\nfor i in range(0, len(predictions)):\n    prediction = predictions[i]\n    if (prediction in frequency):\n        frequency[prediction] += 1\n    else:\n        frequency[prediction] = 1\nmax_frequency = 0\nmax_frequency_prediction = None\nfor prediction in frequency:\n    if (frequency[prediction] > max_frequency):\n        max_frequency = frequency[prediction]\n        max_frequency_prediction = prediction\nreturn max_frequency_prediction\n"}
{"label_name":"predict","label":4,"method_name":"normalize_predictions","method":"\n'\\n    We take the assumption that the data set contains less than 50 % of outlier.\\n    Given that the classifier, gives the label 0 and 1 for the same data\\n    randomly. We make sure that an inlier is described as a 0.\\n\\n    :param predictions:  A 1 D numpy array with the predictions of our detector\\n    :return: predictions: A 1 D numpy array with the predictions of our detector, cleaned\\n    '\nif (np.sum(predictions) > ((len(predictions) \/ 2) - 1)):\n    predictions = (1 - predictions)\nreturn predictions\n"}
{"label_name":"predict","label":4,"method_name":"check_new_observation_predict_parts","method":"\nnew_observation_ = deepcopy(new_observation)\nerror_dim_val = 'Wrong new_observation dimension'\nif isinstance(new_observation_, pd.Series):\n    new_observation_ = new_observation_.to_frame().T\n    new_observation_.columns = explainer.data.columns\nelif isinstance(new_observation_, np.ndarray):\n    if (new_observation_.ndim == 1):\n        new_observation_ = new_observation_.reshape((1, (- 1)))\n    elif (new_observation_.ndim > 2):\n        raise ValueError(error_dim_val)\n    elif (new_observation.shape[0] != 1):\n        raise ValueError(error_dim_val)\n    new_observation_ = pd.DataFrame(new_observation_)\n    new_observation_.columns = explainer.data.columns\nelif isinstance(new_observation_, list):\n    new_observation_ = pd.DataFrame(new_observation_).T\n    new_observation_.columns = explainer.data.columns\nelif isinstance(new_observation_, pd.DataFrame):\n    if (new_observation.shape[0] != 1):\n        raise ValueError(error_dim_val)\n    new_observation_.columns = explainer.data.columns\nelse:\n    raise TypeError('new_observation must be a numpy.ndarray or pandas.Series or pandas.DataFrame')\nif pd.api.types.is_bool_dtype(new_observation_.index):\n    raise ValueError('new_observation index is of boolean type')\nreturn new_observation_\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\nnet.train()\nn_batches = len(loader)\nfor (inputs, targets) in loader:\n    inputs = Variable(inputs)\n    targets = Variable(targets)\n    output = net(inputs)\n    loss = loss_func(output, targets)\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n"}
{"label_name":"save","label":1,"method_name":"save_error_message_file","method":"\nprint(error_message)\nwith open(filename, 'w') as textfile:\n    textfile.write(error_message)\n"}
{"label_name":"save","label":1,"method_name":"save_midis","method":"\npadded_bars = np.concatenate((np.zeros((bars.shape[0], bars.shape[1], 24, bars.shape[3])), bars, np.zeros((bars.shape[0], bars.shape[1], 20, bars.shape[3]))), axis=2)\npause = np.zeros((bars.shape[0], 96, 128, bars.shape[3]))\nimages_with_pause = padded_bars\nimages_with_pause = images_with_pause.reshape((- 1), 96, padded_bars.shape[2], padded_bars.shape[3])\nimages_with_pause_list = []\nfor ch_idx in range(padded_bars.shape[3]):\n    images_with_pause_list.append(images_with_pause[:, :, :, ch_idx].reshape(images_with_pause.shape[0], images_with_pause.shape[1], images_with_pause.shape[2]))\nwrite_midi.write_piano_rolls_to_midi(images_with_pause_list, program_nums=[33, 0, 25, 49, 0], is_drum=[False, True, False, False, False], filename=file_path, tempo=80.0)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\nencoder1_optimizer.zero_grad()\nencoder2_optimizer.zero_grad()\nencoder3_optimizer.zero_grad()\nencoder4_optimizer.zero_grad()\nencoder5_optimizer.zero_grad()\nencoder6_optimizer.zero_grad()\nencoder7_optimizer.zero_grad()\nencoder8_optimizer.zero_grad()\nencoder9_optimizer.zero_grad()\nencoder10_optimizer.zero_grad()\nencoder11_optimizer.zero_grad()\nencoder12_optimizer.zero_grad()\ncnn_optimizer.zero_grad()\nloss = 0\nlead_output = Variable(torch.Tensor().type('torch.cuda.FloatTensor'))\nlead_hidden = Variable(torch.Tensor().type('torch.cuda.FloatTensor'))\ninput_part = input_variable[0].clone()\ninput_lead = input_part.view(N, T, D).transpose(0, 1).clone()\n(encoder_outputs, encoder_hidden, attn_weights) = encoder12(input_lead)\nlead_output = Variable(torch.cat((lead_output.data, encoder_outputs.data), 1))\ninput_part = input_variable[1].clone()\ninput_lead = input_part.view(N, T, D).transpose(0, 1).clone()\n(encoder_outputs, encoder_hidden, attn_weights) = encoder1(input_lead)\nlead_output = Variable(torch.cat((lead_output.data, encoder_outputs.data), 1))\ninput_part = input_variable[2].clone()\ninput_lead = input_part.view(N, T, D).transpose(0, 1).clone()\n(encoder_outputs, encoder_hidden, attn_weights) = encoder2(input_lead)\nlead_output = Variable(torch.cat((lead_output.data, encoder_outputs.data), 1))\ninput_part = input_variable[3].clone()\ninput_lead = input_part.view(N, T, D).transpose(0, 1).clone()\n(encoder_outputs, encoder_hidden, attn_weights) = encoder3(input_lead)\nlead_output = Variable(torch.cat((lead_output.data, encoder_outputs.data), 1))\ninput_part = input_variable[4].clone()\ninput_lead = input_part.view(N, T, D).transpose(0, 1).clone()\n(encoder_outputs, encoder_hidden, attn_weights) = encoder4(input_lead)\nlead_output = Variable(torch.cat((lead_output.data, encoder_outputs.data), 1))\ninput_part = input_variable[5].clone()\ninput_lead = input_part.view(N, T, D).transpose(0, 1).clone()\n(encoder_outputs, encoder_hidden, attn_weights) = encoder5(input_lead)\nlead_output = Variable(torch.cat((lead_output.data, encoder_outputs.data), 1))\ninput_part = input_variable[6].clone()\ninput_lead = input_part.view(N, T, D).transpose(0, 1).clone()\n(encoder_outputs, encoder_hidden, attn_weights) = encoder6(input_lead)\nlead_output = Variable(torch.cat((lead_output.data, encoder_outputs.data), 1))\ninput_part = input_variable[7].clone()\ninput_lead = input_part.view(N, T, D).transpose(0, 1).clone()\n(encoder_outputs, encoder_hidden, attn_weights) = encoder7(input_lead)\nlead_output = Variable(torch.cat((lead_output.data, encoder_outputs.data), 1))\ninput_part = input_variable[8].clone()\ninput_lead = input_part.view(N, T, D).transpose(0, 1).clone()\n(encoder_outputs, encoder_hidden, attn_weights) = encoder8(input_lead)\nlead_output = Variable(torch.cat((lead_output.data, encoder_outputs.data), 1))\ninput_part = input_variable[9].clone()\ninput_lead = input_part.view(N, T, D).transpose(0, 1).clone()\n(encoder_outputs, encoder_hidden, attn_weights) = encoder9(input_lead)\nlead_output = Variable(torch.cat((lead_output.data, encoder_outputs.data), 1))\ninput_part = input_variable[10].clone()\ninput_lead = input_part.view(N, T, D).transpose(0, 1).clone()\n(encoder_outputs, encoder_hidden, attn_weights) = encoder10(input_lead)\nlead_output = Variable(torch.cat((lead_output.data, encoder_outputs.data), 1))\ninput_part = input_variable[11].clone()\ninput_lead = input_part.view(N, T, D).transpose(0, 1).clone()\n(encoder_outputs, encoder_hidden, attn_weights) = encoder11(input_lead)\nlead_output = Variable(torch.cat((lead_output.data, encoder_outputs.data), 1))\nlead_output = lead_output.view(N, L, O)\n(model_output, model_hidden) = cnn(lead_hidden, lead_output)\nloss = criterion(model_output, target_variable)\nloss.backward()\nencoder1_optimizer.step()\nencoder2_optimizer.step()\nencoder3_optimizer.step()\nencoder4_optimizer.step()\nencoder5_optimizer.step()\nencoder6_optimizer.step()\nencoder7_optimizer.step()\nencoder8_optimizer.step()\nencoder9_optimizer.step()\nencoder10_optimizer.step()\nencoder11_optimizer.step()\nencoder12_optimizer.step()\ncnn_optimizer.step()\nreturn loss.data[0]\n"}
{"label_name":"process","label":2,"method_name":"process_arch_str","method":"\nargs.arch = get_default_baseline_args()\narch_vars = get_arch_vars(arch_str)\nargs.navtask.task_params.outputs.rel_goal_loc = True\nargs.navtask.task_params.input_type = 'vision'\nargs.navtask.task_params.outputs.images = True\nif (args.navtask.camera_param.modalities[0] == 'rgb'):\n    args.solver.pretrained_path = rgb_resnet_v2_50_path\nelif (args.navtask.camera_param.modalities[0] == 'depth'):\n    args.solver.pretrained_path = d_resnet_v2_50_path\nelse:\n    logging.fatal('Neither of rgb or d')\nif (arch_vars.dropout == 'DO'):\n    args.arch.fc_dropout = 0.5\nargs.tfcode = 'B'\nexp_ver = arch_vars.ver\nif (exp_ver == 'v0'):\n    args.arch.combine_type = 'multiply'\n    args.arch.pred_neurons = [256, 256]\n    args.arch.goal_embed_neurons = [64, 8]\n    args.arch.img_embed_neurons = [1024, 512, (256 * 8)]\nelif (exp_ver == 'v1'):\n    args.arch.combine_type = 'add'\n    args.arch.pred_neurons = [256, 256]\n    args.arch.goal_embed_neurons = [64, 256]\n    args.arch.img_embed_neurons = [1024, 512, 256]\nelif (exp_ver == 'v2'):\n    args.arch.combine_type = 'multiply'\n    args.arch.goal_embed_neurons = [64, 8]\n    args.arch.img_embed_neurons = [1024, 512, (256 * 8)]\n    args.arch.lstm_output = True\n    args.arch.lstm_output_dim = int(arch_vars.lstm_dim[4:])\n    args.arch.pred_neurons = [256]\nelif (exp_ver == 'v0blind'):\n    args.arch.combine_type = 'goalonly'\n    args.arch.goal_embed_neurons = [64, 256]\n    args.arch.img_embed_neurons = [2]\n    args.arch.lstm_output = True\n    args.arch.lstm_output_dim = 256\n    args.arch.pred_neurons = [256]\nelse:\n    logging.fatal('exp_ver: %s undefined', exp_ver)\n    assert False\nlogging.error('%s', args)\nreturn args\n"}
{"label_name":"predict","label":4,"method_name":"action_predictions_remove","method":"\n'\\n    try to remove the prediction result with the label used as argument\\n    returns \\n        - (False, message) if it there is no directory or the removal failed \\n        - (True, OK) removal succeeded\\n    '\npredictions_path = pathlib.Path(utils.predictions_repository_path())\nlabel_path = predictions_path.joinpath(label)\nif (not os.path.isdir(label_path)):\n    return (False, f'directory {label_path} not found')\ntry:\n    shutil.rmtree(label_path)\nexcept Exception as e:\n    return (False, f'failed to remove {label_path} with error: {e}')\nreturn (True, 'OK')\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\nprogram_translator.enable(to_static)\nplace = (fluid.CUDAPlace(0) if fluid.is_compiled_with_cuda() else fluid.CPUPlace())\nwith fluid.dygraph.guard(place):\n    np.random.seed(SEED)\n    paddle.seed(SEED)\n    paddle.framework.random._manual_program_seed(SEED)\n    train_reader = fake_data_reader(args.class_num, args.vocab_size, args.batch_size, args.padding_size)\n    train_loader = fluid.io.DataLoader.from_generator(capacity=24)\n    train_loader.set_sample_list_generator(train_reader)\n    if (args.model_type == 'cnn_net'):\n        model = CNN(args.vocab_size, args.batch_size, args.padding_size)\n    elif (args.model_type == 'bow_net'):\n        model = BOW(args.vocab_size, args.batch_size, args.padding_size)\n    elif (args.model_type == 'gru_net'):\n        model = GRU(args.vocab_size, args.batch_size, args.padding_size)\n    elif (args.model_type == 'bigru_net'):\n        model = BiGRU(args.vocab_size, args.batch_size, args.padding_size)\n    sgd_optimizer = fluid.optimizer.Adagrad(learning_rate=args.lr, parameter_list=model.parameters())\n    loss_data = []\n    for eop in range(args.epoch):\n        time_begin = time.time()\n        for (batch_id, data) in enumerate(train_loader()):\n            (word_ids, labels, seq_lens) = data\n            doc = to_variable(word_ids.numpy().reshape((- 1))).astype('int64')\n            label = labels.astype('int64')\n            model.train()\n            (avg_cost, prediction, acc) = model(doc, label)\n            loss_data.append(avg_cost.numpy()[0])\n            avg_cost.backward()\n            sgd_optimizer.minimize(avg_cost)\n            model.clear_gradients()\n            if ((batch_id % args.log_step) == 0):\n                time_end = time.time()\n                used_time = (time_end - time_begin)\n                print(('step: %d, ave loss: %f, speed: %f steps\/s' % (batch_id, avg_cost.numpy()[0], (args.log_step \/ used_time))))\n                time_begin = time.time()\n            if (batch_id == args.train_step):\n                break\n            batch_id += 1\nreturn loss_data\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\nmodel = model_mod.Model(hparams=hparams_mod.make_hparams(flags.hparams), session_params=flags)\nmodel.train('train', flags.num_steps)\n"}
{"label_name":"train","label":0,"method_name":"train_deep_model","method":"\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.utils import to_categorical\nfrom models.deep_model import fasttext_model, cnn_model, rnn_model, han_model\nlogger.info('train deep model, model_type:{}, data_path:{}'.format(model_type, data_path))\n(data_content, data_lbl) = data_reader(data_path, col_sep)\nword_lst = []\nfor i in data_content:\n    word_lst.extend(i.split())\nword_vocab = build_vocab(word_lst, min_count=min_count, sort=True, lower=True)\nwrite_vocab(word_vocab, word_vocab_path)\nlabel_vocab = build_vocab(data_lbl)\nwrite_vocab(label_vocab, label_vocab_path)\nlabel_id = load_vocab(label_vocab_path)\nlogger.info(label_id)\ndata_label = [label_id[i] for i in data_lbl]\nnum_classes = len(set(data_label))\nlogger.info(('num_classes:%s' % num_classes))\ndata_label = to_categorical(data_label, num_classes=num_classes)\nprint('Shape of Label Tensor:', data_label.shape)\nif (model_type == 'han'):\n    logger.warn('Hierarchical Attention Network model feature_type must be: doc_vectorize')\n    feature_type = 'doc_vectorize'\nelse:\n    logger.warn('feature_type: vectorize')\n    feature_type = 'vectorize'\nfeature = Feature(data=data_content, feature_type=feature_type, word_vocab=word_vocab, max_len=max_len)\ndata_feature = feature.get_feature()\n(X_train, X_val, y_train, y_val) = train_test_split(data_feature, data_label, test_size=0.1, random_state=0)\nif (model_type == 'fasttext'):\n    model = fasttext_model(max_len=max_len, vocabulary_size=len(word_vocab), embedding_dim=embedding_dim, num_classes=num_classes)\nelif (model_type == 'cnn'):\n    model = cnn_model(max_len, vocabulary_size=len(word_vocab), embedding_dim=embedding_dim, num_filters=num_filters, filter_sizes=filter_sizes, num_classses=num_classes, dropout=dropout)\nelif (model_type == 'rnn'):\n    model = rnn_model(max_len=max_len, vocabulary_size=len(word_vocab), embedding_dim=embedding_dim, hidden_dim=hidden_dim, num_classes=num_classes)\nelse:\n    model = han_model(max_len=max_len, vocabulary_size=len(word_vocab), embedding_dim=embedding_dim, hidden_dim=hidden_dim, num_classes=num_classes)\ncp = ModelCheckpoint(model_save_path, monitor='val_acc', verbose=1, save_best_only=True)\nhistory = model.fit(X_train, y_train, batch_size=batch_size, epochs=nb_epoch, validation_data=(X_val, y_val), callbacks=[cp])\nlogger.info(('save model:%s' % model_save_path))\nplt_history(history, model_name=model_type)\n"}
{"label_name":"save","label":1,"method_name":"save","method":"\nfrom numpy import savetxt\nsavetxt(fileName, ar, precision=8)\n"}
{"label_name":"process","label":2,"method_name":"preprocess_lists","method":"\n\"\\n    Preprocess each list reducing between x(=2 by defect) the number of samples \\n    :param lists: Amount of lists to be reduced\\n    :param index_to_eliminate: represent which index module must be deleted to the graph. For example, if \\n    list len is 60 and 'index_to_eliminate' is 2, then all element with a pair index will be eliminated, remaining 30.\\n    :return: Process_lists\\n    \"\nprocessed_lists = []\nfor list_to_process in lists:\n    if (list_to_process and (len(list_to_process) > index_to_eliminate)):\n        process_list = [i for i in list_to_process if ((list_to_process.index(i) % index_to_eliminate) == 0)]\n        processed_lists.append(process_list)\n    else:\n        processed_lists.append(list_to_process)\nreturn processed_lists\n"}
{"label_name":"process","label":2,"method_name":"_process_image_files_batch","method":"\n'Processes and saves list of images as TFRecord in 1 thread.\\n\\n  Args:\\n    coder: instance of ImageCoder to provide TensorFlow image coding utils.\\n    thread_index: integer, unique batch to run index is within [0, len(ranges)).\\n    ranges: list of pairs of integers specifying ranges of each batches to\\n      analyze in parallel.\\n    name: string, unique identifier specifying the data set\\n    filenames: list of strings; each string is a path to an image file\\n    synsets: list of strings; each string is a unique WordNet ID\\n    labels: list of integer; each integer identifies the ground truth\\n    humans: list of strings; each string is a human-readable label\\n    bboxes: list of bounding boxes for each image. Note that each entry in this\\n      list might contain from 0+ entries corresponding to the number of bounding\\n      box annotations for the image.\\n    num_shards: integer number of shards for this data set.\\n  '\nnum_threads = len(ranges)\nassert (not (num_shards % num_threads))\nnum_shards_per_batch = int((num_shards \/ num_threads))\nshard_ranges = np.linspace(ranges[thread_index][0], ranges[thread_index][1], (num_shards_per_batch + 1)).astype(int)\nnum_files_in_thread = (ranges[thread_index][1] - ranges[thread_index][0])\ncounter = 0\nfor s in range(num_shards_per_batch):\n    shard = ((thread_index * num_shards_per_batch) + s)\n    output_filename = ('%s-%.5d-of-%.5d' % (name, shard, num_shards))\n    output_file = os.path.join(FLAGS.output_directory, output_filename)\n    writer = tf.python_io.TFRecordWriter(output_file)\n    shard_counter = 0\n    files_in_shard = np.arange(shard_ranges[s], shard_ranges[(s + 1)], dtype=int)\n    for i in files_in_shard:\n        filename = filenames[i]\n        label = labels[i]\n        synset = synsets[i]\n        human = humans[i]\n        bbox = bboxes[i]\n        (image_buffer, height, width) = _process_image(filename, coder)\n        example = _convert_to_example(filename, image_buffer, label, synset, human, bbox, height, width)\n        writer.write(example.SerializeToString())\n        shard_counter += 1\n        counter += 1\n        if (not (counter % 1000)):\n            print(('%s [thread %d]: Processed %d of %d images in thread batch.' % (datetime.now(), thread_index, counter, num_files_in_thread)))\n            sys.stdout.flush()\n    writer.close()\n    print(('%s [thread %d]: Wrote %d images to %s' % (datetime.now(), thread_index, shard_counter, output_file)))\n    sys.stdout.flush()\n    shard_counter = 0\nprint(('%s [thread %d]: Wrote %d images to %d shards.' % (datetime.now(), thread_index, counter, num_files_in_thread)))\nsys.stdout.flush()\n"}
{"label_name":"train","label":0,"method_name":"load_train_data","method":"\next = filename.split('.')[(- 1)]\nif (ext == 'csv'):\n    return read_smiles_csv(filename)\nif (ext == 'smi'):\n    return read_smi(filename)\nelse:\n    raise ValueError('data is not smi or csv!')\nreturn\n"}
{"label_name":"train","label":0,"method_name":"train_bpe_model","method":"\nspm_items = params['spm_items']\nsentencepiece_corpus = os.path.join(tmp_dir, 'sentencepiece_corpus.txt')\nnb_samples = 0\nwith io.open(sentencepiece_corpus, 'w', encoding='utf-8') as wrt:\n    df = pd.read_csv(os.path.join(tmp_dir, 'interpreter_samples.tsv'), delimiter='\\t')\n    for (i, r) in df.iterrows():\n        left_data = r.context\n        right_data = r.output\n        wrt.write('{}\\n'.format(left_data))\n        wrt.write('{}\\n'.format(right_data))\n        nb_samples += 1\nspm_name = 'nn_seq2seq_interpreter.sentencepiece'\nprint('Start training bpe model \"{}\" on {} samples'.format(spm_name, nb_samples))\nspm.SentencePieceTrainer.Train('--input={} --model_prefix={} --vocab_size={} --shuffle_input_sentence=true --character_coverage=1.0 --model_type=unigram'.format(sentencepiece_corpus, spm_name, spm_items))\nos.rename((spm_name + '.vocab'), os.path.join(tmp_dir, (spm_name + '.vocab')))\nos.rename((spm_name + '.model'), os.path.join(tmp_dir, (spm_name + '.model')))\nprint('bpe model \"{}\" ready'.format(spm_name))\nreturn spm_name\n"}
{"label_name":"train","label":0,"method_name":"_train_parser","method":"\nfix_random_seed(1)\nparser.add_label('left')\nparser.initialize((lambda : [_parser_example(parser)]))\nsgd = Adam(0.001)\nfor i in range(5):\n    losses = {}\n    doc = Doc(parser.vocab, words=['a', 'b', 'c', 'd'])\n    gold = {'heads': [1, 1, 3, 3], 'deps': ['left', 'ROOT', 'left', 'ROOT']}\n    example = Example.from_dict(doc, gold)\n    parser.update([example], sgd=sgd, losses=losses)\nreturn parser\n"}
{"label_name":"train","label":0,"method_name":"trained_simple_project","method":"\npath = tmpdir_factory.mktemp('simple')\ncreate_simple_project(path)\nos.environ['LOG_LEVEL'] = 'ERROR'\ncheck_call([shutil.which('rasa'), 'train'], cwd=path.strpath)\nreturn path.strpath\n"}
{"label_name":"process","label":2,"method_name":"preprocess","method":"\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\nx \/= 255.0\nx -= 0.5\nx *= 2.0\nreturn x\n"}
{"label_name":"train","label":0,"method_name":"get_training","method":"\nglobal _mndata\nif (_mndata is None):\n    _mndata = MNIST('.\/mnist_data')\n(images, labels) = _mndata.load_training()\ntraining_data = []\nfor (i, j) in zip(images, labels):\n    i = (np.array(i, dtype='f') \/ 255)\n    im = np.array(i)[np.newaxis].T\n    lb = np.zeros(10)\n    lb[j] = 1\n    lb = lb[np.newaxis].T\n    training_data.append((im, lb))\nreturn training_data\n"}
{"label_name":"process","label":2,"method_name":"_postprocess_conv2d_output","method":"\n'Transpose and cast the output from conv2d if needed.\\n\\n  Arguments:\\n      x: A tensor.\\n      data_format: string, one of \"channels_last\", \"channels_first\".\\n\\n  Returns:\\n      A tensor.\\n  '\nif (data_format == 'channels_first'):\n    x = array_ops.transpose(x, (0, 3, 1, 2))\nif (floatx() == 'float64'):\n    x = math_ops.cast(x, 'float64')\nreturn x\n"}
{"label_name":"save","label":1,"method_name":"save","method":"\nprint('This is save')\ntf_x = tf.placeholder(tf.float32, x.shape)\ntf_y = tf.placeholder(tf.float32, y.shape)\nl = tf.layers.dense(tf_x, 10, tf.nn.relu)\no = tf.layers.dense(l, 1)\nloss = tf.losses.mean_squared_error(tf_y, o)\ntrain_op = tf.train.GradientDescentOptimizer(learning_rate=0.5).minimize(loss)\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\nsaver = tf.train.Saver()\nfor step in range(100):\n    sess.run(train_op, {tf_x: x, tf_y: y})\nsaver.save(sess, '.\/params', write_meta_graph=False)\n(pred, l) = sess.run([o, loss], {tf_x: x, tf_y: y})\nplt.figure(1, figsize=(10, 5))\nplt.subplot(121)\nplt.scatter(x, y)\nplt.plot(x, pred, 'r-', lw=5)\nplt.text((- 1), 1.2, ('Save Loss=%.4f' % l), fontdict={'size': 15, 'color': 'red'})\n"}
{"label_name":"process","label":2,"method_name":"process_dollars","method":"\ndollars_to_math(source)\n"}
{"label_name":"save","label":1,"method_name":"save","method":"\nmodel.symbol.save(os.path.join(model_dir, 'model-symbol.json'))\nmodel.save_params(os.path.join(model_dir, 'model-0000.params'))\nsignature = [{'name': data_desc.name, 'shape': [dim for dim in data_desc.shape]} for data_desc in model.data_shapes]\nwith open(os.path.join(model_dir, 'model-shapes.json'), 'w') as f:\n    json.dump(signature, f)\n"}
{"label_name":"save","label":1,"method_name":"imsave","method":"\n\"\\n    Save an array as an image.\\n\\n    This function is only available if Python Imaging Library (PIL) is installed.\\n\\n    .. warning::\\n\\n        This function uses `bytescale` under the hood to rescale images to use\\n        the full (0, 255) range if ``mode`` is one of ``None, 'L', 'P', 'l'``.\\n        It will also cast data for 2-D images to ``uint32`` for ``mode=None``\\n        (which is the default).\\n\\n    Parameters\\n    ----------\\n    name : str or file object\\n        Output file name or file object.\\n    arr : ndarray, MxN or MxNx3 or MxNx4\\n        Array containing image values.  If the shape is ``MxN``, the array\\n        represents a grey-level image.  Shape ``MxNx3`` stores the red, green\\n        and blue bands along the last dimension.  An alpha layer may be\\n        included, specified as the last colour band of an ``MxNx4`` array.\\n    format : str\\n        Image format. If omitted, the format to use is determined from the\\n        file name extension. If a file object was used instead of a file name,\\n        this parameter should always be used.\\n\\n    Examples\\n    --------\\n    Construct an array of gradient intensity values and save to file:\\n\\n    >>> from scipy.misc import imsave\\n    >>> x = np.zeros((255, 255))\\n    >>> x = np.zeros((255, 255), dtype=np.uint8)\\n    >>> x[:] = np.arange(255)\\n    >>> imsave('gradient.png', x)\\n\\n    Construct an array with three colour bands (R, G, B) and store to file:\\n\\n    >>> rgb = np.zeros((255, 255, 3), dtype=np.uint8)\\n    >>> rgb[..., 0] = np.arange(255)\\n    >>> rgb[..., 1] = 55\\n    >>> rgb[..., 2] = 1 - np.arange(255)\\n    >>> imsave('rgb_gradient.png', rgb)\\n\\n    \"\nim = toimage(arr, channel_axis=2)\nif (format is None):\n    im.save(name)\nelse:\n    im.save(name, format)\nreturn\n"}
{"label_name":"predict","label":4,"method_name":"show_prediction_labels_on_image","method":"\n'\\n    Shows the face recognition results visually.\\n\\n    :param frame: frame to show the predictions on\\n    :param predictions: results of the predict function\\n    :return opencv suited image to be fitting with cv2.imshow fucntion:\\n    '\npil_image = Image.fromarray(frame)\ndraw = ImageDraw.Draw(pil_image)\nfor (name, (top, right, bottom, left)) in predictions:\n    top *= 2\n    right *= 2\n    bottom *= 2\n    left *= 2\n    draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255))\n    name = name.encode('UTF-8')\n    (text_width, text_height) = draw.textsize(name)\n    draw.rectangle(((left, ((bottom - text_height) - 10)), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255))\n    draw.text(((left + 6), ((bottom - text_height) - 5)), name, fill=(255, 255, 255, 255))\ndel draw\nopencvimage = np.array(pil_image)\nreturn opencvimage\n"}
{"label_name":"train","label":0,"method_name":"plot_2d_spiketrains","method":"\nfig = plt.figure(figsize=(40, 5))\nax = fig.add_subplot(1, 1, 1)\npickleFilenames = listdir(pathToPickles)\nallPickles = [join(pathToPickles, f) for f in pickleFilenames if isfile(join(pathToPickles, f))]\nallSpiketrains = [pickle.load(open(pickleFile, 'r')) for pickleFile in allPickles]\nfor (featureMapIdx, spiketrain) in enumerate(allSpiketrains):\n    populationName = pickleFilenames[featureMapIdx]\n    x = []\n    y = []\n    for (i, neuron) in enumerate(spiketrain):\n        for spike in neuron:\n            x.append(spike)\n            y.append(i)\n    if populationName.startswith('corner'):\n        markersize = 10\n        alpha = 1\n    else:\n        markersize = 1\n        alpha = 0.1\n    ax.scatter(x, y, marker=marker_list[featureMapIdx], c=color_list[featureMapIdx], label=populationName, linewidths=markersize, alpha=alpha)\nax.legend()\n"}
{"label_name":"train","label":0,"method_name":"_run_train","method":"\n'Train.'\nsummary_writer = tf.summary.FileWriter(event_dir, graph=tf.get_default_graph(), flush_secs=60)\nmodel_saver = tf.train.Saver(((((tf.global_variables((ppo_hparams.policy_network + '\/.*')) + tf.global_variables((('training\/' + ppo_hparams.policy_network) + '\/.*'))) + tf.global_variables('global_step')) + tf.global_variables('losses_avg.*')) + tf.global_variables('train_stats.*')))\nglobal_step = tf.train.get_or_create_global_step()\nwith tf.control_dependencies([tf.assign_add(global_step, 1)]):\n    train_summary_op = tf.identity(train_summary_op)\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    for initializer in initializers:\n        initializer(sess)\n    trainer_lib.restore_checkpoint(model_dir, model_saver, sess)\n    num_target_iterations = restarter.target_local_step\n    num_completed_iterations = (num_target_iterations - restarter.steps_to_go)\n    with restarter.training_loop():\n        for epoch_index in range(num_completed_iterations, num_target_iterations):\n            summary = sess.run(train_summary_op)\n            if summary_writer:\n                summary_writer.add_summary(summary, epoch_index)\n            if (ppo_hparams.eval_every_epochs and ((epoch_index % ppo_hparams.eval_every_epochs) == 0)):\n                eval_summary = sess.run(eval_summary_op)\n                if summary_writer:\n                    summary_writer.add_summary(eval_summary, epoch_index)\n                if report_fn:\n                    summary_proto = tf.Summary()\n                    summary_proto.ParseFromString(eval_summary)\n                    for elem in summary_proto.value:\n                        if ('mean_score' in elem.tag):\n                            report_fn(elem.simple_value, epoch_index)\n                            break\n            if (model_saver and ppo_hparams.save_models_every_epochs and (((epoch_index % ppo_hparams.save_models_every_epochs) == 0) or ((epoch_index + 1) == num_target_iterations))):\n                ckpt_name = 'model.ckpt-{}'.format(tf.train.global_step(sess, global_step))\n                epoch_dir = os.path.join(model_dir, 'epoch_{}'.format(epoch))\n                tf.gfile.MakeDirs(epoch_dir)\n                for ckpt_dir in (model_dir, epoch_dir):\n                    model_saver.save(sess, os.path.join(ckpt_dir, ckpt_name))\n                if model_save_fn:\n                    model_save_fn(model_dir)\n"}
{"label_name":"process","label":2,"method_name":"preprocessed_input_to_img_resnet","method":"\nx = x.copy()\nx[:, :, 0] += 103.939\nx[:, :, 1] += 116.779\nx[:, :, 2] += 123.68\nimg = x.copy()\nimg[:, :, 0] = x[:, :, 2]\nimg[:, :, 1] = x[:, :, 1]\nimg[:, :, 2] = x[:, :, 0]\nreturn (img \/ 255.0)\n"}
{"label_name":"process","label":2,"method_name":"preprocessEv","method":"\nlambda_ti = np.zeros_like(tev, dtype=float)\nsurvival = 0\nfor i in range(len(tev)):\n    lambda_ti[i] = np.sum(np.exp(((- w) * (tev[i] - tev[0:i]))))\n    survival += ((1.0 \/ w) * (1.0 - np.exp(((- w) * (T - tev[i])))))\nreturn (lambda_ti, survival)\n"}
{"label_name":"train","label":0,"method_name":"pretraining_train_step","method":"\ny_true = x\nwith tf.GradientTape() as tape:\n    (y_pred, _) = autoencoder_model(x)\n    pretraining_loss = pretraining_mse_loss(y_pred, y_true)\ngradients = tape.gradient(pretraining_loss, vars(autoencoder_model).values())\npretraining_optimizer.apply_gradients(zip(gradients, vars(autoencoder_model).values()))\n"}
{"label_name":"train","label":0,"method_name":"train_basic_multilabel_classifier","method":"\ncolumn_descriptions = {'airline_sentiment': 'output', 'airline': 'categorical', 'text': 'ignore', 'tweet_location': 'categorical', 'user_timezone': 'categorical', 'tweet_created': 'date'}\nml_predictor = Predictor(type_of_estimator='classifier', column_descriptions=column_descriptions)\nml_predictor.train(df_twitter_train)\nreturn ml_predictor\n"}
{"label_name":"process","label":2,"method_name":"process_repertoires","method":"\nnum_samples = 20\nnum_snips_per_sample = 300\nsnip_size = 6\nnum_features = (snip_size * vector_representation.length)\nxs = np.zeros((num_samples, num_snips_per_sample, num_features), dtype=np.float32)\ncs = np.zeros((num_samples, num_snips_per_sample), dtype=np.float32)\nys = np.zeros(num_samples, dtype=np.float32)\naa_list = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\nfor i in range(num_samples):\n    N = ((np.random.randint(round((num_snips_per_sample \/ 2))) + round((num_snips_per_sample \/ 2))) - 1)\n    for j in range(N):\n        snip = ''\n        for k in range(snip_size):\n            index = np.random.randint(len(aa_list))\n            snip += aa_list[index]\n        xs[i, j, :] = vector_representation.features(snip)\n        cs[(i, j)] = 1.0\nneedle = 'ARKIHG'\nfor i in range(round((num_samples \/ 2))):\n    ys[i] = 1.0\n    xs[i, 0, :] = vector_representation.features(needle)\nreturn (xs, cs, ys)\n"}
{"label_name":"predict","label":4,"method_name":"predict","method":"\n'\\n\\n    :param w:\\n    :param b:\\n    :param X:\\n    :return:\\n    '\nm = X.shape[1]\ny_pred = np.zeros(shape=(1, m))\nw = w.reshape(X.shape[0], 1)\nA = sigmoid((np.dot(w.T, X) + b))\nfor i in range(A.shape[1]):\n    y_pred[(0, i)] = (1 if (A[(0, i)] > 0.5) else 0)\nassert (y_pred.shape == (1, m))\nreturn y_pred\n"}
{"label_name":"process","label":2,"method_name":"preprocessing_all_method","method":"\nif opt_abbreviation_replacement:\n    tweet = abbreviation_replacement(tweet)\nif opt_emphaszie_punctuation:\n    tweet = emphaszie_punctuation(tweet)\nif opt_clean_hastag:\n    tweet = ((tweet + ' ') + clean_hashtag(tweet))\nif opt_emoji_translation:\n    tweet = emoji_translation(tweet)\nif opt_remvoe_number:\n    tweet = remove_number(tweet)\nif opt_emphasize_pos_and_neg_words:\n    tweet = emphasize_pos_and_neg_words(tweet)\nif opt_spelling_correction:\n    tweet = spelling_correction(tweet)\nif opt_remove_stopwords:\n    tweet = remove_stopwords(tweet)\nif opt_stemming_sentence:\n    tweet = stemming_sentence(text)\nif opt_lemmatize_sentence:\n    tweet = lemmatize_sentence(tweet)\nreturn tweet.strip().lower()\n"}
{"label_name":"train","label":0,"method_name":"_create_train_job","method":"\nreturn {'image_uri': _get_full_gpu_image_uri(version, base_framework_version), 'input_mode': 'File', 'input_config': [{'ChannelName': 'training', 'DataSource': {'S3DataSource': {'S3DataDistributionType': 'FullyReplicated', 'S3DataType': 'S3Prefix'}}}], 'role': ROLE, 'job_name': JOB_NAME, 'output_config': {'S3OutputPath': 's3:\/\/{}\/'.format(BUCKET_NAME)}, 'resource_config': {'InstanceType': GPU, 'InstanceCount': 1, 'VolumeSizeInGB': 30}, 'hyperparameters': {'sagemaker_program': json.dumps('dummy_script.py'), 'sagemaker_container_log_level': str(logging.INFO), 'sagemaker_job_name': json.dumps(JOB_NAME), 'sagemaker_submit_directory': json.dumps('s3:\/\/{}\/{}\/source\/sourcedir.tar.gz'.format(BUCKET_NAME, JOB_NAME)), 'sagemaker_region': '\"us-east-1\"'}, 'stop_condition': {'MaxRuntimeInSeconds': ((24 * 60) * 60)}, 'tags': None, 'vpc_config': None, 'metric_definitions': None, 'environment': None, 'experiment_config': None, 'debugger_hook_config': {'CollectionConfigurations': [], 'S3OutputPath': 's3:\/\/{}\/'.format(BUCKET_NAME)}, 'profiler_rule_configs': [{'RuleConfigurationName': 'ProfilerReport-1510006209', 'RuleEvaluatorImage': '503895931360.dkr.ecr.us-east-1.amazonaws.com\/sagemaker-debugger-rules:latest', 'RuleParameters': {'rule_to_invoke': 'ProfilerReport'}}], 'profiler_config': {'S3OutputPath': 's3:\/\/{}\/'.format(BUCKET_NAME)}}\n"}
{"label_name":"train","label":0,"method_name":"subsubtrain_name_pattern","method":"\nreturn _get_value_from_file('subsubtrain_name_pattern')\n"}
{"label_name":"predict","label":4,"method_name":"model_value_predictions","method":"\nreturn {SampleBatch.VF_PREDS: model.value_function()}\n"}
{"label_name":"train","label":0,"method_name":"list_pretrained_mobilebert","method":"\nreturn sorted(list(PRETRAINED_URL.keys()))\n"}
{"label_name":"train","label":0,"method_name":"add_training_data_args","method":"\nparams.add_argument(C.TRAINING_ARG_SOURCE, '-s', required=required, type=regular_file(), help='Source side of parallel training data.')\nparams.add_argument('--source-factors', '-sf', required=False, nargs='+', type=regular_file(), default=[], help='File(s) containing additional token-parallel source-side factors. Default: %(default)s.')\nparams.add_argument('--source-factors-use-source-vocab', required=False, nargs='+', type=bool_str(), default=[], help='List of bools signaling whether to use the source vocabulary for the source factors. If empty (default) each factor has its own vocabulary.')\nparams.add_argument('--target-factors', '-tf', required=False, nargs='+', type=regular_file(), default=[], help='File(s) containing additional token-parallel target-side factors. Default: %(default)s.')\nparams.add_argument('--target-factors-use-target-vocab', required=False, nargs='+', type=bool_str(), default=[], help='List of bools signaling whether to use the target vocabulary for the target factors. If empty (default) each factor has its own vocabulary.')\nparams.add_argument(C.TRAINING_ARG_TARGET, '-t', required=required, type=regular_file(), help='Target side of parallel training data.')\n"}
{"label_name":"predict","label":4,"method_name":"fit_and_predict","method":"\nnet = make_net(train, labtrans)\nmodel = model_class(net, tt.optim.AdamWR(lr, cycle_eta_multiplier=0.8), duration_index=labtrans.cuts)\nlog = model.fit(*train, 256, 128, verbose=False, val_data=val, callbacks=[tt.cb.EarlyStoppingCycle()])\nsurv = model.interpolate(n_itp).predict_surv_df(test[0])\nreturn (surv, model)\n"}
{"label_name":"process","label":2,"method_name":"convert_preprocessing_scaler","method":"\nparams = operator.raw_operator.scaler\ncolor_space = operator.inputs[0].type.color_space\nif (color_space == 'Gray8'):\n    bias = [params.grayBias]\nelif (color_space == 'Rgb8'):\n    bias = [params.redBias, params.greenBias, params.blueBias]\nelif (color_space == 'Bgr8'):\n    bias = [params.blueBias, params.greenBias, params.redBias]\nelse:\n    raise ValueError('Unknown color space for tensor {}'.format(operator.inputs[0].full_name))\nif (container.target_opset < 9):\n    attrs = {'name': operator.full_name, 'scale': params.channelScale}\n    attrs['bias'] = bias\n    container.add_node('ImageScaler', [operator.inputs[0].full_name], [operator.outputs[0].full_name], **attrs)\nelse:\n    aName = scope.get_unique_variable_name((operator.full_name + '_scale'))\n    container.add_initializer(aName, onnx_proto.TensorProto.FLOAT, [1], [params.channelScale])\n    bName = scope.get_unique_variable_name((operator.full_name + '_bias'))\n    container.add_initializer(bName, onnx_proto.TensorProto.FLOAT, [len(bias), 1, 1], bias)\n    zName = scope.get_unique_variable_name((operator.full_name + '_scaled'))\n    apply_mul(scope, [operator.input_full_names[0], aName], zName, container)\n    apply_add(scope, [bName, zName], operator.output_full_names[0], container)\n"}
{"label_name":"process","label":2,"method_name":"color_preprocessing","method":"\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train[:, :, :, 0] = ((x_train[:, :, :, 0] - np.mean(x_train[:, :, :, 0])) \/ np.std(x_train[:, :, :, 0]))\nx_train[:, :, :, 1] = ((x_train[:, :, :, 1] - np.mean(x_train[:, :, :, 1])) \/ np.std(x_train[:, :, :, 1]))\nx_train[:, :, :, 2] = ((x_train[:, :, :, 2] - np.mean(x_train[:, :, :, 2])) \/ np.std(x_train[:, :, :, 2]))\nx_test[:, :, :, 0] = ((x_test[:, :, :, 0] - np.mean(x_test[:, :, :, 0])) \/ np.std(x_test[:, :, :, 0]))\nx_test[:, :, :, 1] = ((x_test[:, :, :, 1] - np.mean(x_test[:, :, :, 1])) \/ np.std(x_test[:, :, :, 1]))\nx_test[:, :, :, 2] = ((x_test[:, :, :, 2] - np.mean(x_test[:, :, :, 2])) \/ np.std(x_test[:, :, :, 2]))\nreturn (x_train, x_test)\n"}
{"label_name":"train","label":0,"method_name":"train","method":"\nwith tf.name_scope('data'):\n    x = tfc.placeholder(tf.float32, [None, 28, 28, 1])\n    tfc.summary.image('data', x)\nwith tfc.variable_scope('variational'):\n    (q_mu, q_sigma) = inference_network(x=x, latent_dim=FLAGS.latent_dim, hidden_size=FLAGS.hidden_size)\n    q_z = tfp.distributions.Normal(loc=q_mu, scale=q_sigma)\n    assert (q_z.reparameterization_type == tfp.distributions.FULLY_REPARAMETERIZED)\nwith tfc.variable_scope('model'):\n    p_x_given_z_logits = generative_network(z=q_z.sample(), hidden_size=FLAGS.hidden_size)\n    p_x_given_z = tfp.distributions.Bernoulli(logits=p_x_given_z_logits)\n    posterior_predictive_samples = p_x_given_z.sample()\n    tfc.summary.image('posterior_predictive', tf.cast(posterior_predictive_samples, tf.float32))\nwith tfc.variable_scope('model', reuse=True):\n    p_z = tfp.distributions.Normal(loc=np.zeros(FLAGS.latent_dim, dtype=np.float32), scale=np.ones(FLAGS.latent_dim, dtype=np.float32))\n    p_z_sample = p_z.sample(FLAGS.n_samples)\n    p_x_given_z_logits = generative_network(z=p_z_sample, hidden_size=FLAGS.hidden_size)\n    prior_predictive = tfp.distributions.Bernoulli(logits=p_x_given_z_logits)\n    prior_predictive_samples = prior_predictive.sample()\n    tfc.summary.image('prior_predictive', tf.cast(prior_predictive_samples, tf.float32))\nwith tfc.variable_scope('model', reuse=True):\n    z_input = tf.placeholder(tf.float32, [None, FLAGS.latent_dim])\n    p_x_given_z_logits = generative_network(z=z_input, hidden_size=FLAGS.hidden_size)\n    prior_predictive_inp = tfp.distributions.Bernoulli(logits=p_x_given_z_logits)\n    prior_predictive_inp_sample = prior_predictive_inp.sample()\nkl = tf.reduce_sum(tfp.distributions.kl_divergence(q_z, p_z), 1)\nexpected_log_likelihood = tf.reduce_sum(p_x_given_z.log_prob(x), [1, 2, 3])\nelbo = tf.reduce_sum((expected_log_likelihood - kl), 0)\noptimizer = tfc.train.RMSPropOptimizer(learning_rate=0.001)\ntrain_op = optimizer.minimize((- elbo))\nsummary_op = tfc.summary.merge_all()\ninit_op = tfc.global_variables_initializer()\nsess = tfc.InteractiveSession()\nsess.run(init_op)\nmnist_data = tfds.load(name='binary_mnist', split='train', shuffle_files=False)\ndataset = mnist_data.repeat().shuffle(buffer_size=1024).batch(FLAGS.batch_size)\nprint(('Saving TensorBoard summaries and images to: %s' % FLAGS.logdir))\ntrain_writer = tfc.summary.FileWriter(FLAGS.logdir, sess.graph)\nt0 = time.time()\nfor (i, batch) in enumerate(tfds.as_numpy(dataset)):\n    np_x = batch['image']\n    sess.run(train_op, {x: np_x})\n    if ((i % FLAGS.print_every) == 0):\n        (np_elbo, summary_str) = sess.run([elbo, summary_op], {x: np_x})\n        train_writer.add_summary(summary_str, i)\n        print('Iteration: {0:d} ELBO: {1:.3f} s\/iter: {2:.3e}'.format(i, (np_elbo \/ FLAGS.batch_size), ((time.time() - t0) \/ FLAGS.print_every)))\n        (np_posterior_samples, np_prior_samples) = sess.run([posterior_predictive_samples, prior_predictive_samples], {x: np_x})\n        for k in range(FLAGS.n_samples):\n            f_name = os.path.join(FLAGS.logdir, ('iter_%d_posterior_predictive_%d_data.jpg' % (i, k)))\n            imwrite(f_name, np_x[k, :, :, 0].astype(np.uint8))\n            f_name = os.path.join(FLAGS.logdir, ('iter_%d_posterior_predictive_%d_sample.jpg' % (i, k)))\n            imwrite(f_name, np_posterior_samples[k, :, :, 0].astype(np.uint8))\n            f_name = os.path.join(FLAGS.logdir, ('iter_%d_prior_predictive_%d.jpg' % (i, k)))\n            imwrite(f_name, np_prior_samples[k, :, :, 0].astype(np.uint8))\n        t0 = time.time()\n"}
{"label_name":"train","label":0,"method_name":"assign_pretrained_word_embedding","method":"\nprint('using pre-trained word emebedding start ...')\nword2vec_model = KeyedVectors.load(word2vec_model_path)\nword_embedding_2dlist = ([[]] * vocab_size)\nword_embedding_2dlist[(- 1)] = np.zeros(FLAGS.embed_size)\nbound = (np.sqrt(6.0) \/ np.sqrt(vocab_size))\ncount_exist = 0\ncount_not_exist = 0\nfor (i, word) in enumerate(list(vocab.keys())):\n    word = word.encode('utf8')\n    embedding = None\n    try:\n        embedding = word2vec_model[word]\n    except Exception as e:\n        embedding = None\n    if (embedding is not None):\n        word_embedding_2dlist[i] = embedding\n        count_exist = (count_exist + 1)\n    else:\n        word_embedding_2dlist[i] = np.random.uniform((- bound), bound, FLAGS.embed_size)\n        count_not_exist = (count_not_exist + 1)\nword_embedding_final = np.array(word_embedding_2dlist)\nword_embedding = tf.constant(word_embedding_final, dtype=tf.float32)\nt_assign_embedding = tf.assign(textCNN.Embedding, word_embedding)\nsess.run(t_assign_embedding)\nprint('word exists embedding: {}, word not exists embedding: {}'.format(count_exist, count_not_exist))\nprint('using pre-trained word emebedding end ...')\n"}
{"label_name":"train","label":0,"method_name":"train_model","method":"\nfrom rasa.constants import DEFAULT_CONFIG_PATH, DEFAULT_DATA_PATH, DEFAULT_DOMAIN_PATH, DEFAULT_MODELS_PATH\nimport rasa.train\noutput = os.path.join(project, DEFAULT_MODELS_PATH, filename)\ndomain = os.path.join(project, DEFAULT_DOMAIN_PATH)\nconfig = os.path.join(project, DEFAULT_CONFIG_PATH)\ntraining_files = os.path.join(project, DEFAULT_DATA_PATH)\nrasa.train(domain, config, training_files, output)\nreturn output\n"}
{"label_name":"predict","label":4,"method_name":"format_predictions","method":"\npredictions_map = dict()\nfor i in range(len(genres)):\n    predictions_map[genres[i]] = predictions[0][i]\nsorted_predictions = sorted(predictions_map.items(), key=operator.itemgetter(1), reverse=True)\npredictions_str = []\nfor (genre, probability) in sorted_predictions:\n    if (genre in movie.genres):\n        is_present = ''\n    else:\n        is_present = '[!]'\n    predictions_str.append((((genre + is_present) + ': ') + my_format.format(probability)))\nspaces = repeat_to_length(' ', (align - len(str(movie))))\nif (crop_results is not None):\n    return ((str(movie) + spaces) + str(predictions_str[:crop_results]))\nelse:\n    return ((str(movie) + spaces) + str(predictions_str))\n"}
{"label_name":"process","label":2,"method_name":"process_pos_annotations_patient","method":"\ndf_node = pandas.read_csv('resources\/luna16_annotations\/annotations.csv')\ndst_dir = (settings.LUNA16_EXTRACTED_IMAGE_DIR + '_labels\/')\nif (not os.path.exists(dst_dir)):\n    os.mkdir(dst_dir)\ndst_dir = ((dst_dir + patient_id) + '\/')\nif (not os.path.exists(dst_dir)):\n    os.mkdir(dst_dir)\nitk_img = SimpleITK.ReadImage(src_path)\nimg_array = SimpleITK.GetArrayFromImage(itk_img)\nprint('Img array: ', img_array.shape)\ndf_patient = df_node[(df_node['seriesuid'] == patient_id)]\nprint('Annos: ', len(df_patient))\n(num_z, height, width) = img_array.shape\norigin = numpy.array(itk_img.GetOrigin())\nprint('Origin (x,y,z): ', origin)\nspacing = numpy.array(itk_img.GetSpacing())\nprint('Spacing (x,y,z): ', spacing)\nrescale = (spacing \/ settings.TARGET_VOXEL_MM)\nprint('Rescale: ', rescale)\ndirection = numpy.array(itk_img.GetDirection())\nprint('Direction: ', direction)\nflip_direction_x = False\nflip_direction_y = False\nif (round(direction[0]) == (- 1)):\n    origin[0] *= (- 1)\n    direction[0] = 1\n    flip_direction_x = True\n    print('Swappint x origin')\nif (round(direction[4]) == (- 1)):\n    origin[1] *= (- 1)\n    direction[4] = 1\n    flip_direction_y = True\n    print('Swappint y origin')\nprint('Direction: ', direction)\nassert (abs((sum(direction) - 3)) < 0.01)\npatient_imgs = helpers.load_patient_images(patient_id, settings.LUNA16_EXTRACTED_IMAGE_DIR, '*_i.png')\npos_annos = []\ndf_patient = df_node[(df_node['seriesuid'] == patient_id)]\nanno_index = 0\nfor (index, annotation) in df_patient.iterrows():\n    node_x = annotation['coordX']\n    if flip_direction_x:\n        node_x *= (- 1)\n    node_y = annotation['coordY']\n    if flip_direction_y:\n        node_y *= (- 1)\n    node_z = annotation['coordZ']\n    diam_mm = annotation['diameter_mm']\n    print('Node org (x,y,z,diam): ', (round(node_x, 2), round(node_y, 2), round(node_z, 2), round(diam_mm, 2)))\n    center_float = numpy.array([node_x, node_y, node_z])\n    center_int = numpy.rint(((center_float - origin) \/ spacing))\n    print('Node tra (x,y,z,diam): ', (center_int[0], center_int[1], center_int[2]))\n    center_float_rescaled = ((center_float - origin) \/ settings.TARGET_VOXEL_MM)\n    center_float_percent = (center_float_rescaled \/ patient_imgs.swapaxes(0, 2).shape)\n    print('Node sca (x,y,z,diam): ', (center_float_rescaled[0], center_float_rescaled[1], center_float_rescaled[2]))\n    diameter_pixels = (diam_mm \/ settings.TARGET_VOXEL_MM)\n    diameter_percent = (diameter_pixels \/ float(patient_imgs.shape[1]))\n    pos_annos.append([anno_index, round(center_float_percent[0], 4), round(center_float_percent[1], 4), round(center_float_percent[2], 4), round(diameter_percent, 4), 1])\n    anno_index += 1\ndf_annos = pandas.DataFrame(pos_annos, columns=['anno_index', 'coord_x', 'coord_y', 'coord_z', 'diameter', 'malscore'])\ndf_annos.to_csv((((settings.LUNA16_EXTRACTED_IMAGE_DIR + '_labels\/') + patient_id) + '_annos_pos.csv'), index=False)\nreturn [patient_id, spacing[0], spacing[1], spacing[2]]\n"}
{"label_name":"save","label":1,"method_name":"saveDatatoCSV","method":"\ngiven_file = os.path.basename(os.path.splitext(filename)[0])\noutput_filename = 'nounData_allText.csv'\nprint('\\n')\nfieldnames = ['FILENAME', 'TEXT_SIZE', 'ALL_NOUNS_IN_ALL_WORDS', 'PRONOUNS_IN_ALL_WORDS', 'PROPER_NOUNS_IN_ALL_WORDS', 'REGULAR_NOUNS_IN_ALL_NOUNS', 'PROPER_NOUNS_IN_ALL_NOUNS', 'GNE_IN_ALL_WORDS', 'GNE_IN_ALL_NOUNS']\nif (not os.path.isfile('plot_percent_data\/{0}'.format(output_filename))):\n    with open('plot_percent_data\/{0}'.format(output_filename), 'w') as noun_data:\n        writer = csv.DictWriter(noun_data, fieldnames=fieldnames)\n        writer.writeheader()\n        writer.writerow({'FILENAME': os.path.basename(os.path.splitext(filename)[0]), 'TEXT_SIZE': percentDict['text_size'], 'ALL_NOUNS_IN_ALL_WORDS': percentDict['all_noun_in_all_words'], 'PRONOUNS_IN_ALL_WORDS': percentDict['pronoun_in_all_words'], 'PROPER_NOUNS_IN_ALL_WORDS': percentDict['proper_noun_in_all_words'], 'REGULAR_NOUNS_IN_ALL_NOUNS': percentDict['regular_nouns_in_all_nouns'], 'PROPER_NOUNS_IN_ALL_NOUNS': percentDict['proper_noun_in_all_nouns'], 'GNE_IN_ALL_WORDS': 0.0, 'GNE_IN_ALL_NOUNS': 0.0})\n    print('\\n{0} created a new CSV NOUN DATA '.format(given_file.upper()))\nelse:\n    stored_results = []\n    with open('plot_percent_data\/{0}'.format(output_filename), 'r') as noun_data:\n        reader = csv.DictReader(noun_data)\n        for row in reader:\n            stored_results.append(row)\n    with open('plot_percent_data\/{0}'.format(output_filename), 'w') as noun_data:\n        new_file_to_append = os.path.basename(os.path.splitext(filename)[0])\n        to_append = True\n        writer = csv.DictWriter(noun_data, fieldnames=fieldnames)\n        writer.writeheader()\n        for data_row in stored_results:\n            if (data_row['FILENAME'] == new_file_to_append):\n                to_append = False\n                writer.writerow({'FILENAME': new_file_to_append, 'TEXT_SIZE': percentDict['text_size'], 'ALL_NOUNS_IN_ALL_WORDS': percentDict['all_noun_in_all_words'], 'PRONOUNS_IN_ALL_WORDS': percentDict['pronoun_in_all_words'], 'PROPER_NOUNS_IN_ALL_WORDS': percentDict['proper_noun_in_all_words'], 'REGULAR_NOUNS_IN_ALL_NOUNS': percentDict['regular_nouns_in_all_nouns'], 'PROPER_NOUNS_IN_ALL_NOUNS': percentDict['proper_noun_in_all_nouns'], 'GNE_IN_ALL_WORDS': 0.0, 'GNE_IN_ALL_NOUNS': 0.0})\n                print('{0} updated in an existing CSV log'.format(given_file.upper()))\n            else:\n                writer.writerow(data_row)\n        if to_append:\n            writer.writerow({'FILENAME': new_file_to_append, 'TEXT_SIZE': percentDict['text_size'], 'ALL_NOUNS_IN_ALL_WORDS': percentDict['all_noun_in_all_words'], 'PRONOUNS_IN_ALL_WORDS': percentDict['pronoun_in_all_words'], 'PROPER_NOUNS_IN_ALL_WORDS': percentDict['proper_noun_in_all_words'], 'REGULAR_NOUNS_IN_ALL_NOUNS': percentDict['regular_nouns_in_all_nouns'], 'PROPER_NOUNS_IN_ALL_NOUNS': percentDict['proper_noun_in_all_nouns'], 'GNE_IN_ALL_WORDS': 0.0, 'GNE_IN_ALL_NOUNS': 0.0})\n            print('{0} (new) appended to end of CSV NOUN DATA '.format(given_file.upper()))\ncsv_data_results = {}\nwith open('plot_percent_data\/{0}'.format(output_filename), 'r') as noun_data:\n    reader = csv.DictReader(noun_data)\n    for row in reader:\n        csv_data_results[row['FILENAME']] = row\nreturn csv_data_results\n"}
{"label_name":"forward","label":3,"method_name":"_apply_forwards_to_bindings","method":"\n'\\n    Replace any feature structure that has a forward pointer with\\n    the target of its forward pointer (to preserve reentrancy).\\n    '\nfor (var, value) in bindings.items():\n    while (id(value) in forward):\n        value = forward[id(value)]\n    bindings[var] = value\n"}
{"label_name":"process","label":2,"method_name":"preprocess_classification","method":"\n\"Preprocesses the image and labels for classification purposes.\\n\\n  Preprocessing includes shifting the images to be 0-centered between -1 and 1.\\n  This is not only a popular method of preprocessing (inception) but is also\\n  the mechanism used by DSNs.\\n\\n  Args:\\n    image: A `Tensor` of size [height, width, 3].\\n    labels: A dictionary of labels.\\n    is_training: Whether or not we're training the model.\\n\\n  Returns:\\n    The preprocessed image and labels.\\n  \"\nimage = tf.image.convert_image_dtype(image, tf.float32)\nimage -= 0.5\nimage *= 2\nreturn (image, labels)\n"}
{"label_name":"process","label":2,"method_name":"_preprocess_image","method":"\nreturn ((tf.to_float(image) \/ 255) - 0.5)\n"}
